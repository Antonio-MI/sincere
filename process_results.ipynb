{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"results/\"\n",
    "filename = \"batch_profiling_results_red_cuda_20240906_123954_heavymodels_fp16.csv\"\n",
    "df = pd.read_csv(path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_alias</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>processing_time</th>\n",
       "      <th>throughput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933442</td>\n",
       "      <td>1.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>2</td>\n",
       "      <td>0.949676</td>\n",
       "      <td>2.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>4</td>\n",
       "      <td>0.930215</td>\n",
       "      <td>4.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>8</td>\n",
       "      <td>1.225456</td>\n",
       "      <td>6.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>16</td>\n",
       "      <td>1.414788</td>\n",
       "      <td>11.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>32</td>\n",
       "      <td>2.214126</td>\n",
       "      <td>14.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>64</td>\n",
       "      <td>3.542751</td>\n",
       "      <td>18.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>128</td>\n",
       "      <td>6.785152</td>\n",
       "      <td>18.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemma-7b</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>granite-7b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998737</td>\n",
       "      <td>1.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>granite-7b</td>\n",
       "      <td>2</td>\n",
       "      <td>0.852757</td>\n",
       "      <td>2.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>granite-7b</td>\n",
       "      <td>4</td>\n",
       "      <td>0.851843</td>\n",
       "      <td>4.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>granite-7b</td>\n",
       "      <td>8</td>\n",
       "      <td>0.937644</td>\n",
       "      <td>8.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>granite-7b</td>\n",
       "      <td>16</td>\n",
       "      <td>1.346197</td>\n",
       "      <td>11.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>granite-7b</td>\n",
       "      <td>32</td>\n",
       "      <td>1.728881</td>\n",
       "      <td>18.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>granite-7b</td>\n",
       "      <td>64</td>\n",
       "      <td>3.202698</td>\n",
       "      <td>20.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>granite-7b</td>\n",
       "      <td>128</td>\n",
       "      <td>5.973265</td>\n",
       "      <td>21.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>granite-7b</td>\n",
       "      <td>256</td>\n",
       "      <td>12.195345</td>\n",
       "      <td>21.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>granite-7b</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770147</td>\n",
       "      <td>4.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>2</td>\n",
       "      <td>0.957225</td>\n",
       "      <td>2.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>4</td>\n",
       "      <td>0.927968</td>\n",
       "      <td>4.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>8</td>\n",
       "      <td>1.099303</td>\n",
       "      <td>7.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>16</td>\n",
       "      <td>1.408103</td>\n",
       "      <td>11.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>32</td>\n",
       "      <td>2.066624</td>\n",
       "      <td>15.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>64</td>\n",
       "      <td>3.258169</td>\n",
       "      <td>19.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>128</td>\n",
       "      <td>6.561684</td>\n",
       "      <td>19.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>256</td>\n",
       "      <td>12.993121</td>\n",
       "      <td>19.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>512</td>\n",
       "      <td>26.059093</td>\n",
       "      <td>19.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>llama3-8b</td>\n",
       "      <td>1024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_alias  batch_size  processing_time  throughput\n",
       "0     gemma-7b           1         0.933442       1.072\n",
       "1     gemma-7b           2         0.949676       2.106\n",
       "2     gemma-7b           4         0.930215       4.302\n",
       "3     gemma-7b           8         1.225456       6.568\n",
       "4     gemma-7b          16         1.414788      11.350\n",
       "5     gemma-7b          32         2.214126      14.676\n",
       "6     gemma-7b          64         3.542751      18.062\n",
       "7     gemma-7b         128         6.785152      18.896\n",
       "8     gemma-7b         256              NaN         NaN\n",
       "9   granite-7b           1         0.998737       1.046\n",
       "10  granite-7b           2         0.852757       2.348\n",
       "11  granite-7b           4         0.851843       4.704\n",
       "12  granite-7b           8         0.937644       8.544\n",
       "13  granite-7b          16         1.346197      11.886\n",
       "14  granite-7b          32         1.728881      18.602\n",
       "15  granite-7b          64         3.202698      20.044\n",
       "16  granite-7b         128         5.973265      21.448\n",
       "17  granite-7b         256        12.195345      21.006\n",
       "18  granite-7b         512              NaN         NaN\n",
       "19   llama3-8b           1         0.770147       4.108\n",
       "20   llama3-8b           2         0.957225       2.088\n",
       "21   llama3-8b           4         0.927968       4.310\n",
       "22   llama3-8b           8         1.099303       7.302\n",
       "23   llama3-8b          16         1.408103      11.412\n",
       "24   llama3-8b          32         2.066624      15.674\n",
       "25   llama3-8b          64         3.258169      19.712\n",
       "26   llama3-8b         128         6.561684      19.566\n",
       "27   llama3-8b         256        12.993121      19.724\n",
       "28   llama3-8b         512        26.059093      19.648\n",
       "29   llama3-8b        1024              NaN         NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['model_alias', 'batch_size']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confidentialinference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
