2024-09-18 12:44:25,510 Using device: cuda
2024-09-18 12:44:25,510 Scheduling mode set as batchedFCFS
2024-09-18 12:44:25,510 Monitoring status set to True
2024-09-18 12:44:40,579 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.122.143:5000
2024-09-18 12:44:40,579 [33mPress CTRL+C to quit[0m
2024-09-18 12:44:45,171 Request with ID e8d9f806 for model llama3-8b received
2024-09-18 12:44:45,171 127.0.0.1 - - [18/Sep/2024 12:44:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:45,303 Request with ID c7ef6795 for model gemma-7b received
2024-09-18 12:44:45,303 127.0.0.1 - - [18/Sep/2024 12:44:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:45,321 Request with ID 274109d4 for model llama3-8b received
2024-09-18 12:44:45,321 127.0.0.1 - - [18/Sep/2024 12:44:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:45,524 Request with ID 71fe3579 for model gemma-7b received
2024-09-18 12:44:45,525 127.0.0.1 - - [18/Sep/2024 12:44:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:45,531 Request with ID b637b272 for model gemma-7b received
2024-09-18 12:44:45,531 127.0.0.1 - - [18/Sep/2024 12:44:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:45,555 Request with ID 4734d0b1 for model granite-7b received
2024-09-18 12:44:45,556 127.0.0.1 - - [18/Sep/2024 12:44:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:45,654 Request with ID 13275c4f for model granite-7b received
2024-09-18 12:44:45,654 127.0.0.1 - - [18/Sep/2024 12:44:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:45,711 Request with ID 4b26c547 for model llama3-8b received
2024-09-18 12:44:45,712 127.0.0.1 - - [18/Sep/2024 12:44:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:45,764 Request with ID d4cdbe31 for model llama3-8b received
2024-09-18 12:44:45,764 127.0.0.1 - - [18/Sep/2024 12:44:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:45,826 Request with ID c7827d21 for model llama3-8b received
2024-09-18 12:44:45,827 127.0.0.1 - - [18/Sep/2024 12:44:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:46,238 Request with ID e28e864c for model llama3-8b received
2024-09-18 12:44:46,238 127.0.0.1 - - [18/Sep/2024 12:44:46] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:46,436 Request with ID 35859f31 for model granite-7b received
2024-09-18 12:44:46,436 127.0.0.1 - - [18/Sep/2024 12:44:46] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:46,497 Request with ID 2aa3e3ba for model granite-7b received
2024-09-18 12:44:46,498 127.0.0.1 - - [18/Sep/2024 12:44:46] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:46,836 Request with ID 80e58938 for model gemma-7b received
2024-09-18 12:44:46,837 127.0.0.1 - - [18/Sep/2024 12:44:46] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:46,873 Request with ID fb3310ea for model llama3-8b received
2024-09-18 12:44:46,874 127.0.0.1 - - [18/Sep/2024 12:44:46] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:46,990 Request with ID 3e780739 for model llama3-8b received
2024-09-18 12:44:46,990 127.0.0.1 - - [18/Sep/2024 12:44:46] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,010 Request with ID f2bc9d67 for model gemma-7b received
2024-09-18 12:44:47,010 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,121 Request with ID 09c74d9f for model gemma-7b received
2024-09-18 12:44:47,121 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,144 Request with ID 05b77991 for model llama3-8b received
2024-09-18 12:44:47,145 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,332 Request with ID 9beaa16b for model gemma-7b received
2024-09-18 12:44:47,332 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,383 Request with ID f1478ae6 for model gemma-7b received
2024-09-18 12:44:47,384 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,515 Request with ID b7a95ccd for model gemma-7b received
2024-09-18 12:44:47,515 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,538 Request with ID cb2e7fa2 for model gemma-7b received
2024-09-18 12:44:47,538 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,579 Request with ID 29724510 for model llama3-8b received
2024-09-18 12:44:47,579 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,758 Request with ID 45539e94 for model granite-7b received
2024-09-18 12:44:47,759 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,774 Request with ID b550c093 for model granite-7b received
2024-09-18 12:44:47,774 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,782 Request with ID 3550c129 for model granite-7b received
2024-09-18 12:44:47,783 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,806 Request with ID 9b255278 for model llama3-8b received
2024-09-18 12:44:47,806 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:47,977 Request with ID add74de4 for model llama3-8b received
2024-09-18 12:44:47,978 127.0.0.1 - - [18/Sep/2024 12:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:48,135 Request with ID 81775a20 for model granite-7b received
2024-09-18 12:44:48,136 127.0.0.1 - - [18/Sep/2024 12:44:48] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:48,398 Request with ID 9c6e08d7 for model llama3-8b received
2024-09-18 12:44:48,398 127.0.0.1 - - [18/Sep/2024 12:44:48] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:48,589 Request with ID bc4b66bf for model gemma-7b received
2024-09-18 12:44:48,589 127.0.0.1 - - [18/Sep/2024 12:44:48] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:48,599 Request with ID fd984841 for model llama3-8b received
2024-09-18 12:44:48,599 127.0.0.1 - - [18/Sep/2024 12:44:48] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:48,712 Request with ID 0b23f4ee for model llama3-8b received
2024-09-18 12:44:48,713 127.0.0.1 - - [18/Sep/2024 12:44:48] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:48,803 Request with ID 9d648421 for model granite-7b received
2024-09-18 12:44:48,803 127.0.0.1 - - [18/Sep/2024 12:44:48] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:48,852 Request with ID f5a6a35b for model llama3-8b received
2024-09-18 12:44:48,852 127.0.0.1 - - [18/Sep/2024 12:44:48] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:48,996 Request with ID b8c006c0 for model llama3-8b received
2024-09-18 12:44:48,997 127.0.0.1 - - [18/Sep/2024 12:44:48] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,027 Request with ID bf2604c2 for model llama3-8b received
2024-09-18 12:44:49,027 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,084 Request with ID 8ec3949a for model llama3-8b received
2024-09-18 12:44:49,084 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,088 Request with ID fb676a84 for model granite-7b received
2024-09-18 12:44:49,088 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,161 Request with ID 8b9e2208 for model granite-7b received
2024-09-18 12:44:49,162 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,192 Request with ID 53c94983 for model llama3-8b received
2024-09-18 12:44:49,192 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,216 Request with ID 0c3dea4b for model llama3-8b received
2024-09-18 12:44:49,216 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,251 Request with ID 6228149c for model gemma-7b received
2024-09-18 12:44:49,251 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,352 Request with ID 80ef0b1a for model granite-7b received
2024-09-18 12:44:49,352 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,363 Request with ID 03755965 for model gemma-7b received
2024-09-18 12:44:49,363 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,580 Request with ID ad0eafb4 for model gemma-7b received
2024-09-18 12:44:49,581 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,593 Request with ID 91e2ddc6 for model llama3-8b received
2024-09-18 12:44:49,594 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,833 Request with ID 382abf9b for model granite-7b received
2024-09-18 12:44:49,833 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,939 Request with ID 527357af for model granite-7b received
2024-09-18 12:44:49,939 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:49,975 Request with ID 2b718042 for model llama3-8b received
2024-09-18 12:44:49,976 127.0.0.1 - - [18/Sep/2024 12:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:50,032 Request with ID 621d0683 for model llama3-8b received
2024-09-18 12:44:50,033 127.0.0.1 - - [18/Sep/2024 12:44:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:50,052 Request with ID 45f05008 for model granite-7b received
2024-09-18 12:44:50,052 127.0.0.1 - - [18/Sep/2024 12:44:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:50,105 Request with ID 42d7c761 for model granite-7b received
2024-09-18 12:44:50,106 127.0.0.1 - - [18/Sep/2024 12:44:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:50,136 Request with ID 5e6f79ea for model gemma-7b received
2024-09-18 12:44:50,136 127.0.0.1 - - [18/Sep/2024 12:44:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:50,257 Request with ID 64ed4748 for model granite-7b received
2024-09-18 12:44:50,258 127.0.0.1 - - [18/Sep/2024 12:44:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:50,868 Request with ID c3f21a9c for model granite-7b received
2024-09-18 12:44:50,869 127.0.0.1 - - [18/Sep/2024 12:44:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:51,246 Request with ID 7682f9ff for model llama3-8b received
2024-09-18 12:44:51,247 127.0.0.1 - - [18/Sep/2024 12:44:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:51,280 Request with ID 1784c602 for model gemma-7b received
2024-09-18 12:44:51,280 127.0.0.1 - - [18/Sep/2024 12:44:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:51,358 Request with ID ede2a95f for model gemma-7b received
2024-09-18 12:44:51,359 127.0.0.1 - - [18/Sep/2024 12:44:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:51,387 Request with ID 8769488b for model llama3-8b received
2024-09-18 12:44:51,387 127.0.0.1 - - [18/Sep/2024 12:44:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:51,532 Request with ID 8f074262 for model granite-7b received
2024-09-18 12:44:51,533 127.0.0.1 - - [18/Sep/2024 12:44:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:51,664 Request with ID 783ca900 for model gemma-7b received
2024-09-18 12:44:51,664 127.0.0.1 - - [18/Sep/2024 12:44:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:51,743 Request with ID ee96d456 for model granite-7b received
2024-09-18 12:44:51,743 127.0.0.1 - - [18/Sep/2024 12:44:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:51,782 Request with ID 44a1f014 for model llama3-8b received
2024-09-18 12:44:51,782 127.0.0.1 - - [18/Sep/2024 12:44:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:51,807 Request with ID 6e7cdb5d for model llama3-8b received
2024-09-18 12:44:51,807 127.0.0.1 - - [18/Sep/2024 12:44:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:51,976 Request with ID 853e59d1 for model granite-7b received
2024-09-18 12:44:51,976 127.0.0.1 - - [18/Sep/2024 12:44:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:52,095 Request with ID 9169b0ac for model llama3-8b received
2024-09-18 12:44:52,095 127.0.0.1 - - [18/Sep/2024 12:44:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:52,373 Request with ID d2ca71f7 for model llama3-8b received
2024-09-18 12:44:52,373 127.0.0.1 - - [18/Sep/2024 12:44:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:52,415 Request with ID eab55a44 for model llama3-8b received
2024-09-18 12:44:52,415 127.0.0.1 - - [18/Sep/2024 12:44:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:52,495 Request with ID bd2c6196 for model llama3-8b received
2024-09-18 12:44:52,495 Batch size condition met for model llama3-8b
2024-09-18 12:44:52,495 Next: call load_model for llama3-8b
2024-09-18 12:44:52,723 Request with ID 668170cd for model granite-7b received
2024-09-18 12:44:52,724 127.0.0.1 - - [18/Sep/2024 12:44:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:52,725 Request with ID b99db9b8 for model gemma-7b received
2024-09-18 12:44:52,725 127.0.0.1 - - [18/Sep/2024 12:44:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:53,252 Request with ID 753f40d3 for model granite-7b received
2024-09-18 12:44:53,253 127.0.0.1 - - [18/Sep/2024 12:44:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:53,480 Request with ID 1fe90f47 for model granite-7b received
2024-09-18 12:44:53,486 127.0.0.1 - - [18/Sep/2024 12:44:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:53,589 Request with ID 9448f104 for model gemma-7b received
2024-09-18 12:44:53,589 127.0.0.1 - - [18/Sep/2024 12:44:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:53,791 Request with ID aba57850 for model llama3-8b received
2024-09-18 12:44:53,792 127.0.0.1 - - [18/Sep/2024 12:44:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:53,928 Request with ID a0a891d1 for model gemma-7b received
2024-09-18 12:44:53,928 127.0.0.1 - - [18/Sep/2024 12:44:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:54,040 Request with ID 8aca384a for model llama3-8b received
2024-09-18 12:44:54,040 127.0.0.1 - - [18/Sep/2024 12:44:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:54,087 Request with ID 7bfabca3 for model llama3-8b received
2024-09-18 12:44:54,087 127.0.0.1 - - [18/Sep/2024 12:44:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:54,453 Request with ID 98db8cd3 for model gemma-7b received
2024-09-18 12:44:54,455 127.0.0.1 - - [18/Sep/2024 12:44:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:54,534 Request with ID 429cb437 for model granite-7b received
2024-09-18 12:44:54,534 127.0.0.1 - - [18/Sep/2024 12:44:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:54,554 Request with ID 727e7923 for model granite-7b received
2024-09-18 12:44:54,554 127.0.0.1 - - [18/Sep/2024 12:44:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:54,624 Request with ID 73532d2e for model llama3-8b received
2024-09-18 12:44:54,625 127.0.0.1 - - [18/Sep/2024 12:44:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:54,754 Request with ID bf3746ee for model granite-7b received
2024-09-18 12:44:54,755 127.0.0.1 - - [18/Sep/2024 12:44:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:54,833 Request with ID cc8a6313 for model llama3-8b received
2024-09-18 12:44:54,834 127.0.0.1 - - [18/Sep/2024 12:44:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:54,937 Request with ID 2b03e64d for model gemma-7b received
2024-09-18 12:44:54,938 127.0.0.1 - - [18/Sep/2024 12:44:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:55,029 Request with ID c593b5d9 for model gemma-7b received
2024-09-18 12:44:55,030 127.0.0.1 - - [18/Sep/2024 12:44:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:55,267 Request with ID 20ce85c9 for model gemma-7b received
2024-09-18 12:44:55,268 127.0.0.1 - - [18/Sep/2024 12:44:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:55,309 Request with ID eebcea73 for model granite-7b received
2024-09-18 12:44:55,310 127.0.0.1 - - [18/Sep/2024 12:44:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:55,332 Request with ID 0dbec41d for model llama3-8b received
2024-09-18 12:44:55,332 127.0.0.1 - - [18/Sep/2024 12:44:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:55,418 Request with ID d2a79666 for model granite-7b received
2024-09-18 12:44:55,419 127.0.0.1 - - [18/Sep/2024 12:44:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:55,423 Request with ID d82732ac for model gemma-7b received
2024-09-18 12:44:55,423 127.0.0.1 - - [18/Sep/2024 12:44:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:55,734 Request with ID dd872d63 for model granite-7b received
2024-09-18 12:44:55,735 127.0.0.1 - - [18/Sep/2024 12:44:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,042 Request with ID 2e6628e8 for model granite-7b received
2024-09-18 12:44:56,043 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,129 Request with ID d19dcd15 for model granite-7b received
2024-09-18 12:44:56,130 Batch size condition met for model granite-7b
2024-09-18 12:44:56,137 Request with ID f44d5dc5 for model llama3-8b received
2024-09-18 12:44:56,138 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,170 Request with ID 95a7c829 for model gemma-7b received
2024-09-18 12:44:56,172 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,254 Request with ID f8f783ee for model gemma-7b received
2024-09-18 12:44:56,254 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,376 Request with ID 88c17536 for model gemma-7b received
2024-09-18 12:44:56,377 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,385 Request with ID 7baf925d for model gemma-7b received
2024-09-18 12:44:56,385 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,416 Request with ID d4ff2c56 for model gemma-7b received
2024-09-18 12:44:56,416 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,553 Request with ID 73404b20 for model llama3-8b received
2024-09-18 12:44:56,554 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,589 Request with ID b9bc8570 for model llama3-8b received
2024-09-18 12:44:56,589 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,622 Request with ID 8502226b for model granite-7b received
2024-09-18 12:44:56,622 Request with ID c9f46882 for model gemma-7b received
2024-09-18 12:44:56,623 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,623 Batch size condition met for model gemma-7b
2024-09-18 12:44:56,644 Request with ID c27d357c for model gemma-7b received
2024-09-18 12:44:56,644 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,867 Request with ID 45b456a7 for model gemma-7b received
2024-09-18 12:44:56,867 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,876 Request with ID 027289e4 for model gemma-7b received
2024-09-18 12:44:56,876 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,918 Request with ID 46e02ec2 for model gemma-7b received
2024-09-18 12:44:56,918 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:56,953 Request with ID 1175b68d for model gemma-7b received
2024-09-18 12:44:56,954 127.0.0.1 - - [18/Sep/2024 12:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,128 Request with ID 3d3a3472 for model llama3-8b received
2024-09-18 12:44:57,129 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,142 Request with ID 9e3ac5a4 for model granite-7b received
2024-09-18 12:44:57,143 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,206 Request with ID 5e78fe78 for model granite-7b received
2024-09-18 12:44:57,207 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,229 Request with ID a489beca for model llama3-8b received
2024-09-18 12:44:57,229 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,333 Request with ID 76766601 for model gemma-7b received
2024-09-18 12:44:57,334 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,409 Request with ID 78a616ba for model llama3-8b received
2024-09-18 12:44:57,409 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,568 Request with ID 9601348f for model llama3-8b received
2024-09-18 12:44:57,568 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,627 Request with ID a8acc119 for model gemma-7b received
2024-09-18 12:44:57,627 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,629 Request with ID 4a331e2f for model gemma-7b received
2024-09-18 12:44:57,630 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,813 Request with ID 2b89349f for model granite-7b received
2024-09-18 12:44:57,813 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,819 Request with ID 200cde84 for model granite-7b received
2024-09-18 12:44:57,819 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,970 Request with ID 79e764ba for model gemma-7b received
2024-09-18 12:44:57,971 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,972 Request with ID af311e8d for model granite-7b received
2024-09-18 12:44:57,973 Request with ID 1862ac7a for model llama3-8b received
2024-09-18 12:44:57,974 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:57,975 127.0.0.1 - - [18/Sep/2024 12:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:58,035 Request with ID a6f568d6 for model gemma-7b received
2024-09-18 12:44:58,035 127.0.0.1 - - [18/Sep/2024 12:44:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:58,167 Request with ID 8b77d147 for model llama3-8b received
2024-09-18 12:44:58,168 127.0.0.1 - - [18/Sep/2024 12:44:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:58,311 Request with ID e6a0b692 for model granite-7b received
2024-09-18 12:44:58,312 127.0.0.1 - - [18/Sep/2024 12:44:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:58,321 Request with ID 3c9bf389 for model gemma-7b received
2024-09-18 12:44:58,322 127.0.0.1 - - [18/Sep/2024 12:44:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:58,714 Request with ID 75431c74 for model gemma-7b received
2024-09-18 12:44:58,714 127.0.0.1 - - [18/Sep/2024 12:44:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:58,860 Request with ID 421b1c36 for model granite-7b received
2024-09-18 12:44:58,860 127.0.0.1 - - [18/Sep/2024 12:44:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:58,924 Request with ID 9f90449d for model llama3-8b received
2024-09-18 12:44:58,925 127.0.0.1 - - [18/Sep/2024 12:44:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:58,930 Request with ID b9f33c4a for model granite-7b received
2024-09-18 12:44:58,931 127.0.0.1 - - [18/Sep/2024 12:44:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:59,150 Request with ID 260e653f for model granite-7b received
2024-09-18 12:44:59,150 127.0.0.1 - - [18/Sep/2024 12:44:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:59,229 Request with ID 88da2f9d for model llama3-8b received
2024-09-18 12:44:59,229 127.0.0.1 - - [18/Sep/2024 12:44:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:59,521 Request with ID 9aaabbe3 for model llama3-8b received
2024-09-18 12:44:59,521 127.0.0.1 - - [18/Sep/2024 12:44:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:59,684 Request with ID f906f90e for model gemma-7b received
2024-09-18 12:44:59,685 127.0.0.1 - - [18/Sep/2024 12:44:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:59,771 Request with ID 4eed80ba for model granite-7b received
2024-09-18 12:44:59,771 127.0.0.1 - - [18/Sep/2024 12:44:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:44:59,939 Request with ID 6102da6a for model llama3-8b received
2024-09-18 12:44:59,939 127.0.0.1 - - [18/Sep/2024 12:44:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:00,113 Request with ID 56646b70 for model gemma-7b received
2024-09-18 12:45:00,113 127.0.0.1 - - [18/Sep/2024 12:45:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:00,135 Request with ID 0a99deac for model granite-7b received
2024-09-18 12:45:00,136 127.0.0.1 - - [18/Sep/2024 12:45:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:00,161 Request with ID ebf06122 for model llama3-8b received
2024-09-18 12:45:00,161 127.0.0.1 - - [18/Sep/2024 12:45:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:00,204 Request with ID 82a60165 for model granite-7b received
2024-09-18 12:45:00,205 127.0.0.1 - - [18/Sep/2024 12:45:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:00,392 Request with ID 31c41015 for model gemma-7b received
2024-09-18 12:45:00,393 127.0.0.1 - - [18/Sep/2024 12:45:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:00,562 Request with ID 2e1bedef for model llama3-8b received
2024-09-18 12:45:00,562 127.0.0.1 - - [18/Sep/2024 12:45:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:00,575 Request with ID 5953a498 for model granite-7b received
2024-09-18 12:45:00,575 127.0.0.1 - - [18/Sep/2024 12:45:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:00,853 Request with ID 7e90817c for model granite-7b received
2024-09-18 12:45:00,854 127.0.0.1 - - [18/Sep/2024 12:45:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:01,198 Request with ID fd878e79 for model gemma-7b received
2024-09-18 12:45:01,199 127.0.0.1 - - [18/Sep/2024 12:45:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:01,258 Request with ID 883a7d2d for model gemma-7b received
2024-09-18 12:45:01,259 127.0.0.1 - - [18/Sep/2024 12:45:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:01,286 Request with ID 75b897dc for model llama3-8b received
2024-09-18 12:45:01,286 127.0.0.1 - - [18/Sep/2024 12:45:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:01,555 Request with ID 692b7aeb for model granite-7b received
2024-09-18 12:45:01,556 127.0.0.1 - - [18/Sep/2024 12:45:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:01,672 Request with ID cf06a7a6 for model gemma-7b received
2024-09-18 12:45:01,672 127.0.0.1 - - [18/Sep/2024 12:45:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:01,905 Request with ID 1593928b for model granite-7b received
2024-09-18 12:45:01,906 127.0.0.1 - - [18/Sep/2024 12:45:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:01,946 Request with ID b26fafb5 for model llama3-8b received
2024-09-18 12:45:01,947 127.0.0.1 - - [18/Sep/2024 12:45:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:01,997 Request with ID d4cdbe28 for model granite-7b received
2024-09-18 12:45:01,997 127.0.0.1 - - [18/Sep/2024 12:45:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:02,235 Request with ID b8708c8f for model granite-7b received
2024-09-18 12:45:02,235 127.0.0.1 - - [18/Sep/2024 12:45:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:02,273 Request with ID 823b1a11 for model llama3-8b received
2024-09-18 12:45:02,274 127.0.0.1 - - [18/Sep/2024 12:45:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:02,576 Request with ID e4c19dae for model gemma-7b received
2024-09-18 12:45:02,577 127.0.0.1 - - [18/Sep/2024 12:45:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:02,677 Request with ID 7a1512e3 for model granite-7b received
2024-09-18 12:45:02,678 127.0.0.1 - - [18/Sep/2024 12:45:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:02,713 Request with ID cb5ec615 for model granite-7b received
2024-09-18 12:45:02,713 127.0.0.1 - - [18/Sep/2024 12:45:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:02,871 Request with ID 43da0674 for model granite-7b received
2024-09-18 12:45:02,871 127.0.0.1 - - [18/Sep/2024 12:45:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:03,140 Request with ID fbb1aec8 for model llama3-8b received
2024-09-18 12:45:03,141 127.0.0.1 - - [18/Sep/2024 12:45:03] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:03,732 Request with ID 236df290 for model granite-7b received
2024-09-18 12:45:03,733 127.0.0.1 - - [18/Sep/2024 12:45:03] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:03,829 Request with ID d5dbf53f for model llama3-8b received
2024-09-18 12:45:03,829 127.0.0.1 - - [18/Sep/2024 12:45:03] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:03,954 Request with ID ad010dac for model granite-7b received
2024-09-18 12:45:03,954 127.0.0.1 - - [18/Sep/2024 12:45:03] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:04,099 Request with ID bffb75a9 for model gemma-7b received
2024-09-18 12:45:04,099 127.0.0.1 - - [18/Sep/2024 12:45:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:04,223 Request with ID d67d9dd2 for model gemma-7b received
2024-09-18 12:45:04,223 127.0.0.1 - - [18/Sep/2024 12:45:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:04,447 Request with ID d11591c6 for model granite-7b received
2024-09-18 12:45:04,447 127.0.0.1 - - [18/Sep/2024 12:45:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:04,520 Request with ID 0dacb459 for model llama3-8b received
2024-09-18 12:45:04,521 127.0.0.1 - - [18/Sep/2024 12:45:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:04,609 Request with ID c0691dbb for model granite-7b received
2024-09-18 12:45:04,610 127.0.0.1 - - [18/Sep/2024 12:45:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:04,824 Request with ID 36268c7d for model llama3-8b received
2024-09-18 12:45:04,824 127.0.0.1 - - [18/Sep/2024 12:45:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:05,064 Request with ID 5d51e835 for model gemma-7b received
2024-09-18 12:45:05,064 127.0.0.1 - - [18/Sep/2024 12:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:05,189 Request with ID cfdb135d for model granite-7b received
2024-09-18 12:45:05,189 127.0.0.1 - - [18/Sep/2024 12:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:05,237 Request with ID 41ce73ec for model gemma-7b received
2024-09-18 12:45:05,238 127.0.0.1 - - [18/Sep/2024 12:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:05,475 Request with ID 19825443 for model gemma-7b received
2024-09-18 12:45:05,476 127.0.0.1 - - [18/Sep/2024 12:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:05,545 Request with ID 712823b9 for model gemma-7b received
2024-09-18 12:45:05,545 127.0.0.1 - - [18/Sep/2024 12:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:05,609 Request with ID 986a392c for model granite-7b received
2024-09-18 12:45:05,610 127.0.0.1 - - [18/Sep/2024 12:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:05,784 Request with ID da076246 for model granite-7b received
2024-09-18 12:45:05,784 127.0.0.1 - - [18/Sep/2024 12:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:05,900 Request with ID d6f7ccc6 for model granite-7b received
2024-09-18 12:45:05,900 127.0.0.1 - - [18/Sep/2024 12:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:05,948 Request with ID fea50733 for model granite-7b received
2024-09-18 12:45:05,949 127.0.0.1 - - [18/Sep/2024 12:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:05,974 Request with ID 533bffa9 for model gemma-7b received
2024-09-18 12:45:05,975 127.0.0.1 - - [18/Sep/2024 12:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:05,976 Request with ID 3183b27e for model llama3-8b received
2024-09-18 12:45:05,977 127.0.0.1 - - [18/Sep/2024 12:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:06,201 Request with ID ab8c1790 for model granite-7b received
2024-09-18 12:45:06,202 Batch size condition met for model granite-7b
2024-09-18 12:45:06,231 Request with ID 166d4b4a for model granite-7b received
2024-09-18 12:45:06,232 127.0.0.1 - - [18/Sep/2024 12:45:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:06,308 Request with ID 68a4b740 for model granite-7b received
2024-09-18 12:45:06,308 127.0.0.1 - - [18/Sep/2024 12:45:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:06,476 Request with ID 88a11296 for model gemma-7b received
2024-09-18 12:45:06,476 127.0.0.1 - - [18/Sep/2024 12:45:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:06,517 Request with ID 50d8cf24 for model granite-7b received
2024-09-18 12:45:06,518 127.0.0.1 - - [18/Sep/2024 12:45:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:06,766 Request with ID 4ccdca88 for model gemma-7b received
2024-09-18 12:45:06,767 127.0.0.1 - - [18/Sep/2024 12:45:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:06,829 Request with ID fe5dee07 for model granite-7b received
2024-09-18 12:45:06,829 127.0.0.1 - - [18/Sep/2024 12:45:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:06,863 Request with ID 00095d43 for model gemma-7b received
2024-09-18 12:45:06,863 127.0.0.1 - - [18/Sep/2024 12:45:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:06,915 Request with ID 2b6b84de for model granite-7b received
2024-09-18 12:45:06,915 127.0.0.1 - - [18/Sep/2024 12:45:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:07,283 Request with ID 7b857507 for model gemma-7b received
2024-09-18 12:45:07,283 127.0.0.1 - - [18/Sep/2024 12:45:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:07,287 Request with ID 2e8ae35d for model granite-7b received
2024-09-18 12:45:07,287 127.0.0.1 - - [18/Sep/2024 12:45:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:07,342 Request with ID f7988183 for model granite-7b received
2024-09-18 12:45:07,342 127.0.0.1 - - [18/Sep/2024 12:45:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:07,587 Request with ID 51b3fc7e for model gemma-7b received
2024-09-18 12:45:07,587 127.0.0.1 - - [18/Sep/2024 12:45:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:07,641 Request with ID 8242b6f6 for model llama3-8b received
2024-09-18 12:45:07,642 127.0.0.1 - - [18/Sep/2024 12:45:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:07,895 Request with ID d6a61376 for model gemma-7b received
2024-09-18 12:45:07,895 Batch size condition met for model gemma-7b
2024-09-18 12:45:08,097 Request with ID fae3441e for model granite-7b received
2024-09-18 12:45:08,098 127.0.0.1 - - [18/Sep/2024 12:45:08] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:08,101 Request with ID 67946549 for model gemma-7b received
2024-09-18 12:45:08,101 127.0.0.1 - - [18/Sep/2024 12:45:08] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:08,269 Request with ID bee93e23 for model llama3-8b received
2024-09-18 12:45:08,270 127.0.0.1 - - [18/Sep/2024 12:45:08] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:08,287 Request with ID 7e79c8e4 for model gemma-7b received
2024-09-18 12:45:08,288 127.0.0.1 - - [18/Sep/2024 12:45:08] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:08,337 Request with ID f81fa311 for model granite-7b received
2024-09-18 12:45:08,337 127.0.0.1 - - [18/Sep/2024 12:45:08] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:08,343 Request with ID 700a61d1 for model llama3-8b received
2024-09-18 12:45:08,344 Batch size condition met for model llama3-8b
2024-09-18 12:45:08,359 Request with ID 09fa3370 for model llama3-8b received
2024-09-18 12:45:08,360 127.0.0.1 - - [18/Sep/2024 12:45:08] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:08,561 Request with ID cbae2a3b for model granite-7b received
2024-09-18 12:45:08,562 127.0.0.1 - - [18/Sep/2024 12:45:08] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:09,382 Request with ID 6e37e2d3 for model llama3-8b received
2024-09-18 12:45:09,382 127.0.0.1 - - [18/Sep/2024 12:45:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:09,464 Request with ID 72caa977 for model gemma-7b received
2024-09-18 12:45:09,464 127.0.0.1 - - [18/Sep/2024 12:45:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:09,512 Request with ID 7480db65 for model granite-7b received
2024-09-18 12:45:09,512 127.0.0.1 - - [18/Sep/2024 12:45:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:09,822 Request with ID ec9252cb for model gemma-7b received
2024-09-18 12:45:09,823 127.0.0.1 - - [18/Sep/2024 12:45:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:10,035 Request with ID 21a85a4c for model gemma-7b received
2024-09-18 12:45:10,036 127.0.0.1 - - [18/Sep/2024 12:45:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:10,081 Request with ID 3be8c473 for model gemma-7b received
2024-09-18 12:45:10,081 127.0.0.1 - - [18/Sep/2024 12:45:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:10,152 Request with ID 1975d0ac for model gemma-7b received
2024-09-18 12:45:10,152 127.0.0.1 - - [18/Sep/2024 12:45:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:10,333 Request with ID 5276ada1 for model granite-7b received
2024-09-18 12:45:10,333 127.0.0.1 - - [18/Sep/2024 12:45:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:10,415 Request with ID 8e2b151c for model gemma-7b received
2024-09-18 12:45:10,415 127.0.0.1 - - [18/Sep/2024 12:45:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:10,627 Request with ID 5f071292 for model granite-7b received
2024-09-18 12:45:10,628 127.0.0.1 - - [18/Sep/2024 12:45:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:10,642 Request with ID 9d477895 for model granite-7b received
2024-09-18 12:45:10,643 127.0.0.1 - - [18/Sep/2024 12:45:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:10,746 Request with ID 5cbe61af for model llama3-8b received
2024-09-18 12:45:10,747 127.0.0.1 - - [18/Sep/2024 12:45:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:10,982 Request with ID ed03d074 for model gemma-7b received
2024-09-18 12:45:10,982 127.0.0.1 - - [18/Sep/2024 12:45:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:11,026 Request with ID 5f8ddafa for model gemma-7b received
2024-09-18 12:45:11,026 127.0.0.1 - - [18/Sep/2024 12:45:11] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:11,077 Request with ID 8be54e4f for model gemma-7b received
2024-09-18 12:45:11,078 127.0.0.1 - - [18/Sep/2024 12:45:11] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:11,121 Request with ID 0fa8d1e2 for model granite-7b received
2024-09-18 12:45:11,122 127.0.0.1 - - [18/Sep/2024 12:45:11] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:11,276 Request with ID 6b134870 for model gemma-7b received
2024-09-18 12:45:11,277 127.0.0.1 - - [18/Sep/2024 12:45:11] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:11,375 Request with ID a11285ed for model granite-7b received
2024-09-18 12:45:11,376 127.0.0.1 - - [18/Sep/2024 12:45:11] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:11,537 Request with ID bfb5f59d for model granite-7b received
2024-09-18 12:45:11,537 127.0.0.1 - - [18/Sep/2024 12:45:11] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:11,606 Request with ID e42da10b for model granite-7b received
2024-09-18 12:45:11,606 127.0.0.1 - - [18/Sep/2024 12:45:11] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:11,999 Request with ID f2e7d2c9 for model gemma-7b received
2024-09-18 12:45:12,000 127.0.0.1 - - [18/Sep/2024 12:45:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:12,040 Request with ID c211c3fe for model llama3-8b received
2024-09-18 12:45:12,041 127.0.0.1 - - [18/Sep/2024 12:45:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:12,049 Request with ID 5cced8ae for model llama3-8b received
2024-09-18 12:45:12,049 127.0.0.1 - - [18/Sep/2024 12:45:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:12,064 Request with ID 89e35056 for model llama3-8b received
2024-09-18 12:45:12,064 127.0.0.1 - - [18/Sep/2024 12:45:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:12,081 Request with ID 02097880 for model granite-7b received
2024-09-18 12:45:12,082 127.0.0.1 - - [18/Sep/2024 12:45:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:12,310 Request with ID 00b0e555 for model granite-7b received
2024-09-18 12:45:12,311 127.0.0.1 - - [18/Sep/2024 12:45:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:12,674 Request with ID f8aa8379 for model gemma-7b received
2024-09-18 12:45:12,674 127.0.0.1 - - [18/Sep/2024 12:45:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:12,699 Request with ID 04db1685 for model gemma-7b received
2024-09-18 12:45:12,700 127.0.0.1 - - [18/Sep/2024 12:45:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:12,734 Request with ID 822e4b1d for model gemma-7b received
2024-09-18 12:45:12,734 127.0.0.1 - - [18/Sep/2024 12:45:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:12,748 Request with ID 37cb32c4 for model gemma-7b received
2024-09-18 12:45:12,748 127.0.0.1 - - [18/Sep/2024 12:45:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:12,975 Request with ID c011f6e9 for model gemma-7b received
2024-09-18 12:45:12,975 127.0.0.1 - - [18/Sep/2024 12:45:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,016 Request with ID 71c4863d for model granite-7b received
2024-09-18 12:45:13,016 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,135 Request with ID b971f359 for model gemma-7b received
2024-09-18 12:45:13,135 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,154 Request with ID fdba957d for model granite-7b received
2024-09-18 12:45:13,155 Request with ID e6b4fb0a for model granite-7b received
2024-09-18 12:45:13,156 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,157 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,248 Request with ID 06723261 for model llama3-8b received
2024-09-18 12:45:13,248 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,326 Request with ID 9d0d8251 for model gemma-7b received
2024-09-18 12:45:13,326 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,354 Request with ID 7ff5e2a5 for model llama3-8b received
2024-09-18 12:45:13,354 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,425 Loaded model llama3-8b
2024-09-18 12:45:13,428 Batch processing started for model llama3-8b
2024-09-18 12:45:13,432 Request with ID 9677b537 for model gemma-7b received
2024-09-18 12:45:13,433 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,436 Request with ID 40252d7f for model llama3-8b received
2024-09-18 12:45:13,437 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,564 Request with ID 9644b8b9 for model llama3-8b received
2024-09-18 12:45:13,564 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,650 Request with ID 60182587 for model granite-7b received
2024-09-18 12:45:13,651 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,843 Request with ID 681a001e for model llama3-8b received
2024-09-18 12:45:13,843 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,858 Request with ID 23d7d190 for model granite-7b received
2024-09-18 12:45:13,858 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:13,873 Request with ID fc57c661 for model granite-7b received
2024-09-18 12:45:13,873 127.0.0.1 - - [18/Sep/2024 12:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:14,059 Request with ID 536b2a4a for model gemma-7b received
2024-09-18 12:45:14,059 127.0.0.1 - - [18/Sep/2024 12:45:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:14,137 Request with ID 753df4c4 for model granite-7b received
2024-09-18 12:45:14,137 127.0.0.1 - - [18/Sep/2024 12:45:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:14,180 Request with ID ce3a7551 for model gemma-7b received
2024-09-18 12:45:14,180 127.0.0.1 - - [18/Sep/2024 12:45:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:14,338 Request with ID 6148d421 for model gemma-7b received
2024-09-18 12:45:14,338 127.0.0.1 - - [18/Sep/2024 12:45:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:14,348 Request with ID b0b17650 for model gemma-7b received
2024-09-18 12:45:14,348 127.0.0.1 - - [18/Sep/2024 12:45:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:14,439 Request with ID 8acd20ff for model gemma-7b received
2024-09-18 12:45:14,440 127.0.0.1 - - [18/Sep/2024 12:45:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:14,534 Request with ID 92264494 for model llama3-8b received
2024-09-18 12:45:14,535 127.0.0.1 - - [18/Sep/2024 12:45:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:14,967 Request with ID 585c80bc for model granite-7b received
2024-09-18 12:45:14,967 127.0.0.1 - - [18/Sep/2024 12:45:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:14,978 Request with ID 066d3bba for model gemma-7b received
2024-09-18 12:45:14,978 127.0.0.1 - - [18/Sep/2024 12:45:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:15,006 Request with ID b4ee41fa for model llama3-8b received
2024-09-18 12:45:15,007 127.0.0.1 - - [18/Sep/2024 12:45:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:15,193 Request with ID 3058c71d for model llama3-8b received
2024-09-18 12:45:15,194 127.0.0.1 - - [18/Sep/2024 12:45:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:15,247 Request with ID 7851f17b for model llama3-8b received
2024-09-18 12:45:15,247 127.0.0.1 - - [18/Sep/2024 12:45:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:15,476 Request with ID 9e3acebf for model llama3-8b received
2024-09-18 12:45:15,477 127.0.0.1 - - [18/Sep/2024 12:45:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:15,679 Request with ID 12a7f7a6 for model gemma-7b received
2024-09-18 12:45:15,679 127.0.0.1 - - [18/Sep/2024 12:45:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:15,710 Request with ID e58cfd5a for model llama3-8b received
2024-09-18 12:45:15,710 127.0.0.1 - - [18/Sep/2024 12:45:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:15,884 Request with ID ba8c7a63 for model llama3-8b received
2024-09-18 12:45:15,884 127.0.0.1 - - [18/Sep/2024 12:45:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:15,962 Request with ID d7a37bba for model granite-7b received
2024-09-18 12:45:15,962 127.0.0.1 - - [18/Sep/2024 12:45:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:16,111 Request with ID 17dc0d19 for model gemma-7b received
2024-09-18 12:45:16,112 127.0.0.1 - - [18/Sep/2024 12:45:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:16,238 Request with ID d5410524 for model granite-7b received
2024-09-18 12:45:16,238 127.0.0.1 - - [18/Sep/2024 12:45:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:16,372 Request with ID b98c6c0d for model granite-7b received
2024-09-18 12:45:16,372 127.0.0.1 - - [18/Sep/2024 12:45:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:16,468 Request with ID e33704ab for model gemma-7b received
2024-09-18 12:45:16,468 127.0.0.1 - - [18/Sep/2024 12:45:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:16,556 Request with ID 73151ab3 for model llama3-8b received
2024-09-18 12:45:16,557 127.0.0.1 - - [18/Sep/2024 12:45:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:16,623 Request with ID 497a1d13 for model llama3-8b received
2024-09-18 12:45:16,624 127.0.0.1 - - [18/Sep/2024 12:45:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:16,629 Request with ID f68e853f for model gemma-7b received
2024-09-18 12:45:16,630 127.0.0.1 - - [18/Sep/2024 12:45:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:16,711 Request with ID 5d6243a0 for model gemma-7b received
2024-09-18 12:45:16,711 Batch size condition met for model gemma-7b
2024-09-18 12:45:16,751 Request with ID 7c21097d for model granite-7b received
2024-09-18 12:45:16,751 Batch size condition met for model granite-7b
2024-09-18 12:45:16,767 Request with ID 55408ec1 for model llama3-8b received
2024-09-18 12:45:16,768 127.0.0.1 - - [18/Sep/2024 12:45:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:16,832 Request with ID 2927bd81 for model llama3-8b received
2024-09-18 12:45:16,832 127.0.0.1 - - [18/Sep/2024 12:45:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:16,876 Request with ID 7bbfe16a for model gemma-7b received
2024-09-18 12:45:16,877 127.0.0.1 - - [18/Sep/2024 12:45:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:17,016 Request with ID 2c7a03e0 for model gemma-7b received
2024-09-18 12:45:17,017 127.0.0.1 - - [18/Sep/2024 12:45:17] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:17,289 Request with ID f2dc4c38 for model gemma-7b received
2024-09-18 12:45:17,290 127.0.0.1 - - [18/Sep/2024 12:45:17] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:17,310 Request with ID 7d52727f for model granite-7b received
2024-09-18 12:45:17,310 127.0.0.1 - - [18/Sep/2024 12:45:17] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:17,447 Request with ID 3d429e89 for model granite-7b received
2024-09-18 12:45:17,447 127.0.0.1 - - [18/Sep/2024 12:45:17] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:17,462 Request with ID 1df13f55 for model granite-7b received
2024-09-18 12:45:17,463 127.0.0.1 - - [18/Sep/2024 12:45:17] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:17,486 Request with ID 2727120d for model granite-7b received
2024-09-18 12:45:17,486 127.0.0.1 - - [18/Sep/2024 12:45:17] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:17,508 Request with ID 0b41b0d4 for model gemma-7b received
2024-09-18 12:45:17,509 127.0.0.1 - - [18/Sep/2024 12:45:17] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:17,750 Request with ID 8615872c for model granite-7b received
2024-09-18 12:45:17,751 127.0.0.1 - - [18/Sep/2024 12:45:17] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:17,841 Request with ID 2be6afbd for model llama3-8b received
2024-09-18 12:45:17,841 127.0.0.1 - - [18/Sep/2024 12:45:17] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:17,968 Processed batch: ['e8d9f806', '274109d4', '4b26c547', 'd4cdbe31', 'c7827d21', 'e28e864c', 'fb3310ea', '3e780739', '05b77991', '29724510', '9b255278', 'add74de4', '9c6e08d7', 'fd984841', '0b23f4ee', 'f5a6a35b', 'b8c006c0', 'bf2604c2', '8ec3949a', '53c94983', '0c3dea4b', '91e2ddc6', '2b718042', '621d0683', '7682f9ff', '8769488b', '44a1f014', '6e7cdb5d', '9169b0ac', 'd2ca71f7', 'eab55a44', 'bd2c6196'] with model llama3-8b in 4.5397 seconds
2024-09-18 12:45:17,968 Saving sys info
2024-09-18 12:45:17,969 Request with ID 92420e0b for model llama3-8b received
2024-09-18 12:45:17,970 127.0.0.1 - - [18/Sep/2024 12:45:17] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,014 Latency for request e8d9f806 with model llama3-8b: 32.7970 seconds
2024-09-18 12:45:18,015 Saving results with gpu monitoring
2024-09-18 12:45:18,020 Latency for request 274109d4 with model llama3-8b: 32.6470 seconds
2024-09-18 12:45:18,020 Saving results with gpu monitoring
2024-09-18 12:45:18,022 Latency for request 4b26c547 with model llama3-8b: 32.2565 seconds
2024-09-18 12:45:18,022 Saving results with gpu monitoring
2024-09-18 12:45:18,024 Latency for request d4cdbe31 with model llama3-8b: 32.2040 seconds
2024-09-18 12:45:18,024 Saving results with gpu monitoring
2024-09-18 12:45:18,027 Latency for request c7827d21 with model llama3-8b: 32.1416 seconds
2024-09-18 12:45:18,027 Saving results with gpu monitoring
2024-09-18 12:45:18,029 Latency for request e28e864c with model llama3-8b: 31.7302 seconds
2024-09-18 12:45:18,029 Saving results with gpu monitoring
2024-09-18 12:45:18,031 Latency for request fb3310ea with model llama3-8b: 31.0947 seconds
2024-09-18 12:45:18,031 Saving results with gpu monitoring
2024-09-18 12:45:18,033 Latency for request 3e780739 with model llama3-8b: 30.9779 seconds
2024-09-18 12:45:18,033 Saving results with gpu monitoring
2024-09-18 12:45:18,035 Latency for request 05b77991 with model llama3-8b: 30.8236 seconds
2024-09-18 12:45:18,035 Saving results with gpu monitoring
2024-09-18 12:45:18,037 Latency for request 29724510 with model llama3-8b: 30.3893 seconds
2024-09-18 12:45:18,038 Saving results with gpu monitoring
2024-09-18 12:45:18,040 Latency for request 9b255278 with model llama3-8b: 30.1621 seconds
2024-09-18 12:45:18,040 Saving results with gpu monitoring
2024-09-18 12:45:18,043 Request with ID 72d9ebbc for model granite-7b received
2024-09-18 12:45:18,043 Latency for request add74de4 with model llama3-8b: 29.9904 seconds
2024-09-18 12:45:18,044 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,044 Saving results with gpu monitoring
2024-09-18 12:45:18,046 Latency for request 9c6e08d7 with model llama3-8b: 29.5703 seconds
2024-09-18 12:45:18,046 Saving results with gpu monitoring
2024-09-18 12:45:18,048 Latency for request fd984841 with model llama3-8b: 29.3692 seconds
2024-09-18 12:45:18,048 Saving results with gpu monitoring
2024-09-18 12:45:18,050 Latency for request 0b23f4ee with model llama3-8b: 29.2558 seconds
2024-09-18 12:45:18,051 Saving results with gpu monitoring
2024-09-18 12:45:18,053 Latency for request f5a6a35b with model llama3-8b: 29.1161 seconds
2024-09-18 12:45:18,053 Saving results with gpu monitoring
2024-09-18 12:45:18,055 Latency for request b8c006c0 with model llama3-8b: 28.9716 seconds
2024-09-18 12:45:18,055 Saving results with gpu monitoring
2024-09-18 12:45:18,057 Latency for request bf2604c2 with model llama3-8b: 28.9408 seconds
2024-09-18 12:45:18,057 Saving results with gpu monitoring
2024-09-18 12:45:18,059 Latency for request 8ec3949a with model llama3-8b: 28.8839 seconds
2024-09-18 12:45:18,059 Saving results with gpu monitoring
2024-09-18 12:45:18,061 Latency for request 53c94983 with model llama3-8b: 28.7758 seconds
2024-09-18 12:45:18,061 Saving results with gpu monitoring
2024-09-18 12:45:18,063 Latency for request 0c3dea4b with model llama3-8b: 28.7523 seconds
2024-09-18 12:45:18,063 Saving results with gpu monitoring
2024-09-18 12:45:18,065 Latency for request 91e2ddc6 with model llama3-8b: 28.3744 seconds
2024-09-18 12:45:18,065 Saving results with gpu monitoring
2024-09-18 12:45:18,068 Latency for request 2b718042 with model llama3-8b: 27.9926 seconds
2024-09-18 12:45:18,068 Saving results with gpu monitoring
2024-09-18 12:45:18,070 Latency for request 621d0683 with model llama3-8b: 27.9357 seconds
2024-09-18 12:45:18,070 Saving results with gpu monitoring
2024-09-18 12:45:18,072 Latency for request 7682f9ff with model llama3-8b: 26.7216 seconds
2024-09-18 12:45:18,072 Saving results with gpu monitoring
2024-09-18 12:45:18,074 Latency for request 8769488b with model llama3-8b: 26.5810 seconds
2024-09-18 12:45:18,075 Saving results with gpu monitoring
2024-09-18 12:45:18,077 Latency for request 44a1f014 with model llama3-8b: 26.1862 seconds
2024-09-18 12:45:18,077 Saving results with gpu monitoring
2024-09-18 12:45:18,080 Request with ID 84bb742c for model gemma-7b received
2024-09-18 12:45:18,080 Latency for request 6e7cdb5d with model llama3-8b: 26.1608 seconds
2024-09-18 12:45:18,081 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,081 Saving results with gpu monitoring
2024-09-18 12:45:18,083 Latency for request 9169b0ac with model llama3-8b: 25.8733 seconds
2024-09-18 12:45:18,083 Saving results with gpu monitoring
2024-09-18 12:45:18,085 Latency for request d2ca71f7 with model llama3-8b: 25.5952 seconds
2024-09-18 12:45:18,085 Saving results with gpu monitoring
2024-09-18 12:45:18,087 Latency for request eab55a44 with model llama3-8b: 25.5531 seconds
2024-09-18 12:45:18,087 Saving results with gpu monitoring
2024-09-18 12:45:18,090 Latency for request bd2c6196 with model llama3-8b: 25.4734 seconds
2024-09-18 12:45:18,090 Saving results with gpu monitoring
2024-09-18 12:45:18,092 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,092 Next: call load_model for granite-7b
2024-09-18 12:45:18,183 Unloaded previous model
2024-09-18 12:45:18,187 Request with ID f704344b for model llama3-8b received
2024-09-18 12:45:18,187 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,235 Request with ID da4a19dc for model gemma-7b received
2024-09-18 12:45:18,236 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,288 Request with ID 43ff91ed for model gemma-7b received
2024-09-18 12:45:18,294 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,312 Request with ID f149e190 for model granite-7b received
2024-09-18 12:45:18,315 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,378 Request with ID 7b8854c3 for model llama3-8b received
2024-09-18 12:45:18,379 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,485 Request with ID 3a9b80a2 for model granite-7b received
2024-09-18 12:45:18,486 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,497 Request with ID 30edbdf5 for model granite-7b received
2024-09-18 12:45:18,498 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,506 Request with ID 03486cdd for model gemma-7b received
2024-09-18 12:45:18,510 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,560 Request with ID 53eb523d for model granite-7b received
2024-09-18 12:45:18,562 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,673 Request with ID 8a78066d for model llama3-8b received
2024-09-18 12:45:18,676 Request with ID 3f164b0e for model llama3-8b received
2024-09-18 12:45:18,677 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,769 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,802 Request with ID 2b4f38ab for model granite-7b received
2024-09-18 12:45:18,807 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:18,951 Request with ID 342fb24b for model llama3-8b received
2024-09-18 12:45:18,958 127.0.0.1 - - [18/Sep/2024 12:45:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:19,027 Request with ID 085b4db1 for model llama3-8b received
2024-09-18 12:45:19,126 127.0.0.1 - - [18/Sep/2024 12:45:19] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:19,127 Request with ID e15aefd6 for model llama3-8b received
2024-09-18 12:45:19,132 127.0.0.1 - - [18/Sep/2024 12:45:19] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:19,437 Request with ID 05128d74 for model llama3-8b received
2024-09-18 12:45:19,437 Batch size condition met for model llama3-8b
2024-09-18 12:45:19,500 Request with ID ba3ca5ab for model gemma-7b received
2024-09-18 12:45:19,501 127.0.0.1 - - [18/Sep/2024 12:45:19] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:19,590 Request with ID b8e0f114 for model granite-7b received
2024-09-18 12:45:19,590 127.0.0.1 - - [18/Sep/2024 12:45:19] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:19,592 Request with ID d8cf85a9 for model llama3-8b received
2024-09-18 12:45:19,593 127.0.0.1 - - [18/Sep/2024 12:45:19] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:19,865 Request with ID 43844f2c for model granite-7b received
2024-09-18 12:45:19,865 127.0.0.1 - - [18/Sep/2024 12:45:19] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:20,122 Request with ID 70fad6b1 for model llama3-8b received
2024-09-18 12:45:20,123 127.0.0.1 - - [18/Sep/2024 12:45:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:20,138 Request with ID edab1244 for model llama3-8b received
2024-09-18 12:45:20,138 127.0.0.1 - - [18/Sep/2024 12:45:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:20,234 Request with ID daca1889 for model llama3-8b received
2024-09-18 12:45:20,234 127.0.0.1 - - [18/Sep/2024 12:45:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:20,369 Request with ID 0e02fdcb for model granite-7b received
2024-09-18 12:45:20,369 127.0.0.1 - - [18/Sep/2024 12:45:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:20,382 Request with ID 88b42b15 for model gemma-7b received
2024-09-18 12:45:20,382 127.0.0.1 - - [18/Sep/2024 12:45:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:20,566 Request with ID 35e1ad52 for model gemma-7b received
2024-09-18 12:45:20,567 127.0.0.1 - - [18/Sep/2024 12:45:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:20,641 Request with ID aa84633e for model llama3-8b received
2024-09-18 12:45:20,641 127.0.0.1 - - [18/Sep/2024 12:45:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:20,692 Request with ID 3119f8de for model granite-7b received
2024-09-18 12:45:20,692 127.0.0.1 - - [18/Sep/2024 12:45:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:20,716 Request with ID 4a039fc7 for model gemma-7b received
2024-09-18 12:45:20,716 127.0.0.1 - - [18/Sep/2024 12:45:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:20,757 Request with ID 33e4983a for model granite-7b received
2024-09-18 12:45:20,758 127.0.0.1 - - [18/Sep/2024 12:45:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:20,959 Request with ID 91742c9d for model llama3-8b received
2024-09-18 12:45:20,960 127.0.0.1 - - [18/Sep/2024 12:45:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:21,003 Request with ID d5bdc53a for model llama3-8b received
2024-09-18 12:45:21,003 127.0.0.1 - - [18/Sep/2024 12:45:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:21,064 Request with ID 689c7739 for model llama3-8b received
2024-09-18 12:45:21,065 127.0.0.1 - - [18/Sep/2024 12:45:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:21,126 Request with ID 74c721d1 for model gemma-7b received
2024-09-18 12:45:21,126 127.0.0.1 - - [18/Sep/2024 12:45:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:21,146 Request with ID 01dbe041 for model gemma-7b received
2024-09-18 12:45:21,146 127.0.0.1 - - [18/Sep/2024 12:45:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:21,149 Request with ID 343f6efc for model granite-7b received
2024-09-18 12:45:21,149 127.0.0.1 - - [18/Sep/2024 12:45:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:21,303 Request with ID 2c6fd4f0 for model gemma-7b received
2024-09-18 12:45:21,304 127.0.0.1 - - [18/Sep/2024 12:45:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:21,329 Request with ID 399e3c6d for model granite-7b received
2024-09-18 12:45:21,329 127.0.0.1 - - [18/Sep/2024 12:45:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:21,350 Request with ID 45fd2eb1 for model granite-7b received
2024-09-18 12:45:21,350 127.0.0.1 - - [18/Sep/2024 12:45:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:21,367 Request with ID 3e7ba59e for model llama3-8b received
2024-09-18 12:45:21,368 127.0.0.1 - - [18/Sep/2024 12:45:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:21,949 Request with ID a45e7cb6 for model granite-7b received
2024-09-18 12:45:21,949 127.0.0.1 - - [18/Sep/2024 12:45:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:21,987 Request with ID 366d4bf4 for model llama3-8b received
2024-09-18 12:45:21,987 127.0.0.1 - - [18/Sep/2024 12:45:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:22,044 Request with ID 16b43112 for model llama3-8b received
2024-09-18 12:45:22,045 127.0.0.1 - - [18/Sep/2024 12:45:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:22,090 Request with ID 15c5ae65 for model granite-7b received
2024-09-18 12:45:22,091 127.0.0.1 - - [18/Sep/2024 12:45:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:22,155 Request with ID b4b41af2 for model granite-7b received
2024-09-18 12:45:22,156 127.0.0.1 - - [18/Sep/2024 12:45:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:22,306 Request with ID 228a5fc8 for model gemma-7b received
2024-09-18 12:45:22,307 127.0.0.1 - - [18/Sep/2024 12:45:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:22,366 Request with ID 4eead919 for model gemma-7b received
2024-09-18 12:45:22,366 127.0.0.1 - - [18/Sep/2024 12:45:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:22,450 Request with ID 7f22d86e for model granite-7b received
2024-09-18 12:45:22,450 127.0.0.1 - - [18/Sep/2024 12:45:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:22,491 Request with ID ffd06874 for model llama3-8b received
2024-09-18 12:45:22,491 127.0.0.1 - - [18/Sep/2024 12:45:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:22,633 Request with ID 93f96826 for model gemma-7b received
2024-09-18 12:45:22,633 127.0.0.1 - - [18/Sep/2024 12:45:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:22,862 Request with ID 6eec405a for model llama3-8b received
2024-09-18 12:45:22,863 127.0.0.1 - - [18/Sep/2024 12:45:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:22,880 Request with ID e8e474ff for model llama3-8b received
2024-09-18 12:45:22,881 127.0.0.1 - - [18/Sep/2024 12:45:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:22,990 Request with ID e3d23149 for model granite-7b received
2024-09-18 12:45:22,991 127.0.0.1 - - [18/Sep/2024 12:45:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:23,016 Request with ID e3630ffd for model llama3-8b received
2024-09-18 12:45:23,017 127.0.0.1 - - [18/Sep/2024 12:45:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:23,130 Request with ID 3708ae69 for model gemma-7b received
2024-09-18 12:45:23,131 127.0.0.1 - - [18/Sep/2024 12:45:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:23,173 Request with ID d97a0e1a for model gemma-7b received
2024-09-18 12:45:23,173 127.0.0.1 - - [18/Sep/2024 12:45:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:23,339 Request with ID 221c1317 for model gemma-7b received
2024-09-18 12:45:23,339 127.0.0.1 - - [18/Sep/2024 12:45:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:23,433 Request with ID e09c5dc3 for model granite-7b received
2024-09-18 12:45:23,434 127.0.0.1 - - [18/Sep/2024 12:45:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:23,448 Request with ID 1c450750 for model llama3-8b received
2024-09-18 12:45:23,449 127.0.0.1 - - [18/Sep/2024 12:45:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:23,489 Request with ID 51e7f6f2 for model llama3-8b received
2024-09-18 12:45:23,490 127.0.0.1 - - [18/Sep/2024 12:45:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:23,593 Request with ID 240ead73 for model granite-7b received
2024-09-18 12:45:23,594 127.0.0.1 - - [18/Sep/2024 12:45:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:23,804 Request with ID 2f79a749 for model gemma-7b received
2024-09-18 12:45:23,805 127.0.0.1 - - [18/Sep/2024 12:45:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:24,029 Request with ID cb5216d6 for model llama3-8b received
2024-09-18 12:45:24,030 127.0.0.1 - - [18/Sep/2024 12:45:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:24,061 Request with ID b4235ebe for model llama3-8b received
2024-09-18 12:45:24,061 127.0.0.1 - - [18/Sep/2024 12:45:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:24,152 Request with ID 17e4ba70 for model granite-7b received
2024-09-18 12:45:24,152 127.0.0.1 - - [18/Sep/2024 12:45:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:24,195 Request with ID 197446c7 for model gemma-7b received
2024-09-18 12:45:24,196 127.0.0.1 - - [18/Sep/2024 12:45:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:24,242 Request with ID e99d36fc for model llama3-8b received
2024-09-18 12:45:24,242 127.0.0.1 - - [18/Sep/2024 12:45:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:24,541 Request with ID 2b58f245 for model granite-7b received
2024-09-18 12:45:24,541 127.0.0.1 - - [18/Sep/2024 12:45:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:24,745 Request with ID 36b94a11 for model gemma-7b received
2024-09-18 12:45:24,745 127.0.0.1 - - [18/Sep/2024 12:45:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:24,809 Request with ID 7abc5ccb for model granite-7b received
2024-09-18 12:45:24,810 127.0.0.1 - - [18/Sep/2024 12:45:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:24,876 Request with ID b67cc351 for model gemma-7b received
2024-09-18 12:45:24,877 127.0.0.1 - - [18/Sep/2024 12:45:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:24,978 Request with ID 436fab7e for model gemma-7b received
2024-09-18 12:45:24,979 127.0.0.1 - - [18/Sep/2024 12:45:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:25,160 Request with ID 7fade5a6 for model gemma-7b received
2024-09-18 12:45:25,161 127.0.0.1 - - [18/Sep/2024 12:45:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:25,237 Request with ID eefbdfba for model llama3-8b received
2024-09-18 12:45:25,237 127.0.0.1 - - [18/Sep/2024 12:45:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:25,411 Request with ID e1cfafcb for model granite-7b received
2024-09-18 12:45:25,412 127.0.0.1 - - [18/Sep/2024 12:45:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:25,444 Request with ID d9d471f7 for model granite-7b received
2024-09-18 12:45:25,444 127.0.0.1 - - [18/Sep/2024 12:45:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:25,517 Request with ID 4d3045d5 for model llama3-8b received
2024-09-18 12:45:25,517 127.0.0.1 - - [18/Sep/2024 12:45:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:25,528 Request with ID 4155f248 for model granite-7b received
2024-09-18 12:45:25,528 Batch size condition met for model granite-7b
2024-09-18 12:45:25,560 Request with ID e3bfd7b5 for model llama3-8b received
2024-09-18 12:45:25,560 127.0.0.1 - - [18/Sep/2024 12:45:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:25,654 Request with ID ed8b8e6f for model granite-7b received
2024-09-18 12:45:25,654 127.0.0.1 - - [18/Sep/2024 12:45:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:25,723 Request with ID cdf4d324 for model granite-7b received
2024-09-18 12:45:25,724 127.0.0.1 - - [18/Sep/2024 12:45:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:25,779 Request with ID e7f5e4b7 for model gemma-7b received
2024-09-18 12:45:25,779 127.0.0.1 - - [18/Sep/2024 12:45:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:25,836 Request with ID 51a44ee4 for model gemma-7b received
2024-09-18 12:45:25,837 127.0.0.1 - - [18/Sep/2024 12:45:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:25,972 Request with ID 893ce371 for model llama3-8b received
2024-09-18 12:45:25,972 127.0.0.1 - - [18/Sep/2024 12:45:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:26,001 Request with ID 26f86f9a for model llama3-8b received
2024-09-18 12:45:26,001 127.0.0.1 - - [18/Sep/2024 12:45:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:26,036 Request with ID eee0185e for model llama3-8b received
2024-09-18 12:45:26,036 127.0.0.1 - - [18/Sep/2024 12:45:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:26,073 Request with ID e08f505a for model gemma-7b received
2024-09-18 12:45:26,073 127.0.0.1 - - [18/Sep/2024 12:45:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:26,257 Request with ID df3c2842 for model gemma-7b received
2024-09-18 12:45:26,257 127.0.0.1 - - [18/Sep/2024 12:45:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:26,272 Request with ID c6b85048 for model gemma-7b received
2024-09-18 12:45:26,272 Batch size condition met for model gemma-7b
2024-09-18 12:45:26,275 Request with ID 87434d29 for model llama3-8b received
2024-09-18 12:45:26,275 127.0.0.1 - - [18/Sep/2024 12:45:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:26,465 Request with ID 80debefa for model llama3-8b received
2024-09-18 12:45:26,465 127.0.0.1 - - [18/Sep/2024 12:45:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:26,506 Request with ID df4894f3 for model gemma-7b received
2024-09-18 12:45:26,506 127.0.0.1 - - [18/Sep/2024 12:45:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:26,519 Request with ID 0f2f981f for model granite-7b received
2024-09-18 12:45:26,519 127.0.0.1 - - [18/Sep/2024 12:45:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:26,589 Request with ID 98335a1c for model gemma-7b received
2024-09-18 12:45:26,590 127.0.0.1 - - [18/Sep/2024 12:45:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:26,653 Request with ID 4a1b8f9a for model gemma-7b received
2024-09-18 12:45:26,654 127.0.0.1 - - [18/Sep/2024 12:45:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:26,816 Request with ID a41179c1 for model llama3-8b received
2024-09-18 12:45:26,817 127.0.0.1 - - [18/Sep/2024 12:45:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:26,848 Request with ID c05fefae for model llama3-8b received
2024-09-18 12:45:26,849 127.0.0.1 - - [18/Sep/2024 12:45:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:27,100 Request with ID 35006261 for model gemma-7b received
2024-09-18 12:45:27,101 127.0.0.1 - - [18/Sep/2024 12:45:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:27,219 Request with ID b690a875 for model llama3-8b received
2024-09-18 12:45:27,219 127.0.0.1 - - [18/Sep/2024 12:45:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:27,228 Request with ID 2c0ee3cb for model llama3-8b received
2024-09-18 12:45:27,228 Batch size condition met for model llama3-8b
2024-09-18 12:45:27,363 Request with ID f849cb7e for model granite-7b received
2024-09-18 12:45:27,363 127.0.0.1 - - [18/Sep/2024 12:45:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:27,482 Request with ID b12b255f for model granite-7b received
2024-09-18 12:45:27,482 127.0.0.1 - - [18/Sep/2024 12:45:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:27,716 Request with ID eaf0a03b for model llama3-8b received
2024-09-18 12:45:27,717 127.0.0.1 - - [18/Sep/2024 12:45:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:27,836 Request with ID 4770d92c for model granite-7b received
2024-09-18 12:45:27,836 127.0.0.1 - - [18/Sep/2024 12:45:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:27,949 Request with ID 91000838 for model llama3-8b received
2024-09-18 12:45:27,949 127.0.0.1 - - [18/Sep/2024 12:45:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:28,685 Request with ID d61475bc for model granite-7b received
2024-09-18 12:45:28,686 127.0.0.1 - - [18/Sep/2024 12:45:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:28,750 Request with ID ec958fa2 for model gemma-7b received
2024-09-18 12:45:28,751 127.0.0.1 - - [18/Sep/2024 12:45:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:28,764 Request with ID 8947d2ac for model llama3-8b received
2024-09-18 12:45:28,764 127.0.0.1 - - [18/Sep/2024 12:45:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:29,024 Request with ID 46465a36 for model llama3-8b received
2024-09-18 12:45:29,025 127.0.0.1 - - [18/Sep/2024 12:45:29] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:29,316 Request with ID 28eb7418 for model llama3-8b received
2024-09-18 12:45:29,316 127.0.0.1 - - [18/Sep/2024 12:45:29] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:29,378 Request with ID edaf3b44 for model gemma-7b received
2024-09-18 12:45:29,379 127.0.0.1 - - [18/Sep/2024 12:45:29] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:29,484 Request with ID f62b98d6 for model llama3-8b received
2024-09-18 12:45:29,484 127.0.0.1 - - [18/Sep/2024 12:45:29] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:29,567 Request with ID 73397042 for model llama3-8b received
2024-09-18 12:45:29,568 127.0.0.1 - - [18/Sep/2024 12:45:29] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:29,688 Request with ID 922d0f9c for model llama3-8b received
2024-09-18 12:45:29,689 127.0.0.1 - - [18/Sep/2024 12:45:29] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:29,694 Request with ID e592842f for model gemma-7b received
2024-09-18 12:45:29,695 127.0.0.1 - - [18/Sep/2024 12:45:29] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:29,735 Request with ID ad748335 for model granite-7b received
2024-09-18 12:45:29,736 127.0.0.1 - - [18/Sep/2024 12:45:29] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:29,833 Request with ID 9ec3b640 for model llama3-8b received
2024-09-18 12:45:29,833 127.0.0.1 - - [18/Sep/2024 12:45:29] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:30,039 Request with ID 8e62dfa6 for model llama3-8b received
2024-09-18 12:45:30,039 127.0.0.1 - - [18/Sep/2024 12:45:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:30,059 Request with ID 1e33d6f4 for model llama3-8b received
2024-09-18 12:45:30,059 127.0.0.1 - - [18/Sep/2024 12:45:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:30,068 Request with ID 95f5a841 for model granite-7b received
2024-09-18 12:45:30,068 127.0.0.1 - - [18/Sep/2024 12:45:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:30,216 Request with ID 0455c3fc for model gemma-7b received
2024-09-18 12:45:30,217 127.0.0.1 - - [18/Sep/2024 12:45:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:30,283 Request with ID a3051842 for model llama3-8b received
2024-09-18 12:45:30,283 127.0.0.1 - - [18/Sep/2024 12:45:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:30,335 Request with ID d4beceeb for model llama3-8b received
2024-09-18 12:45:30,336 127.0.0.1 - - [18/Sep/2024 12:45:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:30,393 Request with ID 3d8dafbb for model granite-7b received
2024-09-18 12:45:30,393 127.0.0.1 - - [18/Sep/2024 12:45:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:30,420 Request with ID 1de1045d for model granite-7b received
2024-09-18 12:45:30,421 127.0.0.1 - - [18/Sep/2024 12:45:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:30,466 Request with ID 304ab630 for model gemma-7b received
2024-09-18 12:45:30,467 127.0.0.1 - - [18/Sep/2024 12:45:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:30,494 Request with ID faf1b7d8 for model granite-7b received
2024-09-18 12:45:30,494 127.0.0.1 - - [18/Sep/2024 12:45:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:30,739 Request with ID 0c3690e5 for model granite-7b received
2024-09-18 12:45:30,739 127.0.0.1 - - [18/Sep/2024 12:45:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:30,750 Request with ID 567b8e15 for model llama3-8b received
2024-09-18 12:45:30,750 127.0.0.1 - - [18/Sep/2024 12:45:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:31,052 Request with ID 73eeeb9b for model granite-7b received
2024-09-18 12:45:31,053 127.0.0.1 - - [18/Sep/2024 12:45:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:31,062 Request with ID 03897b3b for model llama3-8b received
2024-09-18 12:45:31,062 127.0.0.1 - - [18/Sep/2024 12:45:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:31,276 Request with ID 85d539d0 for model llama3-8b received
2024-09-18 12:45:31,276 127.0.0.1 - - [18/Sep/2024 12:45:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:31,512 Request with ID b0eb3294 for model llama3-8b received
2024-09-18 12:45:31,512 127.0.0.1 - - [18/Sep/2024 12:45:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:31,564 Request with ID 35c5bdb8 for model granite-7b received
2024-09-18 12:45:31,564 127.0.0.1 - - [18/Sep/2024 12:45:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:31,744 Request with ID 297f6c21 for model gemma-7b received
2024-09-18 12:45:31,745 127.0.0.1 - - [18/Sep/2024 12:45:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:31,750 Request with ID 4189edc3 for model gemma-7b received
2024-09-18 12:45:31,750 127.0.0.1 - - [18/Sep/2024 12:45:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:31,755 Request with ID c73f1323 for model gemma-7b received
2024-09-18 12:45:31,755 127.0.0.1 - - [18/Sep/2024 12:45:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:31,918 Request with ID 9d872985 for model llama3-8b received
2024-09-18 12:45:31,919 127.0.0.1 - - [18/Sep/2024 12:45:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:31,944 Request with ID cf41b81a for model llama3-8b received
2024-09-18 12:45:31,944 127.0.0.1 - - [18/Sep/2024 12:45:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:32,037 Request with ID c4adbf13 for model granite-7b received
2024-09-18 12:45:32,037 127.0.0.1 - - [18/Sep/2024 12:45:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:32,068 Request with ID 960f51a7 for model gemma-7b received
2024-09-18 12:45:32,068 127.0.0.1 - - [18/Sep/2024 12:45:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:32,162 Loaded model granite-7b
2024-09-18 12:45:32,165 Batch processing started for model granite-7b
2024-09-18 12:45:32,631 Request with ID ab0ea91b for model llama3-8b received
2024-09-18 12:45:32,632 127.0.0.1 - - [18/Sep/2024 12:45:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:32,657 Request with ID 7e2a48ef for model llama3-8b received
2024-09-18 12:45:32,657 127.0.0.1 - - [18/Sep/2024 12:45:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:32,661 Request with ID 58a0479a for model gemma-7b received
2024-09-18 12:45:32,662 127.0.0.1 - - [18/Sep/2024 12:45:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:32,860 Request with ID 26be1a8f for model granite-7b received
2024-09-18 12:45:32,860 127.0.0.1 - - [18/Sep/2024 12:45:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:32,910 Request with ID 1160c7d2 for model granite-7b received
2024-09-18 12:45:32,911 127.0.0.1 - - [18/Sep/2024 12:45:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:33,132 Request with ID b55b1b27 for model gemma-7b received
2024-09-18 12:45:33,133 127.0.0.1 - - [18/Sep/2024 12:45:33] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:33,332 Request with ID 022a8979 for model llama3-8b received
2024-09-18 12:45:33,333 127.0.0.1 - - [18/Sep/2024 12:45:33] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:33,441 Request with ID c72e6dd5 for model llama3-8b received
2024-09-18 12:45:33,442 127.0.0.1 - - [18/Sep/2024 12:45:33] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:33,475 Request with ID 8ccd0a3b for model gemma-7b received
2024-09-18 12:45:33,475 127.0.0.1 - - [18/Sep/2024 12:45:33] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:33,507 Request with ID b3b87390 for model gemma-7b received
2024-09-18 12:45:33,507 127.0.0.1 - - [18/Sep/2024 12:45:33] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:33,585 Request with ID 7ba2def7 for model granite-7b received
2024-09-18 12:45:33,585 127.0.0.1 - - [18/Sep/2024 12:45:33] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:33,812 Request with ID 175218ea for model granite-7b received
2024-09-18 12:45:33,812 127.0.0.1 - - [18/Sep/2024 12:45:33] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:33,818 Request with ID 78a26289 for model gemma-7b received
2024-09-18 12:45:33,819 127.0.0.1 - - [18/Sep/2024 12:45:33] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:33,911 Request with ID 011bedea for model gemma-7b received
2024-09-18 12:45:33,912 127.0.0.1 - - [18/Sep/2024 12:45:33] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:33,991 Request with ID 87593103 for model granite-7b received
2024-09-18 12:45:33,992 127.0.0.1 - - [18/Sep/2024 12:45:33] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:34,125 Request with ID c81fc778 for model llama3-8b received
2024-09-18 12:45:34,126 127.0.0.1 - - [18/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:34,330 Request with ID c794a4c0 for model granite-7b received
2024-09-18 12:45:34,330 127.0.0.1 - - [18/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:34,347 Request with ID 7bbb4221 for model granite-7b received
2024-09-18 12:45:34,348 127.0.0.1 - - [18/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:34,532 Request with ID 4b50ace2 for model gemma-7b received
2024-09-18 12:45:34,532 127.0.0.1 - - [18/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:34,543 Request with ID 1b53ba9d for model llama3-8b received
2024-09-18 12:45:34,543 127.0.0.1 - - [18/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:34,759 Request with ID b52cd727 for model gemma-7b received
2024-09-18 12:45:34,759 127.0.0.1 - - [18/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:34,824 Request with ID 44c28ffb for model llama3-8b received
2024-09-18 12:45:34,825 Request with ID 035affc3 for model llama3-8b received
2024-09-18 12:45:34,826 127.0.0.1 - - [18/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:34,827 Request with ID b4d18ff6 for model granite-7b received
2024-09-18 12:45:34,827 127.0.0.1 - - [18/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:34,828 127.0.0.1 - - [18/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:34,857 Request with ID e995611b for model granite-7b received
2024-09-18 12:45:34,857 127.0.0.1 - - [18/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:34,955 Request with ID b147e5af for model granite-7b received
2024-09-18 12:45:34,955 127.0.0.1 - - [18/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:35,057 Request with ID c22edfe8 for model granite-7b received
2024-09-18 12:45:35,057 127.0.0.1 - - [18/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:35,210 Request with ID 54b50fb8 for model llama3-8b received
2024-09-18 12:45:35,210 127.0.0.1 - - [18/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:35,355 Request with ID 7b61ec01 for model granite-7b received
2024-09-18 12:45:35,355 127.0.0.1 - - [18/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:35,686 Request with ID 78315964 for model llama3-8b received
2024-09-18 12:45:35,686 127.0.0.1 - - [18/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:35,933 Processed batch: ['166d4b4a', '68a4b740', '50d8cf24', 'fe5dee07', '2b6b84de', '2e8ae35d', 'f7988183', 'fae3441e', 'f81fa311', 'cbae2a3b', '7480db65', '5276ada1', '5f071292', '9d477895', '0fa8d1e2', 'a11285ed', 'bfb5f59d', 'e42da10b', '02097880', '00b0e555', '71c4863d', 'fdba957d', 'e6b4fb0a', '60182587', '23d7d190', 'fc57c661', '753df4c4', '585c80bc', 'd7a37bba', 'd5410524', 'b98c6c0d', '7c21097d'] with model granite-7b in 3.7677 seconds
2024-09-18 12:45:35,933 Saving sys info
2024-09-18 12:45:35,957 Request with ID c28d96fa for model gemma-7b received
2024-09-18 12:45:35,957 127.0.0.1 - - [18/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:35,965 Latency for request 166d4b4a with model granite-7b: 29.7020 seconds
2024-09-18 12:45:35,965 Saving results with gpu monitoring
2024-09-18 12:45:35,968 Latency for request 68a4b740 with model granite-7b: 29.6253 seconds
2024-09-18 12:45:35,968 Saving results with gpu monitoring
2024-09-18 12:45:35,970 Latency for request 50d8cf24 with model granite-7b: 29.4157 seconds
2024-09-18 12:45:35,970 Saving results with gpu monitoring
2024-09-18 12:45:35,972 Latency for request fe5dee07 with model granite-7b: 29.1043 seconds
2024-09-18 12:45:35,972 Saving results with gpu monitoring
2024-09-18 12:45:35,974 Latency for request 2b6b84de with model granite-7b: 29.0184 seconds
2024-09-18 12:45:35,974 Saving results with gpu monitoring
2024-09-18 12:45:35,976 Latency for request 2e8ae35d with model granite-7b: 28.6465 seconds
2024-09-18 12:45:35,976 Saving results with gpu monitoring
2024-09-18 12:45:35,978 Latency for request f7988183 with model granite-7b: 28.5914 seconds
2024-09-18 12:45:35,978 Saving results with gpu monitoring
2024-09-18 12:45:35,980 Latency for request fae3441e with model granite-7b: 27.8359 seconds
2024-09-18 12:45:35,980 Saving results with gpu monitoring
2024-09-18 12:45:35,982 Latency for request f81fa311 with model granite-7b: 27.5965 seconds
2024-09-18 12:45:35,982 Saving results with gpu monitoring
2024-09-18 12:45:35,984 Latency for request cbae2a3b with model granite-7b: 27.3717 seconds
2024-09-18 12:45:35,984 Saving results with gpu monitoring
2024-09-18 12:45:35,986 Latency for request 7480db65 with model granite-7b: 26.4211 seconds
2024-09-18 12:45:35,986 Saving results with gpu monitoring
2024-09-18 12:45:35,988 Latency for request 5276ada1 with model granite-7b: 25.6002 seconds
2024-09-18 12:45:35,988 Saving results with gpu monitoring
2024-09-18 12:45:35,990 Latency for request 5f071292 with model granite-7b: 25.3059 seconds
2024-09-18 12:45:35,990 Saving results with gpu monitoring
2024-09-18 12:45:35,992 Latency for request 9d477895 with model granite-7b: 25.2908 seconds
2024-09-18 12:45:35,992 Saving results with gpu monitoring
2024-09-18 12:45:35,994 Latency for request 0fa8d1e2 with model granite-7b: 24.8118 seconds
2024-09-18 12:45:35,994 Saving results with gpu monitoring
2024-09-18 12:45:35,996 Latency for request a11285ed with model granite-7b: 24.5577 seconds
2024-09-18 12:45:35,996 Saving results with gpu monitoring
2024-09-18 12:45:35,998 Latency for request bfb5f59d with model granite-7b: 24.3963 seconds
2024-09-18 12:45:35,998 Saving results with gpu monitoring
2024-09-18 12:45:36,000 Latency for request e42da10b with model granite-7b: 24.3276 seconds
2024-09-18 12:45:36,000 Saving results with gpu monitoring
2024-09-18 12:45:36,002 Latency for request 02097880 with model granite-7b: 23.8519 seconds
2024-09-18 12:45:36,002 Saving results with gpu monitoring
2024-09-18 12:45:36,004 Latency for request 00b0e555 with model granite-7b: 23.6227 seconds
2024-09-18 12:45:36,004 Saving results with gpu monitoring
2024-09-18 12:45:36,006 Latency for request 71c4863d with model granite-7b: 22.9171 seconds
2024-09-18 12:45:36,006 Saving results with gpu monitoring
2024-09-18 12:45:36,008 Latency for request fdba957d with model granite-7b: 22.7792 seconds
2024-09-18 12:45:36,008 Saving results with gpu monitoring
2024-09-18 12:45:36,010 Latency for request e6b4fb0a with model granite-7b: 22.7779 seconds
2024-09-18 12:45:36,010 Saving results with gpu monitoring
2024-09-18 12:45:36,012 Latency for request 60182587 with model granite-7b: 22.2830 seconds
2024-09-18 12:45:36,012 Saving results with gpu monitoring
2024-09-18 12:45:36,014 Latency for request 23d7d190 with model granite-7b: 22.0753 seconds
2024-09-18 12:45:36,014 Saving results with gpu monitoring
2024-09-18 12:45:36,016 Latency for request fc57c661 with model granite-7b: 22.0605 seconds
2024-09-18 12:45:36,016 Saving results with gpu monitoring
2024-09-18 12:45:36,018 Latency for request 753df4c4 with model granite-7b: 21.7965 seconds
2024-09-18 12:45:36,018 Saving results with gpu monitoring
2024-09-18 12:45:36,020 Latency for request 585c80bc with model granite-7b: 20.9664 seconds
2024-09-18 12:45:36,020 Saving results with gpu monitoring
2024-09-18 12:45:36,022 Latency for request d7a37bba with model granite-7b: 19.9713 seconds
2024-09-18 12:45:36,022 Saving results with gpu monitoring
2024-09-18 12:45:36,023 Latency for request d5410524 with model granite-7b: 19.6956 seconds
2024-09-18 12:45:36,024 Saving results with gpu monitoring
2024-09-18 12:45:36,025 Latency for request b98c6c0d with model granite-7b: 19.5614 seconds
2024-09-18 12:45:36,026 Saving results with gpu monitoring
2024-09-18 12:45:36,027 Latency for request 7c21097d with model granite-7b: 19.1826 seconds
2024-09-18 12:45:36,027 Saving results with gpu monitoring
2024-09-18 12:45:36,030 127.0.0.1 - - [18/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:36,030 Next: call load_model for gemma-7b
2024-09-18 12:45:36,126 Unloaded previous model
2024-09-18 12:45:36,628 Request with ID b121a2a0 for model gemma-7b received
2024-09-18 12:45:36,630 Request with ID d539339c for model gemma-7b received
2024-09-18 12:45:36,631 127.0.0.1 - - [18/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:36,632 127.0.0.1 - - [18/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:36,654 Request with ID 55ad6bc7 for model granite-7b received
2024-09-18 12:45:36,655 127.0.0.1 - - [18/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:36,662 Request with ID ef4a5aa3 for model llama3-8b received
2024-09-18 12:45:36,663 127.0.0.1 - - [18/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:37,022 Request with ID 2be08791 for model llama3-8b received
2024-09-18 12:45:37,025 127.0.0.1 - - [18/Sep/2024 12:45:37] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:37,202 Request with ID fe23aaa7 for model granite-7b received
2024-09-18 12:45:37,224 127.0.0.1 - - [18/Sep/2024 12:45:37] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:37,229 Request with ID 1693e132 for model gemma-7b received
2024-09-18 12:45:37,237 127.0.0.1 - - [18/Sep/2024 12:45:37] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:37,238 Request with ID 65e4f5df for model llama3-8b received
2024-09-18 12:45:37,249 Batch size condition met for model llama3-8b
2024-09-18 12:45:37,250 Request with ID 20fbd95f for model granite-7b received
2024-09-18 12:45:37,254 127.0.0.1 - - [18/Sep/2024 12:45:37] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:37,548 Request with ID 91b82238 for model llama3-8b received
2024-09-18 12:45:37,550 127.0.0.1 - - [18/Sep/2024 12:45:37] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:37,697 Request with ID a0d62449 for model gemma-7b received
2024-09-18 12:45:37,702 127.0.0.1 - - [18/Sep/2024 12:45:37] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:37,914 Request with ID 55fafc74 for model llama3-8b received
2024-09-18 12:45:37,915 127.0.0.1 - - [18/Sep/2024 12:45:37] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:38,058 Request with ID 0d4a28ee for model granite-7b received
2024-09-18 12:45:38,058 Batch size condition met for model granite-7b
2024-09-18 12:45:38,300 Request with ID faa1e72e for model llama3-8b received
2024-09-18 12:45:38,301 127.0.0.1 - - [18/Sep/2024 12:45:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:38,636 Request with ID b549fe39 for model granite-7b received
2024-09-18 12:45:38,637 127.0.0.1 - - [18/Sep/2024 12:45:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:38,696 Request with ID 54469744 for model granite-7b received
2024-09-18 12:45:38,696 127.0.0.1 - - [18/Sep/2024 12:45:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:38,737 Request with ID 59760480 for model llama3-8b received
2024-09-18 12:45:38,737 127.0.0.1 - - [18/Sep/2024 12:45:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:38,876 Request with ID 999b6427 for model granite-7b received
2024-09-18 12:45:38,877 127.0.0.1 - - [18/Sep/2024 12:45:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:38,983 Request with ID 4809bc0f for model llama3-8b received
2024-09-18 12:45:38,983 127.0.0.1 - - [18/Sep/2024 12:45:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,048 Request with ID 3dbc681c for model gemma-7b received
2024-09-18 12:45:39,049 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,072 Request with ID d951b758 for model llama3-8b received
2024-09-18 12:45:39,072 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,134 Request with ID a960f3a0 for model llama3-8b received
2024-09-18 12:45:39,135 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,234 Request with ID e841923d for model granite-7b received
2024-09-18 12:45:39,235 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,480 Request with ID 0b35dac3 for model llama3-8b received
2024-09-18 12:45:39,480 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,501 Request with ID cde15789 for model granite-7b received
2024-09-18 12:45:39,502 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,503 Request with ID b72a1ba7 for model granite-7b received
2024-09-18 12:45:39,504 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,527 Request with ID b94d2e3c for model llama3-8b received
2024-09-18 12:45:39,527 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,636 Request with ID 5e9485ec for model gemma-7b received
2024-09-18 12:45:39,637 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,797 Request with ID 20d7ce3f for model granite-7b received
2024-09-18 12:45:39,798 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,815 Request with ID 67e58a9f for model gemma-7b received
2024-09-18 12:45:39,815 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,866 Request with ID 14e261ef for model llama3-8b received
2024-09-18 12:45:39,867 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:39,960 Request with ID 983ea687 for model llama3-8b received
2024-09-18 12:45:39,960 127.0.0.1 - - [18/Sep/2024 12:45:39] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:40,080 Request with ID 923b1205 for model gemma-7b received
2024-09-18 12:45:40,081 127.0.0.1 - - [18/Sep/2024 12:45:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:40,321 Request with ID b162fe51 for model gemma-7b received
2024-09-18 12:45:40,321 127.0.0.1 - - [18/Sep/2024 12:45:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:40,461 Request with ID 792cc180 for model granite-7b received
2024-09-18 12:45:40,461 127.0.0.1 - - [18/Sep/2024 12:45:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:40,472 Request with ID f22998ea for model llama3-8b received
2024-09-18 12:45:40,473 127.0.0.1 - - [18/Sep/2024 12:45:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:40,543 Request with ID c8ce604d for model granite-7b received
2024-09-18 12:45:40,543 127.0.0.1 - - [18/Sep/2024 12:45:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:40,626 Request with ID c67deab2 for model gemma-7b received
2024-09-18 12:45:40,627 Batch size condition met for model gemma-7b
2024-09-18 12:45:40,806 Request with ID 815efb6a for model granite-7b received
2024-09-18 12:45:40,807 127.0.0.1 - - [18/Sep/2024 12:45:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:40,808 Request with ID 1efb221d for model granite-7b received
2024-09-18 12:45:40,809 127.0.0.1 - - [18/Sep/2024 12:45:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:40,852 Request with ID 82bd1d29 for model llama3-8b received
2024-09-18 12:45:40,852 127.0.0.1 - - [18/Sep/2024 12:45:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:40,867 Request with ID bed2ffc5 for model gemma-7b received
2024-09-18 12:45:40,867 127.0.0.1 - - [18/Sep/2024 12:45:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:40,987 Request with ID 8d5bcb51 for model gemma-7b received
2024-09-18 12:45:40,987 127.0.0.1 - - [18/Sep/2024 12:45:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:40,991 Request with ID cbb41ea9 for model granite-7b received
2024-09-18 12:45:40,991 127.0.0.1 - - [18/Sep/2024 12:45:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:41,297 Request with ID 76f982eb for model llama3-8b received
2024-09-18 12:45:41,297 127.0.0.1 - - [18/Sep/2024 12:45:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:41,524 Request with ID 1f2fdb9a for model gemma-7b received
2024-09-18 12:45:41,525 127.0.0.1 - - [18/Sep/2024 12:45:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:41,622 Request with ID 299fbddc for model granite-7b received
2024-09-18 12:45:41,623 127.0.0.1 - - [18/Sep/2024 12:45:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:41,748 Request with ID 5e998807 for model gemma-7b received
2024-09-18 12:45:41,749 127.0.0.1 - - [18/Sep/2024 12:45:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:41,847 Request with ID 0921d4d7 for model gemma-7b received
2024-09-18 12:45:41,847 127.0.0.1 - - [18/Sep/2024 12:45:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:41,942 Request with ID 0729ce8c for model llama3-8b received
2024-09-18 12:45:41,943 127.0.0.1 - - [18/Sep/2024 12:45:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:42,170 Request with ID 69e600fe for model gemma-7b received
2024-09-18 12:45:42,170 127.0.0.1 - - [18/Sep/2024 12:45:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:42,341 Request with ID 43c9f19b for model llama3-8b received
2024-09-18 12:45:42,342 127.0.0.1 - - [18/Sep/2024 12:45:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:42,446 Request with ID ceda6c41 for model gemma-7b received
2024-09-18 12:45:42,447 127.0.0.1 - - [18/Sep/2024 12:45:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:42,505 Request with ID 900360b9 for model granite-7b received
2024-09-18 12:45:42,506 127.0.0.1 - - [18/Sep/2024 12:45:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:42,572 Request with ID 67197b8e for model gemma-7b received
2024-09-18 12:45:42,572 127.0.0.1 - - [18/Sep/2024 12:45:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:42,613 Request with ID eb27341f for model granite-7b received
2024-09-18 12:45:42,613 127.0.0.1 - - [18/Sep/2024 12:45:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:42,635 Request with ID 8d87770e for model llama3-8b received
2024-09-18 12:45:42,635 127.0.0.1 - - [18/Sep/2024 12:45:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:42,654 Request with ID 0bb51ae2 for model gemma-7b received
2024-09-18 12:45:42,654 127.0.0.1 - - [18/Sep/2024 12:45:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:42,763 Request with ID d7026499 for model granite-7b received
2024-09-18 12:45:42,764 127.0.0.1 - - [18/Sep/2024 12:45:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:42,833 Request with ID c97c623b for model llama3-8b received
2024-09-18 12:45:42,833 127.0.0.1 - - [18/Sep/2024 12:45:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:42,949 Request with ID c51a93c3 for model gemma-7b received
2024-09-18 12:45:42,949 127.0.0.1 - - [18/Sep/2024 12:45:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:42,952 Request with ID c1796430 for model llama3-8b received
2024-09-18 12:45:42,952 127.0.0.1 - - [18/Sep/2024 12:45:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:43,016 Request with ID d95b6256 for model llama3-8b received
2024-09-18 12:45:43,017 127.0.0.1 - - [18/Sep/2024 12:45:43] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:43,071 Request with ID 6596fc3c for model granite-7b received
2024-09-18 12:45:43,072 127.0.0.1 - - [18/Sep/2024 12:45:43] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:43,114 Request with ID 76b4565d for model gemma-7b received
2024-09-18 12:45:43,115 127.0.0.1 - - [18/Sep/2024 12:45:43] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:43,668 Request with ID 257d0bbe for model llama3-8b received
2024-09-18 12:45:43,669 Request with ID c77eb333 for model granite-7b received
2024-09-18 12:45:43,669 127.0.0.1 - - [18/Sep/2024 12:45:43] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:43,670 127.0.0.1 - - [18/Sep/2024 12:45:43] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:43,697 Request with ID f2befa9f for model gemma-7b received
2024-09-18 12:45:43,697 127.0.0.1 - - [18/Sep/2024 12:45:43] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:43,807 Request with ID c00374d4 for model llama3-8b received
2024-09-18 12:45:43,807 127.0.0.1 - - [18/Sep/2024 12:45:43] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:43,841 Request with ID 8362fc59 for model llama3-8b received
2024-09-18 12:45:43,841 127.0.0.1 - - [18/Sep/2024 12:45:43] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:43,940 Request with ID fcd468c5 for model llama3-8b received
2024-09-18 12:45:43,941 127.0.0.1 - - [18/Sep/2024 12:45:43] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:43,969 Request with ID 1deece03 for model gemma-7b received
2024-09-18 12:45:43,969 127.0.0.1 - - [18/Sep/2024 12:45:43] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:43,989 Request with ID 85f494e8 for model gemma-7b received
2024-09-18 12:45:43,990 127.0.0.1 - - [18/Sep/2024 12:45:43] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:44,347 Request with ID ecfc42a7 for model granite-7b received
2024-09-18 12:45:44,348 127.0.0.1 - - [18/Sep/2024 12:45:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:44,542 Request with ID e3778034 for model gemma-7b received
2024-09-18 12:45:44,542 127.0.0.1 - - [18/Sep/2024 12:45:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:44,552 Request with ID abed5c12 for model llama3-8b received
2024-09-18 12:45:44,552 127.0.0.1 - - [18/Sep/2024 12:45:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:44,645 Request with ID 716725e4 for model gemma-7b received
2024-09-18 12:45:44,646 127.0.0.1 - - [18/Sep/2024 12:45:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:44,654 Request with ID 5a9e7e05 for model gemma-7b received
2024-09-18 12:45:44,654 127.0.0.1 - - [18/Sep/2024 12:45:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:44,853 Request with ID 0222b3a8 for model llama3-8b received
2024-09-18 12:45:44,853 127.0.0.1 - - [18/Sep/2024 12:45:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:44,942 Request with ID 99372514 for model granite-7b received
2024-09-18 12:45:44,942 127.0.0.1 - - [18/Sep/2024 12:45:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:44,969 Request with ID 5367397a for model gemma-7b received
2024-09-18 12:45:44,969 127.0.0.1 - - [18/Sep/2024 12:45:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:45,011 Request with ID 1155a583 for model gemma-7b received
2024-09-18 12:45:45,011 127.0.0.1 - - [18/Sep/2024 12:45:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:45,124 Request with ID 0f4817b4 for model granite-7b received
2024-09-18 12:45:45,124 127.0.0.1 - - [18/Sep/2024 12:45:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:45,155 Request with ID 75b71c2e for model granite-7b received
2024-09-18 12:45:45,156 127.0.0.1 - - [18/Sep/2024 12:45:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:45:45,171 Waiting for running processes to finish
2024-09-18 12:45:46,173 Waiting for running processes to finish
2024-09-18 12:45:47,175 Waiting for running processes to finish
2024-09-18 12:45:48,176 Waiting for running processes to finish
2024-09-18 12:45:49,178 Waiting for running processes to finish
2024-09-18 12:45:50,179 Waiting for running processes to finish
2024-09-18 12:45:51,181 Waiting for running processes to finish
2024-09-18 12:45:52,182 Waiting for running processes to finish
2024-09-18 12:45:53,184 Waiting for running processes to finish
2024-09-18 12:45:54,186 Waiting for running processes to finish
2024-09-18 12:45:55,187 Waiting for running processes to finish
2024-09-18 12:45:56,189 Waiting for running processes to finish
2024-09-18 12:45:57,190 Waiting for running processes to finish
2024-09-18 12:45:58,192 Waiting for running processes to finish
2024-09-18 12:45:59,193 Waiting for running processes to finish
2024-09-18 12:45:59,466 Loaded model gemma-7b
2024-09-18 12:45:59,469 Batch processing started for model gemma-7b
2024-09-18 12:46:00,195 Waiting for running processes to finish
2024-09-18 12:46:01,197 Waiting for running processes to finish
2024-09-18 12:46:02,198 Waiting for running processes to finish
2024-09-18 12:46:03,158 Processed batch: ['7bbfe16a', '2c7a03e0', 'f2dc4c38', '0b41b0d4', '84bb742c', 'da4a19dc', '43ff91ed', '03486cdd', 'ba3ca5ab', '88b42b15', '35e1ad52', '4a039fc7', '74c721d1', '01dbe041', '2c6fd4f0', '228a5fc8', '4eead919', '93f96826', '3708ae69', 'd97a0e1a', '221c1317', '2f79a749', '197446c7', '36b94a11', 'b67cc351', '436fab7e', '7fade5a6', 'e7f5e4b7', '51a44ee4', 'e08f505a', 'df3c2842', 'c6b85048'] with model gemma-7b in 3.6886 seconds
2024-09-18 12:46:03,158 Saving sys info
2024-09-18 12:46:03,192 Latency for request 7bbfe16a with model gemma-7b: 46.2814 seconds
2024-09-18 12:46:03,192 Saving results with gpu monitoring
2024-09-18 12:46:03,196 Latency for request 2c7a03e0 with model gemma-7b: 46.1414 seconds
2024-09-18 12:46:03,196 Saving results with gpu monitoring
2024-09-18 12:46:03,198 Latency for request f2dc4c38 with model gemma-7b: 45.8681 seconds
2024-09-18 12:46:03,198 Saving results with gpu monitoring
2024-09-18 12:46:03,200 Latency for request 0b41b0d4 with model gemma-7b: 45.6492 seconds
2024-09-18 12:46:03,200 Saving results with gpu monitoring
2024-09-18 12:46:03,202 Waiting for running processes to finish
2024-09-18 12:46:03,203 Latency for request 84bb742c with model gemma-7b: 45.0780 seconds
2024-09-18 12:46:03,203 Saving results with gpu monitoring
2024-09-18 12:46:03,205 Latency for request da4a19dc with model gemma-7b: 44.9225 seconds
2024-09-18 12:46:03,205 Saving results with gpu monitoring
2024-09-18 12:46:03,207 Latency for request 43ff91ed with model gemma-7b: 44.8694 seconds
2024-09-18 12:46:03,207 Saving results with gpu monitoring
2024-09-18 12:46:03,209 Latency for request 03486cdd with model gemma-7b: 44.6514 seconds
2024-09-18 12:46:03,209 Saving results with gpu monitoring
2024-09-18 12:46:03,211 Latency for request ba3ca5ab with model gemma-7b: 43.6574 seconds
2024-09-18 12:46:03,211 Saving results with gpu monitoring
2024-09-18 12:46:03,213 Latency for request 88b42b15 with model gemma-7b: 42.7755 seconds
2024-09-18 12:46:03,213 Saving results with gpu monitoring
2024-09-18 12:46:03,215 Latency for request 35e1ad52 with model gemma-7b: 42.5912 seconds
2024-09-18 12:46:03,215 Saving results with gpu monitoring
2024-09-18 12:46:03,217 Latency for request 4a039fc7 with model gemma-7b: 42.4419 seconds
2024-09-18 12:46:03,217 Saving results with gpu monitoring
2024-09-18 12:46:03,219 Latency for request 74c721d1 with model gemma-7b: 42.0319 seconds
2024-09-18 12:46:03,219 Saving results with gpu monitoring
2024-09-18 12:46:03,220 Latency for request 01dbe041 with model gemma-7b: 42.0118 seconds
2024-09-18 12:46:03,221 Saving results with gpu monitoring
2024-09-18 12:46:03,222 Latency for request 2c6fd4f0 with model gemma-7b: 41.8544 seconds
2024-09-18 12:46:03,223 Saving results with gpu monitoring
2024-09-18 12:46:03,224 Latency for request 228a5fc8 with model gemma-7b: 40.8513 seconds
2024-09-18 12:46:03,224 Saving results with gpu monitoring
2024-09-18 12:46:03,226 Latency for request 4eead919 with model gemma-7b: 40.7917 seconds
2024-09-18 12:46:03,226 Saving results with gpu monitoring
2024-09-18 12:46:03,228 Latency for request 93f96826 with model gemma-7b: 40.5246 seconds
2024-09-18 12:46:03,228 Saving results with gpu monitoring
2024-09-18 12:46:03,230 Latency for request 3708ae69 with model gemma-7b: 40.0274 seconds
2024-09-18 12:46:03,230 Saving results with gpu monitoring
2024-09-18 12:46:03,232 Latency for request d97a0e1a with model gemma-7b: 39.9850 seconds
2024-09-18 12:46:03,232 Saving results with gpu monitoring
2024-09-18 12:46:03,234 Latency for request 221c1317 with model gemma-7b: 39.8190 seconds
2024-09-18 12:46:03,234 Saving results with gpu monitoring
2024-09-18 12:46:03,236 Latency for request 2f79a749 with model gemma-7b: 39.3534 seconds
2024-09-18 12:46:03,236 Saving results with gpu monitoring
2024-09-18 12:46:03,238 Latency for request 197446c7 with model gemma-7b: 38.9623 seconds
2024-09-18 12:46:03,238 Saving results with gpu monitoring
2024-09-18 12:46:03,240 Latency for request 36b94a11 with model gemma-7b: 38.4128 seconds
2024-09-18 12:46:03,240 Saving results with gpu monitoring
2024-09-18 12:46:03,242 Latency for request b67cc351 with model gemma-7b: 38.2811 seconds
2024-09-18 12:46:03,242 Saving results with gpu monitoring
2024-09-18 12:46:03,244 Latency for request 436fab7e with model gemma-7b: 38.1794 seconds
2024-09-18 12:46:03,244 Saving results with gpu monitoring
2024-09-18 12:46:03,246 Latency for request 7fade5a6 with model gemma-7b: 37.9974 seconds
2024-09-18 12:46:03,246 Saving results with gpu monitoring
2024-09-18 12:46:03,248 Latency for request e7f5e4b7 with model gemma-7b: 37.3789 seconds
2024-09-18 12:46:03,248 Saving results with gpu monitoring
2024-09-18 12:46:03,250 Latency for request 51a44ee4 with model gemma-7b: 37.3215 seconds
2024-09-18 12:46:03,250 Saving results with gpu monitoring
2024-09-18 12:46:03,252 Latency for request e08f505a with model gemma-7b: 37.0849 seconds
2024-09-18 12:46:03,252 Saving results with gpu monitoring
2024-09-18 12:46:03,254 Latency for request df3c2842 with model gemma-7b: 36.9006 seconds
2024-09-18 12:46:03,254 Saving results with gpu monitoring
2024-09-18 12:46:03,256 Latency for request c6b85048 with model gemma-7b: 36.8858 seconds
2024-09-18 12:46:03,256 Saving results with gpu monitoring
2024-09-18 12:46:03,258 127.0.0.1 - - [18/Sep/2024 12:46:03] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:46:03,259 Next: call load_model for granite-7b
2024-09-18 12:46:03,368 Unloaded previous model
2024-09-18 12:46:04,204 Waiting for running processes to finish
2024-09-18 12:46:05,205 Waiting for running processes to finish
2024-09-18 12:46:06,207 Waiting for running processes to finish
2024-09-18 12:46:07,209 Waiting for running processes to finish
2024-09-18 12:46:08,210 Waiting for running processes to finish
2024-09-18 12:46:09,265 Waiting for running processes to finish
2024-09-18 12:46:10,267 Waiting for running processes to finish
2024-09-18 12:46:11,269 Waiting for running processes to finish
2024-09-18 12:46:12,270 Waiting for running processes to finish
2024-09-18 12:46:13,272 Waiting for running processes to finish
2024-09-18 12:46:14,185 Loaded model granite-7b
2024-09-18 12:46:14,188 Batch processing started for model granite-7b
2024-09-18 12:46:14,273 Waiting for running processes to finish
2024-09-18 12:46:15,275 Waiting for running processes to finish
2024-09-18 12:46:16,277 Waiting for running processes to finish
2024-09-18 12:46:17,278 Waiting for running processes to finish
2024-09-18 12:46:17,863 Processed batch: ['ed8b8e6f', 'cdf4d324', '0f2f981f', 'f849cb7e', 'b12b255f', '4770d92c', 'd61475bc', 'ad748335', '95f5a841', '3d8dafbb', '1de1045d', 'faf1b7d8', '0c3690e5', '73eeeb9b', '35c5bdb8', 'c4adbf13', '26be1a8f', '1160c7d2', '7ba2def7', '175218ea', '87593103', 'c794a4c0', '7bbb4221', 'b4d18ff6', 'e995611b', 'b147e5af', 'c22edfe8', '7b61ec01', '55ad6bc7', 'fe23aaa7', '20fbd95f', '0d4a28ee'] with model granite-7b in 3.6759 seconds
2024-09-18 12:46:17,864 Saving sys info
2024-09-18 12:46:17,896 Latency for request ed8b8e6f with model granite-7b: 52.2098 seconds
2024-09-18 12:46:17,896 Saving results with gpu monitoring
2024-09-18 12:46:17,899 Latency for request cdf4d324 with model granite-7b: 52.1401 seconds
2024-09-18 12:46:17,899 Saving results with gpu monitoring
2024-09-18 12:46:17,901 Latency for request 0f2f981f with model granite-7b: 51.3446 seconds
2024-09-18 12:46:17,901 Saving results with gpu monitoring
2024-09-18 12:46:17,903 Latency for request f849cb7e with model granite-7b: 50.5009 seconds
2024-09-18 12:46:17,903 Saving results with gpu monitoring
2024-09-18 12:46:17,905 Latency for request b12b255f with model granite-7b: 50.3819 seconds
2024-09-18 12:46:17,905 Saving results with gpu monitoring
2024-09-18 12:46:17,907 Latency for request 4770d92c with model granite-7b: 50.0275 seconds
2024-09-18 12:46:17,907 Saving results with gpu monitoring
2024-09-18 12:46:17,909 Latency for request d61475bc with model granite-7b: 49.1783 seconds
2024-09-18 12:46:17,909 Saving results with gpu monitoring
2024-09-18 12:46:17,911 Latency for request ad748335 with model granite-7b: 48.1282 seconds
2024-09-18 12:46:17,911 Saving results with gpu monitoring
2024-09-18 12:46:17,913 Latency for request 95f5a841 with model granite-7b: 47.7960 seconds
2024-09-18 12:46:17,913 Saving results with gpu monitoring
2024-09-18 12:46:17,915 Latency for request 3d8dafbb with model granite-7b: 47.4707 seconds
2024-09-18 12:46:17,915 Saving results with gpu monitoring
2024-09-18 12:46:17,917 Latency for request 1de1045d with model granite-7b: 47.4432 seconds
2024-09-18 12:46:17,917 Saving results with gpu monitoring
2024-09-18 12:46:17,919 Latency for request faf1b7d8 with model granite-7b: 47.3696 seconds
2024-09-18 12:46:17,919 Saving results with gpu monitoring
2024-09-18 12:46:17,921 Latency for request 0c3690e5 with model granite-7b: 47.1249 seconds
2024-09-18 12:46:17,921 Saving results with gpu monitoring
2024-09-18 12:46:17,923 Latency for request 73eeeb9b with model granite-7b: 46.8111 seconds
2024-09-18 12:46:17,923 Saving results with gpu monitoring
2024-09-18 12:46:17,925 Latency for request 35c5bdb8 with model granite-7b: 46.2996 seconds
2024-09-18 12:46:17,925 Saving results with gpu monitoring
2024-09-18 12:46:17,927 Latency for request c4adbf13 with model granite-7b: 45.8268 seconds
2024-09-18 12:46:17,927 Saving results with gpu monitoring
2024-09-18 12:46:17,929 Latency for request 26be1a8f with model granite-7b: 45.0035 seconds
2024-09-18 12:46:17,929 Saving results with gpu monitoring
2024-09-18 12:46:17,931 Latency for request 1160c7d2 with model granite-7b: 44.9533 seconds
2024-09-18 12:46:17,931 Saving results with gpu monitoring
2024-09-18 12:46:17,933 Latency for request 7ba2def7 with model granite-7b: 44.2788 seconds
2024-09-18 12:46:17,933 Saving results with gpu monitoring
2024-09-18 12:46:17,935 Latency for request 175218ea with model granite-7b: 44.0515 seconds
2024-09-18 12:46:17,935 Saving results with gpu monitoring
2024-09-18 12:46:17,937 Latency for request 87593103 with model granite-7b: 43.8725 seconds
2024-09-18 12:46:17,937 Saving results with gpu monitoring
2024-09-18 12:46:17,939 Latency for request c794a4c0 with model granite-7b: 43.5339 seconds
2024-09-18 12:46:17,939 Saving results with gpu monitoring
2024-09-18 12:46:17,941 Latency for request 7bbb4221 with model granite-7b: 43.5163 seconds
2024-09-18 12:46:17,941 Saving results with gpu monitoring
2024-09-18 12:46:17,943 Latency for request b4d18ff6 with model granite-7b: 43.0366 seconds
2024-09-18 12:46:17,943 Saving results with gpu monitoring
2024-09-18 12:46:17,945 Latency for request e995611b with model granite-7b: 43.0068 seconds
2024-09-18 12:46:17,945 Saving results with gpu monitoring
2024-09-18 12:46:17,947 Latency for request b147e5af with model granite-7b: 42.9086 seconds
2024-09-18 12:46:17,947 Saving results with gpu monitoring
2024-09-18 12:46:17,949 Latency for request c22edfe8 with model granite-7b: 42.8067 seconds
2024-09-18 12:46:17,949 Saving results with gpu monitoring
2024-09-18 12:46:17,951 Latency for request 7b61ec01 with model granite-7b: 42.5087 seconds
2024-09-18 12:46:17,951 Saving results with gpu monitoring
2024-09-18 12:46:17,953 Latency for request 55ad6bc7 with model granite-7b: 41.2090 seconds
2024-09-18 12:46:17,953 Saving results with gpu monitoring
2024-09-18 12:46:17,955 Latency for request fe23aaa7 with model granite-7b: 40.6612 seconds
2024-09-18 12:46:17,955 Saving results with gpu monitoring
2024-09-18 12:46:17,957 Latency for request 20fbd95f with model granite-7b: 40.6132 seconds
2024-09-18 12:46:17,957 Saving results with gpu monitoring
2024-09-18 12:46:17,959 Latency for request 0d4a28ee with model granite-7b: 39.8059 seconds
2024-09-18 12:46:17,959 Saving results with gpu monitoring
2024-09-18 12:46:17,961 127.0.0.1 - - [18/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:46:17,961 Next: call load_model for gemma-7b
2024-09-18 12:46:18,058 Unloaded previous model
2024-09-18 12:46:18,584 Waiting for running processes to finish
2024-09-18 12:46:19,585 Waiting for running processes to finish
2024-09-18 12:46:20,587 Waiting for running processes to finish
2024-09-18 12:46:21,589 Waiting for running processes to finish
2024-09-18 12:46:22,590 Waiting for running processes to finish
2024-09-18 12:46:23,592 Waiting for running processes to finish
2024-09-18 12:46:24,594 Waiting for running processes to finish
2024-09-18 12:46:25,595 Waiting for running processes to finish
2024-09-18 12:46:26,597 Waiting for running processes to finish
2024-09-18 12:46:27,598 Waiting for running processes to finish
2024-09-18 12:46:28,600 Waiting for running processes to finish
2024-09-18 12:46:29,602 Waiting for running processes to finish
2024-09-18 12:46:30,603 Waiting for running processes to finish
2024-09-18 12:46:31,636 Waiting for running processes to finish
2024-09-18 12:46:31,841 Loaded model gemma-7b
2024-09-18 12:46:31,844 Batch processing started for model gemma-7b
2024-09-18 12:46:32,637 Waiting for running processes to finish
2024-09-18 12:46:33,639 Waiting for running processes to finish
2024-09-18 12:46:34,641 Waiting for running processes to finish
2024-09-18 12:46:35,642 Waiting for running processes to finish
2024-09-18 12:46:36,484 Processed batch: ['df4894f3', '98335a1c', '4a1b8f9a', '35006261', 'ec958fa2', 'edaf3b44', 'e592842f', '0455c3fc', '304ab630', '297f6c21', '4189edc3', 'c73f1323', '960f51a7', '58a0479a', 'b55b1b27', '8ccd0a3b', 'b3b87390', '78a26289', '011bedea', '4b50ace2', 'b52cd727', 'c28d96fa', 'b121a2a0', 'd539339c', '1693e132', 'a0d62449', '3dbc681c', '5e9485ec', '67e58a9f', '923b1205', 'b162fe51', 'c67deab2'] with model gemma-7b in 4.6405 seconds
2024-09-18 12:46:36,484 Saving sys info
2024-09-18 12:46:36,516 Latency for request df4894f3 with model gemma-7b: 69.9787 seconds
2024-09-18 12:46:36,516 Saving results with gpu monitoring
2024-09-18 12:46:36,519 Latency for request 98335a1c with model gemma-7b: 69.8952 seconds
2024-09-18 12:46:36,519 Saving results with gpu monitoring
2024-09-18 12:46:36,521 Latency for request 4a1b8f9a with model gemma-7b: 69.8308 seconds
2024-09-18 12:46:36,521 Saving results with gpu monitoring
2024-09-18 12:46:36,523 Latency for request 35006261 with model gemma-7b: 69.3842 seconds
2024-09-18 12:46:36,523 Saving results with gpu monitoring
2024-09-18 12:46:36,525 Latency for request ec958fa2 with model gemma-7b: 67.7338 seconds
2024-09-18 12:46:36,525 Saving results with gpu monitoring
2024-09-18 12:46:36,527 Latency for request edaf3b44 with model gemma-7b: 67.1061 seconds
2024-09-18 12:46:36,527 Saving results with gpu monitoring
2024-09-18 12:46:36,529 Latency for request e592842f with model gemma-7b: 66.7898 seconds
2024-09-18 12:46:36,529 Saving results with gpu monitoring
2024-09-18 12:46:36,531 Latency for request 0455c3fc with model gemma-7b: 66.2679 seconds
2024-09-18 12:46:36,531 Saving results with gpu monitoring
2024-09-18 12:46:36,533 Latency for request 304ab630 with model gemma-7b: 66.0178 seconds
2024-09-18 12:46:36,533 Saving results with gpu monitoring
2024-09-18 12:46:36,535 Latency for request 297f6c21 with model gemma-7b: 64.7398 seconds
2024-09-18 12:46:36,535 Saving results with gpu monitoring
2024-09-18 12:46:36,537 Latency for request 4189edc3 with model gemma-7b: 64.7347 seconds
2024-09-18 12:46:36,537 Saving results with gpu monitoring
2024-09-18 12:46:36,539 Latency for request c73f1323 with model gemma-7b: 64.7296 seconds
2024-09-18 12:46:36,539 Saving results with gpu monitoring
2024-09-18 12:46:36,541 Latency for request 960f51a7 with model gemma-7b: 64.4162 seconds
2024-09-18 12:46:36,541 Saving results with gpu monitoring
2024-09-18 12:46:36,543 Latency for request 58a0479a with model gemma-7b: 63.8231 seconds
2024-09-18 12:46:36,543 Saving results with gpu monitoring
2024-09-18 12:46:36,544 Latency for request b55b1b27 with model gemma-7b: 63.3521 seconds
2024-09-18 12:46:36,545 Saving results with gpu monitoring
2024-09-18 12:46:36,546 Latency for request 8ccd0a3b with model gemma-7b: 63.0091 seconds
2024-09-18 12:46:36,546 Saving results with gpu monitoring
2024-09-18 12:46:36,548 Latency for request b3b87390 with model gemma-7b: 62.9775 seconds
2024-09-18 12:46:36,548 Saving results with gpu monitoring
2024-09-18 12:46:36,550 Latency for request 78a26289 with model gemma-7b: 62.6660 seconds
2024-09-18 12:46:36,550 Saving results with gpu monitoring
2024-09-18 12:46:36,552 Latency for request 011bedea with model gemma-7b: 62.5733 seconds
2024-09-18 12:46:36,552 Saving results with gpu monitoring
2024-09-18 12:46:36,554 Latency for request 4b50ace2 with model gemma-7b: 61.9527 seconds
2024-09-18 12:46:36,554 Saving results with gpu monitoring
2024-09-18 12:46:36,556 Latency for request b52cd727 with model gemma-7b: 61.7256 seconds
2024-09-18 12:46:36,556 Saving results with gpu monitoring
2024-09-18 12:46:36,558 Latency for request c28d96fa with model gemma-7b: 60.5277 seconds
2024-09-18 12:46:36,558 Saving results with gpu monitoring
2024-09-18 12:46:36,560 Latency for request b121a2a0 with model gemma-7b: 59.8562 seconds
2024-09-18 12:46:36,560 Saving results with gpu monitoring
2024-09-18 12:46:36,562 Latency for request d539339c with model gemma-7b: 59.8539 seconds
2024-09-18 12:46:36,562 Saving results with gpu monitoring
2024-09-18 12:46:36,564 Latency for request 1693e132 with model gemma-7b: 59.2555 seconds
2024-09-18 12:46:36,564 Saving results with gpu monitoring
2024-09-18 12:46:36,566 Latency for request a0d62449 with model gemma-7b: 58.7870 seconds
2024-09-18 12:46:36,566 Saving results with gpu monitoring
2024-09-18 12:46:36,568 Latency for request 3dbc681c with model gemma-7b: 57.4360 seconds
2024-09-18 12:46:36,568 Saving results with gpu monitoring
2024-09-18 12:46:36,570 Latency for request 5e9485ec with model gemma-7b: 56.8480 seconds
2024-09-18 12:46:36,570 Saving results with gpu monitoring
2024-09-18 12:46:36,572 Latency for request 67e58a9f with model gemma-7b: 56.6696 seconds
2024-09-18 12:46:36,572 Saving results with gpu monitoring
2024-09-18 12:46:36,574 Latency for request 923b1205 with model gemma-7b: 56.4038 seconds
2024-09-18 12:46:36,574 Saving results with gpu monitoring
2024-09-18 12:46:36,576 Latency for request b162fe51 with model gemma-7b: 56.1637 seconds
2024-09-18 12:46:36,576 Saving results with gpu monitoring
2024-09-18 12:46:36,578 Latency for request c67deab2 with model gemma-7b: 55.8579 seconds
2024-09-18 12:46:36,578 Saving results with gpu monitoring
2024-09-18 12:46:36,580 127.0.0.1 - - [18/Sep/2024 12:46:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:46:36,581 Next: call load_model for llama3-8b
2024-09-18 12:46:36,694 Waiting for running processes to finish
2024-09-18 12:46:36,695 Unloaded previous model
2024-09-18 12:46:37,740 Total time: 111.4095 seconds
2024-09-18 12:46:37,740 Total inference time: 20.3124 seconds
2024-09-18 12:46:37,740 Inference time as percentage of total time: 18.23%
2024-09-18 12:46:37,740 END
2024-09-18 12:46:37,741 127.0.0.1 - - [18/Sep/2024 12:46:37] "POST /inference HTTP/1.1" 200 -
2024-09-18 12:46:55,597 Loaded model llama3-8b
2024-09-18 12:46:55,600 Batch processing started for model llama3-8b
