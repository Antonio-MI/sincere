2024-09-10 10:30:27,507 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.11.77:5000
2024-09-10 10:30:27,507 [33mPress CTRL+C to quit[0m
2024-09-10 10:30:27,581 Request with ID d31720f5 for model gpt2-124m received
2024-09-10 10:30:27,581 Adjusted time limit for model gpt2-124m: 4.7502 seconds
2024-09-10 10:30:27,582 127.0.0.1 - - [10/Sep/2024 10:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:28,078 Request with ID eb26b5ea for model gpt2medium-355m received
2024-09-10 10:30:28,079 Adjusted time limit for model gpt2medium-355m: 1.3550 seconds
2024-09-10 10:30:28,079 127.0.0.1 - - [10/Sep/2024 10:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:28,173 Request with ID 0eca6641 for model gpt2-124m received
2024-09-10 10:30:28,173 127.0.0.1 - - [10/Sep/2024 10:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:28,252 Request with ID 3a695c30 for model gpt2-124m received
2024-09-10 10:30:28,253 127.0.0.1 - - [10/Sep/2024 10:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:28,730 Request with ID a57d0084 for model gpt2-124m received
2024-09-10 10:30:28,730 Batch size condition met for model gpt2-124m
2024-09-10 10:30:28,730 Loading model gpt2-124m
2024-09-10 10:30:29,466 Time limit condition met for model gpt2medium-355m
2024-09-10 10:30:29,529 Processed batch: ['d31720f5', '0eca6641', '3a695c30', 'a57d0084'] with model gpt2-124m in 0.6876 seconds
2024-09-10 10:30:29,529 Latency for request d31720f5 with model gpt2-124m: 1.9487 seconds
2024-09-10 10:30:29,531 Latency for request 0eca6641 with model gpt2-124m: 1.3566 seconds
2024-09-10 10:30:29,532 Latency for request 3a695c30 with model gpt2-124m: 1.2774 seconds
2024-09-10 10:30:29,532 Latency for request a57d0084 with model gpt2-124m: 0.7997 seconds
2024-09-10 10:30:29,532 127.0.0.1 - - [10/Sep/2024 10:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:29,532 Loading model gpt2medium-355m
2024-09-10 10:30:29,722 Request with ID c215db97 for model distilgpt2-124m received
2024-09-10 10:30:29,722 Adjusted time limit for model distilgpt2-124m: 5.6043 seconds
2024-09-10 10:30:29,722 127.0.0.1 - - [10/Sep/2024 10:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:30,635 Request with ID a65d688d for model distilgpt2-124m received
2024-09-10 10:30:30,635 127.0.0.1 - - [10/Sep/2024 10:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:31,484 Request with ID f784ecba for model gpt2medium-355m received
2024-09-10 10:30:31,484 127.0.0.1 - - [10/Sep/2024 10:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:32,072 Request with ID 168bfa6f for model distilgpt2-124m received
2024-09-10 10:30:32,072 127.0.0.1 - - [10/Sep/2024 10:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:32,755 Request with ID 6569d4af for model gpt2medium-355m received
2024-09-10 10:30:32,755 127.0.0.1 - - [10/Sep/2024 10:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:33,488 Request with ID c344cd3d for model gpt2-124m received
2024-09-10 10:30:33,489 Adjusted time limit for model gpt2-124m: 4.7395 seconds
2024-09-10 10:30:33,489 127.0.0.1 - - [10/Sep/2024 10:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:33,670 Processed batch: ['eb26b5ea', '7c75', 'f8f4', '0cfe'] with model gpt2medium-355m in 4.0291 seconds
2024-09-10 10:30:33,670 Latency for request eb26b5ea with model gpt2medium-355m: 5.5914 seconds
2024-09-10 10:30:33,671 Latency for request 7c75 with model gpt2medium-355m: 4.1374 seconds
2024-09-10 10:30:33,671 Latency for request f8f4 with model gpt2medium-355m: 4.1374 seconds
2024-09-10 10:30:33,671 Latency for request 0cfe with model gpt2medium-355m: 4.1374 seconds
2024-09-10 10:30:34,407 Request with ID 1ede6d6b for model gpt2medium-355m received
2024-09-10 10:30:34,407 Adjusted time limit for model gpt2medium-355m: 1.3443 seconds
2024-09-10 10:30:34,407 127.0.0.1 - - [10/Sep/2024 10:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:34,952 Request with ID 0a10fc29 for model gpt2-124m received
2024-09-10 10:30:34,953 127.0.0.1 - - [10/Sep/2024 10:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:35,340 Time limit condition met for model distilgpt2-124m
2024-09-10 10:30:35,341 Loading model distilgpt2-124m
2024-09-10 10:30:35,454 Request with ID 894b86aa for model distilgpt2-124m received
2024-09-10 10:30:35,454 127.0.0.1 - - [10/Sep/2024 10:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:36,626 Processed batch: ['c215db97', 'a65d688d', '168bfa6f', '3288'] with model distilgpt2-124m in 1.2085 seconds
2024-09-10 10:30:36,626 Latency for request c215db97 with model distilgpt2-124m: 6.9040 seconds
2024-09-10 10:30:36,626 Latency for request a65d688d with model distilgpt2-124m: 5.9911 seconds
2024-09-10 10:30:36,627 Latency for request 168bfa6f with model distilgpt2-124m: 4.5538 seconds
2024-09-10 10:30:36,627 Latency for request 3288 with model distilgpt2-124m: 1.2850 seconds
2024-09-10 10:30:36,732 Time limit condition met for model gpt2medium-355m
2024-09-10 10:30:36,732 Loading model gpt2medium-355m
2024-09-10 10:30:37,062 Request with ID c7e4c133 for model gpt2-124m received
2024-09-10 10:30:37,062 127.0.0.1 - - [10/Sep/2024 10:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:38,860 Request with ID ec2d54bb for model gpt2-124m received
2024-09-10 10:30:38,860 Batch size condition met for model gpt2-124m
2024-09-10 10:30:39,340 Processed batch: ['f784ecba', '6569d4af', '1ede6d6b', '03fc'] with model gpt2medium-355m in 2.4693 seconds
2024-09-10 10:30:39,341 Latency for request f784ecba with model gpt2medium-355m: 7.8566 seconds
2024-09-10 10:30:39,342 Latency for request 6569d4af with model gpt2medium-355m: 6.5858 seconds
2024-09-10 10:30:39,342 Latency for request 1ede6d6b with model gpt2medium-355m: 4.9339 seconds
2024-09-10 10:30:39,342 Latency for request 03fc with model gpt2medium-355m: 2.6082 seconds
2024-09-10 10:30:39,342 Loading model gpt2-124m
2024-09-10 10:30:39,959 Request with ID 38b180fd for model distilgpt2-124m received
2024-09-10 10:30:39,959 Adjusted time limit for model distilgpt2-124m: 5.6082 seconds
2024-09-10 10:30:39,959 127.0.0.1 - - [10/Sep/2024 10:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:40,306 Processed batch: ['c344cd3d', '0a10fc29', 'c7e4c133', 'ec2d54bb'] with model gpt2-124m in 0.8938 seconds
2024-09-10 10:30:40,306 Latency for request c344cd3d with model gpt2-124m: 6.8179 seconds
2024-09-10 10:30:40,307 Latency for request 0a10fc29 with model gpt2-124m: 5.3542 seconds
2024-09-10 10:30:40,308 Latency for request c7e4c133 with model gpt2-124m: 3.2442 seconds
2024-09-10 10:30:40,308 Latency for request ec2d54bb with model gpt2-124m: 1.4464 seconds
2024-09-10 10:30:40,308 127.0.0.1 - - [10/Sep/2024 10:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:44,185 Request with ID 753b7756 for model gpt2-124m received
2024-09-10 10:30:44,185 Adjusted time limit for model gpt2-124m: 4.7434 seconds
2024-09-10 10:30:44,186 127.0.0.1 - - [10/Sep/2024 10:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:45,576 Time limit condition met for model distilgpt2-124m
2024-09-10 10:30:45,576 Loading model distilgpt2-124m
2024-09-10 10:30:46,050 Request with ID 603fd7ac for model gpt2medium-355m received
2024-09-10 10:30:46,050 Adjusted time limit for model gpt2medium-355m: 1.3487 seconds
2024-09-10 10:30:46,050 127.0.0.1 - - [10/Sep/2024 10:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:46,291 Processed batch: ['894b86aa', '38b180fd', 'a279', '0c57'] with model distilgpt2-124m in 0.6432 seconds
2024-09-10 10:30:46,291 Latency for request 894b86aa with model distilgpt2-124m: 10.8375 seconds
2024-09-10 10:30:46,292 Latency for request 38b180fd with model distilgpt2-124m: 6.3321 seconds
2024-09-10 10:30:46,293 Latency for request a279 with model distilgpt2-124m: 0.7151 seconds
2024-09-10 10:30:46,293 Latency for request 0c57 with model distilgpt2-124m: 0.7151 seconds
2024-09-10 10:30:47,440 Time limit condition met for model gpt2medium-355m
2024-09-10 10:30:47,441 Loading model gpt2medium-355m
2024-09-10 10:30:47,464 Request with ID d0904347 for model gpt2medium-355m received
2024-09-10 10:30:47,464 127.0.0.1 - - [10/Sep/2024 10:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:48,408 Request with ID b76f2890 for model gpt2medium-355m received
2024-09-10 10:30:48,408 127.0.0.1 - - [10/Sep/2024 10:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:50,106 Processed batch: ['603fd7ac', 'cf24', 'b7ac', '4ad9'] with model gpt2medium-355m in 2.5204 seconds
2024-09-10 10:30:50,106 Latency for request 603fd7ac with model gpt2medium-355m: 4.0556 seconds
2024-09-10 10:30:50,107 Latency for request cf24 with model gpt2medium-355m: 2.6650 seconds
2024-09-10 10:30:50,107 Latency for request b7ac with model gpt2medium-355m: 2.6649 seconds
2024-09-10 10:30:50,107 Latency for request 4ad9 with model gpt2medium-355m: 2.6649 seconds
2024-09-10 10:30:50,142 Request with ID 9ca4641f for model gpt2medium-355m received
2024-09-10 10:30:50,143 Adjusted time limit for model gpt2medium-355m: 1.3443 seconds
2024-09-10 10:30:50,143 127.0.0.1 - - [10/Sep/2024 10:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:50,212 Time limit condition met for model gpt2-124m
2024-09-10 10:30:50,213 Loading model gpt2-124m
2024-09-10 10:30:51,032 Processed batch: ['753b7756', '77e3', '6661', 'be07'] with model gpt2-124m in 0.7523 seconds
2024-09-10 10:30:51,032 Latency for request 753b7756 with model gpt2-124m: 6.8474 seconds
2024-09-10 10:30:51,033 Latency for request 77e3 with model gpt2-124m: 0.8194 seconds
2024-09-10 10:30:51,034 Latency for request 6661 with model gpt2-124m: 0.8194 seconds
2024-09-10 10:30:51,034 Latency for request be07 with model gpt2-124m: 0.8194 seconds
2024-09-10 10:30:51,205 Request with ID e386bbbf for model gpt2-124m received
2024-09-10 10:30:51,205 Adjusted time limit for model gpt2-124m: 4.7434 seconds
2024-09-10 10:30:51,205 127.0.0.1 - - [10/Sep/2024 10:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:51,553 Time limit condition met for model gpt2medium-355m
2024-09-10 10:30:51,554 Loading model gpt2medium-355m
2024-09-10 10:30:51,814 Request with ID 0f510334 for model distilgpt2-124m received
2024-09-10 10:30:51,814 Adjusted time limit for model distilgpt2-124m: 5.6043 seconds
2024-09-10 10:30:51,815 127.0.0.1 - - [10/Sep/2024 10:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:53,406 Request with ID 732385e7 for model distilgpt2-124m received
2024-09-10 10:30:53,406 127.0.0.1 - - [10/Sep/2024 10:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:54,383 Processed batch: ['d0904347', 'b76f2890', '9ca4641f', '1361'] with model gpt2medium-355m in 2.6865 seconds
2024-09-10 10:30:54,383 Latency for request d0904347 with model gpt2medium-355m: 6.9189 seconds
2024-09-10 10:30:54,384 Latency for request b76f2890 with model gpt2medium-355m: 5.9749 seconds
2024-09-10 10:30:54,384 Latency for request 9ca4641f with model gpt2medium-355m: 4.2404 seconds
2024-09-10 10:30:54,384 Latency for request 1361 with model gpt2medium-355m: 2.8290 seconds
2024-09-10 10:30:54,761 Request with ID 776efeff for model distilgpt2-124m received
2024-09-10 10:30:54,761 127.0.0.1 - - [10/Sep/2024 10:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:54,952 Request with ID 3ca72663 for model gpt2-124m received
2024-09-10 10:30:54,953 127.0.0.1 - - [10/Sep/2024 10:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 10:30:56,036 Time limit condition met for model gpt2-124m
2024-09-10 10:30:56,036 Loading model gpt2-124m
2024-09-10 10:30:57,016 Processed batch: ['e386bbbf', '3ca72663', '2265', '726c'] with model gpt2-124m in 0.9128 seconds
2024-09-10 10:30:57,016 Latency for request e386bbbf with model gpt2-124m: 5.8115 seconds
2024-09-10 10:30:57,017 Latency for request 3ca72663 with model gpt2-124m: 2.0640 seconds
2024-09-10 10:30:57,018 Latency for request 2265 with model gpt2-124m: 0.9801 seconds
2024-09-10 10:30:57,018 Latency for request 726c with model gpt2-124m: 0.9801 seconds
2024-09-10 10:30:57,438 Time limit condition met for model distilgpt2-124m
2024-09-10 10:30:57,438 Loading model distilgpt2-124m
2024-09-10 10:30:58,186 Processed batch: ['0f510334', '732385e7', '776efeff', 'e544'] with model distilgpt2-124m in 0.6761 seconds
2024-09-10 10:30:58,186 Latency for request 0f510334 with model distilgpt2-124m: 6.3719 seconds
2024-09-10 10:30:58,187 Latency for request 732385e7 with model distilgpt2-124m: 4.7800 seconds
2024-09-10 10:30:58,187 Latency for request 776efeff with model distilgpt2-124m: 3.4255 seconds
2024-09-10 10:30:58,187 Latency for request e544 with model distilgpt2-124m: 0.7479 seconds
