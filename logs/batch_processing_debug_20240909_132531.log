2024-09-09 13:25:31,394 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.212:5000
2024-09-09 13:25:31,394 [33mPress CTRL+C to quit[0m
2024-09-09 13:25:40,649 Current time: 1725902740.6499
2024-09-09 13:25:40,649 Model gpt2-124m loading time: 0.0741 seconds, unloading time: 0.0000 seconds
2024-09-09 13:25:40,650 Adjusted time limit: 4.9511 seconds
2024-09-09 13:25:40,650 Timer for model gpt2-124m set to fire at: 1725902745.6010
2024-09-09 13:25:40,650 127.0.0.1 - - [09/Sep/2024 13:25:40] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:43,128 Current time: 1725902743.1280
2024-09-09 13:25:43,128 Model gpt2-124m loading time: 0.0741 seconds, unloading time: 0.0000 seconds
2024-09-09 13:25:43,128 Adjusted time limit: 4.9511 seconds
2024-09-09 13:25:43,128 Timer for model gpt2-124m set to fire at: 1725902745.6010
2024-09-09 13:25:43,129 127.0.0.1 - - [09/Sep/2024 13:25:43] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:44,121 Current time: 1725902744.1218
2024-09-09 13:25:44,122 Model gpt2medium-355m loading time: 0.0616 seconds, unloading time: 0.0000 seconds
2024-09-09 13:25:44,122 Adjusted time limit: 2.3610 seconds
2024-09-09 13:25:44,122 Timer for model gpt2medium-355m set to fire at: 1725902746.4828
2024-09-09 13:25:44,123 127.0.0.1 - - [09/Sep/2024 13:25:44] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:44,308 Current time: 1725902744.3087
2024-09-09 13:25:44,309 Model gpt2-124m loading time: 0.0741 seconds, unloading time: 0.0000 seconds
2024-09-09 13:25:44,309 Adjusted time limit: 4.9511 seconds
2024-09-09 13:25:44,309 Timer for model gpt2-124m set to fire at: 1725902745.6010
2024-09-09 13:25:44,310 127.0.0.1 - - [09/Sep/2024 13:25:44] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:45,418 Current time: 1725902745.4187
2024-09-09 13:25:45,419 Model gpt2-124m loading time: 0.0741 seconds, unloading time: 0.0000 seconds
2024-09-09 13:25:45,419 Adjusted time limit: 4.9511 seconds
2024-09-09 13:25:45,419 Timer for model gpt2-124m set to fire at: 1725902745.6010
2024-09-09 13:25:45,420 Batch size condition met for model gpt2-124m
2024-09-09 13:25:45,420 4
2024-09-09 13:25:45,420 Loading model gpt2-124m
2024-09-09 13:25:45,524 Batch processing started at 361524.5370 for model gpt2-124m
2024-09-09 13:25:45,610 Time limit reached for model gpt2-124m at 1725902745.6100
2024-09-09 13:25:45,715 Time limit reached for model gpt2-124m at 1725902745.7152
2024-09-09 13:25:45,820 Time limit reached for model gpt2-124m at 1725902745.8204
2024-09-09 13:25:45,925 Time limit reached for model gpt2-124m at 1725902745.9255
2024-09-09 13:25:46,030 Time limit reached for model gpt2-124m at 1725902746.0307
2024-09-09 13:25:46,133 Time limit reached for model gpt2-124m at 1725902746.1335
2024-09-09 13:25:46,226 Processed request ID dc232f15 with model gpt2-124m
2024-09-09 13:25:46,226 Processed request ID 76c77a5d with model gpt2-124m
2024-09-09 13:25:46,226 Processed request ID 43a5cf9c with model gpt2-124m
2024-09-09 13:25:46,226 Processed request ID c3b26d09 with model gpt2-124m
2024-09-09 13:25:46,226 Processed batch: ['dc232f15', '76c77a5d', '43a5cf9c', 'c3b26d09'] with model gpt2-124m in 0.7028 seconds
2024-09-09 13:25:46,226 Latency for request dc232f15 with model gpt2-124m: 5.5771 seconds
2024-09-09 13:25:46,227 Latency for request 76c77a5d with model gpt2-124m: 3.0991 seconds
2024-09-09 13:25:46,228 Latency for request 43a5cf9c with model gpt2-124m: 1.9184 seconds
2024-09-09 13:25:46,228 Latency for request c3b26d09 with model gpt2-124m: 0.8085 seconds
2024-09-09 13:25:46,228 127.0.0.1 - - [09/Sep/2024 13:25:46] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:46,545 Time limit reached for model gpt2medium-355m at 1725902746.5452
2024-09-09 13:25:46,545 Moving batch for gpt2medium-355m from incoming to running due to time limit with batch size 1
2024-09-09 13:25:46,545 Time limit condition met for model gpt2medium-355m
2024-09-09 13:25:46,545 1
2024-09-09 13:25:46,545 Padding requests generated in 0.0000 seconds
2024-09-09 13:25:46,545 Loading model gpt2medium-355m
2024-09-09 13:25:46,673 Batch processing started at 361525.6865 for model gpt2medium-355m
2024-09-09 13:25:47,403 Current time: 1725902747.4032
2024-09-09 13:25:47,403 Model distilgpt2-124m loading time: 0.0349 seconds, unloading time: 0.0062 seconds
2024-09-09 13:25:47,403 Adjusted time limit: 5.3842 seconds
2024-09-09 13:25:47,403 Timer for model distilgpt2-124m set to fire at: 1725902752.7874
2024-09-09 13:25:47,403 127.0.0.1 - - [09/Sep/2024 13:25:47] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:49,228 Current time: 1725902749.2281
2024-09-09 13:25:49,228 Model distilgpt2-124m loading time: 0.0349 seconds, unloading time: 0.0062 seconds
2024-09-09 13:25:49,228 Adjusted time limit: 5.3842 seconds
2024-09-09 13:25:49,228 Timer for model distilgpt2-124m set to fire at: 1725902752.7874
2024-09-09 13:25:49,228 127.0.0.1 - - [09/Sep/2024 13:25:49] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:49,244 Processed request ID f1334e0e with model gpt2medium-355m
2024-09-09 13:25:49,245 Processed request ID f7eb with model gpt2medium-355m
2024-09-09 13:25:49,245 Processed request ID b05e with model gpt2medium-355m
2024-09-09 13:25:49,245 Processed request ID e6a7 with model gpt2medium-355m
2024-09-09 13:25:49,245 Processed batch: ['f1334e0e', 'f7eb', 'b05e', 'e6a7'] with model gpt2medium-355m in 2.5722 seconds
2024-09-09 13:25:49,245 Latency for request f1334e0e with model gpt2medium-355m: 5.1242 seconds
2024-09-09 13:25:49,246 Latency for request f7eb with model gpt2medium-355m: 2.7001 seconds
2024-09-09 13:25:49,246 Latency for request b05e with model gpt2medium-355m: 2.7001 seconds
2024-09-09 13:25:49,246 Latency for request e6a7 with model gpt2medium-355m: 2.7001 seconds
2024-09-09 13:25:50,928 Current time: 1725902750.9288
2024-09-09 13:25:50,929 Model gpt2medium-355m loading time: 0.0616 seconds, unloading time: 0.0062 seconds
2024-09-09 13:25:50,929 Adjusted time limit: 2.3548 seconds
2024-09-09 13:25:50,929 Timer for model gpt2medium-355m set to fire at: 1725902753.2836
2024-09-09 13:25:50,930 127.0.0.1 - - [09/Sep/2024 13:25:50] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:52,104 Current time: 1725902752.1047
2024-09-09 13:25:52,105 Model distilgpt2-124m loading time: 0.0349 seconds, unloading time: 0.0062 seconds
2024-09-09 13:25:52,105 Adjusted time limit: 5.3842 seconds
2024-09-09 13:25:52,105 Timer for model distilgpt2-124m set to fire at: 1725902752.7874
2024-09-09 13:25:52,105 127.0.0.1 - - [09/Sep/2024 13:25:52] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:52,882 Time limit reached for model distilgpt2-124m at 1725902752.8824
2024-09-09 13:25:52,882 Moving batch for distilgpt2-124m from incoming to running due to time limit with batch size 3
2024-09-09 13:25:52,883 Time limit condition met for model distilgpt2-124m
2024-09-09 13:25:52,883 3
2024-09-09 13:25:52,883 Padding requests generated in 0.0001 seconds
2024-09-09 13:25:52,883 Loading model distilgpt2-124m
2024-09-09 13:25:52,972 Batch processing started at 361531.9857 for model distilgpt2-124m
2024-09-09 13:25:53,465 Current time: 1725902753.4655
2024-09-09 13:25:53,465 Model gpt2medium-355m loading time: 0.0616 seconds, unloading time: 0.0037 seconds
2024-09-09 13:25:53,465 Adjusted time limit: 2.3573 seconds
2024-09-09 13:25:53,465 Timer for model gpt2medium-355m set to fire at: 1725902753.2836
2024-09-09 13:25:53,465 127.0.0.1 - - [09/Sep/2024 13:25:53] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:54,167 Processed request ID 868b794c with model distilgpt2-124m
2024-09-09 13:25:54,167 Processed request ID 36d8dab9 with model distilgpt2-124m
2024-09-09 13:25:54,168 Processed request ID 8889e14e with model distilgpt2-124m
2024-09-09 13:25:54,168 Processed request ID 6422 with model distilgpt2-124m
2024-09-09 13:25:54,168 Processed batch: ['868b794c', '36d8dab9', '8889e14e', '6422'] with model distilgpt2-124m in 1.1956 seconds
2024-09-09 13:25:54,168 Latency for request 868b794c with model distilgpt2-124m: 6.7653 seconds
2024-09-09 13:25:54,169 Latency for request 36d8dab9 with model distilgpt2-124m: 4.9404 seconds
2024-09-09 13:25:54,169 Latency for request 8889e14e with model distilgpt2-124m: 2.0640 seconds
2024-09-09 13:25:54,169 Latency for request 6422 with model distilgpt2-124m: 1.2848 seconds
2024-09-09 13:25:54,275 Time limit reached for model gpt2medium-355m at 1725902754.2751
2024-09-09 13:25:54,275 Moving batch for gpt2medium-355m from incoming to running due to time limit with batch size 2
2024-09-09 13:25:54,275 Time limit condition met for model gpt2medium-355m
2024-09-09 13:25:54,275 2
2024-09-09 13:25:54,275 Padding requests generated in 0.0000 seconds
2024-09-09 13:25:54,275 Loading model gpt2medium-355m
2024-09-09 13:25:54,434 Batch processing started at 361533.4479 for model gpt2medium-355m
2024-09-09 13:25:54,931 Current time: 1725902754.9317
2024-09-09 13:25:54,931 Model gpt2-124m loading time: 0.0741 seconds, unloading time: 0.0062 seconds
2024-09-09 13:25:54,931 Adjusted time limit: 4.9449 seconds
2024-09-09 13:25:54,931 Timer for model gpt2-124m set to fire at: 1725902759.8766
2024-09-09 13:25:54,931 127.0.0.1 - - [09/Sep/2024 13:25:54] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:56,761 Current time: 1725902756.7614
2024-09-09 13:25:56,761 Model gpt2medium-355m loading time: 0.0616 seconds, unloading time: 0.0062 seconds
2024-09-09 13:25:56,761 Adjusted time limit: 2.3548 seconds
2024-09-09 13:25:56,761 Timer for model gpt2medium-355m set to fire at: 1725902753.2836
2024-09-09 13:25:56,761 127.0.0.1 - - [09/Sep/2024 13:25:56] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:56,765 Processed request ID 36d45057 with model gpt2medium-355m
2024-09-09 13:25:56,765 Processed request ID fbe8b02e with model gpt2medium-355m
2024-09-09 13:25:56,765 Processed request ID 1bf9 with model gpt2medium-355m
2024-09-09 13:25:56,765 Processed request ID 201e with model gpt2medium-355m
2024-09-09 13:25:56,765 Processed batch: ['36d45057', 'fbe8b02e', '1bf9', '201e'] with model gpt2medium-355m in 2.3306 seconds
2024-09-09 13:25:56,765 Latency for request 36d45057 with model gpt2medium-355m: 5.8370 seconds
2024-09-09 13:25:56,766 Latency for request fbe8b02e with model gpt2medium-355m: 3.3002 seconds
2024-09-09 13:25:56,766 Latency for request 1bf9 with model gpt2medium-355m: 2.4902 seconds
2024-09-09 13:25:56,767 Latency for request 201e with model gpt2medium-355m: 2.4902 seconds
2024-09-09 13:25:57,852 Current time: 1725902757.8529
2024-09-09 13:25:57,853 Model gpt2-124m loading time: 0.0741 seconds, unloading time: 0.0062 seconds
2024-09-09 13:25:57,854 Adjusted time limit: 4.9449 seconds
2024-09-09 13:25:57,854 Timer for model gpt2-124m set to fire at: 1725902759.8766
2024-09-09 13:25:57,854 127.0.0.1 - - [09/Sep/2024 13:25:57] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:58,858 Current time: 1725902758.8582
2024-09-09 13:25:58,858 Model distilgpt2-124m loading time: 0.0349 seconds, unloading time: 0.0062 seconds
2024-09-09 13:25:58,858 Adjusted time limit: 5.3842 seconds
2024-09-09 13:25:58,858 Timer for model distilgpt2-124m set to fire at: 1725902764.2424
2024-09-09 13:25:58,858 127.0.0.1 - - [09/Sep/2024 13:25:58] "POST /inference HTTP/1.1" 200 -
2024-09-09 13:25:59,888 Time limit reached for model gpt2-124m at 1725902759.8882
2024-09-09 13:25:59,888 Moving batch for gpt2-124m from incoming to running due to time limit with batch size 2
2024-09-09 13:25:59,889 Time limit condition met for model gpt2-124m
2024-09-09 13:25:59,889 2
2024-09-09 13:25:59,889 Padding requests generated in 0.0001 seconds
2024-09-09 13:25:59,889 Loading model gpt2-124m
2024-09-09 13:25:59,980 Batch processing started at 361538.9938 for model gpt2-124m
2024-09-09 13:26:00,803 Processed request ID bbdad860 with model gpt2-124m
2024-09-09 13:26:00,804 Processed request ID 01bbbee1 with model gpt2-124m
2024-09-09 13:26:00,804 Processed request ID 7f91 with model gpt2-124m
2024-09-09 13:26:00,804 Processed request ID 1c53 with model gpt2-124m
2024-09-09 13:26:00,805 Processed batch: ['bbdad860', '01bbbee1', '7f91', '1c53'] with model gpt2-124m in 0.8241 seconds
2024-09-09 13:26:00,805 Latency for request bbdad860 with model gpt2-124m: 5.8734 seconds
2024-09-09 13:26:00,805 Latency for request 01bbbee1 with model gpt2-124m: 2.9525 seconds
2024-09-09 13:26:00,806 Latency for request 7f91 with model gpt2-124m: 0.9156 seconds
2024-09-09 13:26:00,806 Latency for request 1c53 with model gpt2-124m: 0.9155 seconds
2024-09-09 13:26:04,247 Time limit reached for model distilgpt2-124m at 1725902764.2470
2024-09-09 13:26:04,247 Moving batch for distilgpt2-124m from incoming to running due to time limit with batch size 1
2024-09-09 13:26:04,247 Time limit condition met for model distilgpt2-124m
2024-09-09 13:26:04,247 1
2024-09-09 13:26:04,248 Padding requests generated in 0.0001 seconds
2024-09-09 13:26:04,248 Loading model distilgpt2-124m
2024-09-09 13:26:04,341 Batch processing started at 361543.3546 for model distilgpt2-124m
2024-09-09 13:26:04,948 Processed request ID 473060b6 with model distilgpt2-124m
2024-09-09 13:26:04,949 Processed request ID f302 with model distilgpt2-124m
2024-09-09 13:26:04,949 Processed request ID 4ed0 with model distilgpt2-124m
2024-09-09 13:26:04,949 Processed request ID c079 with model distilgpt2-124m
2024-09-09 13:26:04,949 Processed batch: ['473060b6', 'f302', '4ed0', 'c079'] with model distilgpt2-124m in 0.6080 seconds
2024-09-09 13:26:04,949 Latency for request 473060b6 with model distilgpt2-124m: 6.0916 seconds
2024-09-09 13:26:04,950 Latency for request f302 with model distilgpt2-124m: 0.7015 seconds
2024-09-09 13:26:04,950 Latency for request 4ed0 with model distilgpt2-124m: 0.7015 seconds
2024-09-09 13:26:04,951 Latency for request c079 with model distilgpt2-124m: 0.7015 seconds
