2024-09-19 12:29:09,622 Using device: cuda
2024-09-19 12:29:09,622 Scheduling mode set as batchedFCFS+SLA
2024-09-19 12:29:09,626 Monitoring status set to True
2024-09-19 12:29:24,690 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.122.143:5000
2024-09-19 12:29:24,690 [33mPress CTRL+C to quit[0m
2024-09-19 12:29:51,865 Request with ID f1e6b481 for model granite-7b received
2024-09-19 12:29:51,865 Adjusted batch time limit for granite-7b: 3.0000 seconds
2024-09-19 12:29:51,866 127.0.0.1 - - [19/Sep/2024 12:29:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:52,018 Request with ID 386afff8 for model granite-7b received
2024-09-19 12:29:52,019 127.0.0.1 - - [19/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:52,029 Request with ID 77ab8cb4 for model llama3-8b received
2024-09-19 12:29:52,029 Adjusted batch time limit for llama3-8b: 3.0000 seconds
2024-09-19 12:29:52,029 127.0.0.1 - - [19/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:52,123 Request with ID 36b4f526 for model granite-7b received
2024-09-19 12:29:52,124 127.0.0.1 - - [19/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:52,477 Request with ID d102caa5 for model llama3-8b received
2024-09-19 12:29:52,478 127.0.0.1 - - [19/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:52,479 Request with ID c4b4d2e8 for model granite-7b received
2024-09-19 12:29:52,480 127.0.0.1 - - [19/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:52,515 Request with ID 94029699 for model granite-7b received
2024-09-19 12:29:52,515 127.0.0.1 - - [19/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:52,518 Request with ID 354ca950 for model gemma-7b received
2024-09-19 12:29:52,518 Adjusted batch time limit for gemma-7b: 3.0000 seconds
2024-09-19 12:29:52,518 127.0.0.1 - - [19/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:52,535 Request with ID b014b948 for model granite-7b received
2024-09-19 12:29:52,535 127.0.0.1 - - [19/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:52,546 Request with ID dde016cc for model granite-7b received
2024-09-19 12:29:52,546 127.0.0.1 - - [19/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:52,957 Request with ID e2ab67f6 for model granite-7b received
2024-09-19 12:29:52,958 127.0.0.1 - - [19/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:53,053 Request with ID 9c142aae for model granite-7b received
2024-09-19 12:29:53,054 127.0.0.1 - - [19/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:53,055 Request with ID 069e1850 for model llama3-8b received
2024-09-19 12:29:53,056 127.0.0.1 - - [19/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:53,222 Request with ID 6df5a8a5 for model granite-7b received
2024-09-19 12:29:53,223 127.0.0.1 - - [19/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:53,339 Request with ID 1c299613 for model granite-7b received
2024-09-19 12:29:53,340 127.0.0.1 - - [19/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:53,583 Request with ID a712768c for model granite-7b received
2024-09-19 12:29:53,583 127.0.0.1 - - [19/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:53,725 Request with ID 0822ae01 for model gemma-7b received
2024-09-19 12:29:53,725 127.0.0.1 - - [19/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:53,806 Request with ID 6d12a186 for model llama3-8b received
2024-09-19 12:29:53,806 127.0.0.1 - - [19/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:53,957 Request with ID 54b70dba for model granite-7b received
2024-09-19 12:29:53,957 127.0.0.1 - - [19/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,220 Request with ID d190b9da for model granite-7b received
2024-09-19 12:29:54,220 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,306 Request with ID 7a56e30e for model granite-7b received
2024-09-19 12:29:54,306 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,347 Request with ID 59b9ccb1 for model gemma-7b received
2024-09-19 12:29:54,347 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,438 Request with ID 141f70d5 for model gemma-7b received
2024-09-19 12:29:54,438 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,471 Request with ID 681ee35a for model llama3-8b received
2024-09-19 12:29:54,471 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,479 Request with ID d786c8a4 for model granite-7b received
2024-09-19 12:29:54,480 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,515 Request with ID 81f20a46 for model granite-7b received
2024-09-19 12:29:54,516 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,642 Request with ID 1877b172 for model gemma-7b received
2024-09-19 12:29:54,642 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,650 Request with ID 7c28e2c8 for model llama3-8b received
2024-09-19 12:29:54,650 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,841 Request with ID fec1c34c for model granite-7b received
2024-09-19 12:29:54,842 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,848 Request with ID 8b402217 for model gemma-7b received
2024-09-19 12:29:54,848 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,915 Processing batch for granite-7b due to time limit with batch size 18
2024-09-19 12:29:54,915 Time limit condition met for model granite-7b
2024-09-19 12:29:54,915 Next: call load_model for granite-7b
2024-09-19 12:29:54,992 Request with ID 14073021 for model granite-7b received
2024-09-19 12:29:54,993 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:54,995 Request with ID fbd89e4e for model llama3-8b received
2024-09-19 12:29:54,995 127.0.0.1 - - [19/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:55,174 Request with ID 2b34e899 for model gemma-7b received
2024-09-19 12:29:55,177 127.0.0.1 - - [19/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:55,178 Request with ID a0d38d11 for model gemma-7b received
2024-09-19 12:29:55,181 127.0.0.1 - - [19/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:55,185 Request with ID 969ab713 for model granite-7b received
2024-09-19 12:29:55,186 127.0.0.1 - - [19/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:55,410 Request with ID dcec332f for model gemma-7b received
2024-09-19 12:29:55,413 127.0.0.1 - - [19/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:55,524 Request with ID a35da27c for model gemma-7b received
2024-09-19 12:29:55,526 127.0.0.1 - - [19/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:55,556 Request with ID 3e2c0f84 for model gemma-7b received
2024-09-19 12:29:55,559 127.0.0.1 - - [19/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:55,735 Request with ID 84254d19 for model llama3-8b received
2024-09-19 12:29:55,735 127.0.0.1 - - [19/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:55,831 Request with ID 2dab2abe for model llama3-8b received
2024-09-19 12:29:55,832 127.0.0.1 - - [19/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:55,852 Request with ID 400cdee2 for model gemma-7b received
2024-09-19 12:29:55,852 127.0.0.1 - - [19/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:56,020 Request with ID cb43a6db for model granite-7b received
2024-09-19 12:29:56,020 127.0.0.1 - - [19/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:56,032 Request with ID d9104abb for model gemma-7b received
2024-09-19 12:29:56,033 Request with ID efead483 for model llama3-8b received
2024-09-19 12:29:56,033 127.0.0.1 - - [19/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:56,034 127.0.0.1 - - [19/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:56,036 Request with ID 9e07a9c3 for model gemma-7b received
2024-09-19 12:29:56,036 127.0.0.1 - - [19/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:56,103 Request with ID 295c4903 for model granite-7b received
2024-09-19 12:29:56,103 127.0.0.1 - - [19/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:56,390 Request with ID 11992646 for model gemma-7b received
2024-09-19 12:29:56,391 127.0.0.1 - - [19/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:56,443 Request with ID 7d6ef5bb for model llama3-8b received
2024-09-19 12:29:56,443 127.0.0.1 - - [19/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:56,774 Request with ID ed30181a for model granite-7b received
2024-09-19 12:29:56,775 127.0.0.1 - - [19/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:56,777 Request with ID a55cc473 for model llama3-8b received
2024-09-19 12:29:56,777 127.0.0.1 - - [19/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:56,832 Request with ID 6cc9710a for model granite-7b received
2024-09-19 12:29:56,833 127.0.0.1 - - [19/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:57,074 Request with ID a9d63401 for model granite-7b received
2024-09-19 12:29:57,075 127.0.0.1 - - [19/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:57,143 Request with ID dda39cc0 for model gemma-7b received
2024-09-19 12:29:57,143 127.0.0.1 - - [19/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:57,236 Request with ID 3bada6d7 for model granite-7b received
2024-09-19 12:29:57,236 127.0.0.1 - - [19/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:57,263 Request with ID 7d6d7c5b for model granite-7b received
2024-09-19 12:29:57,264 127.0.0.1 - - [19/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:57,366 Request with ID 97e65a9a for model granite-7b received
2024-09-19 12:29:57,367 127.0.0.1 - - [19/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:57,537 Request with ID 3b443d9d for model granite-7b received
2024-09-19 12:29:57,538 127.0.0.1 - - [19/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:57,610 Request with ID 1b5a85f2 for model gemma-7b received
2024-09-19 12:29:57,610 127.0.0.1 - - [19/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:57,725 Request with ID 8354b08a for model gemma-7b received
2024-09-19 12:29:57,725 127.0.0.1 - - [19/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:57,750 Request with ID 3337fb74 for model granite-7b received
2024-09-19 12:29:57,751 127.0.0.1 - - [19/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:57,870 Request with ID fd4fa4eb for model gemma-7b received
2024-09-19 12:29:57,870 127.0.0.1 - - [19/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:58,054 Request with ID f089f914 for model granite-7b received
2024-09-19 12:29:58,054 127.0.0.1 - - [19/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:58,067 Request with ID bc9f1309 for model llama3-8b received
2024-09-19 12:29:58,067 127.0.0.1 - - [19/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:58,206 Request with ID 920b8fba for model granite-7b received
2024-09-19 12:29:58,207 127.0.0.1 - - [19/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:58,504 Request with ID f86b0b35 for model granite-7b received
2024-09-19 12:29:58,504 127.0.0.1 - - [19/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:58,513 Request with ID 1b8e8c61 for model llama3-8b received
2024-09-19 12:29:58,513 127.0.0.1 - - [19/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:58,617 Request with ID 05cf86b2 for model granite-7b received
2024-09-19 12:29:58,618 127.0.0.1 - - [19/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:58,739 Request with ID da516ebc for model llama3-8b received
2024-09-19 12:29:58,739 127.0.0.1 - - [19/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:58,791 Request with ID 3cccecff for model gemma-7b received
2024-09-19 12:29:58,792 127.0.0.1 - - [19/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:58,800 Request with ID a32ff7c0 for model llama3-8b received
2024-09-19 12:29:58,800 127.0.0.1 - - [19/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:58,896 Request with ID 366cc151 for model gemma-7b received
2024-09-19 12:29:58,897 127.0.0.1 - - [19/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:58,898 Request with ID c085b608 for model granite-7b received
2024-09-19 12:29:58,899 127.0.0.1 - - [19/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:58,965 Request with ID 3b14557e for model granite-7b received
2024-09-19 12:29:58,966 127.0.0.1 - - [19/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:59,091 Request with ID 04c14d2c for model granite-7b received
2024-09-19 12:29:59,092 127.0.0.1 - - [19/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:59,231 Request with ID 671f3cee for model gemma-7b received
2024-09-19 12:29:59,232 127.0.0.1 - - [19/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:59,360 Request with ID f3036f78 for model gemma-7b received
2024-09-19 12:29:59,361 127.0.0.1 - - [19/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:59,370 Request with ID 6c6328eb for model granite-7b received
2024-09-19 12:29:59,370 127.0.0.1 - - [19/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:59,400 Request with ID c5d132a5 for model llama3-8b received
2024-09-19 12:29:59,400 127.0.0.1 - - [19/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:59,469 Request with ID 3dc1eab6 for model gemma-7b received
2024-09-19 12:29:59,470 127.0.0.1 - - [19/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:59,629 Request with ID efef784b for model gemma-7b received
2024-09-19 12:29:59,630 127.0.0.1 - - [19/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:59,742 Request with ID 6707709a for model granite-7b received
2024-09-19 12:29:59,742 127.0.0.1 - - [19/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:29:59,872 Request with ID 80e5d90a for model gemma-7b received
2024-09-19 12:29:59,872 127.0.0.1 - - [19/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:00,020 Request with ID bfe666e8 for model llama3-8b received
2024-09-19 12:30:00,021 127.0.0.1 - - [19/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:00,085 Request with ID 46244a67 for model llama3-8b received
2024-09-19 12:30:00,086 127.0.0.1 - - [19/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:00,133 Request with ID 4c7e367b for model llama3-8b received
2024-09-19 12:30:00,133 127.0.0.1 - - [19/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:00,284 Request with ID 358ecab8 for model llama3-8b received
2024-09-19 12:30:00,284 127.0.0.1 - - [19/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:00,509 Request with ID 36652caf for model granite-7b received
2024-09-19 12:30:00,509 127.0.0.1 - - [19/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:00,545 Request with ID 0a1e4a3d for model granite-7b received
2024-09-19 12:30:00,546 127.0.0.1 - - [19/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:00,613 Request with ID 0d7d6571 for model gemma-7b received
2024-09-19 12:30:00,614 127.0.0.1 - - [19/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:00,890 Request with ID ec9d92a1 for model llama3-8b received
2024-09-19 12:30:00,891 127.0.0.1 - - [19/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:00,898 Request with ID 9fbaf579 for model gemma-7b received
2024-09-19 12:30:00,898 127.0.0.1 - - [19/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:01,361 Request with ID 8a92d543 for model granite-7b received
2024-09-19 12:30:01,362 127.0.0.1 - - [19/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:01,401 Request with ID 08cee10a for model granite-7b received
2024-09-19 12:30:01,401 127.0.0.1 - - [19/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:01,437 Request with ID a9f89eb8 for model llama3-8b received
2024-09-19 12:30:01,437 127.0.0.1 - - [19/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:01,641 Request with ID f30142dd for model granite-7b received
2024-09-19 12:30:01,642 127.0.0.1 - - [19/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:01,643 Request with ID 8a05afb2 for model gemma-7b received
2024-09-19 12:30:01,644 127.0.0.1 - - [19/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:01,749 Request with ID 30bceb0c for model granite-7b received
2024-09-19 12:30:01,750 127.0.0.1 - - [19/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:01,969 Request with ID e0ba7974 for model granite-7b received
2024-09-19 12:30:01,969 127.0.0.1 - - [19/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:01,979 Request with ID 4db353b4 for model granite-7b received
2024-09-19 12:30:01,980 127.0.0.1 - - [19/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,044 Request with ID fa3f9230 for model llama3-8b received
2024-09-19 12:30:02,045 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,228 Request with ID f99f6c29 for model granite-7b received
2024-09-19 12:30:02,229 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,265 Request with ID b15cec71 for model granite-7b received
2024-09-19 12:30:02,266 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,444 Request with ID d7aec736 for model llama3-8b received
2024-09-19 12:30:02,444 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,446 Request with ID 3f3de708 for model gemma-7b received
2024-09-19 12:30:02,447 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,447 Request with ID 9b0f6a16 for model llama3-8b received
2024-09-19 12:30:02,448 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,530 Request with ID f3530bca for model gemma-7b received
2024-09-19 12:30:02,531 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,562 Request with ID 0c9a1db7 for model granite-7b received
2024-09-19 12:30:02,563 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,565 Request with ID 96ad47a7 for model granite-7b received
2024-09-19 12:30:02,565 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,623 Request with ID d2273a2e for model granite-7b received
2024-09-19 12:30:02,624 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,643 Request with ID f9efe6f9 for model granite-7b received
2024-09-19 12:30:02,643 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,672 Request with ID e42f2492 for model gemma-7b received
2024-09-19 12:30:02,672 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-19 12:30:02,672 Dynamic batch size condition met for model gemma-7b
2024-09-19 12:30:02,781 Request with ID e6517d85 for model llama3-8b received
2024-09-19 12:30:02,782 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:02,917 Request with ID 14de3009 for model granite-7b received
2024-09-19 12:30:02,918 127.0.0.1 - - [19/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:03,050 Request with ID 99319545 for model granite-7b received
2024-09-19 12:30:03,051 127.0.0.1 - - [19/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:03,194 Request with ID c51e11ed for model granite-7b received
2024-09-19 12:30:03,195 127.0.0.1 - - [19/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:03,199 Request with ID d5b5490c for model llama3-8b received
2024-09-19 12:30:03,199 127.0.0.1 - - [19/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:03,219 Request with ID d54bba00 for model granite-7b received
2024-09-19 12:30:03,220 127.0.0.1 - - [19/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:03,284 Request with ID 70bbada5 for model granite-7b received
2024-09-19 12:30:03,284 127.0.0.1 - - [19/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:03,382 Request with ID cc426b2f for model llama3-8b received
2024-09-19 12:30:03,382 127.0.0.1 - - [19/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:03,492 Request with ID 04fed120 for model gemma-7b received
2024-09-19 12:30:03,492 127.0.0.1 - - [19/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:03,783 Request with ID d419195e for model llama3-8b received
2024-09-19 12:30:03,783 127.0.0.1 - - [19/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:03,886 Request with ID 11137591 for model gemma-7b received
2024-09-19 12:30:03,886 127.0.0.1 - - [19/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:03,937 Request with ID 780ac4c4 for model granite-7b received
2024-09-19 12:30:03,937 127.0.0.1 - - [19/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:04,018 Request with ID b28d19a9 for model gemma-7b received
2024-09-19 12:30:04,018 127.0.0.1 - - [19/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:04,191 Request with ID cc41ed95 for model llama3-8b received
2024-09-19 12:30:04,191 127.0.0.1 - - [19/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:04,214 Request with ID 9075de04 for model granite-7b received
2024-09-19 12:30:04,214 127.0.0.1 - - [19/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:04,217 Request with ID d8c60a4e for model gemma-7b received
2024-09-19 12:30:04,217 127.0.0.1 - - [19/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:04,224 Request with ID d1a1adf7 for model granite-7b received
2024-09-19 12:30:04,225 127.0.0.1 - - [19/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:04,341 Request with ID 154679dc for model granite-7b received
2024-09-19 12:30:04,341 127.0.0.1 - - [19/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:04,411 Request with ID 98cc4613 for model gemma-7b received
2024-09-19 12:30:04,411 127.0.0.1 - - [19/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:04,575 Request with ID 2981133d for model granite-7b received
2024-09-19 12:30:04,576 127.0.0.1 - - [19/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:04,578 Request with ID fd0c8186 for model granite-7b received
2024-09-19 12:30:04,578 127.0.0.1 - - [19/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:04,708 Request with ID 5664e195 for model granite-7b received
2024-09-19 12:30:04,708 127.0.0.1 - - [19/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:04,755 Request with ID 06042ae5 for model granite-7b received
2024-09-19 12:30:04,755 127.0.0.1 - - [19/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:05,024 Request with ID 8f347aa9 for model granite-7b received
2024-09-19 12:30:05,024 127.0.0.1 - - [19/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:05,140 Request with ID 7af3fc5c for model granite-7b received
2024-09-19 12:30:05,140 127.0.0.1 - - [19/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:05,218 Request with ID b8fc5a8e for model llama3-8b received
2024-09-19 12:30:05,218 Moving batch for llama3-8b from incoming to running due to dynamic batch size 32
2024-09-19 12:30:05,218 Dynamic batch size condition met for model llama3-8b
2024-09-19 12:30:05,258 Request with ID f416b5e9 for model granite-7b received
2024-09-19 12:30:05,258 127.0.0.1 - - [19/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:05,263 Request with ID 2faa529f for model granite-7b received
2024-09-19 12:30:05,264 127.0.0.1 - - [19/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:05,581 Request with ID 3e7aa70a for model granite-7b received
2024-09-19 12:30:05,581 127.0.0.1 - - [19/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:05,589 Request with ID dab49315 for model granite-7b received
2024-09-19 12:30:05,590 127.0.0.1 - - [19/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:05,703 Request with ID a5d4128d for model gemma-7b received
2024-09-19 12:30:05,704 127.0.0.1 - - [19/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:05,713 Request with ID efee9987 for model llama3-8b received
2024-09-19 12:30:05,713 127.0.0.1 - - [19/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:06,266 Request with ID 192e165e for model granite-7b received
2024-09-19 12:30:06,267 127.0.0.1 - - [19/Sep/2024 12:30:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:06,486 Request with ID 647a3760 for model gemma-7b received
2024-09-19 12:30:06,487 127.0.0.1 - - [19/Sep/2024 12:30:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:06,835 Request with ID 181b55e3 for model gemma-7b received
2024-09-19 12:30:06,835 127.0.0.1 - - [19/Sep/2024 12:30:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:06,846 Request with ID 987a13f4 for model granite-7b received
2024-09-19 12:30:06,846 127.0.0.1 - - [19/Sep/2024 12:30:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:06,872 Request with ID 57edbf1d for model llama3-8b received
2024-09-19 12:30:06,872 127.0.0.1 - - [19/Sep/2024 12:30:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:06,996 Request with ID bd7f55e5 for model gemma-7b received
2024-09-19 12:30:06,997 127.0.0.1 - - [19/Sep/2024 12:30:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:07,024 Request with ID f7f77469 for model llama3-8b received
2024-09-19 12:30:07,024 127.0.0.1 - - [19/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:07,164 Loaded model granite-7b
2024-09-19 12:30:07,167 Batch processing started for model granite-7b
2024-09-19 12:30:07,238 Request with ID ee0f3774 for model llama3-8b received
2024-09-19 12:30:07,238 127.0.0.1 - - [19/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:07,667 Request with ID 0e14c6e3 for model granite-7b received
2024-09-19 12:30:07,668 127.0.0.1 - - [19/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:07,792 Request with ID 6fa80bde for model gemma-7b received
2024-09-19 12:30:07,793 127.0.0.1 - - [19/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:07,875 Request with ID b67e7030 for model granite-7b received
2024-09-19 12:30:07,876 127.0.0.1 - - [19/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:07,916 Request with ID 1e6cb623 for model granite-7b received
2024-09-19 12:30:07,917 127.0.0.1 - - [19/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:07,982 Request with ID ecd651ba for model gemma-7b received
2024-09-19 12:30:07,982 127.0.0.1 - - [19/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:08,130 Request with ID fd2827f7 for model gemma-7b received
2024-09-19 12:30:08,131 127.0.0.1 - - [19/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:08,270 Request with ID fe790229 for model granite-7b received
2024-09-19 12:30:08,271 127.0.0.1 - - [19/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:08,323 Request with ID 3ee7456d for model granite-7b received
2024-09-19 12:30:08,323 127.0.0.1 - - [19/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:08,528 Request with ID 0342b3e7 for model granite-7b received
2024-09-19 12:30:08,528 127.0.0.1 - - [19/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:08,692 Request with ID ec767ac5 for model llama3-8b received
2024-09-19 12:30:08,692 127.0.0.1 - - [19/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:08,697 Request with ID 2efdc182 for model granite-7b received
2024-09-19 12:30:08,697 127.0.0.1 - - [19/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:08,958 Request with ID 5d618599 for model granite-7b received
2024-09-19 12:30:08,958 Moving batch for granite-7b from incoming to running due to dynamic batch size 64
2024-09-19 12:30:08,959 Dynamic batch size condition met for model granite-7b
2024-09-19 12:30:09,080 Request with ID 8d0f41a4 for model gemma-7b received
2024-09-19 12:30:09,081 127.0.0.1 - - [19/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:09,201 Request with ID fd2d0a92 for model gemma-7b received
2024-09-19 12:30:09,201 127.0.0.1 - - [19/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:09,250 Request with ID 89e603b1 for model granite-7b received
2024-09-19 12:30:09,251 127.0.0.1 - - [19/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:09,284 Request with ID 6edf628c for model granite-7b received
2024-09-19 12:30:09,285 127.0.0.1 - - [19/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:09,296 Request with ID c9044f30 for model granite-7b received
2024-09-19 12:30:09,296 127.0.0.1 - - [19/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:09,318 Request with ID 7c56b520 for model granite-7b received
2024-09-19 12:30:09,319 127.0.0.1 - - [19/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:09,345 Request with ID 873855d4 for model granite-7b received
2024-09-19 12:30:09,346 127.0.0.1 - - [19/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:09,715 Request with ID 41d5d34d for model gemma-7b received
2024-09-19 12:30:09,715 127.0.0.1 - - [19/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:09,792 Request with ID eaa71ea4 for model granite-7b received
2024-09-19 12:30:09,793 127.0.0.1 - - [19/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:09,886 Request with ID 98109440 for model granite-7b received
2024-09-19 12:30:09,887 127.0.0.1 - - [19/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:09,895 Request with ID 5cdfbd11 for model llama3-8b received
2024-09-19 12:30:09,895 127.0.0.1 - - [19/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:10,027 Request with ID d4312f3f for model llama3-8b received
2024-09-19 12:30:10,027 127.0.0.1 - - [19/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:10,035 Request with ID 51064939 for model llama3-8b received
2024-09-19 12:30:10,035 127.0.0.1 - - [19/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:10,041 Request with ID 4f093c2a for model granite-7b received
2024-09-19 12:30:10,042 127.0.0.1 - - [19/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:10,211 Request with ID d2d5bb46 for model llama3-8b received
2024-09-19 12:30:10,211 127.0.0.1 - - [19/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:10,259 Request with ID 1b9b5175 for model granite-7b received
2024-09-19 12:30:10,259 127.0.0.1 - - [19/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:10,380 Processed batch: ['f1e6b481', '386afff8', '36b4f526', 'c4b4d2e8', '94029699', 'b014b948', 'dde016cc', 'e2ab67f6', '9c142aae', '6df5a8a5', '1c299613', 'a712768c', '54b70dba', 'd190b9da', '7a56e30e', 'd786c8a4', '81f20a46', 'fec1c34c'] with model granite-7b in 3.2129 seconds
2024-09-19 12:30:10,380 Saving sys info
2024-09-19 12:30:10,419 Latency for request f1e6b481 with model granite-7b: 18.5150 seconds
2024-09-19 12:30:10,419 Saving results with gpu monitoring
2024-09-19 12:30:10,424 Latency for request 386afff8 with model granite-7b: 18.3610 seconds
2024-09-19 12:30:10,424 Saving results with gpu monitoring
2024-09-19 12:30:10,426 Latency for request 36b4f526 with model granite-7b: 18.2560 seconds
2024-09-19 12:30:10,426 Saving results with gpu monitoring
2024-09-19 12:30:10,428 Latency for request c4b4d2e8 with model granite-7b: 17.9010 seconds
2024-09-19 12:30:10,428 Saving results with gpu monitoring
2024-09-19 12:30:10,430 Latency for request 94029699 with model granite-7b: 17.8650 seconds
2024-09-19 12:30:10,430 Saving results with gpu monitoring
2024-09-19 12:30:10,432 Latency for request b014b948 with model granite-7b: 17.8450 seconds
2024-09-19 12:30:10,432 Saving results with gpu monitoring
2024-09-19 12:30:10,434 Latency for request dde016cc with model granite-7b: 17.8340 seconds
2024-09-19 12:30:10,434 Saving results with gpu monitoring
2024-09-19 12:30:10,436 Latency for request e2ab67f6 with model granite-7b: 17.4220 seconds
2024-09-19 12:30:10,436 Saving results with gpu monitoring
2024-09-19 12:30:10,438 Latency for request 9c142aae with model granite-7b: 17.3270 seconds
2024-09-19 12:30:10,438 Saving results with gpu monitoring
2024-09-19 12:30:10,440 Latency for request 6df5a8a5 with model granite-7b: 17.1570 seconds
2024-09-19 12:30:10,440 Saving results with gpu monitoring
2024-09-19 12:30:10,442 Latency for request 1c299613 with model granite-7b: 17.0400 seconds
2024-09-19 12:30:10,442 Saving results with gpu monitoring
2024-09-19 12:30:10,444 Latency for request a712768c with model granite-7b: 16.7970 seconds
2024-09-19 12:30:10,444 Saving results with gpu monitoring
2024-09-19 12:30:10,446 Latency for request 54b70dba with model granite-7b: 16.4230 seconds
2024-09-19 12:30:10,446 Saving results with gpu monitoring
2024-09-19 12:30:10,448 Latency for request d190b9da with model granite-7b: 16.1600 seconds
2024-09-19 12:30:10,448 Saving results with gpu monitoring
2024-09-19 12:30:10,450 Latency for request 7a56e30e with model granite-7b: 16.0740 seconds
2024-09-19 12:30:10,450 Saving results with gpu monitoring
2024-09-19 12:30:10,452 Latency for request d786c8a4 with model granite-7b: 15.9000 seconds
2024-09-19 12:30:10,452 Saving results with gpu monitoring
2024-09-19 12:30:10,454 Latency for request 81f20a46 with model granite-7b: 15.8650 seconds
2024-09-19 12:30:10,455 Saving results with gpu monitoring
2024-09-19 12:30:10,457 Latency for request fec1c34c with model granite-7b: 15.5380 seconds
2024-09-19 12:30:10,457 Saving results with gpu monitoring
2024-09-19 12:30:10,460 Request with ID 3854b160 for model llama3-8b received
2024-09-19 12:30:10,460 127.0.0.1 - - [19/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:10,461 Next: call load_model for gemma-7b
2024-09-19 12:30:10,551 Unloaded previous model
2024-09-19 12:30:10,554 Request with ID 99f7b4e8 for model granite-7b received
2024-09-19 12:30:10,556 Request with ID d5b3ebee for model gemma-7b received
2024-09-19 12:30:10,556 Adjusted batch time limit for granite-7b: 3.0000 seconds
2024-09-19 12:30:10,557 127.0.0.1 - - [19/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:10,558 127.0.0.1 - - [19/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,048 Processing batch for llama3-8b due to time limit with batch size 10
2024-09-19 12:30:11,052 Time limit condition met for model llama3-8b
2024-09-19 12:30:11,055 Request with ID 10718c99 for model llama3-8b received
2024-09-19 12:30:11,056 Request with ID 65fb9101 for model llama3-8b received
2024-09-19 12:30:11,058 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,059 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,062 Request with ID 5462f00b for model granite-7b received
2024-09-19 12:30:11,063 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,066 Request with ID cbed74be for model llama3-8b received
2024-09-19 12:30:11,066 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,069 Request with ID 7107236c for model granite-7b received
2024-09-19 12:30:11,070 Request with ID ec401b05 for model gemma-7b received
2024-09-19 12:30:11,071 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,071 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,073 Request with ID 207fe094 for model llama3-8b received
2024-09-19 12:30:11,074 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,455 Request with ID f4e8edcb for model granite-7b received
2024-09-19 12:30:11,456 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,459 Request with ID 0b87dde4 for model gemma-7b received
2024-09-19 12:30:11,460 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,634 Request with ID 60c936f6 for model llama3-8b received
2024-09-19 12:30:11,635 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,638 Request with ID 4f0bffde for model gemma-7b received
2024-09-19 12:30:11,638 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,753 Request with ID 397e5339 for model gemma-7b received
2024-09-19 12:30:11,753 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,836 Request with ID e73982c4 for model granite-7b received
2024-09-19 12:30:11,837 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,854 Request with ID 558853e5 for model llama3-8b received
2024-09-19 12:30:11,855 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,872 Request with ID 72b46e15 for model gemma-7b received
2024-09-19 12:30:11,873 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,880 Request with ID ae3e4918 for model llama3-8b received
2024-09-19 12:30:11,880 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:11,950 Request with ID f9758810 for model granite-7b received
2024-09-19 12:30:11,951 127.0.0.1 - - [19/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,038 Request with ID 7b6fc86d for model gemma-7b received
2024-09-19 12:30:12,039 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,101 Request with ID fe37aac8 for model granite-7b received
2024-09-19 12:30:12,101 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,222 Request with ID 09ddf5a1 for model granite-7b received
2024-09-19 12:30:12,222 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,267 Request with ID 48214d8c for model granite-7b received
2024-09-19 12:30:12,267 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,379 Request with ID fc848865 for model gemma-7b received
2024-09-19 12:30:12,379 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,404 Request with ID 5c50e778 for model granite-7b received
2024-09-19 12:30:12,405 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,448 Request with ID 085a5e66 for model gemma-7b received
2024-09-19 12:30:12,449 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,527 Request with ID 196bb68f for model granite-7b received
2024-09-19 12:30:12,528 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,573 Request with ID 645f2844 for model granite-7b received
2024-09-19 12:30:12,574 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,615 Request with ID 4a8f4214 for model gemma-7b received
2024-09-19 12:30:12,615 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,624 Request with ID 1d850c9b for model llama3-8b received
2024-09-19 12:30:12,624 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,631 Request with ID efe5e0f4 for model llama3-8b received
2024-09-19 12:30:12,632 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,641 Request with ID 3ecb0819 for model granite-7b received
2024-09-19 12:30:12,642 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,667 Request with ID be0a78a4 for model llama3-8b received
2024-09-19 12:30:12,668 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,695 Request with ID 28057f17 for model granite-7b received
2024-09-19 12:30:12,695 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,759 Request with ID 23946d18 for model granite-7b received
2024-09-19 12:30:12,760 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:12,777 Request with ID d7cc6583 for model gemma-7b received
2024-09-19 12:30:12,778 127.0.0.1 - - [19/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,005 Request with ID c39bd246 for model granite-7b received
2024-09-19 12:30:13,006 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,209 Request with ID 50bf7104 for model granite-7b received
2024-09-19 12:30:13,209 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,241 Request with ID 15f4100e for model granite-7b received
2024-09-19 12:30:13,241 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,526 Request with ID b9bdb193 for model llama3-8b received
2024-09-19 12:30:13,526 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,527 Request with ID 5ce62fe2 for model granite-7b received
2024-09-19 12:30:13,528 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,529 Request with ID 8831be32 for model granite-7b received
2024-09-19 12:30:13,530 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,565 Request with ID 4fccccd6 for model granite-7b received
2024-09-19 12:30:13,565 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,644 Request with ID 6be7a1a8 for model gemma-7b received
2024-09-19 12:30:13,644 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,734 Request with ID 2c974845 for model llama3-8b received
2024-09-19 12:30:13,734 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,829 Request with ID 64493224 for model granite-7b received
2024-09-19 12:30:13,829 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,870 Request with ID 2bdbcaac for model granite-7b received
2024-09-19 12:30:13,870 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,896 Request with ID f5f4889f for model granite-7b received
2024-09-19 12:30:13,897 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:13,915 Request with ID 63555a01 for model granite-7b received
2024-09-19 12:30:13,915 127.0.0.1 - - [19/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:14,103 Request with ID 290f81cf for model granite-7b received
2024-09-19 12:30:14,103 127.0.0.1 - - [19/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:14,224 Request with ID 7bb9b05a for model granite-7b received
2024-09-19 12:30:14,224 127.0.0.1 - - [19/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:14,276 Request with ID b9cd7a4f for model llama3-8b received
2024-09-19 12:30:14,277 Request with ID 36a02a53 for model granite-7b received
2024-09-19 12:30:14,278 127.0.0.1 - - [19/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:14,278 127.0.0.1 - - [19/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:14,296 Request with ID a0b0e3cb for model llama3-8b received
2024-09-19 12:30:14,296 127.0.0.1 - - [19/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:14,425 Request with ID d9fbe669 for model granite-7b received
2024-09-19 12:30:14,426 127.0.0.1 - - [19/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:14,609 Request with ID b870628f for model granite-7b received
2024-09-19 12:30:14,610 127.0.0.1 - - [19/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:14,650 Request with ID e98e4d2f for model granite-7b received
2024-09-19 12:30:14,651 127.0.0.1 - - [19/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:14,786 Request with ID c9ac56d6 for model gemma-7b received
2024-09-19 12:30:14,787 127.0.0.1 - - [19/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:14,935 Request with ID f37c09db for model gemma-7b received
2024-09-19 12:30:14,936 127.0.0.1 - - [19/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:14,953 Request with ID eca3e79e for model gemma-7b received
2024-09-19 12:30:14,953 127.0.0.1 - - [19/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:15,165 Request with ID e7b74451 for model granite-7b received
2024-09-19 12:30:15,166 Request with ID 4e0513b9 for model gemma-7b received
2024-09-19 12:30:15,167 127.0.0.1 - - [19/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:15,168 Request with ID fb6bda58 for model gemma-7b received
2024-09-19 12:30:15,168 127.0.0.1 - - [19/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:15,169 Request with ID 025252cf for model granite-7b received
2024-09-19 12:30:15,170 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-19 12:30:15,171 127.0.0.1 - - [19/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:15,172 Dynamic batch size condition met for model gemma-7b
2024-09-19 12:30:15,261 Request with ID 420b8b6f for model llama3-8b received
2024-09-19 12:30:15,261 127.0.0.1 - - [19/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:15,441 Request with ID 2ed4dd39 for model granite-7b received
2024-09-19 12:30:15,441 127.0.0.1 - - [19/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:15,714 Request with ID 0a9fb367 for model granite-7b received
2024-09-19 12:30:15,714 127.0.0.1 - - [19/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:15,762 Request with ID c9e6e988 for model gemma-7b received
2024-09-19 12:30:15,763 127.0.0.1 - - [19/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:15,767 Request with ID 62a0555b for model granite-7b received
2024-09-19 12:30:15,767 127.0.0.1 - - [19/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:15,929 Request with ID f0752699 for model granite-7b received
2024-09-19 12:30:15,929 127.0.0.1 - - [19/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:15,947 Request with ID 08a3feeb for model granite-7b received
2024-09-19 12:30:15,947 127.0.0.1 - - [19/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:16,050 Request with ID 11af7f5f for model granite-7b received
2024-09-19 12:30:16,050 127.0.0.1 - - [19/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:16,140 Request with ID b5ec7f35 for model granite-7b received
2024-09-19 12:30:16,140 127.0.0.1 - - [19/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:16,188 Request with ID a833c3bf for model gemma-7b received
2024-09-19 12:30:16,188 127.0.0.1 - - [19/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:16,260 Request with ID a33728b9 for model granite-7b received
2024-09-19 12:30:16,261 127.0.0.1 - - [19/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:16,338 Request with ID 30391fb0 for model llama3-8b received
2024-09-19 12:30:16,339 127.0.0.1 - - [19/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:16,438 Request with ID 1a424332 for model granite-7b received
2024-09-19 12:30:16,439 127.0.0.1 - - [19/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:16,479 Request with ID 8caa22d3 for model granite-7b received
2024-09-19 12:30:16,480 127.0.0.1 - - [19/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:16,494 Request with ID 6c64a39c for model gemma-7b received
2024-09-19 12:30:16,495 127.0.0.1 - - [19/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:16,573 Request with ID 961ab5ba for model gemma-7b received
2024-09-19 12:30:16,574 127.0.0.1 - - [19/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:17,183 Request with ID b7ba959f for model gemma-7b received
2024-09-19 12:30:17,183 127.0.0.1 - - [19/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:17,335 Request with ID 38aa9558 for model granite-7b received
2024-09-19 12:30:17,335 127.0.0.1 - - [19/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:17,462 Request with ID e32abe7f for model llama3-8b received
2024-09-19 12:30:17,462 127.0.0.1 - - [19/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:17,505 Request with ID 960cee65 for model granite-7b received
2024-09-19 12:30:17,506 127.0.0.1 - - [19/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:17,695 Request with ID dbe00e6b for model gemma-7b received
2024-09-19 12:30:17,696 127.0.0.1 - - [19/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:17,713 Request with ID 73b00d08 for model granite-7b received
2024-09-19 12:30:17,713 127.0.0.1 - - [19/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:17,864 Request with ID ebc1f6c4 for model gemma-7b received
2024-09-19 12:30:17,865 127.0.0.1 - - [19/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:17,949 Request with ID 970e32c8 for model granite-7b received
2024-09-19 12:30:17,950 127.0.0.1 - - [19/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:17,992 Request with ID 1642f870 for model llama3-8b received
2024-09-19 12:30:17,993 127.0.0.1 - - [19/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:18,036 Request with ID 9c72474a for model granite-7b received
2024-09-19 12:30:18,037 127.0.0.1 - - [19/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:18,070 Request with ID 5dd183f8 for model granite-7b received
2024-09-19 12:30:18,071 127.0.0.1 - - [19/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:18,161 Request with ID d9de4231 for model granite-7b received
2024-09-19 12:30:18,162 127.0.0.1 - - [19/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:18,467 Request with ID c0be3eab for model llama3-8b received
2024-09-19 12:30:18,468 Request with ID bb7bff04 for model gemma-7b received
2024-09-19 12:30:18,469 127.0.0.1 - - [19/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:18,469 127.0.0.1 - - [19/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:18,600 Request with ID a4739ea3 for model granite-7b received
2024-09-19 12:30:18,600 127.0.0.1 - - [19/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:18,735 Request with ID 0dedf693 for model granite-7b received
2024-09-19 12:30:18,735 127.0.0.1 - - [19/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:18,763 Request with ID f57d56f7 for model granite-7b received
2024-09-19 12:30:18,763 127.0.0.1 - - [19/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:18,947 Request with ID 1b5f5093 for model granite-7b received
2024-09-19 12:30:18,947 127.0.0.1 - - [19/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:18,973 Request with ID be710ec5 for model granite-7b received
2024-09-19 12:30:18,973 Moving batch for granite-7b from incoming to running due to dynamic batch size 64
2024-09-19 12:30:18,974 Dynamic batch size condition met for model granite-7b
2024-09-19 12:30:18,980 Request with ID 78964498 for model llama3-8b received
2024-09-19 12:30:18,981 Request with ID 7fb9d370 for model granite-7b received
2024-09-19 12:30:18,981 127.0.0.1 - - [19/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:18,982 127.0.0.1 - - [19/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:19,036 Request with ID 1f4b3972 for model llama3-8b received
2024-09-19 12:30:19,036 127.0.0.1 - - [19/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:19,079 Request with ID 6f3e2207 for model gemma-7b received
2024-09-19 12:30:19,079 127.0.0.1 - - [19/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:19,141 Request with ID 9f36fd93 for model granite-7b received
2024-09-19 12:30:19,142 127.0.0.1 - - [19/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:19,388 Request with ID 0e934e91 for model granite-7b received
2024-09-19 12:30:19,388 127.0.0.1 - - [19/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:19,457 Request with ID aebcb60d for model granite-7b received
2024-09-19 12:30:19,458 127.0.0.1 - - [19/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:19,496 Request with ID bc20c488 for model gemma-7b received
2024-09-19 12:30:19,496 127.0.0.1 - - [19/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:19,598 Request with ID b2725346 for model gemma-7b received
2024-09-19 12:30:19,598 127.0.0.1 - - [19/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:19,971 Request with ID 49bdd1a4 for model gemma-7b received
2024-09-19 12:30:19,972 127.0.0.1 - - [19/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:20,169 Request with ID 9d9d3344 for model llama3-8b received
2024-09-19 12:30:20,170 127.0.0.1 - - [19/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:20,240 Request with ID 5f5d833e for model granite-7b received
2024-09-19 12:30:20,241 127.0.0.1 - - [19/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:20,292 Request with ID 166997d6 for model llama3-8b received
2024-09-19 12:30:20,292 127.0.0.1 - - [19/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:20,315 Request with ID cc0f1959 for model granite-7b received
2024-09-19 12:30:20,316 127.0.0.1 - - [19/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:20,499 Request with ID 17d771f6 for model granite-7b received
2024-09-19 12:30:20,500 127.0.0.1 - - [19/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:20,626 Request with ID c52f147f for model gemma-7b received
2024-09-19 12:30:20,627 127.0.0.1 - - [19/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:20,774 Request with ID d292f09a for model llama3-8b received
2024-09-19 12:30:20,775 127.0.0.1 - - [19/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:20,776 Request with ID cc7c4c91 for model gemma-7b received
2024-09-19 12:30:20,777 127.0.0.1 - - [19/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:20,779 Request with ID d1908954 for model llama3-8b received
2024-09-19 12:30:20,779 127.0.0.1 - - [19/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:20,829 Request with ID 35c992ef for model llama3-8b received
2024-09-19 12:30:20,829 127.0.0.1 - - [19/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:21,014 Request with ID 1e200237 for model gemma-7b received
2024-09-19 12:30:21,014 127.0.0.1 - - [19/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:21,045 Request with ID f5787e17 for model gemma-7b received
2024-09-19 12:30:21,045 127.0.0.1 - - [19/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:21,047 Request with ID 16420bf2 for model granite-7b received
2024-09-19 12:30:21,047 127.0.0.1 - - [19/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:21,078 Request with ID 5c8f6bcd for model llama3-8b received
2024-09-19 12:30:21,079 127.0.0.1 - - [19/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:21,259 Request with ID 10976f87 for model llama3-8b received
2024-09-19 12:30:21,259 127.0.0.1 - - [19/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:21,273 Request with ID 9e7e3eee for model granite-7b received
2024-09-19 12:30:21,273 127.0.0.1 - - [19/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:21,503 Request with ID 23c9e2f7 for model gemma-7b received
2024-09-19 12:30:21,504 127.0.0.1 - - [19/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:21,637 Request with ID 110444f7 for model granite-7b received
2024-09-19 12:30:21,638 127.0.0.1 - - [19/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:21,850 Request with ID 644ff42f for model granite-7b received
2024-09-19 12:30:21,850 127.0.0.1 - - [19/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:22,075 Request with ID ca7ad058 for model granite-7b received
2024-09-19 12:30:22,076 127.0.0.1 - - [19/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:22,252 Request with ID 79791494 for model gemma-7b received
2024-09-19 12:30:22,252 127.0.0.1 - - [19/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:22,284 Request with ID a185aa69 for model granite-7b received
2024-09-19 12:30:22,284 127.0.0.1 - - [19/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:22,367 Request with ID edd9a85b for model granite-7b received
2024-09-19 12:30:22,367 127.0.0.1 - - [19/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:22,665 Request with ID 65fdec27 for model granite-7b received
2024-09-19 12:30:22,666 127.0.0.1 - - [19/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:22,869 Request with ID 8c8fb536 for model llama3-8b received
2024-09-19 12:30:22,870 127.0.0.1 - - [19/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:23,032 Request with ID 3173de34 for model gemma-7b received
2024-09-19 12:30:23,032 127.0.0.1 - - [19/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:23,133 Request with ID 4fe5e0b7 for model gemma-7b received
2024-09-19 12:30:23,134 127.0.0.1 - - [19/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:23,189 Request with ID 88101fec for model llama3-8b received
2024-09-19 12:30:23,190 127.0.0.1 - - [19/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:23,308 Request with ID 574f9fbd for model granite-7b received
2024-09-19 12:30:23,309 127.0.0.1 - - [19/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:23,555 Request with ID 879bda41 for model gemma-7b received
2024-09-19 12:30:23,556 127.0.0.1 - - [19/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:23,588 Request with ID 8d87e63b for model gemma-7b received
2024-09-19 12:30:23,589 127.0.0.1 - - [19/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:23,769 Request with ID 14bd4db0 for model granite-7b received
2024-09-19 12:30:23,770 127.0.0.1 - - [19/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:23,785 Request with ID 771659ca for model llama3-8b received
2024-09-19 12:30:23,785 127.0.0.1 - - [19/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:23,996 Request with ID 087cbd27 for model granite-7b received
2024-09-19 12:30:23,996 127.0.0.1 - - [19/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:24,098 Request with ID f8509fe2 for model gemma-7b received
2024-09-19 12:30:24,099 127.0.0.1 - - [19/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:24,282 Request with ID 1e0e67de for model gemma-7b received
2024-09-19 12:30:24,283 127.0.0.1 - - [19/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:24,287 Request with ID c04b98e7 for model gemma-7b received
2024-09-19 12:30:24,287 127.0.0.1 - - [19/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:24,297 Request with ID e822ea6f for model granite-7b received
2024-09-19 12:30:24,297 127.0.0.1 - - [19/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:24,348 Request with ID 14f5cd4f for model granite-7b received
2024-09-19 12:30:24,349 127.0.0.1 - - [19/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:24,598 Request with ID 7ddcee9d for model granite-7b received
2024-09-19 12:30:24,598 127.0.0.1 - - [19/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:24,683 Request with ID 322df7de for model granite-7b received
2024-09-19 12:30:24,683 127.0.0.1 - - [19/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:24,993 Request with ID febd66ae for model gemma-7b received
2024-09-19 12:30:24,993 127.0.0.1 - - [19/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:25,018 Request with ID c384afc8 for model granite-7b received
2024-09-19 12:30:25,018 127.0.0.1 - - [19/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:25,110 Request with ID ad26603a for model granite-7b received
2024-09-19 12:30:25,110 127.0.0.1 - - [19/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:25,210 Request with ID a955091c for model granite-7b received
2024-09-19 12:30:25,210 127.0.0.1 - - [19/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:25,254 Request with ID 4af25466 for model granite-7b received
2024-09-19 12:30:25,254 127.0.0.1 - - [19/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:25,372 Request with ID e5db10d4 for model granite-7b received
2024-09-19 12:30:25,373 127.0.0.1 - - [19/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:25,380 Request with ID 8ec5e69e for model granite-7b received
2024-09-19 12:30:25,380 127.0.0.1 - - [19/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:25,726 Request with ID 0fcb2c19 for model gemma-7b received
2024-09-19 12:30:25,726 127.0.0.1 - - [19/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:25,771 Request with ID d1a55dcd for model llama3-8b received
2024-09-19 12:30:25,771 Moving batch for llama3-8b from incoming to running due to dynamic batch size 32
2024-09-19 12:30:25,771 Dynamic batch size condition met for model llama3-8b
2024-09-19 12:30:25,832 Request with ID 139436a3 for model gemma-7b received
2024-09-19 12:30:25,832 127.0.0.1 - - [19/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:26,074 Request with ID ac016a44 for model gemma-7b received
2024-09-19 12:30:26,074 127.0.0.1 - - [19/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:26,184 Request with ID ada3510b for model gemma-7b received
2024-09-19 12:30:26,184 127.0.0.1 - - [19/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:26,376 Request with ID 176369fc for model gemma-7b received
2024-09-19 12:30:26,376 127.0.0.1 - - [19/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:26,422 Loaded model gemma-7b
2024-09-19 12:30:26,425 Batch processing started for model gemma-7b
2024-09-19 12:30:26,495 Request with ID c285013e for model llama3-8b received
2024-09-19 12:30:26,496 127.0.0.1 - - [19/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:26,499 Request with ID 54665f9d for model gemma-7b received
2024-09-19 12:30:26,499 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-19 12:30:26,500 Dynamic batch size condition met for model gemma-7b
2024-09-19 12:30:27,237 Request with ID 2dc4c6d8 for model gemma-7b received
2024-09-19 12:30:27,238 127.0.0.1 - - [19/Sep/2024 12:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:27,487 Request with ID 0e8b6404 for model gemma-7b received
2024-09-19 12:30:27,487 127.0.0.1 - - [19/Sep/2024 12:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:27,523 Request with ID b21277ff for model granite-7b received
2024-09-19 12:30:27,523 127.0.0.1 - - [19/Sep/2024 12:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:27,684 Request with ID b5f135e7 for model granite-7b received
2024-09-19 12:30:27,684 127.0.0.1 - - [19/Sep/2024 12:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:27,745 Request with ID 284ad007 for model llama3-8b received
2024-09-19 12:30:27,746 127.0.0.1 - - [19/Sep/2024 12:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:27,749 Request with ID 5da08c52 for model granite-7b received
2024-09-19 12:30:27,750 127.0.0.1 - - [19/Sep/2024 12:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:27,835 Request with ID cb2a1bd6 for model llama3-8b received
2024-09-19 12:30:27,835 127.0.0.1 - - [19/Sep/2024 12:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:27,913 Request with ID 9198e041 for model granite-7b received
2024-09-19 12:30:27,913 127.0.0.1 - - [19/Sep/2024 12:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:28,000 Request with ID b1019767 for model gemma-7b received
2024-09-19 12:30:28,000 127.0.0.1 - - [19/Sep/2024 12:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:28,136 Request with ID 7ee36064 for model granite-7b received
2024-09-19 12:30:28,136 127.0.0.1 - - [19/Sep/2024 12:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:28,348 Request with ID 982fb032 for model granite-7b received
2024-09-19 12:30:28,348 127.0.0.1 - - [19/Sep/2024 12:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:28,814 Request with ID ff174d32 for model llama3-8b received
2024-09-19 12:30:28,814 127.0.0.1 - - [19/Sep/2024 12:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:28,891 Request with ID cfff4b0f for model gemma-7b received
2024-09-19 12:30:28,892 127.0.0.1 - - [19/Sep/2024 12:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:29,512 Request with ID baa8f218 for model gemma-7b received
2024-09-19 12:30:29,512 127.0.0.1 - - [19/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:29,564 Request with ID 8ef7a685 for model granite-7b received
2024-09-19 12:30:29,565 127.0.0.1 - - [19/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:29,653 Request with ID b90b0977 for model llama3-8b received
2024-09-19 12:30:29,654 127.0.0.1 - - [19/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:29,802 Request with ID 5db740fa for model granite-7b received
2024-09-19 12:30:29,803 127.0.0.1 - - [19/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:29,879 Request with ID 1faf9522 for model granite-7b received
2024-09-19 12:30:29,880 127.0.0.1 - - [19/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:29,915 Request with ID 67053204 for model granite-7b received
2024-09-19 12:30:29,916 127.0.0.1 - - [19/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:29,943 Request with ID 9c4ba926 for model granite-7b received
2024-09-19 12:30:29,943 127.0.0.1 - - [19/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:30,386 Request with ID fb6c7b37 for model granite-7b received
2024-09-19 12:30:30,387 127.0.0.1 - - [19/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:30,502 Request with ID 3ee6b61d for model gemma-7b received
2024-09-19 12:30:30,503 127.0.0.1 - - [19/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:30,533 Request with ID f972831b for model llama3-8b received
2024-09-19 12:30:30,534 127.0.0.1 - - [19/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:30,758 Processed batch: ['354ca950', '0822ae01', '59b9ccb1', '141f70d5', '1877b172', '8b402217', '2b34e899', 'a0d38d11', 'dcec332f', 'a35da27c', '3e2c0f84', '400cdee2', 'd9104abb', '9e07a9c3', '11992646', 'dda39cc0', '1b5a85f2', '8354b08a', 'fd4fa4eb', '3cccecff', '366cc151', '671f3cee', 'f3036f78', '3dc1eab6', 'efef784b', '80e5d90a', '0d7d6571', '9fbaf579', '8a05afb2', '3f3de708', 'f3530bca', 'e42f2492'] with model gemma-7b in 4.3331 seconds
2024-09-19 12:30:30,758 Saving sys info
2024-09-19 12:30:30,759 Request with ID e36f3d1e for model llama3-8b received
2024-09-19 12:30:30,759 127.0.0.1 - - [19/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:30,795 Latency for request 354ca950 with model gemma-7b: 38.2400 seconds
2024-09-19 12:30:30,795 Saving results with gpu monitoring
2024-09-19 12:30:30,798 Latency for request 0822ae01 with model gemma-7b: 37.0330 seconds
2024-09-19 12:30:30,798 Saving results with gpu monitoring
2024-09-19 12:30:30,800 Latency for request 59b9ccb1 with model gemma-7b: 36.4110 seconds
2024-09-19 12:30:30,800 Saving results with gpu monitoring
2024-09-19 12:30:30,802 Latency for request 141f70d5 with model gemma-7b: 36.3200 seconds
2024-09-19 12:30:30,802 Saving results with gpu monitoring
2024-09-19 12:30:30,804 Latency for request 1877b172 with model gemma-7b: 36.1160 seconds
2024-09-19 12:30:30,804 Saving results with gpu monitoring
2024-09-19 12:30:30,806 Latency for request 8b402217 with model gemma-7b: 35.9100 seconds
2024-09-19 12:30:30,806 Saving results with gpu monitoring
2024-09-19 12:30:30,808 Latency for request 2b34e899 with model gemma-7b: 35.5840 seconds
2024-09-19 12:30:30,808 Saving results with gpu monitoring
2024-09-19 12:30:30,810 Latency for request a0d38d11 with model gemma-7b: 35.5800 seconds
2024-09-19 12:30:30,810 Saving results with gpu monitoring
2024-09-19 12:30:30,812 Latency for request dcec332f with model gemma-7b: 35.3480 seconds
2024-09-19 12:30:30,812 Saving results with gpu monitoring
2024-09-19 12:30:30,814 Latency for request a35da27c with model gemma-7b: 35.2330 seconds
2024-09-19 12:30:30,814 Saving results with gpu monitoring
2024-09-19 12:30:30,816 Latency for request 3e2c0f84 with model gemma-7b: 35.2020 seconds
2024-09-19 12:30:30,816 Saving results with gpu monitoring
2024-09-19 12:30:30,818 Latency for request 400cdee2 with model gemma-7b: 34.9060 seconds
2024-09-19 12:30:30,818 Saving results with gpu monitoring
2024-09-19 12:30:30,820 Latency for request d9104abb with model gemma-7b: 34.7260 seconds
2024-09-19 12:30:30,820 Saving results with gpu monitoring
2024-09-19 12:30:30,822 Latency for request 9e07a9c3 with model gemma-7b: 34.7220 seconds
2024-09-19 12:30:30,822 Saving results with gpu monitoring
2024-09-19 12:30:30,824 Latency for request 11992646 with model gemma-7b: 34.3680 seconds
2024-09-19 12:30:30,824 Saving results with gpu monitoring
2024-09-19 12:30:30,826 Latency for request dda39cc0 with model gemma-7b: 33.6150 seconds
2024-09-19 12:30:30,826 Saving results with gpu monitoring
2024-09-19 12:30:30,828 Latency for request 1b5a85f2 with model gemma-7b: 33.1480 seconds
2024-09-19 12:30:30,828 Saving results with gpu monitoring
2024-09-19 12:30:30,830 Latency for request 8354b08a with model gemma-7b: 33.0330 seconds
2024-09-19 12:30:30,830 Saving results with gpu monitoring
2024-09-19 12:30:30,832 Latency for request fd4fa4eb with model gemma-7b: 32.8880 seconds
2024-09-19 12:30:30,832 Saving results with gpu monitoring
2024-09-19 12:30:30,834 Latency for request 3cccecff with model gemma-7b: 31.9660 seconds
2024-09-19 12:30:30,834 Saving results with gpu monitoring
2024-09-19 12:30:30,836 Latency for request 366cc151 with model gemma-7b: 31.8610 seconds
2024-09-19 12:30:30,836 Saving results with gpu monitoring
2024-09-19 12:30:30,838 Latency for request 671f3cee with model gemma-7b: 31.5270 seconds
2024-09-19 12:30:30,838 Saving results with gpu monitoring
2024-09-19 12:30:30,840 Latency for request f3036f78 with model gemma-7b: 31.3970 seconds
2024-09-19 12:30:30,840 Saving results with gpu monitoring
2024-09-19 12:30:30,842 Latency for request 3dc1eab6 with model gemma-7b: 31.2880 seconds
2024-09-19 12:30:30,842 Saving results with gpu monitoring
2024-09-19 12:30:30,844 Latency for request efef784b with model gemma-7b: 31.1280 seconds
2024-09-19 12:30:30,844 Saving results with gpu monitoring
2024-09-19 12:30:30,846 Latency for request 80e5d90a with model gemma-7b: 30.8860 seconds
2024-09-19 12:30:30,846 Saving results with gpu monitoring
2024-09-19 12:30:30,848 Latency for request 0d7d6571 with model gemma-7b: 30.1450 seconds
2024-09-19 12:30:30,848 Saving results with gpu monitoring
2024-09-19 12:30:30,850 Latency for request 9fbaf579 with model gemma-7b: 29.8600 seconds
2024-09-19 12:30:30,850 Saving results with gpu monitoring
2024-09-19 12:30:30,851 Latency for request 8a05afb2 with model gemma-7b: 29.1140 seconds
2024-09-19 12:30:30,852 Saving results with gpu monitoring
2024-09-19 12:30:30,853 Latency for request 3f3de708 with model gemma-7b: 28.3120 seconds
2024-09-19 12:30:30,853 Saving results with gpu monitoring
2024-09-19 12:30:30,855 Latency for request f3530bca with model gemma-7b: 28.2270 seconds
2024-09-19 12:30:30,855 Saving results with gpu monitoring
2024-09-19 12:30:30,857 Latency for request e42f2492 with model gemma-7b: 28.0860 seconds
2024-09-19 12:30:30,857 Saving results with gpu monitoring
2024-09-19 12:30:30,860 127.0.0.1 - - [19/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:30,860 Next: call load_model for llama3-8b
2024-09-19 12:30:30,976 Unloaded previous model
2024-09-19 12:30:31,207 Request with ID 8907e23a for model granite-7b received
2024-09-19 12:30:31,207 127.0.0.1 - - [19/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:31,577 Request with ID f63c8fe7 for model gemma-7b received
2024-09-19 12:30:31,581 Adjusted batch time limit for gemma-7b: 3.0000 seconds
2024-09-19 12:30:31,594 Request with ID ce4d3de5 for model granite-7b received
2024-09-19 12:30:31,595 127.0.0.1 - - [19/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:31,598 Request with ID a6df0ec7 for model granite-7b received
2024-09-19 12:30:31,607 127.0.0.1 - - [19/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:31,613 Request with ID 4e9ca1fe for model llama3-8b received
2024-09-19 12:30:31,621 127.0.0.1 - - [19/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:31,644 127.0.0.1 - - [19/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:31,867 Request with ID 3b5c5b73 for model gemma-7b received
2024-09-19 12:30:31,871 127.0.0.1 - - [19/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:31,888 Request with ID 157db961 for model gemma-7b received
2024-09-19 12:30:31,888 127.0.0.1 - - [19/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:31,899 Request with ID 59a29641 for model granite-7b received
2024-09-19 12:30:31,903 127.0.0.1 - - [19/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:32,028 Request with ID b143c63f for model gemma-7b received
2024-09-19 12:30:32,032 127.0.0.1 - - [19/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:32,113 Request with ID 824255b2 for model llama3-8b received
2024-09-19 12:30:32,124 127.0.0.1 - - [19/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:32,251 Request with ID b83fcd02 for model granite-7b received
2024-09-19 12:30:32,255 127.0.0.1 - - [19/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:32,262 Request with ID 19c11982 for model llama3-8b received
2024-09-19 12:30:32,262 127.0.0.1 - - [19/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:32,380 Request with ID c2cd5343 for model granite-7b received
2024-09-19 12:30:32,381 127.0.0.1 - - [19/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:32,636 Request with ID 63b8d4ba for model granite-7b received
2024-09-19 12:30:32,637 127.0.0.1 - - [19/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:32,688 Request with ID 32bd8fb9 for model granite-7b received
2024-09-19 12:30:32,689 127.0.0.1 - - [19/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:32,809 Request with ID 85662222 for model granite-7b received
2024-09-19 12:30:32,810 127.0.0.1 - - [19/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:32,817 Request with ID bb98cdd0 for model gemma-7b received
2024-09-19 12:30:32,817 127.0.0.1 - - [19/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:32,826 Request with ID 5849feb2 for model granite-7b received
2024-09-19 12:30:32,826 127.0.0.1 - - [19/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:33,044 Request with ID 82439b68 for model gemma-7b received
2024-09-19 12:30:33,044 127.0.0.1 - - [19/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:33,220 Request with ID 5cd552ed for model gemma-7b received
2024-09-19 12:30:33,221 127.0.0.1 - - [19/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:33,301 Request with ID c208f353 for model granite-7b received
2024-09-19 12:30:33,301 127.0.0.1 - - [19/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:33,516 Request with ID cece3a5b for model llama3-8b received
2024-09-19 12:30:33,517 127.0.0.1 - - [19/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:33,719 Request with ID d9b0a3df for model granite-7b received
2024-09-19 12:30:33,720 127.0.0.1 - - [19/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:33,746 Request with ID 4cbc4485 for model gemma-7b received
2024-09-19 12:30:33,746 127.0.0.1 - - [19/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:33,844 Request with ID fed5e86d for model granite-7b received
2024-09-19 12:30:33,845 127.0.0.1 - - [19/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:34,059 Request with ID bdaba6ea for model granite-7b received
2024-09-19 12:30:34,059 127.0.0.1 - - [19/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:34,273 Request with ID 4f9b7709 for model granite-7b received
2024-09-19 12:30:34,273 127.0.0.1 - - [19/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:34,314 Request with ID 67717a4f for model granite-7b received
2024-09-19 12:30:34,315 127.0.0.1 - - [19/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:34,488 Request with ID ef3f0f85 for model gemma-7b received
2024-09-19 12:30:34,490 Request with ID 382631df for model granite-7b received
2024-09-19 12:30:34,490 127.0.0.1 - - [19/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:34,491 127.0.0.1 - - [19/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:34,529 Request with ID 3a003cd7 for model gemma-7b received
2024-09-19 12:30:34,530 127.0.0.1 - - [19/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:34,559 Request with ID 2d1e847e for model granite-7b received
2024-09-19 12:30:34,560 127.0.0.1 - - [19/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:34,733 Request with ID 54b53077 for model granite-7b received
2024-09-19 12:30:34,734 127.0.0.1 - - [19/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:34,878 Request with ID 32445882 for model granite-7b received
2024-09-19 12:30:34,879 127.0.0.1 - - [19/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:35,064 Request with ID 89e26186 for model gemma-7b received
2024-09-19 12:30:35,064 127.0.0.1 - - [19/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:35,334 Request with ID 4d496113 for model gemma-7b received
2024-09-19 12:30:35,335 127.0.0.1 - - [19/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:35,354 Request with ID 9780458e for model granite-7b received
2024-09-19 12:30:35,354 127.0.0.1 - - [19/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:35,392 Request with ID a9dc18ab for model gemma-7b received
2024-09-19 12:30:35,393 127.0.0.1 - - [19/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:35,517 Request with ID 39c32f85 for model granite-7b received
2024-09-19 12:30:35,518 127.0.0.1 - - [19/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:35,617 Request with ID ff7deda4 for model gemma-7b received
2024-09-19 12:30:35,618 127.0.0.1 - - [19/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:35,676 Request with ID dd29c517 for model granite-7b received
2024-09-19 12:30:35,676 127.0.0.1 - - [19/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:35,820 Request with ID a1bd6016 for model granite-7b received
2024-09-19 12:30:35,820 Moving batch for granite-7b from incoming to running due to dynamic batch size 64
2024-09-19 12:30:35,821 Dynamic batch size condition met for model granite-7b
2024-09-19 12:30:35,994 Request with ID 666f958d for model llama3-8b received
2024-09-19 12:30:35,994 127.0.0.1 - - [19/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,024 Request with ID 2186bbfa for model granite-7b received
2024-09-19 12:30:36,025 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,059 Request with ID cc54e839 for model granite-7b received
2024-09-19 12:30:36,059 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,120 Request with ID 4ba41f25 for model gemma-7b received
2024-09-19 12:30:36,121 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,297 Request with ID d457597f for model granite-7b received
2024-09-19 12:30:36,298 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,306 Request with ID f12d556b for model granite-7b received
2024-09-19 12:30:36,307 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,321 Request with ID 6469587a for model llama3-8b received
2024-09-19 12:30:36,321 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,378 Request with ID d2a75821 for model granite-7b received
2024-09-19 12:30:36,378 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,411 Request with ID 8f1c6358 for model granite-7b received
2024-09-19 12:30:36,411 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,452 Request with ID 1b5245c3 for model granite-7b received
2024-09-19 12:30:36,452 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,476 Request with ID ff167d8d for model llama3-8b received
2024-09-19 12:30:36,477 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,604 Request with ID a3c27e29 for model llama3-8b received
2024-09-19 12:30:36,605 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,670 Request with ID 16e27b9b for model granite-7b received
2024-09-19 12:30:36,670 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,694 Request with ID 2cac35c6 for model gemma-7b received
2024-09-19 12:30:36,694 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:36,882 Request with ID 0a0db729 for model granite-7b received
2024-09-19 12:30:36,883 127.0.0.1 - - [19/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:37,044 Request with ID 16781167 for model granite-7b received
2024-09-19 12:30:37,044 127.0.0.1 - - [19/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:37,299 Request with ID da57ec4b for model granite-7b received
2024-09-19 12:30:37,300 127.0.0.1 - - [19/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:37,313 Request with ID 4254ce27 for model granite-7b received
2024-09-19 12:30:37,313 127.0.0.1 - - [19/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:37,397 Request with ID 6c7d8337 for model granite-7b received
2024-09-19 12:30:37,397 127.0.0.1 - - [19/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:37,504 Request with ID c8ff75b6 for model gemma-7b received
2024-09-19 12:30:37,504 127.0.0.1 - - [19/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:37,561 Request with ID 86c56695 for model granite-7b received
2024-09-19 12:30:37,562 127.0.0.1 - - [19/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:37,563 Request with ID 487ffbfe for model gemma-7b received
2024-09-19 12:30:37,563 127.0.0.1 - - [19/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:37,616 Request with ID 644f4d06 for model gemma-7b received
2024-09-19 12:30:37,616 127.0.0.1 - - [19/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:37,726 Request with ID a58c6f06 for model llama3-8b received
2024-09-19 12:30:37,726 127.0.0.1 - - [19/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:37,879 Request with ID 5b0f2db7 for model gemma-7b received
2024-09-19 12:30:37,880 127.0.0.1 - - [19/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:38,019 Request with ID 08ac5563 for model granite-7b received
2024-09-19 12:30:38,020 127.0.0.1 - - [19/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:38,453 Request with ID 4ee81dd0 for model granite-7b received
2024-09-19 12:30:38,453 127.0.0.1 - - [19/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:38,520 Request with ID a8d373e3 for model gemma-7b received
2024-09-19 12:30:38,521 127.0.0.1 - - [19/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:38,604 Request with ID 46804e80 for model llama3-8b received
2024-09-19 12:30:38,605 127.0.0.1 - - [19/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:38,612 Request with ID 39554934 for model granite-7b received
2024-09-19 12:30:38,612 127.0.0.1 - - [19/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:38,616 Request with ID 8a801ffb for model granite-7b received
2024-09-19 12:30:38,616 127.0.0.1 - - [19/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:38,657 Request with ID 10177fe7 for model gemma-7b received
2024-09-19 12:30:38,657 127.0.0.1 - - [19/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:38,822 Request with ID 2867163d for model granite-7b received
2024-09-19 12:30:38,823 127.0.0.1 - - [19/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:38,832 Request with ID 4223828a for model granite-7b received
2024-09-19 12:30:38,832 127.0.0.1 - - [19/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:39,061 Request with ID 0f157537 for model llama3-8b received
2024-09-19 12:30:39,062 127.0.0.1 - - [19/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:39,066 Request with ID e48c8910 for model granite-7b received
2024-09-19 12:30:39,066 127.0.0.1 - - [19/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:39,344 Request with ID 8027101d for model gemma-7b received
2024-09-19 12:30:39,345 127.0.0.1 - - [19/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:39,498 Request with ID 0af55a8b for model llama3-8b received
2024-09-19 12:30:39,499 127.0.0.1 - - [19/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:39,508 Request with ID bcd1f80e for model gemma-7b received
2024-09-19 12:30:39,509 127.0.0.1 - - [19/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:39,602 Request with ID a172d160 for model granite-7b received
2024-09-19 12:30:39,603 127.0.0.1 - - [19/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:39,706 Request with ID a03fb434 for model granite-7b received
2024-09-19 12:30:39,706 127.0.0.1 - - [19/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:39,764 Request with ID 4af8fe45 for model gemma-7b received
2024-09-19 12:30:39,765 127.0.0.1 - - [19/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:39,831 Request with ID 89f3901f for model granite-7b received
2024-09-19 12:30:39,831 127.0.0.1 - - [19/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:40,205 Request with ID 1aeb4052 for model granite-7b received
2024-09-19 12:30:40,206 127.0.0.1 - - [19/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:40,363 Request with ID 363cdc2c for model granite-7b received
2024-09-19 12:30:40,364 127.0.0.1 - - [19/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:40,382 Request with ID f6fa800d for model gemma-7b received
2024-09-19 12:30:40,382 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-19 12:30:40,382 Dynamic batch size condition met for model gemma-7b
2024-09-19 12:30:40,410 Request with ID ee25dc59 for model llama3-8b received
2024-09-19 12:30:40,410 127.0.0.1 - - [19/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:40,517 Request with ID c21f82ee for model granite-7b received
2024-09-19 12:30:40,518 127.0.0.1 - - [19/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:40,542 Request with ID cc56a55f for model granite-7b received
2024-09-19 12:30:40,542 127.0.0.1 - - [19/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:40,728 Request with ID 1a90f9b0 for model gemma-7b received
2024-09-19 12:30:40,728 127.0.0.1 - - [19/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:40,865 Request with ID 72196cd2 for model gemma-7b received
2024-09-19 12:30:40,865 127.0.0.1 - - [19/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:40,999 Request with ID 1b579b73 for model granite-7b received
2024-09-19 12:30:41,000 127.0.0.1 - - [19/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:41,202 Request with ID 821fb560 for model gemma-7b received
2024-09-19 12:30:41,203 127.0.0.1 - - [19/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:41,205 Request with ID 2d392647 for model gemma-7b received
2024-09-19 12:30:41,205 127.0.0.1 - - [19/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:41,299 Request with ID 3313a6a9 for model gemma-7b received
2024-09-19 12:30:41,299 127.0.0.1 - - [19/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:41,785 Request with ID 0b25bfd6 for model llama3-8b received
2024-09-19 12:30:41,786 Moving batch for llama3-8b from incoming to running due to dynamic batch size 16
2024-09-19 12:30:41,786 Dynamic batch size condition met for model llama3-8b
2024-09-19 12:30:41,810 Request with ID 287f77d9 for model gemma-7b received
2024-09-19 12:30:41,810 127.0.0.1 - - [19/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:41,945 Request with ID ff0d8d18 for model gemma-7b received
2024-09-19 12:30:41,945 127.0.0.1 - - [19/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:42,187 Request with ID 89129a3c for model gemma-7b received
2024-09-19 12:30:42,187 127.0.0.1 - - [19/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:42,235 Request with ID 6d695efc for model granite-7b received
2024-09-19 12:30:42,236 127.0.0.1 - - [19/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:42,429 Request with ID 50fe28d6 for model granite-7b received
2024-09-19 12:30:42,430 127.0.0.1 - - [19/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:42,636 Request with ID 4b909187 for model gemma-7b received
2024-09-19 12:30:42,637 127.0.0.1 - - [19/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:42,723 Request with ID 40d167f1 for model granite-7b received
2024-09-19 12:30:42,724 127.0.0.1 - - [19/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:42,831 Request with ID 6fb89038 for model granite-7b received
2024-09-19 12:30:42,832 127.0.0.1 - - [19/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,029 Request with ID 80204aac for model granite-7b received
2024-09-19 12:30:43,030 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,180 Request with ID 6a933888 for model granite-7b received
2024-09-19 12:30:43,181 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,208 Request with ID 43afbbc1 for model granite-7b received
2024-09-19 12:30:43,208 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,283 Request with ID e31444a4 for model gemma-7b received
2024-09-19 12:30:43,283 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,299 Request with ID 36c91a4c for model gemma-7b received
2024-09-19 12:30:43,300 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,424 Request with ID 64ad2d95 for model granite-7b received
2024-09-19 12:30:43,424 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,473 Request with ID 65e41473 for model granite-7b received
2024-09-19 12:30:43,474 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,551 Request with ID 47076118 for model llama3-8b received
2024-09-19 12:30:43,552 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,642 Request with ID 6745a628 for model gemma-7b received
2024-09-19 12:30:43,642 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,721 Request with ID f423a61e for model granite-7b received
2024-09-19 12:30:43,722 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,727 Request with ID 9cac27a7 for model llama3-8b received
2024-09-19 12:30:43,728 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,733 Request with ID 1db1a513 for model granite-7b received
2024-09-19 12:30:43,733 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,755 Request with ID 13367d2e for model granite-7b received
2024-09-19 12:30:43,756 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,827 Request with ID dfa5bfaa for model gemma-7b received
2024-09-19 12:30:43,828 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,879 Request with ID 5a47bfbd for model gemma-7b received
2024-09-19 12:30:43,881 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:43,884 Request with ID d5475c3d for model gemma-7b received
2024-09-19 12:30:43,885 127.0.0.1 - - [19/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:44,196 Request with ID 6c848732 for model granite-7b received
2024-09-19 12:30:44,197 127.0.0.1 - - [19/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:44,199 Request with ID e0776c8d for model gemma-7b received
2024-09-19 12:30:44,199 127.0.0.1 - - [19/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:44,200 Request with ID 9d874538 for model granite-7b received
2024-09-19 12:30:44,201 127.0.0.1 - - [19/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:44,300 Request with ID 0e463bd4 for model gemma-7b received
2024-09-19 12:30:44,300 127.0.0.1 - - [19/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:44,653 Request with ID ebd82df1 for model gemma-7b received
2024-09-19 12:30:44,654 127.0.0.1 - - [19/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:44,671 Request with ID 098b2e04 for model llama3-8b received
2024-09-19 12:30:44,671 127.0.0.1 - - [19/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:44,692 Request with ID f310d906 for model llama3-8b received
2024-09-19 12:30:44,692 127.0.0.1 - - [19/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:44,809 Request with ID 09c56291 for model granite-7b received
2024-09-19 12:30:44,809 127.0.0.1 - - [19/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:44,989 Request with ID 3fb2131e for model gemma-7b received
2024-09-19 12:30:44,990 127.0.0.1 - - [19/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:44,992 Request with ID cb4252c9 for model gemma-7b received
2024-09-19 12:30:44,992 127.0.0.1 - - [19/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:45,246 Request with ID ec466e4b for model gemma-7b received
2024-09-19 12:30:45,246 127.0.0.1 - - [19/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:45,297 Request with ID 09b13578 for model gemma-7b received
2024-09-19 12:30:45,298 127.0.0.1 - - [19/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:45,341 Request with ID c84db59a for model gemma-7b received
2024-09-19 12:30:45,342 127.0.0.1 - - [19/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:45,383 Request with ID b344aaae for model llama3-8b received
2024-09-19 12:30:45,384 127.0.0.1 - - [19/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:45,537 Request with ID ad02b2f2 for model granite-7b received
2024-09-19 12:30:45,538 127.0.0.1 - - [19/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:45,644 Request with ID 9d8b2576 for model llama3-8b received
2024-09-19 12:30:45,645 127.0.0.1 - - [19/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:45,703 Request with ID 018247b1 for model granite-7b received
2024-09-19 12:30:45,703 127.0.0.1 - - [19/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:45,908 Request with ID b43ae4bb for model granite-7b received
2024-09-19 12:30:45,908 127.0.0.1 - - [19/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,014 Request with ID a96fbc29 for model gemma-7b received
2024-09-19 12:30:46,014 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,062 Request with ID 34627fce for model gemma-7b received
2024-09-19 12:30:46,063 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,143 Request with ID 81f3c406 for model granite-7b received
2024-09-19 12:30:46,143 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,233 Request with ID e5d821bc for model granite-7b received
2024-09-19 12:30:46,233 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,281 Request with ID 2504bd3a for model granite-7b received
2024-09-19 12:30:46,282 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,285 Request with ID c40789c1 for model granite-7b received
2024-09-19 12:30:46,286 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,304 Request with ID a78319a1 for model gemma-7b received
2024-09-19 12:30:46,304 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,382 Request with ID 32a50228 for model gemma-7b received
2024-09-19 12:30:46,382 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,551 Request with ID bd3ea851 for model gemma-7b received
2024-09-19 12:30:46,551 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,838 Request with ID dc851fc7 for model llama3-8b received
2024-09-19 12:30:46,839 Request with ID e7918395 for model llama3-8b received
2024-09-19 12:30:46,839 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,840 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,841 Request with ID e2b58d51 for model granite-7b received
2024-09-19 12:30:46,843 Request with ID 6e49b0b3 for model granite-7b received
2024-09-19 12:30:46,845 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,846 Request with ID d88dd421 for model llama3-8b received
2024-09-19 12:30:46,847 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,848 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:46,873 Request with ID 4acad014 for model gemma-7b received
2024-09-19 12:30:46,873 127.0.0.1 - - [19/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:47,001 Request with ID b643e2f2 for model granite-7b received
2024-09-19 12:30:47,002 127.0.0.1 - - [19/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:47,022 Request with ID ad5585cb for model gemma-7b received
2024-09-19 12:30:47,023 127.0.0.1 - - [19/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:47,148 Request with ID f47ecdc3 for model granite-7b received
2024-09-19 12:30:47,148 127.0.0.1 - - [19/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:47,479 Request with ID e60921c5 for model granite-7b received
2024-09-19 12:30:47,479 127.0.0.1 - - [19/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:47,650 Request with ID 4f3ab683 for model granite-7b received
2024-09-19 12:30:47,650 127.0.0.1 - - [19/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:47,752 Request with ID 5b5fc1c5 for model llama3-8b received
2024-09-19 12:30:47,752 127.0.0.1 - - [19/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:47,778 Request with ID 673869fc for model gemma-7b received
2024-09-19 12:30:47,779 127.0.0.1 - - [19/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:47,798 Request with ID 0018f72c for model llama3-8b received
2024-09-19 12:30:47,798 127.0.0.1 - - [19/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:48,031 Request with ID df5d550d for model gemma-7b received
2024-09-19 12:30:48,032 127.0.0.1 - - [19/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:48,062 Request with ID 1cf64e1d for model granite-7b received
2024-09-19 12:30:48,063 127.0.0.1 - - [19/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:48,237 Request with ID 2cf341ed for model gemma-7b received
2024-09-19 12:30:48,238 127.0.0.1 - - [19/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:48,255 Request with ID d88a9b2d for model gemma-7b received
2024-09-19 12:30:48,255 127.0.0.1 - - [19/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:48,275 Request with ID 9dbb5f50 for model llama3-8b received
2024-09-19 12:30:48,275 127.0.0.1 - - [19/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:48,341 Request with ID 294c3f19 for model granite-7b received
2024-09-19 12:30:48,341 127.0.0.1 - - [19/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:48,445 Request with ID a62afff8 for model granite-7b received
2024-09-19 12:30:48,445 127.0.0.1 - - [19/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:48,548 Request with ID d61cb7e2 for model granite-7b received
2024-09-19 12:30:48,549 127.0.0.1 - - [19/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:48,641 Request with ID aee47228 for model llama3-8b received
2024-09-19 12:30:48,642 127.0.0.1 - - [19/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:48,656 Request with ID 73df14db for model granite-7b received
2024-09-19 12:30:48,657 127.0.0.1 - - [19/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:48,784 Request with ID 1de113c2 for model granite-7b received
2024-09-19 12:30:48,785 127.0.0.1 - - [19/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:48,958 Request with ID 13fa35ba for model gemma-7b received
2024-09-19 12:30:48,959 127.0.0.1 - - [19/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,045 Request with ID 3a1e7f82 for model gemma-7b received
2024-09-19 12:30:49,047 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,076 Request with ID 541c658e for model llama3-8b received
2024-09-19 12:30:49,077 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,099 Request with ID af7b7367 for model granite-7b received
2024-09-19 12:30:49,099 Moving batch for granite-7b from incoming to running due to dynamic batch size 64
2024-09-19 12:30:49,100 Dynamic batch size condition met for model granite-7b
2024-09-19 12:30:49,145 Request with ID ded4292d for model granite-7b received
2024-09-19 12:30:49,146 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,327 Request with ID fa94d227 for model llama3-8b received
2024-09-19 12:30:49,327 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,354 Request with ID da099838 for model gemma-7b received
2024-09-19 12:30:49,355 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,432 Request with ID 4db1fd53 for model granite-7b received
2024-09-19 12:30:49,433 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,545 Request with ID 3e04727d for model gemma-7b received
2024-09-19 12:30:49,546 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,627 Request with ID 8cc49f92 for model granite-7b received
2024-09-19 12:30:49,628 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,634 Request with ID de2974e3 for model llama3-8b received
2024-09-19 12:30:49,634 Moving batch for llama3-8b from incoming to running due to dynamic batch size 16
2024-09-19 12:30:49,635 Dynamic batch size condition met for model llama3-8b
2024-09-19 12:30:49,655 Request with ID c6b40423 for model granite-7b received
2024-09-19 12:30:49,656 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,712 Request with ID fe6f1847 for model llama3-8b received
2024-09-19 12:30:49,714 Request with ID 1f04d8d7 for model gemma-7b received
2024-09-19 12:30:49,715 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,715 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,900 Request with ID 59642dbf for model granite-7b received
2024-09-19 12:30:49,901 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:49,902 Request with ID 75e0ef56 for model llama3-8b received
2024-09-19 12:30:49,903 127.0.0.1 - - [19/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,149 Request with ID 774df2f9 for model granite-7b received
2024-09-19 12:30:50,150 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,265 Request with ID c50f4121 for model gemma-7b received
2024-09-19 12:30:50,266 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,272 Request with ID 8ea6e95c for model llama3-8b received
2024-09-19 12:30:50,273 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,368 Request with ID 62ab8e22 for model gemma-7b received
2024-09-19 12:30:50,369 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,372 Request with ID f76ee4f9 for model granite-7b received
2024-09-19 12:30:50,372 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,416 Request with ID 4fb5ff2b for model granite-7b received
2024-09-19 12:30:50,416 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,445 Request with ID 50334fa7 for model llama3-8b received
2024-09-19 12:30:50,446 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,480 Request with ID 15fcd93a for model gemma-7b received
2024-09-19 12:30:50,480 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,556 Request with ID b381334f for model gemma-7b received
2024-09-19 12:30:50,557 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,641 Request with ID 0adec1e6 for model llama3-8b received
2024-09-19 12:30:50,642 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,665 Request with ID 48899e0b for model granite-7b received
2024-09-19 12:30:50,665 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,838 Request with ID a3cdd1fe for model gemma-7b received
2024-09-19 12:30:50,839 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,916 Request with ID 69ffecb0 for model granite-7b received
2024-09-19 12:30:50,917 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,942 Request with ID 60d705a6 for model granite-7b received
2024-09-19 12:30:50,942 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:50,944 Request with ID 199511e0 for model granite-7b received
2024-09-19 12:30:50,945 127.0.0.1 - - [19/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:51,265 Request with ID af4a281e for model gemma-7b received
2024-09-19 12:30:51,266 127.0.0.1 - - [19/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:51,437 Request with ID acbfd3c3 for model granite-7b received
2024-09-19 12:30:51,438 127.0.0.1 - - [19/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:51,476 Request with ID 1e8f150b for model granite-7b received
2024-09-19 12:30:51,476 127.0.0.1 - - [19/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:51,592 Loaded model llama3-8b
2024-09-19 12:30:51,594 Request with ID ee2fddf7 for model llama3-8b received
2024-09-19 12:30:51,595 127.0.0.1 - - [19/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:51,598 Batch processing started for model llama3-8b
2024-09-19 12:30:51,609 Request with ID 2d190584 for model llama3-8b received
2024-09-19 12:30:51,610 127.0.0.1 - - [19/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:51,721 Request with ID 9265ce91 for model granite-7b received
2024-09-19 12:30:51,721 127.0.0.1 - - [19/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:52,053 Request with ID 8eafa28b for model gemma-7b received
2024-09-19 12:30:52,054 127.0.0.1 - - [19/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:52,066 Request with ID ba078a8b for model granite-7b received
2024-09-19 12:30:52,067 127.0.0.1 - - [19/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:52,140 Request with ID b907c6aa for model granite-7b received
2024-09-19 12:30:52,140 127.0.0.1 - - [19/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:52,333 Request with ID 4b6fa874 for model granite-7b received
2024-09-19 12:30:52,334 127.0.0.1 - - [19/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:52,427 Request with ID 0515fb9e for model gemma-7b received
2024-09-19 12:30:52,428 127.0.0.1 - - [19/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:52,490 Request with ID f25de6c4 for model granite-7b received
2024-09-19 12:30:52,490 127.0.0.1 - - [19/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:52,632 Request with ID fbe9b73c for model gemma-7b received
2024-09-19 12:30:52,632 127.0.0.1 - - [19/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,045 Request with ID 414537a3 for model granite-7b received
2024-09-19 12:30:53,046 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,053 Request with ID 27c03552 for model granite-7b received
2024-09-19 12:30:53,053 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,065 Request with ID ebee2f2d for model granite-7b received
2024-09-19 12:30:53,066 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,139 Request with ID b61e0469 for model granite-7b received
2024-09-19 12:30:53,139 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,166 Request with ID cd1b139c for model granite-7b received
2024-09-19 12:30:53,167 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,266 Request with ID 2e109d5a for model llama3-8b received
2024-09-19 12:30:53,267 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,396 Request with ID 8780e7dd for model llama3-8b received
2024-09-19 12:30:53,397 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,458 Request with ID e57ac9bc for model granite-7b received
2024-09-19 12:30:53,458 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,535 Request with ID 67ca72b1 for model granite-7b received
2024-09-19 12:30:53,536 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,585 Request with ID 54dcd3fb for model granite-7b received
2024-09-19 12:30:53,586 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,600 Request with ID b7360a75 for model granite-7b received
2024-09-19 12:30:53,600 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,746 Request with ID eaa72232 for model gemma-7b received
2024-09-19 12:30:53,746 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:53,771 Request with ID 5b189f3f for model granite-7b received
2024-09-19 12:30:53,771 127.0.0.1 - - [19/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:54,146 Request with ID e0e7fd15 for model llama3-8b received
2024-09-19 12:30:54,147 127.0.0.1 - - [19/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:54,214 Request with ID 6dbc5e40 for model gemma-7b received
2024-09-19 12:30:54,215 127.0.0.1 - - [19/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:54,277 Request with ID 98ee9dd2 for model granite-7b received
2024-09-19 12:30:54,278 127.0.0.1 - - [19/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:54,344 Request with ID aa8faf5f for model llama3-8b received
2024-09-19 12:30:54,344 127.0.0.1 - - [19/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:54,373 Request with ID 0dd1817a for model granite-7b received
2024-09-19 12:30:54,373 127.0.0.1 - - [19/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:54,421 Request with ID 69eaf883 for model llama3-8b received
2024-09-19 12:30:54,422 127.0.0.1 - - [19/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:54,473 Request with ID e4231231 for model granite-7b received
2024-09-19 12:30:54,473 127.0.0.1 - - [19/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:54,583 Request with ID e2aa251e for model gemma-7b received
2024-09-19 12:30:54,583 127.0.0.1 - - [19/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:54,641 Request with ID aedc7f6f for model granite-7b received
2024-09-19 12:30:54,642 127.0.0.1 - - [19/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:54,910 Request with ID 05eaf1c9 for model llama3-8b received
2024-09-19 12:30:54,910 127.0.0.1 - - [19/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:54,980 Request with ID 654c665a for model llama3-8b received
2024-09-19 12:30:54,980 127.0.0.1 - - [19/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,083 Request with ID 135d9e03 for model llama3-8b received
2024-09-19 12:30:55,083 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,143 Request with ID 60d55ee7 for model llama3-8b received
2024-09-19 12:30:55,144 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,203 Request with ID f5d6ec37 for model granite-7b received
2024-09-19 12:30:55,204 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,213 Request with ID d9f05a49 for model gemma-7b received
2024-09-19 12:30:55,213 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,378 Request with ID 02606ac5 for model gemma-7b received
2024-09-19 12:30:55,378 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,428 Request with ID 80a05655 for model granite-7b received
2024-09-19 12:30:55,428 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,472 Request with ID d0ee8a7c for model llama3-8b received
2024-09-19 12:30:55,473 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,627 Request with ID f26b885d for model granite-7b received
2024-09-19 12:30:55,628 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,638 Request with ID 58167f25 for model gemma-7b received
2024-09-19 12:30:55,638 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,670 Request with ID 5be8b53d for model granite-7b received
2024-09-19 12:30:55,671 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,745 Request with ID 2fd2fac9 for model gemma-7b received
2024-09-19 12:30:55,746 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,772 Request with ID 3f5eb798 for model granite-7b received
2024-09-19 12:30:55,772 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:55,870 Request with ID 2fd23754 for model granite-7b received
2024-09-19 12:30:55,871 127.0.0.1 - - [19/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:56,194 Request with ID 1380876f for model granite-7b received
2024-09-19 12:30:56,194 127.0.0.1 - - [19/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:56,525 Processed batch: ['10718c99', '65fb9101', 'cbed74be', '207fe094', '60c936f6', '558853e5', 'ae3e4918', '1d850c9b', 'efe5e0f4', 'be0a78a4', 'b9bdb193', '2c974845', 'b9cd7a4f', 'a0b0e3cb', '420b8b6f', '30391fb0', 'e32abe7f', '1642f870', 'c0be3eab', '78964498', '1f4b3972', '9d9d3344', '166997d6', 'd292f09a', 'd1908954', '35c992ef', '5c8f6bcd', '10976f87', '8c8fb536', '88101fec', '771659ca', 'd1a55dcd'] with model llama3-8b in 4.9266 seconds
2024-09-19 12:30:56,525 Saving sys info
2024-09-19 12:30:56,541 Request with ID 5af96b21 for model granite-7b received
2024-09-19 12:30:56,542 127.0.0.1 - - [19/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:56,554 Request with ID 6317eae9 for model gemma-7b received
2024-09-19 12:30:56,555 127.0.0.1 - - [19/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:56,556 Latency for request 10718c99 with model llama3-8b: 45.4700 seconds
2024-09-19 12:30:56,557 Saving results with gpu monitoring
2024-09-19 12:30:56,560 Latency for request 65fb9101 with model llama3-8b: 45.4680 seconds
2024-09-19 12:30:56,560 Saving results with gpu monitoring
2024-09-19 12:30:56,562 Latency for request cbed74be with model llama3-8b: 45.4590 seconds
2024-09-19 12:30:56,562 Saving results with gpu monitoring
2024-09-19 12:30:56,564 Latency for request 207fe094 with model llama3-8b: 45.4520 seconds
2024-09-19 12:30:56,564 Saving results with gpu monitoring
2024-09-19 12:30:56,566 Latency for request 60c936f6 with model llama3-8b: 44.8910 seconds
2024-09-19 12:30:56,566 Saving results with gpu monitoring
2024-09-19 12:30:56,568 Latency for request 558853e5 with model llama3-8b: 44.6700 seconds
2024-09-19 12:30:56,568 Saving results with gpu monitoring
2024-09-19 12:30:56,570 Latency for request ae3e4918 with model llama3-8b: 44.6450 seconds
2024-09-19 12:30:56,570 Saving results with gpu monitoring
2024-09-19 12:30:56,572 Latency for request 1d850c9b with model llama3-8b: 43.9010 seconds
2024-09-19 12:30:56,572 Saving results with gpu monitoring
2024-09-19 12:30:56,574 Latency for request efe5e0f4 with model llama3-8b: 43.8930 seconds
2024-09-19 12:30:56,574 Saving results with gpu monitoring
2024-09-19 12:30:56,576 Latency for request be0a78a4 with model llama3-8b: 43.8580 seconds
2024-09-19 12:30:56,576 Saving results with gpu monitoring
2024-09-19 12:30:56,578 Latency for request b9bdb193 with model llama3-8b: 42.9990 seconds
2024-09-19 12:30:56,578 Saving results with gpu monitoring
2024-09-19 12:30:56,580 Latency for request 2c974845 with model llama3-8b: 42.7910 seconds
2024-09-19 12:30:56,580 Saving results with gpu monitoring
2024-09-19 12:30:56,582 Latency for request b9cd7a4f with model llama3-8b: 42.2490 seconds
2024-09-19 12:30:56,582 Saving results with gpu monitoring
2024-09-19 12:30:56,584 Latency for request a0b0e3cb with model llama3-8b: 42.2290 seconds
2024-09-19 12:30:56,584 Saving results with gpu monitoring
2024-09-19 12:30:56,586 Latency for request 420b8b6f with model llama3-8b: 41.2640 seconds
2024-09-19 12:30:56,586 Saving results with gpu monitoring
2024-09-19 12:30:56,588 Latency for request 30391fb0 with model llama3-8b: 40.1870 seconds
2024-09-19 12:30:56,588 Saving results with gpu monitoring
2024-09-19 12:30:56,590 Latency for request e32abe7f with model llama3-8b: 39.0630 seconds
2024-09-19 12:30:56,590 Saving results with gpu monitoring
2024-09-19 12:30:56,592 Latency for request 1642f870 with model llama3-8b: 38.5320 seconds
2024-09-19 12:30:56,592 Saving results with gpu monitoring
2024-09-19 12:30:56,594 Latency for request c0be3eab with model llama3-8b: 38.0580 seconds
2024-09-19 12:30:56,594 Saving results with gpu monitoring
2024-09-19 12:30:56,596 Latency for request 78964498 with model llama3-8b: 37.5450 seconds
2024-09-19 12:30:56,596 Saving results with gpu monitoring
2024-09-19 12:30:56,598 Latency for request 1f4b3972 with model llama3-8b: 37.4890 seconds
2024-09-19 12:30:56,598 Saving results with gpu monitoring
2024-09-19 12:30:56,600 Latency for request 9d9d3344 with model llama3-8b: 36.3550 seconds
2024-09-19 12:30:56,600 Saving results with gpu monitoring
2024-09-19 12:30:56,602 Latency for request 166997d6 with model llama3-8b: 36.2330 seconds
2024-09-19 12:30:56,602 Saving results with gpu monitoring
2024-09-19 12:30:56,604 Latency for request d292f09a with model llama3-8b: 35.7510 seconds
2024-09-19 12:30:56,604 Saving results with gpu monitoring
2024-09-19 12:30:56,606 Latency for request d1908954 with model llama3-8b: 35.7460 seconds
2024-09-19 12:30:56,606 Saving results with gpu monitoring
2024-09-19 12:30:56,608 Latency for request 35c992ef with model llama3-8b: 35.6960 seconds
2024-09-19 12:30:56,608 Saving results with gpu monitoring
2024-09-19 12:30:56,610 Latency for request 5c8f6bcd with model llama3-8b: 35.4470 seconds
2024-09-19 12:30:56,610 Saving results with gpu monitoring
2024-09-19 12:30:56,612 Latency for request 10976f87 with model llama3-8b: 35.2660 seconds
2024-09-19 12:30:56,612 Saving results with gpu monitoring
2024-09-19 12:30:56,614 Latency for request 8c8fb536 with model llama3-8b: 33.6550 seconds
2024-09-19 12:30:56,614 Saving results with gpu monitoring
2024-09-19 12:30:56,616 Latency for request 88101fec with model llama3-8b: 33.3360 seconds
2024-09-19 12:30:56,616 Saving results with gpu monitoring
2024-09-19 12:30:56,618 Latency for request 771659ca with model llama3-8b: 32.7400 seconds
2024-09-19 12:30:56,618 Saving results with gpu monitoring
2024-09-19 12:30:56,620 Latency for request d1a55dcd with model llama3-8b: 30.7540 seconds
2024-09-19 12:30:56,620 Saving results with gpu monitoring
2024-09-19 12:30:56,622 127.0.0.1 - - [19/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:56,622 Next: call load_model for granite-7b
2024-09-19 12:30:56,720 Unloaded previous model
2024-09-19 12:30:56,767 Request with ID 2907f369 for model granite-7b received
2024-09-19 12:30:56,768 Request with ID 461f7079 for model gemma-7b received
2024-09-19 12:30:56,768 127.0.0.1 - - [19/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:56,772 127.0.0.1 - - [19/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:56,986 Request with ID 2e38193f for model granite-7b received
2024-09-19 12:30:56,987 127.0.0.1 - - [19/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:57,063 Request with ID 6c4cf00e for model granite-7b received
2024-09-19 12:30:57,067 127.0.0.1 - - [19/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:57,177 Request with ID 1b21ea72 for model granite-7b received
2024-09-19 12:30:57,178 127.0.0.1 - - [19/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:57,579 Request with ID a3e6e46d for model llama3-8b received
2024-09-19 12:30:57,673 Adjusted batch time limit for llama3-8b: 3.0000 seconds
2024-09-19 12:30:57,674 127.0.0.1 - - [19/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:57,771 Request with ID e0583340 for model llama3-8b received
2024-09-19 12:30:57,772 127.0.0.1 - - [19/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:57,803 Request with ID 91328365 for model gemma-7b received
2024-09-19 12:30:57,803 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-19 12:30:57,803 Dynamic batch size condition met for model gemma-7b
2024-09-19 12:30:57,886 Request with ID 8f8c3b29 for model gemma-7b received
2024-09-19 12:30:57,887 127.0.0.1 - - [19/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:57,907 Request with ID 098db706 for model gemma-7b received
2024-09-19 12:30:57,907 127.0.0.1 - - [19/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:57,940 Request with ID b06afeef for model granite-7b received
2024-09-19 12:30:57,940 127.0.0.1 - - [19/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:58,072 Request with ID 254c4ecc for model llama3-8b received
2024-09-19 12:30:58,072 127.0.0.1 - - [19/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:58,140 Request with ID 646514f4 for model llama3-8b received
2024-09-19 12:30:58,140 127.0.0.1 - - [19/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:58,273 Request with ID 4d7599b1 for model gemma-7b received
2024-09-19 12:30:58,274 127.0.0.1 - - [19/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:58,369 Request with ID cf166c88 for model gemma-7b received
2024-09-19 12:30:58,370 127.0.0.1 - - [19/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:58,488 Request with ID 8c31ccff for model gemma-7b received
2024-09-19 12:30:58,489 127.0.0.1 - - [19/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:58,700 Request with ID a2cb76d2 for model granite-7b received
2024-09-19 12:30:58,701 127.0.0.1 - - [19/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:58,783 Request with ID 1efe9993 for model gemma-7b received
2024-09-19 12:30:58,784 127.0.0.1 - - [19/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:59,267 Request with ID 19a15573 for model granite-7b received
2024-09-19 12:30:59,267 127.0.0.1 - - [19/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:59,429 Request with ID d781a875 for model gemma-7b received
2024-09-19 12:30:59,429 127.0.0.1 - - [19/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:59,527 Request with ID 86525b54 for model gemma-7b received
2024-09-19 12:30:59,527 127.0.0.1 - - [19/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:59,576 Request with ID b59dc3c9 for model gemma-7b received
2024-09-19 12:30:59,576 127.0.0.1 - - [19/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:59,578 Request with ID 9057a91e for model granite-7b received
2024-09-19 12:30:59,578 127.0.0.1 - - [19/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:59,716 Request with ID 63bebea9 for model gemma-7b received
2024-09-19 12:30:59,716 127.0.0.1 - - [19/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:59,860 Request with ID 16214158 for model llama3-8b received
2024-09-19 12:30:59,860 127.0.0.1 - - [19/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:30:59,925 Request with ID 83fe0a50 for model granite-7b received
2024-09-19 12:30:59,925 127.0.0.1 - - [19/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,086 Request with ID bb149cc3 for model gemma-7b received
2024-09-19 12:31:00,087 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,194 Request with ID 82e8bf3b for model granite-7b received
2024-09-19 12:31:00,194 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,306 Request with ID 8123eceb for model granite-7b received
2024-09-19 12:31:00,307 Request with ID 55346c60 for model gemma-7b received
2024-09-19 12:31:00,307 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,308 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,326 Request with ID 11d77aad for model granite-7b received
2024-09-19 12:31:00,326 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,416 Request with ID 04d6bcf0 for model gemma-7b received
2024-09-19 12:31:00,417 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,427 Request with ID cd4fbe84 for model gemma-7b received
2024-09-19 12:31:00,427 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,434 Request with ID 7984e3d3 for model gemma-7b received
2024-09-19 12:31:00,435 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,529 Request with ID 8a9ca3b6 for model granite-7b received
2024-09-19 12:31:00,529 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,632 Request with ID 2cf5598f for model gemma-7b received
2024-09-19 12:31:00,632 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,772 Request with ID 19d989ad for model gemma-7b received
2024-09-19 12:31:00,772 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,929 Request with ID f285e76c for model granite-7b received
2024-09-19 12:31:00,929 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,946 Request with ID b131ffe4 for model gemma-7b received
2024-09-19 12:31:00,947 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:00,975 Request with ID 74053131 for model granite-7b received
2024-09-19 12:31:00,976 127.0.0.1 - - [19/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:01,068 Request with ID 057cd850 for model llama3-8b received
2024-09-19 12:31:01,068 127.0.0.1 - - [19/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:01,341 Request with ID 2b25a59a for model granite-7b received
2024-09-19 12:31:01,341 127.0.0.1 - - [19/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:01,444 Request with ID 274e7374 for model gemma-7b received
2024-09-19 12:31:01,445 127.0.0.1 - - [19/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:01,458 Request with ID 1ef49544 for model llama3-8b received
2024-09-19 12:31:01,458 127.0.0.1 - - [19/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:01,598 Request with ID 213b0f53 for model gemma-7b received
2024-09-19 12:31:01,598 127.0.0.1 - - [19/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:01,618 Request with ID 9c3c592d for model llama3-8b received
2024-09-19 12:31:01,619 127.0.0.1 - - [19/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:01,638 Request with ID 8f439399 for model granite-7b received
2024-09-19 12:31:01,638 127.0.0.1 - - [19/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:01,819 Request with ID fd60daa6 for model gemma-7b received
2024-09-19 12:31:01,820 127.0.0.1 - - [19/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:02,086 Request with ID 73f1894e for model llama3-8b received
2024-09-19 12:31:02,086 127.0.0.1 - - [19/Sep/2024 12:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:02,112 Request with ID 347ab0cc for model llama3-8b received
2024-09-19 12:31:02,112 127.0.0.1 - - [19/Sep/2024 12:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:02,134 Request with ID 020770c9 for model granite-7b received
2024-09-19 12:31:02,134 127.0.0.1 - - [19/Sep/2024 12:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:02,415 Request with ID 1609ab44 for model granite-7b received
2024-09-19 12:31:02,416 127.0.0.1 - - [19/Sep/2024 12:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:02,547 Request with ID 1d4c1936 for model llama3-8b received
2024-09-19 12:31:02,548 127.0.0.1 - - [19/Sep/2024 12:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:02,698 Request with ID 7066b30c for model granite-7b received
2024-09-19 12:31:02,699 127.0.0.1 - - [19/Sep/2024 12:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:02,724 Request with ID bcfce2c5 for model granite-7b received
2024-09-19 12:31:02,725 127.0.0.1 - - [19/Sep/2024 12:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:02,982 Request with ID 9f05ebd7 for model llama3-8b received
2024-09-19 12:31:02,983 127.0.0.1 - - [19/Sep/2024 12:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:02,990 Request with ID 492639e3 for model granite-7b received
2024-09-19 12:31:02,990 127.0.0.1 - - [19/Sep/2024 12:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:02,994 Request with ID b75a5886 for model granite-7b received
2024-09-19 12:31:02,994 Moving batch for granite-7b from incoming to running due to dynamic batch size 64
2024-09-19 12:31:02,995 Dynamic batch size condition met for model granite-7b
2024-09-19 12:31:03,254 Request with ID e35f7da3 for model llama3-8b received
2024-09-19 12:31:03,254 127.0.0.1 - - [19/Sep/2024 12:31:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:03,282 Request with ID 8fce0bd2 for model granite-7b received
2024-09-19 12:31:03,282 127.0.0.1 - - [19/Sep/2024 12:31:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:03,435 Request with ID 72e2dc66 for model granite-7b received
2024-09-19 12:31:03,435 127.0.0.1 - - [19/Sep/2024 12:31:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:03,632 Request with ID 5cc2788c for model granite-7b received
2024-09-19 12:31:03,633 127.0.0.1 - - [19/Sep/2024 12:31:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:03,871 Request with ID bab76203 for model granite-7b received
2024-09-19 12:31:03,872 127.0.0.1 - - [19/Sep/2024 12:31:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:03,911 Request with ID 6355f62c for model granite-7b received
2024-09-19 12:31:03,911 127.0.0.1 - - [19/Sep/2024 12:31:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:04,143 Request with ID 5a003d04 for model gemma-7b received
2024-09-19 12:31:04,143 127.0.0.1 - - [19/Sep/2024 12:31:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:04,224 Request with ID ccdd63e7 for model gemma-7b received
2024-09-19 12:31:04,224 127.0.0.1 - - [19/Sep/2024 12:31:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:04,502 Request with ID 84ab2aa5 for model llama3-8b received
2024-09-19 12:31:04,502 127.0.0.1 - - [19/Sep/2024 12:31:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:04,659 Request with ID 2ee3f030 for model granite-7b received
2024-09-19 12:31:04,660 127.0.0.1 - - [19/Sep/2024 12:31:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:05,050 Request with ID 9e382bac for model granite-7b received
2024-09-19 12:31:05,050 127.0.0.1 - - [19/Sep/2024 12:31:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:05,092 Request with ID 4a72accb for model llama3-8b received
2024-09-19 12:31:05,092 Moving batch for llama3-8b from incoming to running due to dynamic batch size 32
2024-09-19 12:31:05,093 Dynamic batch size condition met for model llama3-8b
2024-09-19 12:31:05,188 Request with ID 39c777b7 for model granite-7b received
2024-09-19 12:31:05,188 127.0.0.1 - - [19/Sep/2024 12:31:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:05,317 Request with ID 65c98385 for model granite-7b received
2024-09-19 12:31:05,317 127.0.0.1 - - [19/Sep/2024 12:31:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:05,509 Request with ID 0bfff12a for model llama3-8b received
2024-09-19 12:31:05,510 127.0.0.1 - - [19/Sep/2024 12:31:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:05,535 Request with ID 4cd5aff5 for model gemma-7b received
2024-09-19 12:31:05,535 127.0.0.1 - - [19/Sep/2024 12:31:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:05,543 Request with ID 695fa31e for model gemma-7b received
2024-09-19 12:31:05,543 127.0.0.1 - - [19/Sep/2024 12:31:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:05,553 Request with ID 5c424748 for model llama3-8b received
2024-09-19 12:31:05,553 127.0.0.1 - - [19/Sep/2024 12:31:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:05,611 Request with ID 75a2302d for model gemma-7b received
2024-09-19 12:31:05,611 127.0.0.1 - - [19/Sep/2024 12:31:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:05,635 Request with ID 4ba9fa36 for model llama3-8b received
2024-09-19 12:31:05,636 127.0.0.1 - - [19/Sep/2024 12:31:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:05,700 Request with ID 6d71c82a for model granite-7b received
2024-09-19 12:31:05,700 127.0.0.1 - - [19/Sep/2024 12:31:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:05,773 Request with ID 23750aff for model granite-7b received
2024-09-19 12:31:05,774 127.0.0.1 - - [19/Sep/2024 12:31:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:06,158 Request with ID b474406e for model granite-7b received
2024-09-19 12:31:06,158 127.0.0.1 - - [19/Sep/2024 12:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:06,200 Request with ID 64eb2932 for model gemma-7b received
2024-09-19 12:31:06,201 127.0.0.1 - - [19/Sep/2024 12:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:06,345 Request with ID 665be836 for model gemma-7b received
2024-09-19 12:31:06,345 127.0.0.1 - - [19/Sep/2024 12:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:06,369 Request with ID 3406c0b8 for model llama3-8b received
2024-09-19 12:31:06,369 127.0.0.1 - - [19/Sep/2024 12:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:06,575 Request with ID b3a4dfc4 for model gemma-7b received
2024-09-19 12:31:06,576 127.0.0.1 - - [19/Sep/2024 12:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:06,658 Request with ID 18da5860 for model granite-7b received
2024-09-19 12:31:06,659 127.0.0.1 - - [19/Sep/2024 12:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:06,723 Request with ID 8a1b2fb5 for model granite-7b received
2024-09-19 12:31:06,723 127.0.0.1 - - [19/Sep/2024 12:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:06,773 Request with ID 5d70c039 for model granite-7b received
2024-09-19 12:31:06,774 127.0.0.1 - - [19/Sep/2024 12:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:06,835 Request with ID 2a2dddd7 for model granite-7b received
2024-09-19 12:31:06,835 127.0.0.1 - - [19/Sep/2024 12:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:06,894 Request with ID e961b972 for model granite-7b received
2024-09-19 12:31:06,895 127.0.0.1 - - [19/Sep/2024 12:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:06,971 Request with ID d39975f9 for model gemma-7b received
2024-09-19 12:31:06,972 127.0.0.1 - - [19/Sep/2024 12:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:07,005 Request with ID 0b10806d for model granite-7b received
2024-09-19 12:31:07,005 127.0.0.1 - - [19/Sep/2024 12:31:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:07,254 Request with ID c4af61d4 for model gemma-7b received
2024-09-19 12:31:07,254 127.0.0.1 - - [19/Sep/2024 12:31:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:07,314 Request with ID 196428f9 for model llama3-8b received
2024-09-19 12:31:07,315 127.0.0.1 - - [19/Sep/2024 12:31:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:07,553 Request with ID 538e60cb for model granite-7b received
2024-09-19 12:31:07,553 127.0.0.1 - - [19/Sep/2024 12:31:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:07,625 Request with ID a0b6d5f7 for model granite-7b received
2024-09-19 12:31:07,626 127.0.0.1 - - [19/Sep/2024 12:31:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:07,852 Request with ID 52970a2d for model llama3-8b received
2024-09-19 12:31:07,852 127.0.0.1 - - [19/Sep/2024 12:31:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:07,890 Request with ID d2318af8 for model llama3-8b received
2024-09-19 12:31:07,891 127.0.0.1 - - [19/Sep/2024 12:31:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:07,904 Request with ID a80967d0 for model gemma-7b received
2024-09-19 12:31:07,904 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-19 12:31:07,904 Dynamic batch size condition met for model gemma-7b
2024-09-19 12:31:08,248 Request with ID 0a9d8adc for model granite-7b received
2024-09-19 12:31:08,249 127.0.0.1 - - [19/Sep/2024 12:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:08,262 Request with ID efac3e10 for model gemma-7b received
2024-09-19 12:31:08,262 127.0.0.1 - - [19/Sep/2024 12:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:08,281 Request with ID cd45996a for model llama3-8b received
2024-09-19 12:31:08,281 127.0.0.1 - - [19/Sep/2024 12:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:08,391 Request with ID 2887c5ba for model granite-7b received
2024-09-19 12:31:08,392 127.0.0.1 - - [19/Sep/2024 12:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:08,394 Request with ID 88f0c89b for model llama3-8b received
2024-09-19 12:31:08,394 127.0.0.1 - - [19/Sep/2024 12:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:08,404 Request with ID 06643426 for model granite-7b received
2024-09-19 12:31:08,405 127.0.0.1 - - [19/Sep/2024 12:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:08,601 Request with ID e176f576 for model llama3-8b received
2024-09-19 12:31:08,602 127.0.0.1 - - [19/Sep/2024 12:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:08,613 Request with ID dd2fe63e for model llama3-8b received
2024-09-19 12:31:08,613 127.0.0.1 - - [19/Sep/2024 12:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:08,723 Request with ID bbc4e7ed for model llama3-8b received
2024-09-19 12:31:08,723 127.0.0.1 - - [19/Sep/2024 12:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:09,053 Request with ID 67587565 for model granite-7b received
2024-09-19 12:31:09,053 127.0.0.1 - - [19/Sep/2024 12:31:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:09,061 Request with ID 3e341fcc for model granite-7b received
2024-09-19 12:31:09,061 127.0.0.1 - - [19/Sep/2024 12:31:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:09,090 Request with ID 591dd08f for model llama3-8b received
2024-09-19 12:31:09,090 127.0.0.1 - - [19/Sep/2024 12:31:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:09,227 Request with ID 3304c709 for model gemma-7b received
2024-09-19 12:31:09,228 127.0.0.1 - - [19/Sep/2024 12:31:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:09,333 Request with ID 39f74f16 for model granite-7b received
2024-09-19 12:31:09,334 127.0.0.1 - - [19/Sep/2024 12:31:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:09,520 Request with ID 92b47766 for model llama3-8b received
2024-09-19 12:31:09,520 127.0.0.1 - - [19/Sep/2024 12:31:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:09,551 Request with ID cc5f634f for model granite-7b received
2024-09-19 12:31:09,552 127.0.0.1 - - [19/Sep/2024 12:31:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:09,666 Request with ID 2ad05344 for model granite-7b received
2024-09-19 12:31:09,668 Request with ID a3f8ef8a for model granite-7b received
2024-09-19 12:31:09,668 127.0.0.1 - - [19/Sep/2024 12:31:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:09,669 127.0.0.1 - - [19/Sep/2024 12:31:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:09,862 Request with ID 76b79404 for model llama3-8b received
2024-09-19 12:31:09,862 127.0.0.1 - - [19/Sep/2024 12:31:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:09,869 Request with ID 1fb6262c for model gemma-7b received
2024-09-19 12:31:09,870 127.0.0.1 - - [19/Sep/2024 12:31:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:09,991 Request with ID 1543aff5 for model granite-7b received
2024-09-19 12:31:09,991 127.0.0.1 - - [19/Sep/2024 12:31:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,036 Request with ID 04ae25e2 for model granite-7b received
2024-09-19 12:31:10,037 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,074 Request with ID 38c2b288 for model llama3-8b received
2024-09-19 12:31:10,074 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,222 Request with ID 8094fdde for model gemma-7b received
2024-09-19 12:31:10,222 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,253 Request with ID 4071afe5 for model gemma-7b received
2024-09-19 12:31:10,253 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,338 Request with ID 7d62eb25 for model granite-7b received
2024-09-19 12:31:10,340 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,400 Request with ID 2de7a9ca for model gemma-7b received
2024-09-19 12:31:10,400 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,449 Request with ID a950500f for model llama3-8b received
2024-09-19 12:31:10,449 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,516 Request with ID 5881bf81 for model granite-7b received
2024-09-19 12:31:10,517 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,652 Request with ID 6880b3cc for model llama3-8b received
2024-09-19 12:31:10,653 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,666 Request with ID b197b1e7 for model llama3-8b received
2024-09-19 12:31:10,666 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,844 Request with ID d8bc8991 for model llama3-8b received
2024-09-19 12:31:10,845 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,846 Request with ID 4c21d834 for model llama3-8b received
2024-09-19 12:31:10,847 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,880 Request with ID a02ed45c for model granite-7b received
2024-09-19 12:31:10,881 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,893 Request with ID 188daa84 for model granite-7b received
2024-09-19 12:31:10,894 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,980 Request with ID da1f1add for model llama3-8b received
2024-09-19 12:31:10,980 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:10,988 Request with ID cac1d89b for model granite-7b received
2024-09-19 12:31:10,988 127.0.0.1 - - [19/Sep/2024 12:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:11,225 Request with ID 17439824 for model llama3-8b received
2024-09-19 12:31:11,225 127.0.0.1 - - [19/Sep/2024 12:31:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:11,266 Request with ID 226fb3fe for model llama3-8b received
2024-09-19 12:31:11,267 127.0.0.1 - - [19/Sep/2024 12:31:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:11,287 Request with ID dfeb00b4 for model gemma-7b received
2024-09-19 12:31:11,287 127.0.0.1 - - [19/Sep/2024 12:31:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:11,472 Request with ID ea0ecf51 for model granite-7b received
2024-09-19 12:31:11,473 127.0.0.1 - - [19/Sep/2024 12:31:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:11,503 Request with ID 677ad552 for model llama3-8b received
2024-09-19 12:31:11,504 127.0.0.1 - - [19/Sep/2024 12:31:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:11,580 Request with ID 23f8196c for model granite-7b received
2024-09-19 12:31:11,580 127.0.0.1 - - [19/Sep/2024 12:31:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:11,605 Request with ID 8d4ec9b9 for model gemma-7b received
2024-09-19 12:31:11,605 127.0.0.1 - - [19/Sep/2024 12:31:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:11,609 Request with ID 77482ef3 for model llama3-8b received
2024-09-19 12:31:11,609 127.0.0.1 - - [19/Sep/2024 12:31:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:11,823 Request with ID b80cc9cc for model gemma-7b received
2024-09-19 12:31:11,824 127.0.0.1 - - [19/Sep/2024 12:31:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:11,881 Request with ID 89115844 for model gemma-7b received
2024-09-19 12:31:11,882 127.0.0.1 - - [19/Sep/2024 12:31:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:12,163 Request with ID 8181e5dc for model gemma-7b received
2024-09-19 12:31:12,164 127.0.0.1 - - [19/Sep/2024 12:31:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:12,207 Request with ID fbf6c38d for model gemma-7b received
2024-09-19 12:31:12,207 127.0.0.1 - - [19/Sep/2024 12:31:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:12,311 Request with ID d23b7e25 for model gemma-7b received
2024-09-19 12:31:12,311 127.0.0.1 - - [19/Sep/2024 12:31:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:12,323 Request with ID 84bb8d55 for model gemma-7b received
2024-09-19 12:31:12,323 127.0.0.1 - - [19/Sep/2024 12:31:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:12,679 Request with ID 28911d6d for model llama3-8b received
2024-09-19 12:31:12,680 127.0.0.1 - - [19/Sep/2024 12:31:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:12,772 Request with ID 52db6e95 for model gemma-7b received
2024-09-19 12:31:12,773 127.0.0.1 - - [19/Sep/2024 12:31:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:12,875 Request with ID a1d42a84 for model granite-7b received
2024-09-19 12:31:12,875 127.0.0.1 - - [19/Sep/2024 12:31:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:12,969 Request with ID b060727b for model granite-7b received
2024-09-19 12:31:12,970 127.0.0.1 - - [19/Sep/2024 12:31:12] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,003 Request with ID 5c2c2a2f for model granite-7b received
2024-09-19 12:31:13,003 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,070 Request with ID bbb5e3bb for model granite-7b received
2024-09-19 12:31:13,071 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,131 Request with ID 35dcc688 for model granite-7b received
2024-09-19 12:31:13,132 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,207 Request with ID ba49371a for model llama3-8b received
2024-09-19 12:31:13,208 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,212 Request with ID b16a0a26 for model granite-7b received
2024-09-19 12:31:13,213 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,224 Request with ID 3eb065f5 for model granite-7b received
2024-09-19 12:31:13,225 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,284 Request with ID 2d64b89d for model gemma-7b received
2024-09-19 12:31:13,284 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,320 Request with ID 339360cb for model llama3-8b received
2024-09-19 12:31:13,321 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,355 Request with ID b371fce0 for model gemma-7b received
2024-09-19 12:31:13,355 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,569 Request with ID 30f9e288 for model llama3-8b received
2024-09-19 12:31:13,570 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,638 Request with ID 06bff4b5 for model llama3-8b received
2024-09-19 12:31:13,638 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,652 Request with ID ec41923b for model granite-7b received
2024-09-19 12:31:13,653 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,786 Request with ID cfe3df8e for model llama3-8b received
2024-09-19 12:31:13,786 Moving batch for llama3-8b from incoming to running due to dynamic batch size 32
2024-09-19 12:31:13,786 Dynamic batch size condition met for model llama3-8b
2024-09-19 12:31:13,938 Loaded model granite-7b
2024-09-19 12:31:13,939 Request with ID 5dcad2d9 for model llama3-8b received
2024-09-19 12:31:13,940 127.0.0.1 - - [19/Sep/2024 12:31:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:13,944 Batch processing started for model granite-7b
2024-09-19 12:31:14,226 Request with ID 7f8f55f4 for model llama3-8b received
2024-09-19 12:31:14,227 127.0.0.1 - - [19/Sep/2024 12:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:14,228 Request with ID 97e01194 for model granite-7b received
2024-09-19 12:31:14,229 127.0.0.1 - - [19/Sep/2024 12:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:14,433 Request with ID c3942251 for model granite-7b received
2024-09-19 12:31:14,434 127.0.0.1 - - [19/Sep/2024 12:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:14,483 Request with ID 596b27a5 for model granite-7b received
2024-09-19 12:31:14,484 127.0.0.1 - - [19/Sep/2024 12:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:14,497 Request with ID d7aed061 for model gemma-7b received
2024-09-19 12:31:14,497 127.0.0.1 - - [19/Sep/2024 12:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:14,504 Request with ID 0ca2d0b4 for model llama3-8b received
2024-09-19 12:31:14,505 127.0.0.1 - - [19/Sep/2024 12:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:14,618 Request with ID 1995006b for model gemma-7b received
2024-09-19 12:31:14,619 127.0.0.1 - - [19/Sep/2024 12:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:14,839 Request with ID c0801bd3 for model granite-7b received
2024-09-19 12:31:14,840 127.0.0.1 - - [19/Sep/2024 12:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:14,943 Request with ID 65734124 for model granite-7b received
2024-09-19 12:31:14,943 127.0.0.1 - - [19/Sep/2024 12:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:15,046 Request with ID 72f70418 for model llama3-8b received
2024-09-19 12:31:15,046 127.0.0.1 - - [19/Sep/2024 12:31:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:15,052 Request with ID 3c5145d6 for model llama3-8b received
2024-09-19 12:31:15,052 127.0.0.1 - - [19/Sep/2024 12:31:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:15,227 Request with ID be3e8c9c for model granite-7b received
2024-09-19 12:31:15,228 127.0.0.1 - - [19/Sep/2024 12:31:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:15,295 Request with ID 5a996c43 for model granite-7b received
2024-09-19 12:31:15,295 127.0.0.1 - - [19/Sep/2024 12:31:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:15,308 Request with ID 0e8e339f for model granite-7b received
2024-09-19 12:31:15,308 127.0.0.1 - - [19/Sep/2024 12:31:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:15,373 Request with ID c1f26aa3 for model gemma-7b received
2024-09-19 12:31:15,374 127.0.0.1 - - [19/Sep/2024 12:31:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:15,563 Request with ID 83f2cd5a for model llama3-8b received
2024-09-19 12:31:15,563 127.0.0.1 - - [19/Sep/2024 12:31:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:15,615 Request with ID 14b7e1dc for model gemma-7b received
2024-09-19 12:31:15,616 127.0.0.1 - - [19/Sep/2024 12:31:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:15,815 Request with ID e8c7e173 for model granite-7b received
2024-09-19 12:31:15,816 127.0.0.1 - - [19/Sep/2024 12:31:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:15,978 Request with ID 81000a34 for model granite-7b received
2024-09-19 12:31:15,978 127.0.0.1 - - [19/Sep/2024 12:31:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,066 Request with ID b45442b3 for model granite-7b received
2024-09-19 12:31:16,067 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,105 Request with ID 76b2e2b1 for model granite-7b received
2024-09-19 12:31:16,106 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,108 Request with ID 8b16d7c7 for model gemma-7b received
2024-09-19 12:31:16,108 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,157 Request with ID 9bce4f47 for model granite-7b received
2024-09-19 12:31:16,157 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,380 Request with ID 53ccac8f for model granite-7b received
2024-09-19 12:31:16,381 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,485 Request with ID 426aa2e6 for model granite-7b received
2024-09-19 12:31:16,486 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,535 Request with ID 7db0beb1 for model gemma-7b received
2024-09-19 12:31:16,535 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,546 Request with ID 32034c53 for model gemma-7b received
2024-09-19 12:31:16,546 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,593 Request with ID 78398f45 for model llama3-8b received
2024-09-19 12:31:16,594 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,655 Request with ID 4855d9f2 for model granite-7b received
2024-09-19 12:31:16,656 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,724 Request with ID bed53b15 for model llama3-8b received
2024-09-19 12:31:16,724 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,802 Request with ID a94bd07a for model granite-7b received
2024-09-19 12:31:16,802 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,806 Request with ID d8e76646 for model llama3-8b received
2024-09-19 12:31:16,806 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:16,863 Request with ID 3d348ec5 for model granite-7b received
2024-09-19 12:31:16,863 Moving batch for granite-7b from incoming to running due to dynamic batch size 64
2024-09-19 12:31:16,863 Dynamic batch size condition met for model granite-7b
2024-09-19 12:31:16,880 Request with ID 4d21fc7e for model granite-7b received
2024-09-19 12:31:16,880 127.0.0.1 - - [19/Sep/2024 12:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:17,112 Request with ID 8f9548b8 for model llama3-8b received
2024-09-19 12:31:17,113 127.0.0.1 - - [19/Sep/2024 12:31:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:17,150 Request with ID 6f664edb for model llama3-8b received
2024-09-19 12:31:17,151 127.0.0.1 - - [19/Sep/2024 12:31:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:17,231 Request with ID 335d637d for model granite-7b received
2024-09-19 12:31:17,232 127.0.0.1 - - [19/Sep/2024 12:31:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:17,558 Request with ID fa8596a7 for model granite-7b received
2024-09-19 12:31:17,558 127.0.0.1 - - [19/Sep/2024 12:31:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:17,915 Request with ID 70e9efae for model gemma-7b received
2024-09-19 12:31:17,915 127.0.0.1 - - [19/Sep/2024 12:31:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:17,933 Request with ID 6d9c9cb8 for model gemma-7b received
2024-09-19 12:31:17,933 127.0.0.1 - - [19/Sep/2024 12:31:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:18,079 Request with ID f647a89d for model llama3-8b received
2024-09-19 12:31:18,079 127.0.0.1 - - [19/Sep/2024 12:31:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:18,123 Request with ID 7c2cf392 for model granite-7b received
2024-09-19 12:31:18,124 127.0.0.1 - - [19/Sep/2024 12:31:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:18,146 Request with ID 446bebba for model granite-7b received
2024-09-19 12:31:18,146 127.0.0.1 - - [19/Sep/2024 12:31:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:18,179 Request with ID d508fe93 for model llama3-8b received
2024-09-19 12:31:18,179 127.0.0.1 - - [19/Sep/2024 12:31:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:18,260 Request with ID 7e24a7d8 for model gemma-7b received
2024-09-19 12:31:18,260 127.0.0.1 - - [19/Sep/2024 12:31:18] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:19,077 Request with ID b6212e07 for model gemma-7b received
2024-09-19 12:31:19,078 127.0.0.1 - - [19/Sep/2024 12:31:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:19,146 Request with ID c0145296 for model granite-7b received
2024-09-19 12:31:19,147 127.0.0.1 - - [19/Sep/2024 12:31:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:19,306 Request with ID 87bfc468 for model gemma-7b received
2024-09-19 12:31:19,306 127.0.0.1 - - [19/Sep/2024 12:31:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:19,321 Request with ID bccee20d for model gemma-7b received
2024-09-19 12:31:19,322 127.0.0.1 - - [19/Sep/2024 12:31:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:19,562 Request with ID fe338449 for model llama3-8b received
2024-09-19 12:31:19,562 127.0.0.1 - - [19/Sep/2024 12:31:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:19,805 Request with ID bebcf12e for model granite-7b received
2024-09-19 12:31:19,805 127.0.0.1 - - [19/Sep/2024 12:31:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:19,867 Request with ID 0415d897 for model granite-7b received
2024-09-19 12:31:19,868 127.0.0.1 - - [19/Sep/2024 12:31:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:19,968 Processed batch: ['2186bbfa', 'cc54e839', 'd457597f', 'f12d556b', 'd2a75821', '8f1c6358', '1b5245c3', '16e27b9b', '0a0db729', '16781167', 'da57ec4b', '4254ce27', '6c7d8337', '86c56695', '08ac5563', '4ee81dd0', '39554934', '8a801ffb', '2867163d', '4223828a', 'e48c8910', 'a172d160', 'a03fb434', '89f3901f', '1aeb4052', '363cdc2c', 'c21f82ee', 'cc56a55f', '1b579b73', '6d695efc', '50fe28d6', '40d167f1', '6fb89038', '80204aac', '6a933888', '43afbbc1', '64ad2d95', '65e41473', 'f423a61e', '1db1a513', '13367d2e', '6c848732', '9d874538', '09c56291', 'ad02b2f2', '018247b1', 'b43ae4bb', '81f3c406', 'e5d821bc', '2504bd3a', 'c40789c1', 'e2b58d51', '6e49b0b3', 'b643e2f2', 'f47ecdc3', 'e60921c5', '4f3ab683', '1cf64e1d', '294c3f19', 'a62afff8', 'd61cb7e2', '73df14db', '1de113c2', 'af7b7367'] with model granite-7b in 6.0244 seconds
2024-09-19 12:31:19,968 Saving sys info
2024-09-19 12:31:20,016 Latency for request 2186bbfa with model granite-7b: 43.9440 seconds
2024-09-19 12:31:20,017 Saving results with gpu monitoring
2024-09-19 12:31:20,020 Latency for request cc54e839 with model granite-7b: 43.9090 seconds
2024-09-19 12:31:20,020 Saving results with gpu monitoring
2024-09-19 12:31:20,022 Latency for request d457597f with model granite-7b: 43.6710 seconds
2024-09-19 12:31:20,022 Saving results with gpu monitoring
2024-09-19 12:31:20,024 Latency for request f12d556b with model granite-7b: 43.6620 seconds
2024-09-19 12:31:20,024 Saving results with gpu monitoring
2024-09-19 12:31:20,026 Latency for request d2a75821 with model granite-7b: 43.5900 seconds
2024-09-19 12:31:20,026 Saving results with gpu monitoring
2024-09-19 12:31:20,028 Latency for request 8f1c6358 with model granite-7b: 43.5570 seconds
2024-09-19 12:31:20,028 Saving results with gpu monitoring
2024-09-19 12:31:20,030 Latency for request 1b5245c3 with model granite-7b: 43.5160 seconds
2024-09-19 12:31:20,030 Saving results with gpu monitoring
2024-09-19 12:31:20,033 Latency for request 16e27b9b with model granite-7b: 43.2980 seconds
2024-09-19 12:31:20,033 Saving results with gpu monitoring
2024-09-19 12:31:20,036 Request with ID 9ceba12c for model granite-7b received
2024-09-19 12:31:20,037 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,037 Latency for request 0a0db729 with model granite-7b: 43.0860 seconds
2024-09-19 12:31:20,038 Saving results with gpu monitoring
2024-09-19 12:31:20,040 Latency for request 16781167 with model granite-7b: 42.9240 seconds
2024-09-19 12:31:20,040 Saving results with gpu monitoring
2024-09-19 12:31:20,043 Request with ID 68bd5603 for model granite-7b received
2024-09-19 12:31:20,043 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,044 Latency for request da57ec4b with model granite-7b: 42.6690 seconds
2024-09-19 12:31:20,044 Saving results with gpu monitoring
2024-09-19 12:31:20,050 Latency for request 4254ce27 with model granite-7b: 42.6550 seconds
2024-09-19 12:31:20,050 Saving results with gpu monitoring
2024-09-19 12:31:20,054 Latency for request 6c7d8337 with model granite-7b: 42.5710 seconds
2024-09-19 12:31:20,054 Saving results with gpu monitoring
2024-09-19 12:31:20,058 Latency for request 86c56695 with model granite-7b: 42.4070 seconds
2024-09-19 12:31:20,059 Saving results with gpu monitoring
2024-09-19 12:31:20,063 Latency for request 08ac5563 with model granite-7b: 41.9490 seconds
2024-09-19 12:31:20,063 Saving results with gpu monitoring
2024-09-19 12:31:20,067 Latency for request 4ee81dd0 with model granite-7b: 41.5160 seconds
2024-09-19 12:31:20,067 Saving results with gpu monitoring
2024-09-19 12:31:20,071 Latency for request 39554934 with model granite-7b: 41.3560 seconds
2024-09-19 12:31:20,071 Saving results with gpu monitoring
2024-09-19 12:31:20,075 Latency for request 8a801ffb with model granite-7b: 41.3520 seconds
2024-09-19 12:31:20,075 Saving results with gpu monitoring
2024-09-19 12:31:20,079 Latency for request 2867163d with model granite-7b: 41.1460 seconds
2024-09-19 12:31:20,079 Saving results with gpu monitoring
2024-09-19 12:31:20,083 Latency for request 4223828a with model granite-7b: 41.1370 seconds
2024-09-19 12:31:20,083 Saving results with gpu monitoring
2024-09-19 12:31:20,087 Latency for request e48c8910 with model granite-7b: 40.9020 seconds
2024-09-19 12:31:20,087 Saving results with gpu monitoring
2024-09-19 12:31:20,091 Latency for request a172d160 with model granite-7b: 40.3660 seconds
2024-09-19 12:31:20,091 Saving results with gpu monitoring
2024-09-19 12:31:20,095 Latency for request a03fb434 with model granite-7b: 40.2630 seconds
2024-09-19 12:31:20,095 Saving results with gpu monitoring
2024-09-19 12:31:20,099 Latency for request 89f3901f with model granite-7b: 40.1370 seconds
2024-09-19 12:31:20,099 Saving results with gpu monitoring
2024-09-19 12:31:20,102 Latency for request 1aeb4052 with model granite-7b: 39.7630 seconds
2024-09-19 12:31:20,102 Saving results with gpu monitoring
2024-09-19 12:31:20,106 Request with ID 588afea3 for model gemma-7b received
2024-09-19 12:31:20,106 Latency for request 363cdc2c with model granite-7b: 39.6050 seconds
2024-09-19 12:31:20,107 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,107 Saving results with gpu monitoring
2024-09-19 12:31:20,111 Latency for request c21f82ee with model granite-7b: 39.4510 seconds
2024-09-19 12:31:20,111 Saving results with gpu monitoring
2024-09-19 12:31:20,114 Latency for request cc56a55f with model granite-7b: 39.4260 seconds
2024-09-19 12:31:20,114 Saving results with gpu monitoring
2024-09-19 12:31:20,118 Latency for request 1b579b73 with model granite-7b: 38.9690 seconds
2024-09-19 12:31:20,118 Saving results with gpu monitoring
2024-09-19 12:31:20,121 Latency for request 6d695efc with model granite-7b: 37.7330 seconds
2024-09-19 12:31:20,121 Saving results with gpu monitoring
2024-09-19 12:31:20,124 Latency for request 50fe28d6 with model granite-7b: 37.5390 seconds
2024-09-19 12:31:20,124 Saving results with gpu monitoring
2024-09-19 12:31:20,127 Latency for request 40d167f1 with model granite-7b: 37.2450 seconds
2024-09-19 12:31:20,127 Saving results with gpu monitoring
2024-09-19 12:31:20,130 Latency for request 6fb89038 with model granite-7b: 37.1370 seconds
2024-09-19 12:31:20,130 Saving results with gpu monitoring
2024-09-19 12:31:20,132 Latency for request 80204aac with model granite-7b: 36.9390 seconds
2024-09-19 12:31:20,133 Saving results with gpu monitoring
2024-09-19 12:31:20,135 Latency for request 6a933888 with model granite-7b: 36.7880 seconds
2024-09-19 12:31:20,135 Saving results with gpu monitoring
2024-09-19 12:31:20,138 Latency for request 43afbbc1 with model granite-7b: 36.7610 seconds
2024-09-19 12:31:20,138 Saving results with gpu monitoring
2024-09-19 12:31:20,140 Latency for request 64ad2d95 with model granite-7b: 36.5440 seconds
2024-09-19 12:31:20,140 Saving results with gpu monitoring
2024-09-19 12:31:20,143 Latency for request 65e41473 with model granite-7b: 36.4950 seconds
2024-09-19 12:31:20,143 Saving results with gpu monitoring
2024-09-19 12:31:20,145 Latency for request f423a61e with model granite-7b: 36.2470 seconds
2024-09-19 12:31:20,145 Saving results with gpu monitoring
2024-09-19 12:31:20,147 Latency for request 1db1a513 with model granite-7b: 36.2360 seconds
2024-09-19 12:31:20,147 Saving results with gpu monitoring
2024-09-19 12:31:20,150 Latency for request 13367d2e with model granite-7b: 36.2130 seconds
2024-09-19 12:31:20,150 Saving results with gpu monitoring
2024-09-19 12:31:20,152 Latency for request 6c848732 with model granite-7b: 35.7720 seconds
2024-09-19 12:31:20,152 Saving results with gpu monitoring
2024-09-19 12:31:20,154 Latency for request 9d874538 with model granite-7b: 35.7680 seconds
2024-09-19 12:31:20,154 Saving results with gpu monitoring
2024-09-19 12:31:20,156 Latency for request 09c56291 with model granite-7b: 35.1600 seconds
2024-09-19 12:31:20,156 Saving results with gpu monitoring
2024-09-19 12:31:20,158 Latency for request ad02b2f2 with model granite-7b: 34.4310 seconds
2024-09-19 12:31:20,158 Saving results with gpu monitoring
2024-09-19 12:31:20,160 Latency for request 018247b1 with model granite-7b: 34.2650 seconds
2024-09-19 12:31:20,160 Saving results with gpu monitoring
2024-09-19 12:31:20,162 Latency for request b43ae4bb with model granite-7b: 34.0600 seconds
2024-09-19 12:31:20,163 Saving results with gpu monitoring
2024-09-19 12:31:20,165 Latency for request 81f3c406 with model granite-7b: 33.8250 seconds
2024-09-19 12:31:20,165 Saving results with gpu monitoring
2024-09-19 12:31:20,167 Latency for request e5d821bc with model granite-7b: 33.7350 seconds
2024-09-19 12:31:20,167 Saving results with gpu monitoring
2024-09-19 12:31:20,169 Latency for request 2504bd3a with model granite-7b: 33.6870 seconds
2024-09-19 12:31:20,169 Saving results with gpu monitoring
2024-09-19 12:31:20,172 Latency for request c40789c1 with model granite-7b: 33.6830 seconds
2024-09-19 12:31:20,172 Saving results with gpu monitoring
2024-09-19 12:31:20,174 Request with ID 7294f297 for model granite-7b received
2024-09-19 12:31:20,175 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,176 Latency for request e2b58d51 with model granite-7b: 33.1270 seconds
2024-09-19 12:31:20,176 Saving results with gpu monitoring
2024-09-19 12:31:20,178 Latency for request 6e49b0b3 with model granite-7b: 33.1250 seconds
2024-09-19 12:31:20,178 Saving results with gpu monitoring
2024-09-19 12:31:20,180 Latency for request b643e2f2 with model granite-7b: 32.9670 seconds
2024-09-19 12:31:20,180 Saving results with gpu monitoring
2024-09-19 12:31:20,182 Latency for request f47ecdc3 with model granite-7b: 32.8210 seconds
2024-09-19 12:31:20,182 Saving results with gpu monitoring
2024-09-19 12:31:20,184 Latency for request e60921c5 with model granite-7b: 32.4890 seconds
2024-09-19 12:31:20,184 Saving results with gpu monitoring
2024-09-19 12:31:20,186 Latency for request 4f3ab683 with model granite-7b: 32.3180 seconds
2024-09-19 12:31:20,186 Saving results with gpu monitoring
2024-09-19 12:31:20,189 Latency for request 1cf64e1d with model granite-7b: 31.9060 seconds
2024-09-19 12:31:20,189 Saving results with gpu monitoring
2024-09-19 12:31:20,191 Latency for request 294c3f19 with model granite-7b: 31.6280 seconds
2024-09-19 12:31:20,191 Saving results with gpu monitoring
2024-09-19 12:31:20,193 Latency for request a62afff8 with model granite-7b: 31.5230 seconds
2024-09-19 12:31:20,193 Saving results with gpu monitoring
2024-09-19 12:31:20,194 Latency for request d61cb7e2 with model granite-7b: 31.4200 seconds
2024-09-19 12:31:20,195 Saving results with gpu monitoring
2024-09-19 12:31:20,197 Latency for request 73df14db with model granite-7b: 31.3120 seconds
2024-09-19 12:31:20,197 Saving results with gpu monitoring
2024-09-19 12:31:20,199 Latency for request 1de113c2 with model granite-7b: 31.1840 seconds
2024-09-19 12:31:20,199 Saving results with gpu monitoring
2024-09-19 12:31:20,201 Latency for request af7b7367 with model granite-7b: 30.8690 seconds
2024-09-19 12:31:20,201 Saving results with gpu monitoring
2024-09-19 12:31:20,203 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,203 Next: call load_model for llama3-8b
2024-09-19 12:31:20,205 Request with ID ee173355 for model granite-7b received
2024-09-19 12:31:20,206 Adjusted batch time limit for granite-7b: 3.0000 seconds
2024-09-19 12:31:20,206 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,324 Unloaded previous model
2024-09-19 12:31:20,327 Request with ID a5fcd79f for model granite-7b received
2024-09-19 12:31:20,550 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,554 Request with ID 1908dcad for model llama3-8b received
2024-09-19 12:31:20,556 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,558 Request with ID 64711746 for model llama3-8b received
2024-09-19 12:31:20,560 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,589 Request with ID 60f25ec4 for model llama3-8b received
2024-09-19 12:31:20,590 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,614 Request with ID ccc4f924 for model llama3-8b received
2024-09-19 12:31:20,614 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,726 Request with ID a4802ab8 for model granite-7b received
2024-09-19 12:31:20,727 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,728 Request with ID 1e9d2042 for model granite-7b received
2024-09-19 12:31:20,730 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,827 Request with ID 98381595 for model llama3-8b received
2024-09-19 12:31:20,828 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:20,834 Request with ID b31b7406 for model gemma-7b received
2024-09-19 12:31:20,834 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-19 12:31:20,834 Dynamic batch size condition met for model gemma-7b
2024-09-19 12:31:20,930 Request with ID c8e7a70a for model gemma-7b received
2024-09-19 12:31:20,930 127.0.0.1 - - [19/Sep/2024 12:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:21,096 Request with ID 0493f4f0 for model llama3-8b received
2024-09-19 12:31:21,096 127.0.0.1 - - [19/Sep/2024 12:31:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:21,101 Request with ID ac6d3065 for model gemma-7b received
2024-09-19 12:31:21,101 127.0.0.1 - - [19/Sep/2024 12:31:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:21,235 Request with ID ad5700b0 for model granite-7b received
2024-09-19 12:31:21,236 127.0.0.1 - - [19/Sep/2024 12:31:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:21,732 Request with ID f7433431 for model granite-7b received
2024-09-19 12:31:21,733 127.0.0.1 - - [19/Sep/2024 12:31:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:21,867 Request with ID 7f3153c8 for model gemma-7b received
2024-09-19 12:31:21,868 127.0.0.1 - - [19/Sep/2024 12:31:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:21,875 Request with ID 3da002e8 for model gemma-7b received
2024-09-19 12:31:21,875 127.0.0.1 - - [19/Sep/2024 12:31:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:22,026 Request with ID f13e17a9 for model gemma-7b received
2024-09-19 12:31:22,027 127.0.0.1 - - [19/Sep/2024 12:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:22,213 Request with ID af86afc5 for model granite-7b received
2024-09-19 12:31:22,214 127.0.0.1 - - [19/Sep/2024 12:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:22,267 Request with ID baa72fc0 for model granite-7b received
2024-09-19 12:31:22,268 127.0.0.1 - - [19/Sep/2024 12:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:22,306 Request with ID b7b22cba for model llama3-8b received
2024-09-19 12:31:22,307 127.0.0.1 - - [19/Sep/2024 12:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:22,604 Request with ID 38b9a9c7 for model granite-7b received
2024-09-19 12:31:22,606 127.0.0.1 - - [19/Sep/2024 12:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:22,614 Request with ID d07cbe83 for model granite-7b received
2024-09-19 12:31:22,615 127.0.0.1 - - [19/Sep/2024 12:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:22,622 Request with ID 2f45e433 for model gemma-7b received
2024-09-19 12:31:22,623 127.0.0.1 - - [19/Sep/2024 12:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:22,749 Request with ID c1be0629 for model gemma-7b received
2024-09-19 12:31:22,749 127.0.0.1 - - [19/Sep/2024 12:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:22,860 Request with ID a266490c for model granite-7b received
2024-09-19 12:31:22,860 127.0.0.1 - - [19/Sep/2024 12:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:22,894 Request with ID 51984e41 for model llama3-8b received
2024-09-19 12:31:22,894 127.0.0.1 - - [19/Sep/2024 12:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:22,949 Request with ID d9187dcb for model granite-7b received
2024-09-19 12:31:22,949 127.0.0.1 - - [19/Sep/2024 12:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,038 Request with ID 5b87ee81 for model llama3-8b received
2024-09-19 12:31:23,038 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,132 Request with ID 85fcbbef for model granite-7b received
2024-09-19 12:31:23,132 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,276 Request with ID 80ff0637 for model llama3-8b received
2024-09-19 12:31:23,277 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,347 Request with ID eb81ba2e for model granite-7b received
2024-09-19 12:31:23,348 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,521 Request with ID 9d7dd97f for model granite-7b received
2024-09-19 12:31:23,522 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,637 Request with ID 3d6a750c for model granite-7b received
2024-09-19 12:31:23,638 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,672 Request with ID 97319b79 for model gemma-7b received
2024-09-19 12:31:23,673 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,690 Request with ID 54ff1dc5 for model gemma-7b received
2024-09-19 12:31:23,690 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,743 Request with ID fb080f33 for model granite-7b received
2024-09-19 12:31:23,743 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,757 Request with ID 0ce0ebe8 for model gemma-7b received
2024-09-19 12:31:23,757 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,791 Request with ID ced70d30 for model granite-7b received
2024-09-19 12:31:23,791 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,865 Request with ID fac513ce for model granite-7b received
2024-09-19 12:31:23,865 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,991 Request with ID b6da1621 for model llama3-8b received
2024-09-19 12:31:23,992 Request with ID 053bbb00 for model granite-7b received
2024-09-19 12:31:23,993 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:23,993 127.0.0.1 - - [19/Sep/2024 12:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:24,261 Request with ID 65681eeb for model granite-7b received
2024-09-19 12:31:24,261 127.0.0.1 - - [19/Sep/2024 12:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:24,293 Request with ID e7b817db for model llama3-8b received
2024-09-19 12:31:24,293 127.0.0.1 - - [19/Sep/2024 12:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:24,379 Request with ID 958837fc for model granite-7b received
2024-09-19 12:31:24,380 127.0.0.1 - - [19/Sep/2024 12:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:24,623 Request with ID 710e71e0 for model gemma-7b received
2024-09-19 12:31:24,623 127.0.0.1 - - [19/Sep/2024 12:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:24,636 Request with ID a8ef0360 for model granite-7b received
2024-09-19 12:31:24,636 127.0.0.1 - - [19/Sep/2024 12:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:24,687 Request with ID 3a01e8c9 for model llama3-8b received
2024-09-19 12:31:24,688 127.0.0.1 - - [19/Sep/2024 12:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:24,801 Request with ID 866bc7a1 for model granite-7b received
2024-09-19 12:31:24,802 127.0.0.1 - - [19/Sep/2024 12:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:25,013 Request with ID 1e5da328 for model llama3-8b received
2024-09-19 12:31:25,013 127.0.0.1 - - [19/Sep/2024 12:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:25,218 Request with ID 03d9453b for model gemma-7b received
2024-09-19 12:31:25,218 127.0.0.1 - - [19/Sep/2024 12:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:25,447 Request with ID 4afd1bca for model granite-7b received
2024-09-19 12:31:25,448 127.0.0.1 - - [19/Sep/2024 12:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:25,601 Request with ID 66572633 for model llama3-8b received
2024-09-19 12:31:25,602 127.0.0.1 - - [19/Sep/2024 12:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:25,612 Request with ID 8b64e2f9 for model llama3-8b received
2024-09-19 12:31:25,613 127.0.0.1 - - [19/Sep/2024 12:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:25,685 Request with ID 1ae81461 for model granite-7b received
2024-09-19 12:31:25,686 127.0.0.1 - - [19/Sep/2024 12:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:25,698 Request with ID e41457fc for model gemma-7b received
2024-09-19 12:31:25,699 Request with ID bccfacba for model gemma-7b received
2024-09-19 12:31:25,699 127.0.0.1 - - [19/Sep/2024 12:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:25,700 127.0.0.1 - - [19/Sep/2024 12:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:25,753 Request with ID bb8f760e for model granite-7b received
2024-09-19 12:31:25,754 127.0.0.1 - - [19/Sep/2024 12:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:25,882 Request with ID e9bbdd4c for model gemma-7b received
2024-09-19 12:31:25,883 127.0.0.1 - - [19/Sep/2024 12:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:25,947 Request with ID e3bbeb1c for model gemma-7b received
2024-09-19 12:31:25,948 127.0.0.1 - - [19/Sep/2024 12:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:26,108 Request with ID f3067193 for model gemma-7b received
2024-09-19 12:31:26,109 127.0.0.1 - - [19/Sep/2024 12:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:26,144 Request with ID d6c1dcbc for model llama3-8b received
2024-09-19 12:31:26,145 127.0.0.1 - - [19/Sep/2024 12:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:26,159 Request with ID 6079cb61 for model llama3-8b received
2024-09-19 12:31:26,159 Moving batch for llama3-8b from incoming to running due to dynamic batch size 32
2024-09-19 12:31:26,159 Dynamic batch size condition met for model llama3-8b
2024-09-19 12:31:26,165 Request with ID 66a8094b for model gemma-7b received
2024-09-19 12:31:26,166 127.0.0.1 - - [19/Sep/2024 12:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:26,188 Request with ID a2083b99 for model granite-7b received
2024-09-19 12:31:26,189 127.0.0.1 - - [19/Sep/2024 12:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:26,193 Request with ID d35e457a for model granite-7b received
2024-09-19 12:31:26,193 127.0.0.1 - - [19/Sep/2024 12:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:26,206 Request with ID 3eb80899 for model gemma-7b received
2024-09-19 12:31:26,206 127.0.0.1 - - [19/Sep/2024 12:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:26,219 Request with ID 05fb834b for model granite-7b received
2024-09-19 12:31:26,219 127.0.0.1 - - [19/Sep/2024 12:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:26,463 Request with ID d0f959ed for model gemma-7b received
2024-09-19 12:31:26,464 127.0.0.1 - - [19/Sep/2024 12:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:26,763 Request with ID 0cecade0 for model granite-7b received
2024-09-19 12:31:26,763 127.0.0.1 - - [19/Sep/2024 12:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:26,815 Request with ID 80e34462 for model llama3-8b received
2024-09-19 12:31:26,816 127.0.0.1 - - [19/Sep/2024 12:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:26,847 Request with ID d5b73969 for model granite-7b received
2024-09-19 12:31:26,848 127.0.0.1 - - [19/Sep/2024 12:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:27,181 Request with ID 8b1b3f17 for model gemma-7b received
2024-09-19 12:31:27,182 127.0.0.1 - - [19/Sep/2024 12:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:27,331 Request with ID 5ca10d5b for model granite-7b received
2024-09-19 12:31:27,332 127.0.0.1 - - [19/Sep/2024 12:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:27,528 Request with ID b7ea7a1c for model gemma-7b received
2024-09-19 12:31:27,528 127.0.0.1 - - [19/Sep/2024 12:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:27,695 Request with ID 94458ffe for model granite-7b received
2024-09-19 12:31:27,695 127.0.0.1 - - [19/Sep/2024 12:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:27,753 Request with ID e9ab46b2 for model granite-7b received
2024-09-19 12:31:27,753 127.0.0.1 - - [19/Sep/2024 12:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:27,903 Request with ID 6651546f for model granite-7b received
2024-09-19 12:31:27,904 127.0.0.1 - - [19/Sep/2024 12:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:27,939 Request with ID 466722d0 for model gemma-7b received
2024-09-19 12:31:27,940 127.0.0.1 - - [19/Sep/2024 12:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:28,154 Request with ID edd8eeb3 for model granite-7b received
2024-09-19 12:31:28,154 127.0.0.1 - - [19/Sep/2024 12:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:28,384 Request with ID 0463ae19 for model gemma-7b received
2024-09-19 12:31:28,384 127.0.0.1 - - [19/Sep/2024 12:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:28,419 Request with ID a7d00db7 for model granite-7b received
2024-09-19 12:31:28,420 127.0.0.1 - - [19/Sep/2024 12:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:28,427 Request with ID f7b9484c for model llama3-8b received
2024-09-19 12:31:28,427 127.0.0.1 - - [19/Sep/2024 12:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:28,522 Request with ID 98047460 for model granite-7b received
2024-09-19 12:31:28,523 127.0.0.1 - - [19/Sep/2024 12:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:28,636 Request with ID 8579f631 for model llama3-8b received
2024-09-19 12:31:28,636 127.0.0.1 - - [19/Sep/2024 12:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:28,992 Request with ID 0102f001 for model llama3-8b received
2024-09-19 12:31:28,992 127.0.0.1 - - [19/Sep/2024 12:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,002 Request with ID 4891ce8b for model granite-7b received
2024-09-19 12:31:29,002 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,028 Request with ID 4630b268 for model llama3-8b received
2024-09-19 12:31:29,029 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,069 Request with ID a62b6078 for model llama3-8b received
2024-09-19 12:31:29,070 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,173 Request with ID 36b8e2f8 for model granite-7b received
2024-09-19 12:31:29,173 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,277 Request with ID bbed24fb for model llama3-8b received
2024-09-19 12:31:29,278 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,319 Request with ID 791dec1c for model gemma-7b received
2024-09-19 12:31:29,320 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,325 Request with ID a9d2bca5 for model granite-7b received
2024-09-19 12:31:29,326 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,343 Request with ID c0f6f42a for model granite-7b received
2024-09-19 12:31:29,343 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,370 Request with ID fd1286a7 for model granite-7b received
2024-09-19 12:31:29,371 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,408 Request with ID fad12cc0 for model granite-7b received
2024-09-19 12:31:29,409 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,710 Request with ID cf0a07c6 for model granite-7b received
2024-09-19 12:31:29,710 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,743 Request with ID c4b7eac5 for model granite-7b received
2024-09-19 12:31:29,744 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,825 Request with ID 14244169 for model granite-7b received
2024-09-19 12:31:29,826 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:29,849 Request with ID 8d07239e for model llama3-8b received
2024-09-19 12:31:29,850 127.0.0.1 - - [19/Sep/2024 12:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:30,250 Request with ID 13889af1 for model llama3-8b received
2024-09-19 12:31:30,250 127.0.0.1 - - [19/Sep/2024 12:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:30,278 Request with ID 7c8f0ae9 for model granite-7b received
2024-09-19 12:31:30,278 127.0.0.1 - - [19/Sep/2024 12:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:30,381 Request with ID 628f09bb for model llama3-8b received
2024-09-19 12:31:30,382 127.0.0.1 - - [19/Sep/2024 12:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:30,507 Request with ID 5d495d55 for model granite-7b received
2024-09-19 12:31:30,508 127.0.0.1 - - [19/Sep/2024 12:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:30,566 Request with ID 79dc9637 for model granite-7b received
2024-09-19 12:31:30,567 127.0.0.1 - - [19/Sep/2024 12:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:30,666 Request with ID d100ab0c for model granite-7b received
2024-09-19 12:31:30,666 127.0.0.1 - - [19/Sep/2024 12:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:30,825 Request with ID d627032b for model llama3-8b received
2024-09-19 12:31:30,826 127.0.0.1 - - [19/Sep/2024 12:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:30,900 Request with ID afebfa45 for model gemma-7b received
2024-09-19 12:31:30,901 127.0.0.1 - - [19/Sep/2024 12:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:30,918 Request with ID f30e452c for model gemma-7b received
2024-09-19 12:31:30,919 127.0.0.1 - - [19/Sep/2024 12:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:30,958 Request with ID 936087c0 for model gemma-7b received
2024-09-19 12:31:30,958 127.0.0.1 - - [19/Sep/2024 12:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,070 Request with ID 9cb457e4 for model llama3-8b received
2024-09-19 12:31:31,070 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,218 Request with ID a2afea31 for model gemma-7b received
2024-09-19 12:31:31,218 Request with ID 0e4a521b for model granite-7b received
2024-09-19 12:31:31,219 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,219 Moving batch for granite-7b from incoming to running due to dynamic batch size 64
2024-09-19 12:31:31,220 Dynamic batch size condition met for model granite-7b
2024-09-19 12:31:31,266 Request with ID d6313f46 for model llama3-8b received
2024-09-19 12:31:31,267 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,286 Request with ID b8021019 for model granite-7b received
2024-09-19 12:31:31,287 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,344 Request with ID 02ed6810 for model granite-7b received
2024-09-19 12:31:31,345 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,454 Request with ID f9cf8930 for model llama3-8b received
2024-09-19 12:31:31,455 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,473 Request with ID 593cece8 for model llama3-8b received
2024-09-19 12:31:31,474 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,544 Request with ID 597d4b62 for model gemma-7b received
2024-09-19 12:31:31,544 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,592 Request with ID 19b6d9e2 for model granite-7b received
2024-09-19 12:31:31,592 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,595 Request with ID 48d42394 for model llama3-8b received
2024-09-19 12:31:31,595 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,646 Request with ID 4052313e for model granite-7b received
2024-09-19 12:31:31,647 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,757 Request with ID 85ac2f30 for model llama3-8b received
2024-09-19 12:31:31,757 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:31,969 Request with ID b337b543 for model granite-7b received
2024-09-19 12:31:31,970 127.0.0.1 - - [19/Sep/2024 12:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:32,042 Request with ID aedf371e for model granite-7b received
2024-09-19 12:31:32,043 127.0.0.1 - - [19/Sep/2024 12:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:32,046 Request with ID 3f613a50 for model granite-7b received
2024-09-19 12:31:32,046 127.0.0.1 - - [19/Sep/2024 12:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:32,163 Request with ID eb03a1de for model llama3-8b received
2024-09-19 12:31:32,164 127.0.0.1 - - [19/Sep/2024 12:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:32,252 Request with ID f11a9d8e for model gemma-7b received
2024-09-19 12:31:32,252 127.0.0.1 - - [19/Sep/2024 12:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:32,309 Request with ID 61a02acf for model granite-7b received
2024-09-19 12:31:32,310 127.0.0.1 - - [19/Sep/2024 12:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:32,536 Request with ID f9f91629 for model granite-7b received
2024-09-19 12:31:32,537 127.0.0.1 - - [19/Sep/2024 12:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:32,681 Request with ID 5725d4c9 for model llama3-8b received
2024-09-19 12:31:32,682 127.0.0.1 - - [19/Sep/2024 12:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:32,810 Request with ID e7831b0f for model granite-7b received
2024-09-19 12:31:32,811 Request with ID 96fdaa5d for model llama3-8b received
2024-09-19 12:31:32,812 127.0.0.1 - - [19/Sep/2024 12:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:32,813 127.0.0.1 - - [19/Sep/2024 12:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:32,822 Request with ID 74723182 for model granite-7b received
2024-09-19 12:31:32,823 127.0.0.1 - - [19/Sep/2024 12:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,107 Request with ID d9dcdf6b for model granite-7b received
2024-09-19 12:31:33,108 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,275 Request with ID 65c02741 for model granite-7b received
2024-09-19 12:31:33,276 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,407 Request with ID 26a97077 for model gemma-7b received
2024-09-19 12:31:33,407 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-19 12:31:33,407 Dynamic batch size condition met for model gemma-7b
2024-09-19 12:31:33,515 Request with ID 8f6baf5c for model llama3-8b received
2024-09-19 12:31:33,515 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,594 Request with ID 784e07c3 for model llama3-8b received
2024-09-19 12:31:33,594 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,647 Request with ID 29b5981d for model gemma-7b received
2024-09-19 12:31:33,647 Request with ID 3e10db9a for model gemma-7b received
2024-09-19 12:31:33,648 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,648 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,651 Request with ID 33606469 for model granite-7b received
2024-09-19 12:31:33,652 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,677 Request with ID 10895797 for model granite-7b received
2024-09-19 12:31:33,678 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,678 Request with ID 0bb50346 for model granite-7b received
2024-09-19 12:31:33,679 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,715 Request with ID 6e2a6125 for model gemma-7b received
2024-09-19 12:31:33,716 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,771 Request with ID 644afb4d for model granite-7b received
2024-09-19 12:31:33,771 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,808 Request with ID 0ccaaa91 for model gemma-7b received
2024-09-19 12:31:33,809 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,976 Loaded model llama3-8b
2024-09-19 12:31:33,981 Request with ID 42de1c96 for model granite-7b received
2024-09-19 12:31:33,981 127.0.0.1 - - [19/Sep/2024 12:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:33,982 Batch processing started for model llama3-8b
2024-09-19 12:31:34,023 Request with ID 83f13916 for model granite-7b received
2024-09-19 12:31:34,023 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:34,048 Request with ID e5744efa for model granite-7b received
2024-09-19 12:31:34,048 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:34,141 Request with ID cb552460 for model granite-7b received
2024-09-19 12:31:34,141 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:34,221 Request with ID c0f30624 for model granite-7b received
2024-09-19 12:31:34,221 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:34,374 Request with ID 056acac6 for model granite-7b received
2024-09-19 12:31:34,374 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:34,475 Request with ID a3d3ca5c for model granite-7b received
2024-09-19 12:31:34,475 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:34,602 Request with ID 2c52ecfc for model gemma-7b received
2024-09-19 12:31:34,602 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:34,620 Request with ID 00805b2d for model llama3-8b received
2024-09-19 12:31:34,621 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:34,800 Request with ID f0db45a9 for model granite-7b received
2024-09-19 12:31:34,801 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:34,810 Request with ID 548f6410 for model gemma-7b received
2024-09-19 12:31:34,811 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:34,944 Request with ID bdcf29a6 for model granite-7b received
2024-09-19 12:31:34,945 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:34,947 Request with ID a9051cb2 for model granite-7b received
2024-09-19 12:31:34,947 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:34,992 Request with ID 6ff3cb28 for model gemma-7b received
2024-09-19 12:31:34,992 127.0.0.1 - - [19/Sep/2024 12:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:35,009 Request with ID a02a065d for model gemma-7b received
2024-09-19 12:31:35,009 127.0.0.1 - - [19/Sep/2024 12:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:35,095 Request with ID f91b6595 for model granite-7b received
2024-09-19 12:31:35,095 127.0.0.1 - - [19/Sep/2024 12:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:35,143 Request with ID edfbdba9 for model granite-7b received
2024-09-19 12:31:35,143 127.0.0.1 - - [19/Sep/2024 12:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:35,383 Request with ID 68f8ffe2 for model granite-7b received
2024-09-19 12:31:35,384 127.0.0.1 - - [19/Sep/2024 12:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:35,567 Request with ID 5bf94260 for model gemma-7b received
2024-09-19 12:31:35,568 127.0.0.1 - - [19/Sep/2024 12:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:35,922 Request with ID 606da388 for model granite-7b received
2024-09-19 12:31:35,922 127.0.0.1 - - [19/Sep/2024 12:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:36,005 Request with ID c90a63fa for model gemma-7b received
2024-09-19 12:31:36,006 127.0.0.1 - - [19/Sep/2024 12:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:36,348 Request with ID e65fce13 for model gemma-7b received
2024-09-19 12:31:36,349 127.0.0.1 - - [19/Sep/2024 12:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:36,549 Request with ID ba5157ed for model llama3-8b received
2024-09-19 12:31:36,549 127.0.0.1 - - [19/Sep/2024 12:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:36,676 Request with ID 54263f9e for model granite-7b received
2024-09-19 12:31:36,677 127.0.0.1 - - [19/Sep/2024 12:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:36,690 Request with ID 743fa62d for model llama3-8b received
2024-09-19 12:31:36,691 127.0.0.1 - - [19/Sep/2024 12:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:36,807 Request with ID bb2c5db2 for model llama3-8b received
2024-09-19 12:31:36,807 127.0.0.1 - - [19/Sep/2024 12:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:36,920 Request with ID 27852777 for model granite-7b received
2024-09-19 12:31:36,920 127.0.0.1 - - [19/Sep/2024 12:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:37,019 Request with ID 2bd5189c for model llama3-8b received
2024-09-19 12:31:37,020 127.0.0.1 - - [19/Sep/2024 12:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:37,423 Request with ID 7228551a for model granite-7b received
2024-09-19 12:31:37,423 127.0.0.1 - - [19/Sep/2024 12:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:37,440 Request with ID e491efd4 for model granite-7b received
2024-09-19 12:31:37,441 127.0.0.1 - - [19/Sep/2024 12:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:37,493 Request with ID 93cd7605 for model granite-7b received
2024-09-19 12:31:37,493 127.0.0.1 - - [19/Sep/2024 12:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:37,592 Request with ID dcea7eef for model gemma-7b received
2024-09-19 12:31:37,592 127.0.0.1 - - [19/Sep/2024 12:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:37,645 Request with ID c2574e2c for model granite-7b received
2024-09-19 12:31:37,645 127.0.0.1 - - [19/Sep/2024 12:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:37,690 Request with ID 8adfed78 for model granite-7b received
2024-09-19 12:31:37,690 127.0.0.1 - - [19/Sep/2024 12:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:37,755 Processed batch: ['0bfff12a', '5c424748', '4ba9fa36', '3406c0b8', '196428f9', '52970a2d', 'd2318af8', 'cd45996a', '88f0c89b', 'e176f576', 'dd2fe63e', 'bbc4e7ed', '591dd08f', '92b47766', '76b79404', '38c2b288', 'a950500f', '6880b3cc', 'b197b1e7', 'd8bc8991', '4c21d834', 'da1f1add', '17439824', '226fb3fe', '677ad552', '77482ef3', '28911d6d', 'ba49371a', '339360cb', '30f9e288', '06bff4b5', 'cfe3df8e'] with model llama3-8b in 3.7734 seconds
2024-09-19 12:31:37,755 Saving sys info
2024-09-19 12:31:37,788 Latency for request 0bfff12a with model llama3-8b: 32.2460 seconds
2024-09-19 12:31:37,788 Saving results with gpu monitoring
2024-09-19 12:31:37,791 Latency for request 5c424748 with model llama3-8b: 32.2020 seconds
2024-09-19 12:31:37,791 Saving results with gpu monitoring
2024-09-19 12:31:37,793 Latency for request 4ba9fa36 with model llama3-8b: 32.1200 seconds
2024-09-19 12:31:37,793 Saving results with gpu monitoring
2024-09-19 12:31:37,795 Latency for request 3406c0b8 with model llama3-8b: 31.3860 seconds
2024-09-19 12:31:37,795 Saving results with gpu monitoring
2024-09-19 12:31:37,797 Latency for request 196428f9 with model llama3-8b: 30.4410 seconds
2024-09-19 12:31:37,797 Saving results with gpu monitoring
2024-09-19 12:31:37,799 Latency for request 52970a2d with model llama3-8b: 29.9030 seconds
2024-09-19 12:31:37,799 Saving results with gpu monitoring
2024-09-19 12:31:37,801 Latency for request d2318af8 with model llama3-8b: 29.8650 seconds
2024-09-19 12:31:37,801 Saving results with gpu monitoring
2024-09-19 12:31:37,803 Latency for request cd45996a with model llama3-8b: 29.4740 seconds
2024-09-19 12:31:37,803 Saving results with gpu monitoring
2024-09-19 12:31:37,805 Latency for request 88f0c89b with model llama3-8b: 29.3610 seconds
2024-09-19 12:31:37,805 Saving results with gpu monitoring
2024-09-19 12:31:37,807 Latency for request e176f576 with model llama3-8b: 29.1540 seconds
2024-09-19 12:31:37,807 Saving results with gpu monitoring
2024-09-19 12:31:37,809 Latency for request dd2fe63e with model llama3-8b: 29.1420 seconds
2024-09-19 12:31:37,809 Saving results with gpu monitoring
2024-09-19 12:31:37,812 Latency for request bbc4e7ed with model llama3-8b: 29.0320 seconds
2024-09-19 12:31:37,812 Saving results with gpu monitoring
2024-09-19 12:31:37,814 Request with ID 0e6f7236 for model granite-7b received
2024-09-19 12:31:37,815 127.0.0.1 - - [19/Sep/2024 12:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:37,816 Latency for request 591dd08f with model llama3-8b: 28.6650 seconds
2024-09-19 12:31:37,816 Saving results with gpu monitoring
2024-09-19 12:31:37,818 Latency for request 92b47766 with model llama3-8b: 28.2350 seconds
2024-09-19 12:31:37,818 Saving results with gpu monitoring
2024-09-19 12:31:37,820 Latency for request 76b79404 with model llama3-8b: 27.8930 seconds
2024-09-19 12:31:37,820 Saving results with gpu monitoring
2024-09-19 12:31:37,822 Latency for request 38c2b288 with model llama3-8b: 27.6820 seconds
2024-09-19 12:31:37,822 Saving results with gpu monitoring
2024-09-19 12:31:37,824 Latency for request a950500f with model llama3-8b: 27.3060 seconds
2024-09-19 12:31:37,824 Saving results with gpu monitoring
2024-09-19 12:31:37,826 Latency for request 6880b3cc with model llama3-8b: 27.1030 seconds
2024-09-19 12:31:37,826 Saving results with gpu monitoring
2024-09-19 12:31:37,828 Latency for request b197b1e7 with model llama3-8b: 27.0890 seconds
2024-09-19 12:31:37,829 Saving results with gpu monitoring
2024-09-19 12:31:37,831 Latency for request d8bc8991 with model llama3-8b: 26.9110 seconds
2024-09-19 12:31:37,831 Saving results with gpu monitoring
2024-09-19 12:31:37,833 Latency for request 4c21d834 with model llama3-8b: 26.9090 seconds
2024-09-19 12:31:37,833 Saving results with gpu monitoring
2024-09-19 12:31:37,835 Latency for request da1f1add with model llama3-8b: 26.7750 seconds
2024-09-19 12:31:37,835 Saving results with gpu monitoring
2024-09-19 12:31:37,837 Latency for request 17439824 with model llama3-8b: 26.5300 seconds
2024-09-19 12:31:37,837 Saving results with gpu monitoring
2024-09-19 12:31:37,839 Latency for request 226fb3fe with model llama3-8b: 26.4890 seconds
2024-09-19 12:31:37,839 Saving results with gpu monitoring
2024-09-19 12:31:37,841 Latency for request 677ad552 with model llama3-8b: 26.2520 seconds
2024-09-19 12:31:37,841 Saving results with gpu monitoring
2024-09-19 12:31:37,843 Latency for request 77482ef3 with model llama3-8b: 26.1460 seconds
2024-09-19 12:31:37,843 Saving results with gpu monitoring
2024-09-19 12:31:37,845 Latency for request 28911d6d with model llama3-8b: 25.0760 seconds
2024-09-19 12:31:37,845 Saving results with gpu monitoring
2024-09-19 12:31:37,847 Latency for request ba49371a with model llama3-8b: 24.5480 seconds
2024-09-19 12:31:37,847 Saving results with gpu monitoring
2024-09-19 12:31:37,849 Latency for request 339360cb with model llama3-8b: 24.4350 seconds
2024-09-19 12:31:37,849 Saving results with gpu monitoring
2024-09-19 12:31:37,851 Latency for request 30f9e288 with model llama3-8b: 24.1860 seconds
2024-09-19 12:31:37,851 Saving results with gpu monitoring
2024-09-19 12:31:37,853 Latency for request 06bff4b5 with model llama3-8b: 24.1170 seconds
2024-09-19 12:31:37,853 Saving results with gpu monitoring
2024-09-19 12:31:37,855 Latency for request cfe3df8e with model llama3-8b: 23.9690 seconds
2024-09-19 12:31:37,855 Saving results with gpu monitoring
2024-09-19 12:31:37,857 Processing batch for gemma-7b due to time limit with batch size 12
2024-09-19 12:31:37,857 Time limit condition met for model gemma-7b
2024-09-19 12:31:37,857 Next: call load_model for gemma-7b
2024-09-19 12:31:37,858 Request with ID 9eb6351a for model gemma-7b received
2024-09-19 12:31:37,859 127.0.0.1 - - [19/Sep/2024 12:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:37,957 Unloaded previous model
2024-09-19 12:31:38,456 Request with ID ceeeb5be for model granite-7b received
2024-09-19 12:31:38,458 127.0.0.1 - - [19/Sep/2024 12:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:38,460 Request with ID 6c1255ce for model gemma-7b received
2024-09-19 12:31:38,461 127.0.0.1 - - [19/Sep/2024 12:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:38,514 Request with ID 1945134e for model granite-7b received
2024-09-19 12:31:38,515 127.0.0.1 - - [19/Sep/2024 12:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:38,664 Request with ID 0640d4e8 for model granite-7b received
2024-09-19 12:31:38,665 127.0.0.1 - - [19/Sep/2024 12:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:38,668 Request with ID 8194cfe4 for model granite-7b received
2024-09-19 12:31:38,679 127.0.0.1 - - [19/Sep/2024 12:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:39,039 Request with ID 7fc46529 for model llama3-8b received
2024-09-19 12:31:39,045 Adjusted batch time limit for llama3-8b: 3.0000 seconds
2024-09-19 12:31:39,046 127.0.0.1 - - [19/Sep/2024 12:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:39,081 Request with ID 2ab45911 for model granite-7b received
2024-09-19 12:31:39,084 127.0.0.1 - - [19/Sep/2024 12:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:39,141 Request with ID 4e955540 for model gemma-7b received
2024-09-19 12:31:39,236 127.0.0.1 - - [19/Sep/2024 12:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:39,296 Request with ID 07cc2a31 for model granite-7b received
2024-09-19 12:31:39,302 127.0.0.1 - - [19/Sep/2024 12:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:39,429 Request with ID e0e656aa for model granite-7b received
2024-09-19 12:31:39,439 127.0.0.1 - - [19/Sep/2024 12:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:39,481 Request with ID 109a0070 for model granite-7b received
2024-09-19 12:31:39,481 127.0.0.1 - - [19/Sep/2024 12:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:39,835 Request with ID 40062229 for model gemma-7b received
2024-09-19 12:31:39,836 127.0.0.1 - - [19/Sep/2024 12:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:39,838 Request with ID 78c429fd for model gemma-7b received
2024-09-19 12:31:39,838 127.0.0.1 - - [19/Sep/2024 12:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:39,943 Request with ID 68d7d290 for model granite-7b received
2024-09-19 12:31:39,943 127.0.0.1 - - [19/Sep/2024 12:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:40,057 Request with ID 58e29dd0 for model gemma-7b received
2024-09-19 12:31:40,057 127.0.0.1 - - [19/Sep/2024 12:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:40,146 Request with ID 8a1305cf for model granite-7b received
2024-09-19 12:31:40,146 127.0.0.1 - - [19/Sep/2024 12:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:40,239 Request with ID a1d35195 for model granite-7b received
2024-09-19 12:31:40,239 127.0.0.1 - - [19/Sep/2024 12:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:40,253 Request with ID cda4f159 for model granite-7b received
2024-09-19 12:31:40,253 127.0.0.1 - - [19/Sep/2024 12:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:40,547 Request with ID d28fe1be for model llama3-8b received
2024-09-19 12:31:40,548 Request with ID fd4fbe49 for model gemma-7b received
2024-09-19 12:31:40,549 127.0.0.1 - - [19/Sep/2024 12:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:40,549 127.0.0.1 - - [19/Sep/2024 12:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:40,670 Request with ID f13880fc for model granite-7b received
2024-09-19 12:31:40,671 127.0.0.1 - - [19/Sep/2024 12:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:40,771 Request with ID 0a1fa502 for model gemma-7b received
2024-09-19 12:31:40,771 127.0.0.1 - - [19/Sep/2024 12:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:40,801 Request with ID 11c2d585 for model llama3-8b received
2024-09-19 12:31:40,802 127.0.0.1 - - [19/Sep/2024 12:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:40,855 Request with ID 0b0d0477 for model granite-7b received
2024-09-19 12:31:40,855 127.0.0.1 - - [19/Sep/2024 12:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:40,969 Request with ID 7675ee6d for model gemma-7b received
2024-09-19 12:31:40,969 127.0.0.1 - - [19/Sep/2024 12:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:41,039 Request with ID c15718a6 for model granite-7b received
2024-09-19 12:31:41,039 127.0.0.1 - - [19/Sep/2024 12:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:41,049 Request with ID af4dddba for model llama3-8b received
2024-09-19 12:31:41,049 127.0.0.1 - - [19/Sep/2024 12:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:41,108 Request with ID 053a1221 for model granite-7b received
2024-09-19 12:31:41,109 127.0.0.1 - - [19/Sep/2024 12:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:41,239 Request with ID 6271bf52 for model granite-7b received
2024-09-19 12:31:41,240 127.0.0.1 - - [19/Sep/2024 12:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:41,320 Request with ID 06d840dd for model granite-7b received
2024-09-19 12:31:41,321 127.0.0.1 - - [19/Sep/2024 12:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:41,447 Request with ID a75f74ec for model granite-7b received
2024-09-19 12:31:41,448 127.0.0.1 - - [19/Sep/2024 12:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:41,660 Request with ID a65d4636 for model llama3-8b received
2024-09-19 12:31:41,661 Moving batch for llama3-8b from incoming to running due to dynamic batch size 32
2024-09-19 12:31:41,661 Dynamic batch size condition met for model llama3-8b
2024-09-19 12:31:41,664 Request with ID d862862e for model granite-7b received
2024-09-19 12:31:41,664 127.0.0.1 - - [19/Sep/2024 12:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:41,672 Request with ID dbbfb235 for model granite-7b received
2024-09-19 12:31:41,673 127.0.0.1 - - [19/Sep/2024 12:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:41,737 Request with ID a13d7691 for model gemma-7b received
2024-09-19 12:31:41,737 127.0.0.1 - - [19/Sep/2024 12:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:41,830 Request with ID c6a3bfda for model llama3-8b received
2024-09-19 12:31:41,831 127.0.0.1 - - [19/Sep/2024 12:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,015 Request with ID e3f34527 for model granite-7b received
2024-09-19 12:31:42,015 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,085 Request with ID 5b9936db for model gemma-7b received
2024-09-19 12:31:42,085 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,115 Request with ID 0fa3b452 for model gemma-7b received
2024-09-19 12:31:42,116 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,124 Request with ID 4ef0e8fd for model granite-7b received
2024-09-19 12:31:42,124 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,147 Request with ID 9a7c74fd for model granite-7b received
2024-09-19 12:31:42,148 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,195 Request with ID ff197e6b for model llama3-8b received
2024-09-19 12:31:42,196 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,200 Request with ID fdcb2ca3 for model llama3-8b received
2024-09-19 12:31:42,200 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,305 Request with ID 793b9d62 for model granite-7b received
2024-09-19 12:31:42,305 Moving batch for granite-7b from incoming to running due to dynamic batch size 64
2024-09-19 12:31:42,306 Dynamic batch size condition met for model granite-7b
2024-09-19 12:31:42,365 Request with ID 5f9b02c1 for model llama3-8b received
2024-09-19 12:31:42,508 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,510 Request with ID 62cadd13 for model granite-7b received
2024-09-19 12:31:42,511 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,513 Request with ID 947aac39 for model granite-7b received
2024-09-19 12:31:42,513 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,516 Request with ID 7730cd0e for model granite-7b received
2024-09-19 12:31:42,517 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,767 Request with ID ebb702b2 for model gemma-7b received
2024-09-19 12:31:42,767 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,769 Request with ID 497d60d1 for model granite-7b received
2024-09-19 12:31:42,769 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,786 Request with ID 30e4f419 for model gemma-7b received
2024-09-19 12:31:42,787 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:42,943 Request with ID 3bd615ee for model gemma-7b received
2024-09-19 12:31:42,943 127.0.0.1 - - [19/Sep/2024 12:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:43,072 Request with ID a7b7b4ba for model granite-7b received
2024-09-19 12:31:43,072 127.0.0.1 - - [19/Sep/2024 12:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:43,237 Request with ID eda144c0 for model granite-7b received
2024-09-19 12:31:43,238 127.0.0.1 - - [19/Sep/2024 12:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:43,267 Request with ID e9c7eb85 for model gemma-7b received
2024-09-19 12:31:43,267 127.0.0.1 - - [19/Sep/2024 12:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:43,313 Request with ID 567a5f74 for model llama3-8b received
2024-09-19 12:31:43,313 127.0.0.1 - - [19/Sep/2024 12:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:43,470 Request with ID ff9f2160 for model granite-7b received
2024-09-19 12:31:43,470 127.0.0.1 - - [19/Sep/2024 12:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:43,637 Request with ID cdddf21d for model gemma-7b received
2024-09-19 12:31:43,637 127.0.0.1 - - [19/Sep/2024 12:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:43,684 Request with ID 0caa20cf for model llama3-8b received
2024-09-19 12:31:43,685 127.0.0.1 - - [19/Sep/2024 12:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:43,896 Request with ID 9e23da8c for model llama3-8b received
2024-09-19 12:31:43,896 127.0.0.1 - - [19/Sep/2024 12:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:43,905 Request with ID c31b28ac for model gemma-7b received
2024-09-19 12:31:43,905 127.0.0.1 - - [19/Sep/2024 12:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:43,928 Request with ID 593fe3aa for model llama3-8b received
2024-09-19 12:31:43,928 127.0.0.1 - - [19/Sep/2024 12:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:44,126 Request with ID 051ab755 for model granite-7b received
2024-09-19 12:31:44,126 127.0.0.1 - - [19/Sep/2024 12:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:44,180 Request with ID 443a4adf for model granite-7b received
2024-09-19 12:31:44,181 127.0.0.1 - - [19/Sep/2024 12:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:44,238 Request with ID d2727358 for model gemma-7b received
2024-09-19 12:31:44,238 127.0.0.1 - - [19/Sep/2024 12:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:44,372 Request with ID 115b82b7 for model granite-7b received
2024-09-19 12:31:44,373 127.0.0.1 - - [19/Sep/2024 12:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:44,381 Request with ID 8544f49e for model granite-7b received
2024-09-19 12:31:44,382 127.0.0.1 - - [19/Sep/2024 12:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:44,515 Request with ID 3cfc987f for model granite-7b received
2024-09-19 12:31:44,516 127.0.0.1 - - [19/Sep/2024 12:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:44,559 Request with ID 8aab7ee7 for model granite-7b received
2024-09-19 12:31:44,560 127.0.0.1 - - [19/Sep/2024 12:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:44,636 Request with ID f15bcc00 for model granite-7b received
2024-09-19 12:31:44,637 127.0.0.1 - - [19/Sep/2024 12:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:44,776 Request with ID 3da0d4da for model gemma-7b received
2024-09-19 12:31:44,777 127.0.0.1 - - [19/Sep/2024 12:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:44,859 Request with ID 7596661f for model gemma-7b received
2024-09-19 12:31:44,860 127.0.0.1 - - [19/Sep/2024 12:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:44,914 Request with ID ec24822e for model granite-7b received
2024-09-19 12:31:44,915 127.0.0.1 - - [19/Sep/2024 12:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:44,984 Request with ID 31f98c61 for model gemma-7b received
2024-09-19 12:31:44,985 127.0.0.1 - - [19/Sep/2024 12:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:45,072 Request with ID 094e1b4b for model gemma-7b received
2024-09-19 12:31:45,073 127.0.0.1 - - [19/Sep/2024 12:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:45,086 Request with ID da51bd1a for model granite-7b received
2024-09-19 12:31:45,086 127.0.0.1 - - [19/Sep/2024 12:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:45,381 Request with ID c8fc5b66 for model granite-7b received
2024-09-19 12:31:45,382 127.0.0.1 - - [19/Sep/2024 12:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:45,479 Request with ID 01848b90 for model granite-7b received
2024-09-19 12:31:45,480 127.0.0.1 - - [19/Sep/2024 12:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:45,625 Request with ID 62131795 for model gemma-7b received
2024-09-19 12:31:45,626 127.0.0.1 - - [19/Sep/2024 12:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:45,930 Request with ID 0138fe9b for model granite-7b received
2024-09-19 12:31:45,930 127.0.0.1 - - [19/Sep/2024 12:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:46,089 Request with ID 86d1fcda for model granite-7b received
2024-09-19 12:31:46,089 127.0.0.1 - - [19/Sep/2024 12:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:46,172 Request with ID 89d41575 for model gemma-7b received
2024-09-19 12:31:46,173 127.0.0.1 - - [19/Sep/2024 12:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:46,203 Request with ID 5da7e371 for model gemma-7b received
2024-09-19 12:31:46,203 127.0.0.1 - - [19/Sep/2024 12:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:46,325 Request with ID a20b3b40 for model llama3-8b received
2024-09-19 12:31:46,325 127.0.0.1 - - [19/Sep/2024 12:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:46,498 Request with ID 244a3123 for model granite-7b received
2024-09-19 12:31:46,499 127.0.0.1 - - [19/Sep/2024 12:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:46,658 Request with ID 4d930911 for model gemma-7b received
2024-09-19 12:31:46,659 127.0.0.1 - - [19/Sep/2024 12:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:46,831 Request with ID 8cdccec2 for model granite-7b received
2024-09-19 12:31:46,831 127.0.0.1 - - [19/Sep/2024 12:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:46,833 Request with ID 89a58843 for model gemma-7b received
2024-09-19 12:31:46,833 127.0.0.1 - - [19/Sep/2024 12:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:46,834 Request with ID 5eb65e25 for model granite-7b received
2024-09-19 12:31:46,835 127.0.0.1 - - [19/Sep/2024 12:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:46,842 Request with ID 465241f9 for model llama3-8b received
2024-09-19 12:31:46,842 127.0.0.1 - - [19/Sep/2024 12:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:46,849 Request with ID 58b684ea for model granite-7b received
2024-09-19 12:31:46,850 127.0.0.1 - - [19/Sep/2024 12:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:46,924 Request with ID 89b5ca7a for model llama3-8b received
2024-09-19 12:31:46,924 127.0.0.1 - - [19/Sep/2024 12:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:47,007 Request with ID ee8c1324 for model granite-7b received
2024-09-19 12:31:47,008 127.0.0.1 - - [19/Sep/2024 12:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:47,140 Request with ID c6a96ef1 for model granite-7b received
2024-09-19 12:31:47,141 127.0.0.1 - - [19/Sep/2024 12:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:47,188 Request with ID 99da2c09 for model granite-7b received
2024-09-19 12:31:47,188 127.0.0.1 - - [19/Sep/2024 12:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:47,192 Request with ID 80f0f231 for model granite-7b received
2024-09-19 12:31:47,193 127.0.0.1 - - [19/Sep/2024 12:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:47,219 Request with ID 4881af94 for model llama3-8b received
2024-09-19 12:31:47,220 127.0.0.1 - - [19/Sep/2024 12:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:47,269 Request with ID 69ce0d16 for model llama3-8b received
2024-09-19 12:31:47,270 127.0.0.1 - - [19/Sep/2024 12:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:47,419 Request with ID c494ea17 for model granite-7b received
2024-09-19 12:31:47,420 127.0.0.1 - - [19/Sep/2024 12:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:47,508 Request with ID 6936d830 for model gemma-7b received
2024-09-19 12:31:47,508 127.0.0.1 - - [19/Sep/2024 12:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:47,582 Request with ID 2b45e6a0 for model llama3-8b received
2024-09-19 12:31:47,582 127.0.0.1 - - [19/Sep/2024 12:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:47,656 Request with ID 38de694e for model gemma-7b received
2024-09-19 12:31:47,657 127.0.0.1 - - [19/Sep/2024 12:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:47,794 Request with ID 09a4098b for model gemma-7b received
2024-09-19 12:31:47,794 127.0.0.1 - - [19/Sep/2024 12:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:47,838 Request with ID a0923fda for model gemma-7b received
2024-09-19 12:31:47,838 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-19 12:31:47,838 Dynamic batch size condition met for model gemma-7b
2024-09-19 12:31:48,080 Request with ID 9ea24a64 for model gemma-7b received
2024-09-19 12:31:48,081 127.0.0.1 - - [19/Sep/2024 12:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:48,189 Request with ID 804ccda8 for model llama3-8b received
2024-09-19 12:31:48,190 127.0.0.1 - - [19/Sep/2024 12:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:48,270 Request with ID e7a4a6d7 for model granite-7b received
2024-09-19 12:31:48,271 127.0.0.1 - - [19/Sep/2024 12:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:48,396 Request with ID 635a275d for model granite-7b received
2024-09-19 12:31:48,396 127.0.0.1 - - [19/Sep/2024 12:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:48,423 Request with ID d18f3cb8 for model llama3-8b received
2024-09-19 12:31:48,424 127.0.0.1 - - [19/Sep/2024 12:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:48,629 Request with ID 5219212a for model gemma-7b received
2024-09-19 12:31:48,629 127.0.0.1 - - [19/Sep/2024 12:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:48,652 Request with ID b2a51dc9 for model llama3-8b received
2024-09-19 12:31:48,652 127.0.0.1 - - [19/Sep/2024 12:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:48,762 Request with ID dbd222b6 for model granite-7b received
2024-09-19 12:31:48,762 127.0.0.1 - - [19/Sep/2024 12:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:48,881 Request with ID f0fbc53a for model gemma-7b received
2024-09-19 12:31:48,882 127.0.0.1 - - [19/Sep/2024 12:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:49,022 Request with ID dec2ab38 for model granite-7b received
2024-09-19 12:31:49,022 127.0.0.1 - - [19/Sep/2024 12:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:49,054 Request with ID ef413767 for model granite-7b received
2024-09-19 12:31:49,054 127.0.0.1 - - [19/Sep/2024 12:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:49,088 Request with ID e9fa1515 for model gemma-7b received
2024-09-19 12:31:49,088 127.0.0.1 - - [19/Sep/2024 12:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:49,122 Request with ID 27049304 for model llama3-8b received
2024-09-19 12:31:49,123 127.0.0.1 - - [19/Sep/2024 12:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:49,184 Request with ID 611eb964 for model gemma-7b received
2024-09-19 12:31:49,184 127.0.0.1 - - [19/Sep/2024 12:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:49,334 Request with ID 21fe5b86 for model granite-7b received
2024-09-19 12:31:49,334 127.0.0.1 - - [19/Sep/2024 12:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:49,359 Request with ID 68ab0608 for model granite-7b received
2024-09-19 12:31:49,359 127.0.0.1 - - [19/Sep/2024 12:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:49,581 Request with ID 6e65a043 for model gemma-7b received
2024-09-19 12:31:49,581 127.0.0.1 - - [19/Sep/2024 12:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:49,586 Request with ID dbfc2d47 for model gemma-7b received
2024-09-19 12:31:49,586 127.0.0.1 - - [19/Sep/2024 12:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:49,644 Request with ID 823a692b for model llama3-8b received
2024-09-19 12:31:49,644 127.0.0.1 - - [19/Sep/2024 12:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:49,685 Request with ID 3b1004e0 for model llama3-8b received
2024-09-19 12:31:49,686 127.0.0.1 - - [19/Sep/2024 12:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:49,862 Request with ID be44dabf for model gemma-7b received
2024-09-19 12:31:49,862 127.0.0.1 - - [19/Sep/2024 12:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:50,205 Request with ID 720848f1 for model llama3-8b received
2024-09-19 12:31:50,206 127.0.0.1 - - [19/Sep/2024 12:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:50,247 Request with ID ba9c4f3f for model llama3-8b received
2024-09-19 12:31:50,248 127.0.0.1 - - [19/Sep/2024 12:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:50,445 Request with ID 9032c9a3 for model granite-7b received
2024-09-19 12:31:50,445 127.0.0.1 - - [19/Sep/2024 12:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:50,531 Request with ID c0c16e41 for model llama3-8b received
2024-09-19 12:31:50,531 127.0.0.1 - - [19/Sep/2024 12:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:50,756 Request with ID fc829acc for model granite-7b received
2024-09-19 12:31:50,758 127.0.0.1 - - [19/Sep/2024 12:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:50,759 Request with ID 9411e541 for model gemma-7b received
2024-09-19 12:31:50,760 127.0.0.1 - - [19/Sep/2024 12:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:50,784 Request with ID 9b5403f7 for model granite-7b received
2024-09-19 12:31:50,784 127.0.0.1 - - [19/Sep/2024 12:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:51,035 Request with ID 4fb99b97 for model granite-7b received
2024-09-19 12:31:51,036 127.0.0.1 - - [19/Sep/2024 12:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:51,050 Request with ID bae06e15 for model granite-7b received
2024-09-19 12:31:51,051 127.0.0.1 - - [19/Sep/2024 12:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:51,330 Request with ID a8824d9b for model llama3-8b received
2024-09-19 12:31:51,331 127.0.0.1 - - [19/Sep/2024 12:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:51,421 Request with ID d83640ae for model llama3-8b received
2024-09-19 12:31:51,421 127.0.0.1 - - [19/Sep/2024 12:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:51,564 Request with ID b47a95b2 for model granite-7b received
2024-09-19 12:31:51,564 127.0.0.1 - - [19/Sep/2024 12:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:51,652 Request with ID 689d9545 for model granite-7b received
2024-09-19 12:31:51,652 127.0.0.1 - - [19/Sep/2024 12:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:51,699 Request with ID f611984a for model granite-7b received
2024-09-19 12:31:51,700 127.0.0.1 - - [19/Sep/2024 12:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:51,760 Request with ID 5c632b99 for model gemma-7b received
2024-09-19 12:31:51,760 127.0.0.1 - - [19/Sep/2024 12:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:31:51,867 Waiting for running processes to finish
2024-09-19 12:31:52,868 Waiting for running processes to finish
2024-09-19 12:31:53,870 Waiting for running processes to finish
2024-09-19 12:31:54,871 Waiting for running processes to finish
2024-09-19 12:31:55,873 Waiting for running processes to finish
2024-09-19 12:31:56,981 Waiting for running processes to finish
2024-09-19 12:31:57,983 Waiting for running processes to finish
2024-09-19 12:31:58,984 Waiting for running processes to finish
2024-09-19 12:31:59,986 Waiting for running processes to finish
2024-09-19 12:32:00,307 Loaded model gemma-7b
2024-09-19 12:32:00,310 Batch processing started for model gemma-7b
2024-09-19 12:32:00,988 Waiting for running processes to finish
2024-09-19 12:32:01,990 Waiting for running processes to finish
2024-09-19 12:32:02,991 Waiting for running processes to finish
2024-09-19 12:32:03,067 Processed batch: ['29b5981d', '3e10db9a', '6e2a6125', '0ccaaa91', '2c52ecfc', '548f6410', '6ff3cb28', 'a02a065d', '5bf94260', 'c90a63fa', 'e65fce13', 'dcea7eef'] with model gemma-7b in 2.7570 seconds
2024-09-19 12:32:03,067 Saving sys info
2024-09-19 12:32:03,098 Latency for request 29b5981d with model gemma-7b: 29.4200 seconds
2024-09-19 12:32:03,098 Saving results with gpu monitoring
2024-09-19 12:32:03,101 Latency for request 3e10db9a with model gemma-7b: 29.4200 seconds
2024-09-19 12:32:03,101 Saving results with gpu monitoring
2024-09-19 12:32:03,103 Latency for request 6e2a6125 with model gemma-7b: 29.3520 seconds
2024-09-19 12:32:03,103 Saving results with gpu monitoring
2024-09-19 12:32:03,105 Latency for request 0ccaaa91 with model gemma-7b: 29.2590 seconds
2024-09-19 12:32:03,105 Saving results with gpu monitoring
2024-09-19 12:32:03,107 Latency for request 2c52ecfc with model gemma-7b: 28.4650 seconds
2024-09-19 12:32:03,107 Saving results with gpu monitoring
2024-09-19 12:32:03,109 Latency for request 548f6410 with model gemma-7b: 28.2570 seconds
2024-09-19 12:32:03,109 Saving results with gpu monitoring
2024-09-19 12:32:03,111 Latency for request 6ff3cb28 with model gemma-7b: 28.0750 seconds
2024-09-19 12:32:03,111 Saving results with gpu monitoring
2024-09-19 12:32:03,113 Latency for request a02a065d with model gemma-7b: 28.0580 seconds
2024-09-19 12:32:03,113 Saving results with gpu monitoring
2024-09-19 12:32:03,115 Latency for request 5bf94260 with model gemma-7b: 27.4990 seconds
2024-09-19 12:32:03,115 Saving results with gpu monitoring
2024-09-19 12:32:03,117 Latency for request c90a63fa with model gemma-7b: 27.0620 seconds
2024-09-19 12:32:03,117 Saving results with gpu monitoring
2024-09-19 12:32:03,119 Latency for request e65fce13 with model gemma-7b: 26.7190 seconds
2024-09-19 12:32:03,119 Saving results with gpu monitoring
2024-09-19 12:32:03,121 Latency for request dcea7eef with model gemma-7b: 25.4750 seconds
2024-09-19 12:32:03,121 Saving results with gpu monitoring
2024-09-19 12:32:03,123 127.0.0.1 - - [19/Sep/2024 12:32:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:32:03,124 Next: call load_model for granite-7b
2024-09-19 12:32:03,233 Unloaded previous model
2024-09-19 12:32:04,001 Waiting for running processes to finish
2024-09-19 12:32:05,003 Waiting for running processes to finish
2024-09-19 12:32:06,005 Waiting for running processes to finish
2024-09-19 12:32:07,006 Waiting for running processes to finish
2024-09-19 12:32:08,008 Waiting for running processes to finish
2024-09-19 12:32:09,009 Waiting for running processes to finish
2024-09-19 12:32:10,011 Waiting for running processes to finish
2024-09-19 12:32:11,012 Waiting for running processes to finish
2024-09-19 12:32:12,014 Waiting for running processes to finish
2024-09-19 12:32:13,016 Waiting for running processes to finish
2024-09-19 12:32:14,038 Waiting for running processes to finish
2024-09-19 12:32:15,040 Waiting for running processes to finish
2024-09-19 12:32:16,041 Waiting for running processes to finish
2024-09-19 12:32:17,043 Waiting for running processes to finish
2024-09-19 12:32:18,044 Waiting for running processes to finish
2024-09-19 12:32:19,046 Waiting for running processes to finish
2024-09-19 12:32:20,047 Waiting for running processes to finish
2024-09-19 12:32:21,049 Waiting for running processes to finish
2024-09-19 12:32:21,375 Loaded model granite-7b
2024-09-19 12:32:21,378 Batch processing started for model granite-7b
2024-09-19 12:32:22,051 Waiting for running processes to finish
2024-09-19 12:32:23,052 Waiting for running processes to finish
2024-09-19 12:32:24,054 Waiting for running processes to finish
2024-09-19 12:32:25,056 Waiting for running processes to finish
2024-09-19 12:32:26,057 Waiting for running processes to finish
2024-09-19 12:32:27,059 Waiting for running processes to finish
2024-09-19 12:32:28,061 Waiting for running processes to finish
2024-09-19 12:32:29,062 Waiting for running processes to finish
2024-09-19 12:32:30,064 Waiting for running processes to finish
2024-09-19 12:32:30,847 Processed batch: ['b8021019', '02ed6810', '19b6d9e2', '4052313e', 'b337b543', 'aedf371e', '3f613a50', '61a02acf', 'f9f91629', 'e7831b0f', '74723182', 'd9dcdf6b', '65c02741', '33606469', '10895797', '0bb50346', '644afb4d', '42de1c96', '83f13916', 'e5744efa', 'cb552460', 'c0f30624', '056acac6', 'a3d3ca5c', 'f0db45a9', 'bdcf29a6', 'a9051cb2', 'f91b6595', 'edfbdba9', '68f8ffe2', '606da388', '54263f9e', '27852777', '7228551a', 'e491efd4', '93cd7605', 'c2574e2c', '8adfed78', '0e6f7236', 'ceeeb5be', '1945134e', '0640d4e8', '8194cfe4', '2ab45911', '07cc2a31', 'e0e656aa', '109a0070', '68d7d290', '8a1305cf', 'a1d35195', 'cda4f159', 'f13880fc', '0b0d0477', 'c15718a6', '053a1221', '6271bf52', '06d840dd', 'a75f74ec', 'd862862e', 'dbbfb235', 'e3f34527', '4ef0e8fd', '9a7c74fd', '793b9d62'] with model granite-7b in 9.4686 seconds
2024-09-19 12:32:30,847 Saving sys info
2024-09-19 12:32:30,879 Latency for request b8021019 with model granite-7b: 59.5610 seconds
2024-09-19 12:32:30,879 Saving results with gpu monitoring
2024-09-19 12:32:30,882 Latency for request 02ed6810 with model granite-7b: 59.5030 seconds
2024-09-19 12:32:30,882 Saving results with gpu monitoring
2024-09-19 12:32:30,884 Latency for request 19b6d9e2 with model granite-7b: 59.2550 seconds
2024-09-19 12:32:30,884 Saving results with gpu monitoring
2024-09-19 12:32:30,886 Latency for request 4052313e with model granite-7b: 59.2010 seconds
2024-09-19 12:32:30,886 Saving results with gpu monitoring
2024-09-19 12:32:30,888 Latency for request b337b543 with model granite-7b: 58.8780 seconds
2024-09-19 12:32:30,888 Saving results with gpu monitoring
2024-09-19 12:32:30,890 Latency for request aedf371e with model granite-7b: 58.8050 seconds
2024-09-19 12:32:30,890 Saving results with gpu monitoring
2024-09-19 12:32:30,892 Latency for request 3f613a50 with model granite-7b: 58.8010 seconds
2024-09-19 12:32:30,892 Saving results with gpu monitoring
2024-09-19 12:32:30,894 Latency for request 61a02acf with model granite-7b: 58.5380 seconds
2024-09-19 12:32:30,894 Saving results with gpu monitoring
2024-09-19 12:32:30,896 Latency for request f9f91629 with model granite-7b: 58.3110 seconds
2024-09-19 12:32:30,896 Saving results with gpu monitoring
2024-09-19 12:32:30,898 Latency for request e7831b0f with model granite-7b: 58.0370 seconds
2024-09-19 12:32:30,898 Saving results with gpu monitoring
2024-09-19 12:32:30,900 Latency for request 74723182 with model granite-7b: 58.0250 seconds
2024-09-19 12:32:30,900 Saving results with gpu monitoring
2024-09-19 12:32:30,902 Latency for request d9dcdf6b with model granite-7b: 57.7400 seconds
2024-09-19 12:32:30,902 Saving results with gpu monitoring
2024-09-19 12:32:30,904 Latency for request 65c02741 with model granite-7b: 57.5720 seconds
2024-09-19 12:32:30,904 Saving results with gpu monitoring
2024-09-19 12:32:30,906 Latency for request 33606469 with model granite-7b: 57.1960 seconds
2024-09-19 12:32:30,906 Saving results with gpu monitoring
2024-09-19 12:32:30,908 Latency for request 10895797 with model granite-7b: 57.1700 seconds
2024-09-19 12:32:30,908 Saving results with gpu monitoring
2024-09-19 12:32:30,910 Latency for request 0bb50346 with model granite-7b: 57.1690 seconds
2024-09-19 12:32:30,910 Saving results with gpu monitoring
2024-09-19 12:32:30,912 Latency for request 644afb4d with model granite-7b: 57.0760 seconds
2024-09-19 12:32:30,912 Saving results with gpu monitoring
2024-09-19 12:32:30,914 Latency for request 42de1c96 with model granite-7b: 56.8660 seconds
2024-09-19 12:32:30,914 Saving results with gpu monitoring
2024-09-19 12:32:30,916 Latency for request 83f13916 with model granite-7b: 56.8240 seconds
2024-09-19 12:32:30,916 Saving results with gpu monitoring
2024-09-19 12:32:30,918 Latency for request e5744efa with model granite-7b: 56.7990 seconds
2024-09-19 12:32:30,918 Saving results with gpu monitoring
2024-09-19 12:32:30,920 Latency for request cb552460 with model granite-7b: 56.7060 seconds
2024-09-19 12:32:30,920 Saving results with gpu monitoring
2024-09-19 12:32:30,922 Latency for request c0f30624 with model granite-7b: 56.6260 seconds
2024-09-19 12:32:30,922 Saving results with gpu monitoring
2024-09-19 12:32:30,924 Latency for request 056acac6 with model granite-7b: 56.4730 seconds
2024-09-19 12:32:30,924 Saving results with gpu monitoring
2024-09-19 12:32:30,926 Latency for request a3d3ca5c with model granite-7b: 56.3720 seconds
2024-09-19 12:32:30,926 Saving results with gpu monitoring
2024-09-19 12:32:30,928 Latency for request f0db45a9 with model granite-7b: 56.0470 seconds
2024-09-19 12:32:30,928 Saving results with gpu monitoring
2024-09-19 12:32:30,930 Latency for request bdcf29a6 with model granite-7b: 55.9030 seconds
2024-09-19 12:32:30,930 Saving results with gpu monitoring
2024-09-19 12:32:30,932 Latency for request a9051cb2 with model granite-7b: 55.9000 seconds
2024-09-19 12:32:30,932 Saving results with gpu monitoring
2024-09-19 12:32:30,934 Latency for request f91b6595 with model granite-7b: 55.7520 seconds
2024-09-19 12:32:30,934 Saving results with gpu monitoring
2024-09-19 12:32:30,936 Latency for request edfbdba9 with model granite-7b: 55.7040 seconds
2024-09-19 12:32:30,936 Saving results with gpu monitoring
2024-09-19 12:32:30,938 Latency for request 68f8ffe2 with model granite-7b: 55.4640 seconds
2024-09-19 12:32:30,938 Saving results with gpu monitoring
2024-09-19 12:32:30,940 Latency for request 606da388 with model granite-7b: 54.9250 seconds
2024-09-19 12:32:30,940 Saving results with gpu monitoring
2024-09-19 12:32:30,942 Latency for request 54263f9e with model granite-7b: 54.1710 seconds
2024-09-19 12:32:30,942 Saving results with gpu monitoring
2024-09-19 12:32:30,944 Latency for request 27852777 with model granite-7b: 53.9270 seconds
2024-09-19 12:32:30,944 Saving results with gpu monitoring
2024-09-19 12:32:30,946 Latency for request 7228551a with model granite-7b: 53.4240 seconds
2024-09-19 12:32:30,946 Saving results with gpu monitoring
2024-09-19 12:32:30,948 Latency for request e491efd4 with model granite-7b: 53.4070 seconds
2024-09-19 12:32:30,948 Saving results with gpu monitoring
2024-09-19 12:32:30,950 Latency for request 93cd7605 with model granite-7b: 53.3540 seconds
2024-09-19 12:32:30,950 Saving results with gpu monitoring
2024-09-19 12:32:30,952 Latency for request c2574e2c with model granite-7b: 53.2020 seconds
2024-09-19 12:32:30,952 Saving results with gpu monitoring
2024-09-19 12:32:30,954 Latency for request 8adfed78 with model granite-7b: 53.1570 seconds
2024-09-19 12:32:30,954 Saving results with gpu monitoring
2024-09-19 12:32:30,956 Latency for request 0e6f7236 with model granite-7b: 53.0330 seconds
2024-09-19 12:32:30,956 Saving results with gpu monitoring
2024-09-19 12:32:30,958 Latency for request ceeeb5be with model granite-7b: 52.3910 seconds
2024-09-19 12:32:30,958 Saving results with gpu monitoring
2024-09-19 12:32:30,960 Latency for request 1945134e with model granite-7b: 52.3330 seconds
2024-09-19 12:32:30,960 Saving results with gpu monitoring
2024-09-19 12:32:30,962 Latency for request 0640d4e8 with model granite-7b: 52.1830 seconds
2024-09-19 12:32:30,962 Saving results with gpu monitoring
2024-09-19 12:32:30,964 Latency for request 8194cfe4 with model granite-7b: 52.1790 seconds
2024-09-19 12:32:30,964 Saving results with gpu monitoring
2024-09-19 12:32:30,966 Latency for request 2ab45911 with model granite-7b: 51.7660 seconds
2024-09-19 12:32:30,966 Saving results with gpu monitoring
2024-09-19 12:32:30,968 Latency for request 07cc2a31 with model granite-7b: 51.5510 seconds
2024-09-19 12:32:30,968 Saving results with gpu monitoring
2024-09-19 12:32:30,970 Latency for request e0e656aa with model granite-7b: 51.4180 seconds
2024-09-19 12:32:30,970 Saving results with gpu monitoring
2024-09-19 12:32:30,972 Latency for request 109a0070 with model granite-7b: 51.3660 seconds
2024-09-19 12:32:30,972 Saving results with gpu monitoring
2024-09-19 12:32:30,974 Latency for request 68d7d290 with model granite-7b: 50.9040 seconds
2024-09-19 12:32:30,974 Saving results with gpu monitoring
2024-09-19 12:32:30,976 Latency for request 8a1305cf with model granite-7b: 50.7010 seconds
2024-09-19 12:32:30,976 Saving results with gpu monitoring
2024-09-19 12:32:30,978 Latency for request a1d35195 with model granite-7b: 50.6080 seconds
2024-09-19 12:32:30,978 Saving results with gpu monitoring
2024-09-19 12:32:30,980 Latency for request cda4f159 with model granite-7b: 50.5940 seconds
2024-09-19 12:32:30,980 Saving results with gpu monitoring
2024-09-19 12:32:30,982 Latency for request f13880fc with model granite-7b: 50.1770 seconds
2024-09-19 12:32:30,982 Saving results with gpu monitoring
2024-09-19 12:32:30,984 Latency for request 0b0d0477 with model granite-7b: 49.9920 seconds
2024-09-19 12:32:30,984 Saving results with gpu monitoring
2024-09-19 12:32:30,986 Latency for request c15718a6 with model granite-7b: 49.8080 seconds
2024-09-19 12:32:30,986 Saving results with gpu monitoring
2024-09-19 12:32:30,988 Latency for request 053a1221 with model granite-7b: 49.7390 seconds
2024-09-19 12:32:30,988 Saving results with gpu monitoring
2024-09-19 12:32:30,990 Latency for request 6271bf52 with model granite-7b: 49.6080 seconds
2024-09-19 12:32:30,990 Saving results with gpu monitoring
2024-09-19 12:32:30,992 Latency for request 06d840dd with model granite-7b: 49.5270 seconds
2024-09-19 12:32:30,992 Saving results with gpu monitoring
2024-09-19 12:32:30,994 Latency for request a75f74ec with model granite-7b: 49.4000 seconds
2024-09-19 12:32:30,994 Saving results with gpu monitoring
2024-09-19 12:32:30,996 Latency for request d862862e with model granite-7b: 49.1830 seconds
2024-09-19 12:32:30,996 Saving results with gpu monitoring
2024-09-19 12:32:30,998 Latency for request dbbfb235 with model granite-7b: 49.1750 seconds
2024-09-19 12:32:30,998 Saving results with gpu monitoring
2024-09-19 12:32:31,000 Latency for request e3f34527 with model granite-7b: 48.8320 seconds
2024-09-19 12:32:31,000 Saving results with gpu monitoring
2024-09-19 12:32:31,002 Latency for request 4ef0e8fd with model granite-7b: 48.7230 seconds
2024-09-19 12:32:31,002 Saving results with gpu monitoring
2024-09-19 12:32:31,004 Latency for request 9a7c74fd with model granite-7b: 48.7000 seconds
2024-09-19 12:32:31,004 Saving results with gpu monitoring
2024-09-19 12:32:31,006 Latency for request 793b9d62 with model granite-7b: 48.5420 seconds
2024-09-19 12:32:31,006 Saving results with gpu monitoring
2024-09-19 12:32:31,008 127.0.0.1 - - [19/Sep/2024 12:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:32:31,008 Next: call load_model for llama3-8b
2024-09-19 12:32:31,109 Waiting for running processes to finish
2024-09-19 12:32:31,109 Unloaded previous model
2024-09-19 12:32:32,181 Waiting for running processes to finish
2024-09-19 12:32:33,187 Waiting for running processes to finish
2024-09-19 12:32:34,189 Waiting for running processes to finish
2024-09-19 12:32:35,191 Waiting for running processes to finish
2024-09-19 12:32:36,192 Waiting for running processes to finish
2024-09-19 12:32:37,194 Waiting for running processes to finish
2024-09-19 12:32:38,195 Waiting for running processes to finish
2024-09-19 12:32:39,197 Waiting for running processes to finish
2024-09-19 12:32:40,199 Waiting for running processes to finish
2024-09-19 12:32:41,274 Waiting for running processes to finish
2024-09-19 12:32:42,276 Waiting for running processes to finish
2024-09-19 12:32:43,278 Waiting for running processes to finish
2024-09-19 12:32:44,318 Waiting for running processes to finish
2024-09-19 12:32:45,319 Waiting for running processes to finish
2024-09-19 12:32:46,321 Waiting for running processes to finish
2024-09-19 12:32:47,324 Waiting for running processes to finish
2024-09-19 12:32:48,326 Waiting for running processes to finish
2024-09-19 12:32:49,328 Waiting for running processes to finish
2024-09-19 12:32:50,330 Waiting for running processes to finish
2024-09-19 12:32:51,331 Waiting for running processes to finish
2024-09-19 12:32:51,687 Loaded model llama3-8b
2024-09-19 12:32:51,690 Batch processing started for model llama3-8b
2024-09-19 12:32:52,333 Waiting for running processes to finish
2024-09-19 12:32:53,334 Waiting for running processes to finish
2024-09-19 12:32:54,336 Waiting for running processes to finish
2024-09-19 12:32:55,338 Waiting for running processes to finish
2024-09-19 12:32:55,826 Processed batch: ['80e34462', 'f7b9484c', '8579f631', '0102f001', '4630b268', 'a62b6078', 'bbed24fb', '8d07239e', '13889af1', '628f09bb', 'd627032b', '9cb457e4', 'd6313f46', 'f9cf8930', '593cece8', '48d42394', '85ac2f30', 'eb03a1de', '5725d4c9', '96fdaa5d', '8f6baf5c', '784e07c3', '00805b2d', 'ba5157ed', '743fa62d', 'bb2c5db2', '2bd5189c', '7fc46529', 'd28fe1be', '11c2d585', 'af4dddba', 'a65d4636'] with model llama3-8b in 4.1360 seconds
2024-09-19 12:32:55,826 Saving sys info
2024-09-19 12:32:55,857 Latency for request 80e34462 with model llama3-8b: 89.0110 seconds
2024-09-19 12:32:55,857 Saving results with gpu monitoring
2024-09-19 12:32:55,860 Latency for request f7b9484c with model llama3-8b: 87.3990 seconds
2024-09-19 12:32:55,860 Saving results with gpu monitoring
2024-09-19 12:32:55,862 Latency for request 8579f631 with model llama3-8b: 87.1900 seconds
2024-09-19 12:32:55,862 Saving results with gpu monitoring
2024-09-19 12:32:55,864 Latency for request 0102f001 with model llama3-8b: 86.8340 seconds
2024-09-19 12:32:55,864 Saving results with gpu monitoring
2024-09-19 12:32:55,866 Latency for request 4630b268 with model llama3-8b: 86.7970 seconds
2024-09-19 12:32:55,866 Saving results with gpu monitoring
2024-09-19 12:32:55,868 Latency for request a62b6078 with model llama3-8b: 86.7560 seconds
2024-09-19 12:32:55,868 Saving results with gpu monitoring
2024-09-19 12:32:55,870 Latency for request bbed24fb with model llama3-8b: 86.5490 seconds
2024-09-19 12:32:55,870 Saving results with gpu monitoring
2024-09-19 12:32:55,872 Latency for request 8d07239e with model llama3-8b: 85.9770 seconds
2024-09-19 12:32:55,872 Saving results with gpu monitoring
2024-09-19 12:32:55,874 Latency for request 13889af1 with model llama3-8b: 85.5760 seconds
2024-09-19 12:32:55,874 Saving results with gpu monitoring
2024-09-19 12:32:55,876 Latency for request 628f09bb with model llama3-8b: 85.4450 seconds
2024-09-19 12:32:55,876 Saving results with gpu monitoring
2024-09-19 12:32:55,878 Latency for request d627032b with model llama3-8b: 85.0010 seconds
2024-09-19 12:32:55,878 Saving results with gpu monitoring
2024-09-19 12:32:55,880 Latency for request 9cb457e4 with model llama3-8b: 84.7560 seconds
2024-09-19 12:32:55,880 Saving results with gpu monitoring
2024-09-19 12:32:55,882 Latency for request d6313f46 with model llama3-8b: 84.5600 seconds
2024-09-19 12:32:55,882 Saving results with gpu monitoring
2024-09-19 12:32:55,884 Latency for request f9cf8930 with model llama3-8b: 84.3710 seconds
2024-09-19 12:32:55,884 Saving results with gpu monitoring
2024-09-19 12:32:55,886 Latency for request 593cece8 with model llama3-8b: 84.3520 seconds
2024-09-19 12:32:55,886 Saving results with gpu monitoring
2024-09-19 12:32:55,888 Latency for request 48d42394 with model llama3-8b: 84.2310 seconds
2024-09-19 12:32:55,888 Saving results with gpu monitoring
2024-09-19 12:32:55,890 Latency for request 85ac2f30 with model llama3-8b: 84.0690 seconds
2024-09-19 12:32:55,890 Saving results with gpu monitoring
2024-09-19 12:32:55,892 Latency for request eb03a1de with model llama3-8b: 83.6630 seconds
2024-09-19 12:32:55,892 Saving results with gpu monitoring
2024-09-19 12:32:55,894 Latency for request 5725d4c9 with model llama3-8b: 83.1440 seconds
2024-09-19 12:32:55,894 Saving results with gpu monitoring
2024-09-19 12:32:55,896 Latency for request 96fdaa5d with model llama3-8b: 83.0150 seconds
2024-09-19 12:32:55,896 Saving results with gpu monitoring
2024-09-19 12:32:55,898 Latency for request 8f6baf5c with model llama3-8b: 82.3110 seconds
2024-09-19 12:32:55,898 Saving results with gpu monitoring
2024-09-19 12:32:55,900 Latency for request 784e07c3 with model llama3-8b: 82.2320 seconds
2024-09-19 12:32:55,900 Saving results with gpu monitoring
2024-09-19 12:32:55,902 Latency for request 00805b2d with model llama3-8b: 81.2060 seconds
2024-09-19 12:32:55,902 Saving results with gpu monitoring
2024-09-19 12:32:55,904 Latency for request ba5157ed with model llama3-8b: 79.2770 seconds
2024-09-19 12:32:55,904 Saving results with gpu monitoring
2024-09-19 12:32:55,906 Latency for request 743fa62d with model llama3-8b: 79.1350 seconds
2024-09-19 12:32:55,906 Saving results with gpu monitoring
2024-09-19 12:32:55,908 Latency for request bb2c5db2 with model llama3-8b: 79.0190 seconds
2024-09-19 12:32:55,908 Saving results with gpu monitoring
2024-09-19 12:32:55,910 Latency for request 2bd5189c with model llama3-8b: 78.8070 seconds
2024-09-19 12:32:55,910 Saving results with gpu monitoring
2024-09-19 12:32:55,912 Latency for request 7fc46529 with model llama3-8b: 76.7870 seconds
2024-09-19 12:32:55,912 Saving results with gpu monitoring
2024-09-19 12:32:55,914 Latency for request d28fe1be with model llama3-8b: 75.2790 seconds
2024-09-19 12:32:55,914 Saving results with gpu monitoring
2024-09-19 12:32:55,916 Latency for request 11c2d585 with model llama3-8b: 75.0240 seconds
2024-09-19 12:32:55,916 Saving results with gpu monitoring
2024-09-19 12:32:55,918 Latency for request af4dddba with model llama3-8b: 74.7770 seconds
2024-09-19 12:32:55,918 Saving results with gpu monitoring
2024-09-19 12:32:55,920 Latency for request a65d4636 with model llama3-8b: 74.1650 seconds
2024-09-19 12:32:55,920 Saving results with gpu monitoring
2024-09-19 12:32:55,922 127.0.0.1 - - [19/Sep/2024 12:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:32:55,922 Next: call load_model for gemma-7b
2024-09-19 12:32:56,018 Unloaded previous model
2024-09-19 12:32:56,510 Waiting for running processes to finish
2024-09-19 12:32:58,605 Total time: 184.0570 seconds
2024-09-19 12:32:58,605 Total inference time: 38.6320 seconds
2024-09-19 12:32:58,605 Inference time as percentage of total time: 20.99%
2024-09-19 12:32:58,605 END
2024-09-19 12:32:58,606 127.0.0.1 - - [19/Sep/2024 12:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:18,649 Loaded model gemma-7b
2024-09-19 12:33:18,652 Batch processing started for model gemma-7b
2024-09-19 12:33:23,921 Processed batch: ['9eb6351a', '6c1255ce', '4e955540', '40062229', '78c429fd', '58e29dd0', 'fd4fbe49', '0a1fa502', '7675ee6d', 'a13d7691', '5b9936db', '0fa3b452', 'ebb702b2', '30e4f419', '3bd615ee', 'e9c7eb85', 'cdddf21d', 'c31b28ac', 'd2727358', '3da0d4da', '7596661f', '31f98c61', '094e1b4b', '62131795', '89d41575', '5da7e371', '4d930911', '89a58843', '6936d830', '38de694e', '09a4098b', 'a0923fda'] with model gemma-7b in 5.2690 seconds
2024-09-19 12:33:23,921 Saving sys info
2024-09-19 12:33:23,988 Latency for request 9eb6351a with model gemma-7b: 106.0630 seconds
2024-09-19 12:33:23,989 Saving results with gpu monitoring
2024-09-19 12:33:23,992 Latency for request 6c1255ce with model gemma-7b: 105.4610 seconds
2024-09-19 12:33:23,992 Saving results with gpu monitoring
2024-09-19 12:33:23,994 Latency for request 4e955540 with model gemma-7b: 104.7800 seconds
2024-09-19 12:33:23,994 Saving results with gpu monitoring
2024-09-19 12:33:23,996 Latency for request 40062229 with model gemma-7b: 104.0860 seconds
2024-09-19 12:33:23,996 Saving results with gpu monitoring
2024-09-19 12:33:23,998 Latency for request 78c429fd with model gemma-7b: 104.0830 seconds
2024-09-19 12:33:23,998 Saving results with gpu monitoring
2024-09-19 12:33:24,000 Latency for request 58e29dd0 with model gemma-7b: 103.8640 seconds
2024-09-19 12:33:24,000 Saving results with gpu monitoring
2024-09-19 12:33:24,002 Latency for request fd4fbe49 with model gemma-7b: 103.3730 seconds
2024-09-19 12:33:24,002 Saving results with gpu monitoring
2024-09-19 12:33:24,004 Latency for request 0a1fa502 with model gemma-7b: 103.1500 seconds
2024-09-19 12:33:24,004 Saving results with gpu monitoring
2024-09-19 12:33:24,006 Latency for request 7675ee6d with model gemma-7b: 102.9520 seconds
2024-09-19 12:33:24,006 Saving results with gpu monitoring
2024-09-19 12:33:24,008 Latency for request a13d7691 with model gemma-7b: 102.1840 seconds
2024-09-19 12:33:24,008 Saving results with gpu monitoring
2024-09-19 12:33:24,010 Latency for request 5b9936db with model gemma-7b: 101.8360 seconds
2024-09-19 12:33:24,010 Saving results with gpu monitoring
2024-09-19 12:33:24,012 Latency for request 0fa3b452 with model gemma-7b: 101.8060 seconds
2024-09-19 12:33:24,012 Saving results with gpu monitoring
2024-09-19 12:33:24,014 Latency for request ebb702b2 with model gemma-7b: 101.1540 seconds
2024-09-19 12:33:24,014 Saving results with gpu monitoring
2024-09-19 12:33:24,016 Latency for request 30e4f419 with model gemma-7b: 101.1350 seconds
2024-09-19 12:33:24,016 Saving results with gpu monitoring
2024-09-19 12:33:24,018 Latency for request 3bd615ee with model gemma-7b: 100.9780 seconds
2024-09-19 12:33:24,018 Saving results with gpu monitoring
2024-09-19 12:33:24,020 Latency for request e9c7eb85 with model gemma-7b: 100.6540 seconds
2024-09-19 12:33:24,020 Saving results with gpu monitoring
2024-09-19 12:33:24,022 Latency for request cdddf21d with model gemma-7b: 100.2840 seconds
2024-09-19 12:33:24,022 Saving results with gpu monitoring
2024-09-19 12:33:24,024 Latency for request c31b28ac with model gemma-7b: 100.0160 seconds
2024-09-19 12:33:24,024 Saving results with gpu monitoring
2024-09-19 12:33:24,026 Latency for request d2727358 with model gemma-7b: 99.6830 seconds
2024-09-19 12:33:24,026 Saving results with gpu monitoring
2024-09-19 12:33:24,028 Latency for request 3da0d4da with model gemma-7b: 99.1450 seconds
2024-09-19 12:33:24,028 Saving results with gpu monitoring
2024-09-19 12:33:24,030 Latency for request 7596661f with model gemma-7b: 99.0620 seconds
2024-09-19 12:33:24,030 Saving results with gpu monitoring
2024-09-19 12:33:24,032 Latency for request 31f98c61 with model gemma-7b: 98.9370 seconds
2024-09-19 12:33:24,032 Saving results with gpu monitoring
2024-09-19 12:33:24,034 Latency for request 094e1b4b with model gemma-7b: 98.8490 seconds
2024-09-19 12:33:24,034 Saving results with gpu monitoring
2024-09-19 12:33:24,036 Latency for request 62131795 with model gemma-7b: 98.2960 seconds
2024-09-19 12:33:24,036 Saving results with gpu monitoring
2024-09-19 12:33:24,038 Latency for request 89d41575 with model gemma-7b: 97.7490 seconds
2024-09-19 12:33:24,038 Saving results with gpu monitoring
2024-09-19 12:33:24,040 Latency for request 5da7e371 with model gemma-7b: 97.7180 seconds
2024-09-19 12:33:24,040 Saving results with gpu monitoring
2024-09-19 12:33:24,042 Latency for request 4d930911 with model gemma-7b: 97.2630 seconds
2024-09-19 12:33:24,042 Saving results with gpu monitoring
2024-09-19 12:33:24,044 Latency for request 89a58843 with model gemma-7b: 97.0880 seconds
2024-09-19 12:33:24,044 Saving results with gpu monitoring
2024-09-19 12:33:24,046 Latency for request 6936d830 with model gemma-7b: 96.4130 seconds
2024-09-19 12:33:24,046 Saving results with gpu monitoring
2024-09-19 12:33:24,048 Latency for request 38de694e with model gemma-7b: 96.2650 seconds
2024-09-19 12:33:24,048 Saving results with gpu monitoring
2024-09-19 12:33:24,050 Latency for request 09a4098b with model gemma-7b: 96.1270 seconds
2024-09-19 12:33:24,050 Saving results with gpu monitoring
2024-09-19 12:33:24,052 Latency for request a0923fda with model gemma-7b: 96.0830 seconds
2024-09-19 12:33:24,052 Saving results with gpu monitoring
2024-09-19 12:33:24,055 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,055 No batch to process for model granite-7b
2024-09-19 12:33:24,056 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,056 No batch to process for model gemma-7b
2024-09-19 12:33:24,057 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,058 No batch to process for model llama3-8b
2024-09-19 12:33:24,059 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,059 No batch to process for model granite-7b
2024-09-19 12:33:24,061 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,061 No batch to process for model llama3-8b
2024-09-19 12:33:24,061 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,062 No batch to process for model gemma-7b
2024-09-19 12:33:24,063 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,063 No batch to process for model granite-7b
2024-09-19 12:33:24,064 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,064 No batch to process for model llama3-8b
2024-09-19 12:33:24,065 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,065 No batch to process for model gemma-7b
2024-09-19 12:33:24,066 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,067 No batch to process for model llama3-8b
2024-09-19 12:33:24,067 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,067 No batch to process for model granite-7b
2024-09-19 12:33:24,068 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,068 No batch to process for model gemma-7b
2024-09-19 12:33:24,069 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,069 No batch to process for model llama3-8b
2024-09-19 12:33:24,070 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,071 No batch to process for model granite-7b
2024-09-19 12:33:24,071 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,072 No batch to process for model gemma-7b
2024-09-19 12:33:24,072 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,073 No batch to process for model gemma-7b
2024-09-19 12:33:24,073 No batch to process for model llama3-8b
2024-09-19 12:33:24,074 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,074 No batch to process for model granite-7b
2024-09-19 12:33:24,074 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 12:33:24,074 No batch to process for model gemma-7b
2024-09-19 12:33:24,075 127.0.0.1 - - [19/Sep/2024 12:33:24] "POST /inference HTTP/1.1" 200 -
