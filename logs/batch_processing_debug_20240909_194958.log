2024-09-09 19:49:58,175 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.212:5000
2024-09-09 19:49:58,175 [33mPress CTRL+C to quit[0m
2024-09-09 19:51:54,570 Request with ID 1a897ff9 for model gpt2-124m received
2024-09-09 19:51:54,570 Adjusted time limit for model gpt2-124m: 4.7502 seconds
2024-09-09 19:51:54,570 127.0.0.1 - - [09/Sep/2024 19:51:54] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:51:57,047 Request with ID a92ca6da for model gpt2-124m received
2024-09-09 19:51:57,048 127.0.0.1 - - [09/Sep/2024 19:51:57] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:51:58,039 Request with ID baa2afee for model gpt2medium-355m received
2024-09-09 19:51:58,039 Adjusted time limit for model gpt2medium-355m: 1.3550 seconds
2024-09-09 19:51:58,039 127.0.0.1 - - [09/Sep/2024 19:51:58] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:51:58,227 Request with ID 7b7b21dd for model gpt2-124m received
2024-09-09 19:51:58,227 127.0.0.1 - - [09/Sep/2024 19:51:58] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:51:59,338 Request with ID 8ced003a for model gpt2-124m received
2024-09-09 19:51:59,338 Time limit condition met for model gpt2-124m
2024-09-09 19:51:59,338 127.0.0.1 - - [09/Sep/2024 19:51:59] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:51:59,338 Loading model gpt2-124m
2024-09-09 19:52:00,101 Processed batch: ['1a897ff9', 'a92ca6da', '7b7b21dd', 'd5f6'] with model gpt2-124m in 0.6505 seconds
2024-09-09 19:52:00,101 Latency for request 1a897ff9 with model gpt2-124m: 5.5309 seconds
2024-09-09 19:52:00,103 Latency for request a92ca6da with model gpt2-124m: 3.0540 seconds
2024-09-09 19:52:00,103 Latency for request 7b7b21dd with model gpt2-124m: 1.8741 seconds
2024-09-09 19:52:00,103 Latency for request d5f6 with model gpt2-124m: 0.7624 seconds
2024-09-09 19:52:00,206 Time limit condition met for model gpt2medium-355m
2024-09-09 19:52:00,206 Loading model gpt2medium-355m
2024-09-09 19:52:01,323 Request with ID 1ff1ecd6 for model distilgpt2-124m received
2024-09-09 19:52:01,323 Adjusted time limit for model distilgpt2-124m: 5.6043 seconds
2024-09-09 19:52:01,323 127.0.0.1 - - [09/Sep/2024 19:52:01] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:52:02,895 Processed batch: ['baa2afee', '5b8e', '56fe', '085b'] with model gpt2medium-355m in 2.5829 seconds
2024-09-09 19:52:02,895 Latency for request baa2afee with model gpt2medium-355m: 4.8562 seconds
2024-09-09 19:52:02,896 Latency for request 5b8e with model gpt2medium-355m: 2.6886 seconds
2024-09-09 19:52:02,896 Latency for request 56fe with model gpt2medium-355m: 2.6886 seconds
2024-09-09 19:52:02,897 Latency for request 085b with model gpt2medium-355m: 2.6886 seconds
2024-09-09 19:52:03,148 Request with ID 9abd3008 for model distilgpt2-124m received
2024-09-09 19:52:03,149 127.0.0.1 - - [09/Sep/2024 19:52:03] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:52:04,848 Request with ID 50002c6b for model gpt2medium-355m received
2024-09-09 19:52:04,849 Adjusted time limit for model gpt2medium-355m: 1.3443 seconds
2024-09-09 19:52:04,849 127.0.0.1 - - [09/Sep/2024 19:52:04] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:52:06,024 Request with ID 6a87e568 for model distilgpt2-124m received
2024-09-09 19:52:06,025 127.0.0.1 - - [09/Sep/2024 19:52:06] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:52:06,235 Time limit condition met for model gpt2medium-355m
2024-09-09 19:52:06,235 Loading model gpt2medium-355m
2024-09-09 19:52:07,386 Request with ID d5ff45f5 for model gpt2medium-355m received
2024-09-09 19:52:07,386 127.0.0.1 - - [09/Sep/2024 19:52:07] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:52:08,478 Processed batch: ['50002c6b', 'd1cf', '9641', '5b2a'] with model gpt2medium-355m in 2.2418 seconds
2024-09-09 19:52:08,478 Latency for request 50002c6b with model gpt2medium-355m: 3.6293 seconds
2024-09-09 19:52:08,479 Latency for request d1cf with model gpt2medium-355m: 2.2426 seconds
2024-09-09 19:52:08,479 Latency for request 9641 with model gpt2medium-355m: 2.2426 seconds
2024-09-09 19:52:08,479 Latency for request 5b2a with model gpt2medium-355m: 2.2426 seconds
2024-09-09 19:52:08,584 Time limit condition met for model distilgpt2-124m
2024-09-09 19:52:08,585 Loading model distilgpt2-124m
2024-09-09 19:52:08,851 Request with ID f3aa6b62 for model gpt2-124m received
2024-09-09 19:52:08,851 Adjusted time limit for model gpt2-124m: 4.7439 seconds
2024-09-09 19:52:08,851 127.0.0.1 - - [09/Sep/2024 19:52:08] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:52:09,237 Processed batch: ['1ff1ecd6', '9abd3008', '6a87e568', 'a0a9'] with model distilgpt2-124m in 0.6009 seconds
2024-09-09 19:52:09,237 Latency for request 1ff1ecd6 with model distilgpt2-124m: 7.9144 seconds
2024-09-09 19:52:09,238 Latency for request 9abd3008 with model distilgpt2-124m: 6.0888 seconds
2024-09-09 19:52:09,238 Latency for request 6a87e568 with model distilgpt2-124m: 3.2133 seconds
2024-09-09 19:52:09,238 Latency for request a0a9 with model distilgpt2-124m: 0.6526 seconds
2024-09-09 19:52:10,682 Request with ID dbb936e8 for model gpt2medium-355m received
2024-09-09 19:52:10,682 Adjusted time limit for model gpt2medium-355m: 1.3487 seconds
2024-09-09 19:52:10,683 127.0.0.1 - - [09/Sep/2024 19:52:10] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:52:11,773 Request with ID b29ba182 for model gpt2-124m received
2024-09-09 19:52:11,774 127.0.0.1 - - [09/Sep/2024 19:52:11] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:52:12,051 Time limit condition met for model gpt2medium-355m
2024-09-09 19:52:12,052 Loading model gpt2medium-355m
2024-09-09 19:52:12,776 Request with ID b88ebb6e for model distilgpt2-124m received
2024-09-09 19:52:12,776 Adjusted time limit for model distilgpt2-124m: 5.6043 seconds
2024-09-09 19:52:12,777 127.0.0.1 - - [09/Sep/2024 19:52:12] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:52:14,762 Processed batch: ['d5ff45f5', 'dbb936e8', '2a63', '3c69'] with model gpt2medium-355m in 2.5372 seconds
2024-09-09 19:52:14,762 Latency for request d5ff45f5 with model gpt2medium-355m: 7.3765 seconds
2024-09-09 19:52:14,763 Latency for request dbb936e8 with model gpt2medium-355m: 4.0798 seconds
2024-09-09 19:52:14,764 Latency for request 2a63 with model gpt2medium-355m: 2.7103 seconds
2024-09-09 19:52:14,764 Latency for request 3c69 with model gpt2medium-355m: 2.7103 seconds
2024-09-09 19:52:14,869 Time limit condition met for model gpt2-124m
2024-09-09 19:52:14,869 Loading model gpt2-124m
2024-09-09 19:52:15,754 Processed batch: ['8ced003a', 'f3aa6b62', 'b29ba182', '7c06'] with model gpt2-124m in 0.8240 seconds
2024-09-09 19:52:15,754 Latency for request 8ced003a with model gpt2-124m: 16.4160 seconds
2024-09-09 19:52:15,755 Latency for request f3aa6b62 with model gpt2-124m: 6.9025 seconds
2024-09-09 19:52:15,755 Latency for request b29ba182 with model gpt2-124m: 3.9806 seconds
2024-09-09 19:52:15,755 Latency for request 7c06 with model gpt2-124m: 0.8848 seconds
2024-09-09 19:52:15,991 Request with ID cf644ea3 for model gpt2-124m received
2024-09-09 19:52:15,992 Adjusted time limit for model gpt2-124m: 4.7434 seconds
2024-09-09 19:52:15,992 127.0.0.1 - - [09/Sep/2024 19:52:15] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:52:18,462 Time limit condition met for model distilgpt2-124m
2024-09-09 19:52:18,463 Loading model distilgpt2-124m
2024-09-09 19:52:19,053 Processed batch: ['b88ebb6e', '9481', '765c', '933e'] with model distilgpt2-124m in 0.5207 seconds
2024-09-09 19:52:19,053 Latency for request b88ebb6e with model distilgpt2-124m: 6.2768 seconds
2024-09-09 19:52:19,054 Latency for request 9481 with model distilgpt2-124m: 0.5903 seconds
2024-09-09 19:52:19,054 Latency for request 765c with model distilgpt2-124m: 0.5903 seconds
2024-09-09 19:52:19,055 Latency for request 933e with model distilgpt2-124m: 0.5903 seconds
2024-09-09 19:52:19,588 Request with ID ceaf8018 for model gpt2-124m received
2024-09-09 19:52:19,589 127.0.0.1 - - [09/Sep/2024 19:52:19] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:52:20,828 Time limit condition met for model gpt2-124m
2024-09-09 19:52:20,828 Loading model gpt2-124m
2024-09-09 19:52:21,651 Processed batch: ['cf644ea3', 'ceaf8018', '994f', '7db5'] with model gpt2-124m in 0.7442 seconds
2024-09-09 19:52:21,651 Latency for request cf644ea3 with model gpt2-124m: 5.6592 seconds
2024-09-09 19:52:21,651 Latency for request ceaf8018 with model gpt2-124m: 2.0625 seconds
2024-09-09 19:52:21,652 Latency for request 994f with model gpt2-124m: 0.8224 seconds
2024-09-09 19:52:21,652 Latency for request 7db5 with model gpt2-124m: 0.8224 seconds
2024-09-09 19:52:21,784 Request with ID 3f0f408a for model distilgpt2-124m received
2024-09-09 19:52:21,784 Adjusted time limit for model distilgpt2-124m: 5.6082 seconds
2024-09-09 19:52:21,784 127.0.0.1 - - [09/Sep/2024 19:52:21] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:52:27,486 Time limit condition met for model distilgpt2-124m
2024-09-09 19:52:27,487 Loading model distilgpt2-124m
2024-09-09 19:52:28,047 Processed batch: ['3f0f408a', 'd378', 'b8fc', 'bcca'] with model distilgpt2-124m in 0.4791 seconds
2024-09-09 19:52:28,048 Latency for request 3f0f408a with model distilgpt2-124m: 6.2631 seconds
2024-09-09 19:52:28,048 Latency for request d378 with model distilgpt2-124m: 0.5604 seconds
2024-09-09 19:52:28,049 Latency for request b8fc with model distilgpt2-124m: 0.5604 seconds
2024-09-09 19:52:28,049 Latency for request bcca with model distilgpt2-124m: 0.5604 seconds
