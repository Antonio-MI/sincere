2024-09-09 18:43:07,842  * Debugger is active!
2024-09-09 18:43:07,853  * Debugger PIN: 128-860-637
2024-09-09 18:43:10,685 Current time: 1725921790.6858
2024-09-09 18:43:10,685 Model gpt2-124m loading time: 0.2240 seconds, unloading time: 0.0000 seconds
2024-09-09 18:43:10,685 Adjusted time limit: 4.3502 seconds
2024-09-09 18:43:10,685 Timer for model gpt2-124m set to fire at: 1725921795.0360
2024-09-09 18:43:10,686 127.0.0.1 - - [09/Sep/2024 18:43:10] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:13,162 Current time: 1725921793.1627
2024-09-09 18:43:13,163 Model gpt2-124m loading time: 0.2240 seconds, unloading time: 0.0000 seconds
2024-09-09 18:43:13,163 Adjusted time limit: 4.3502 seconds
2024-09-09 18:43:13,163 Timer for model gpt2-124m set to fire at: 1725921795.0360
2024-09-09 18:43:13,163 127.0.0.1 - - [09/Sep/2024 18:43:13] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:14,156 Current time: 1725921794.1566
2024-09-09 18:43:14,156 Model gpt2medium-355m loading time: 0.1053 seconds, unloading time: 0.0000 seconds
2024-09-09 18:43:14,157 Adjusted time limit: 0.9550 seconds
2024-09-09 18:43:14,157 Timer for model gpt2medium-355m set to fire at: 1725921795.1116
2024-09-09 18:43:14,157 127.0.0.1 - - [09/Sep/2024 18:43:14] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:14,340 Current time: 1725921794.3400
2024-09-09 18:43:14,340 Model gpt2-124m loading time: 0.2240 seconds, unloading time: 0.0000 seconds
2024-09-09 18:43:14,340 Adjusted time limit: 4.3502 seconds
2024-09-09 18:43:14,340 Timer for model gpt2-124m set to fire at: 1725921795.0360
2024-09-09 18:43:14,340 127.0.0.1 - - [09/Sep/2024 18:43:14] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:15,128 Time limit reached for model gpt2-124m at 1725921795.1279
2024-09-09 18:43:15,128 Moving batch for gpt2-124m from incoming to running due to time limit with batch size 3
2024-09-09 18:43:15,128 Time limit condition met for model gpt2-124m
2024-09-09 18:43:15,129 3
2024-09-09 18:43:15,129 Padding requests generated in 0.0001 seconds
2024-09-09 18:43:15,129 Loading model gpt2-124m
2024-09-09 18:43:15,313 Batch processing started at 3363.3940 for model gpt2-124m
2024-09-09 18:43:15,449 Current time: 1725921795.4490
2024-09-09 18:43:15,449 Model gpt2-124m loading time: 0.2240 seconds, unloading time: 0.0068 seconds
2024-09-09 18:43:15,449 Adjusted time limit: 4.3434 seconds
2024-09-09 18:43:15,449 Timer for model gpt2-124m set to fire at: 1725921795.0360
2024-09-09 18:43:15,449 127.0.0.1 - - [09/Sep/2024 18:43:15] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:16,891 Processed request ID ba1157b9 with model gpt2-124m
2024-09-09 18:43:16,891 Processed request ID f302a782 with model gpt2-124m
2024-09-09 18:43:16,891 Processed request ID ba756ff0 with model gpt2-124m
2024-09-09 18:43:16,892 Processed request ID 3155 with model gpt2-124m
2024-09-09 18:43:16,892 Processed batch: ['ba1157b9', 'f302a782', 'ba756ff0', '3155'] with model gpt2-124m in 1.5786 seconds
2024-09-09 18:43:16,892 Latency for request ba1157b9 with model gpt2-124m: 6.2064 seconds
2024-09-09 18:43:16,894 Latency for request f302a782 with model gpt2-124m: 3.7297 seconds
2024-09-09 18:43:16,894 Latency for request ba756ff0 with model gpt2-124m: 2.5521 seconds
2024-09-09 18:43:16,895 Latency for request 3155 with model gpt2-124m: 1.7629 seconds
2024-09-09 18:43:16,895 Time limit reached for model gpt2medium-355m at 1725921795.1279
2024-09-09 18:43:16,895 Moving batch for gpt2medium-355m from incoming to running due to time limit with batch size 1
2024-09-09 18:43:16,895 Time limit condition met for model gpt2medium-355m
2024-09-09 18:43:16,895 1
2024-09-09 18:43:16,895 Padding requests generated in 0.0000 seconds
2024-09-09 18:43:16,895 Loading model gpt2medium-355m
2024-09-09 18:43:16,998 Batch processing started at 3365.0787 for model gpt2medium-355m
2024-09-09 18:43:17,436 Current time: 1725921797.4367
2024-09-09 18:43:17,436 Model distilgpt2-124m loading time: 0.0411 seconds, unloading time: 0.0107 seconds
2024-09-09 18:43:17,436 Adjusted time limit: 5.2043 seconds
2024-09-09 18:43:17,436 Timer for model distilgpt2-124m set to fire at: 1725921802.6410
2024-09-09 18:43:17,436 127.0.0.1 - - [09/Sep/2024 18:43:17] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:19,261 Current time: 1725921799.2618
2024-09-09 18:43:19,261 Model distilgpt2-124m loading time: 0.0411 seconds, unloading time: 0.0107 seconds
2024-09-09 18:43:19,261 Adjusted time limit: 5.2043 seconds
2024-09-09 18:43:19,261 Timer for model distilgpt2-124m set to fire at: 1725921802.6410
2024-09-09 18:43:19,262 127.0.0.1 - - [09/Sep/2024 18:43:19] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:20,958 Current time: 1725921800.9587
2024-09-09 18:43:20,958 Model gpt2medium-355m loading time: 0.1053 seconds, unloading time: 0.0107 seconds
2024-09-09 18:43:20,958 Adjusted time limit: 0.9443 seconds
2024-09-09 18:43:20,958 Timer for model gpt2medium-355m set to fire at: 1725921795.1116
2024-09-09 18:43:20,958 127.0.0.1 - - [09/Sep/2024 18:43:20] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:21,884 Processed request ID b642af8e with model gpt2medium-355m
2024-09-09 18:43:21,884 Processed request ID a045 with model gpt2medium-355m
2024-09-09 18:43:21,885 Processed request ID 867a with model gpt2medium-355m
2024-09-09 18:43:21,885 Processed request ID d13a with model gpt2medium-355m
2024-09-09 18:43:21,885 Processed batch: ['b642af8e', 'a045', '867a', 'd13a'] with model gpt2medium-355m in 4.8873 seconds
2024-09-09 18:43:21,885 Latency for request b642af8e with model gpt2medium-355m: 7.7291 seconds
2024-09-09 18:43:21,886 Latency for request a045 with model gpt2medium-355m: 4.9898 seconds
2024-09-09 18:43:21,886 Latency for request 867a with model gpt2medium-355m: 4.9898 seconds
2024-09-09 18:43:21,886 Latency for request d13a with model gpt2medium-355m: 4.9898 seconds
2024-09-09 18:43:22,133 Current time: 1725921802.1335
2024-09-09 18:43:22,133 Model distilgpt2-124m loading time: 0.0411 seconds, unloading time: 0.0107 seconds
2024-09-09 18:43:22,133 Adjusted time limit: 5.2043 seconds
2024-09-09 18:43:22,133 Timer for model distilgpt2-124m set to fire at: 1725921802.6410
2024-09-09 18:43:22,133 127.0.0.1 - - [09/Sep/2024 18:43:22] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:22,721 Time limit reached for model distilgpt2-124m at 1725921802.7217
2024-09-09 18:43:22,722 Moving batch for distilgpt2-124m from incoming to running due to time limit with batch size 3
2024-09-09 18:43:22,722 Time limit condition met for model distilgpt2-124m
2024-09-09 18:43:22,722 3
2024-09-09 18:43:22,722 Padding requests generated in 0.0001 seconds
2024-09-09 18:43:22,723 Loading model distilgpt2-124m
2024-09-09 18:43:22,807 Batch processing started at 3370.8878 for model distilgpt2-124m
2024-09-09 18:43:23,497 Current time: 1725921803.4975
2024-09-09 18:43:23,497 Model gpt2medium-355m loading time: 0.1053 seconds, unloading time: 0.0063 seconds
2024-09-09 18:43:23,497 Adjusted time limit: 0.9487 seconds
2024-09-09 18:43:23,497 Timer for model gpt2medium-355m set to fire at: 1725921804.4462
2024-09-09 18:43:23,497 127.0.0.1 - - [09/Sep/2024 18:43:23] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:24,002 Processed request ID bd6aaf92 with model distilgpt2-124m
2024-09-09 18:43:24,002 Processed request ID 5fe241e8 with model distilgpt2-124m
2024-09-09 18:43:24,003 Processed request ID b1223999 with model distilgpt2-124m
2024-09-09 18:43:24,003 Processed request ID 8a2c with model distilgpt2-124m
2024-09-09 18:43:24,003 Processed batch: ['bd6aaf92', '5fe241e8', 'b1223999', '8a2c'] with model distilgpt2-124m in 1.1963 seconds
2024-09-09 18:43:24,003 Latency for request bd6aaf92 with model distilgpt2-124m: 6.5670 seconds
2024-09-09 18:43:24,004 Latency for request 5fe241e8 with model distilgpt2-124m: 4.7418 seconds
2024-09-09 18:43:24,004 Latency for request b1223999 with model distilgpt2-124m: 1.8702 seconds
2024-09-09 18:43:24,004 Latency for request 8a2c with model distilgpt2-124m: 1.2806 seconds
2024-09-09 18:43:24,529 Time limit reached for model gpt2medium-355m at 1725921804.5297
2024-09-09 18:43:24,530 Moving batch for gpt2medium-355m from incoming to running due to time limit with batch size 2
2024-09-09 18:43:24,530 Time limit condition met for model gpt2medium-355m
2024-09-09 18:43:24,530 2
2024-09-09 18:43:24,531 Padding requests generated in 0.0002 seconds
2024-09-09 18:43:24,531 Loading model gpt2medium-355m
2024-09-09 18:43:24,723 Batch processing started at 3372.8045 for model gpt2medium-355m
2024-09-09 18:43:24,962 Current time: 1725921804.9628
2024-09-09 18:43:24,962 Model gpt2-124m loading time: 0.2240 seconds, unloading time: 0.0107 seconds
2024-09-09 18:43:24,962 Adjusted time limit: 4.3395 seconds
2024-09-09 18:43:24,962 Timer for model gpt2-124m set to fire at: 1725921809.3022
2024-09-09 18:43:24,962 127.0.0.1 - - [09/Sep/2024 18:43:24] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:26,793 Current time: 1725921806.7937
2024-09-09 18:43:26,793 Model gpt2medium-355m loading time: 0.1053 seconds, unloading time: 0.0107 seconds
2024-09-09 18:43:26,793 Adjusted time limit: 0.9443 seconds
2024-09-09 18:43:26,793 Timer for model gpt2medium-355m set to fire at: 1725921804.4462
2024-09-09 18:43:26,793 127.0.0.1 - - [09/Sep/2024 18:43:26] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:27,018 Processed request ID 7012a7a5 with model gpt2medium-355m
2024-09-09 18:43:27,018 Processed request ID 8a623839 with model gpt2medium-355m
2024-09-09 18:43:27,018 Processed request ID 9781 with model gpt2medium-355m
2024-09-09 18:43:27,018 Processed request ID 77ef with model gpt2medium-355m
2024-09-09 18:43:27,018 Processed batch: ['7012a7a5', '8a623839', '9781', '77ef'] with model gpt2medium-355m in 2.2950 seconds
2024-09-09 18:43:27,018 Latency for request 7012a7a5 with model gpt2medium-355m: 6.0603 seconds
2024-09-09 18:43:27,019 Latency for request 8a623839 with model gpt2medium-355m: 3.5214 seconds
2024-09-09 18:43:27,019 Latency for request 9781 with model gpt2medium-355m: 2.4876 seconds
2024-09-09 18:43:27,020 Latency for request 77ef with model gpt2medium-355m: 2.4876 seconds
2024-09-09 18:43:27,884 Current time: 1725921807.8847
2024-09-09 18:43:27,885 Model gpt2-124m loading time: 0.2240 seconds, unloading time: 0.0107 seconds
2024-09-09 18:43:27,885 Adjusted time limit: 4.3395 seconds
2024-09-09 18:43:27,885 Timer for model gpt2-124m set to fire at: 1725921809.3022
2024-09-09 18:43:27,885 127.0.0.1 - - [09/Sep/2024 18:43:27] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:28,892 Current time: 1725921808.8923
2024-09-09 18:43:28,892 Model distilgpt2-124m loading time: 0.0411 seconds, unloading time: 0.0107 seconds
2024-09-09 18:43:28,892 Adjusted time limit: 5.2043 seconds
2024-09-09 18:43:28,892 Timer for model distilgpt2-124m set to fire at: 1725921814.0966
2024-09-09 18:43:28,893 127.0.0.1 - - [09/Sep/2024 18:43:28] "POST /inference HTTP/1.1" 200 -
2024-09-09 18:43:29,400 Time limit reached for model gpt2-124m at 1725921809.4001
2024-09-09 18:43:29,400 Moving batch for gpt2-124m from incoming to running due to time limit with batch size 3
2024-09-09 18:43:29,400 Time limit condition met for model gpt2-124m
2024-09-09 18:43:29,400 3
2024-09-09 18:43:29,400 Padding requests generated in 0.0000 seconds
2024-09-09 18:43:29,400 Loading model gpt2-124m
2024-09-09 18:43:29,485 Batch processing started at 3377.5661 for model gpt2-124m
2024-09-09 18:43:30,318 Processed request ID 534b94ee with model gpt2-124m
2024-09-09 18:43:30,318 Processed request ID 4382aac7 with model gpt2-124m
2024-09-09 18:43:30,318 Processed request ID d132deec with model gpt2-124m
2024-09-09 18:43:30,319 Processed request ID bb0d with model gpt2-124m
2024-09-09 18:43:30,319 Processed batch: ['534b94ee', '4382aac7', 'd132deec', 'bb0d'] with model gpt2-124m in 0.8337 seconds
2024-09-09 18:43:30,319 Latency for request 534b94ee with model gpt2-124m: 14.8704 seconds
2024-09-09 18:43:30,320 Latency for request 4382aac7 with model gpt2-124m: 5.3566 seconds
2024-09-09 18:43:30,320 Latency for request d132deec with model gpt2-124m: 2.4348 seconds
2024-09-09 18:43:30,320 Latency for request bb0d with model gpt2-124m: 0.9187 seconds
2024-09-09 18:43:34,169 Time limit reached for model distilgpt2-124m at 1725921814.1693
2024-09-09 18:43:34,169 Moving batch for distilgpt2-124m from incoming to running due to time limit with batch size 1
2024-09-09 18:43:34,170 Time limit condition met for model distilgpt2-124m
2024-09-09 18:43:34,170 1
2024-09-09 18:43:34,170 Padding requests generated in 0.0001 seconds
2024-09-09 18:43:34,170 Loading model distilgpt2-124m
2024-09-09 18:43:34,264 Batch processing started at 3382.3446 for model distilgpt2-124m
2024-09-09 18:43:34,803 Processed request ID 915793f5 with model distilgpt2-124m
2024-09-09 18:43:34,803 Processed request ID 5428 with model distilgpt2-124m
2024-09-09 18:43:34,803 Processed request ID 67ae with model distilgpt2-124m
2024-09-09 18:43:34,804 Processed request ID 2815 with model distilgpt2-124m
2024-09-09 18:43:34,804 Processed batch: ['915793f5', '5428', '67ae', '2815'] with model distilgpt2-124m in 0.5403 seconds
2024-09-09 18:43:34,804 Latency for request 915793f5 with model distilgpt2-124m: 5.9122 seconds
2024-09-09 18:43:34,804 Latency for request 5428 with model distilgpt2-124m: 0.6339 seconds
2024-09-09 18:43:34,805 Latency for request 67ae with model distilgpt2-124m: 0.6338 seconds
2024-09-09 18:43:34,805 Latency for request 2815 with model distilgpt2-124m: 0.6338 seconds
2024-09-09 19:04:36,359  * Detected change in '/Users/amartinezi/Documents/SINCERE/api_scheduler.py', reloading
