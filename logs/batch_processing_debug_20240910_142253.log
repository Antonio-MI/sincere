2024-09-10 14:22:58,402 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.11.77:5000
2024-09-10 14:22:58,402 [33mPress CTRL+C to quit[0m
2024-09-10 14:22:58,433 Request with ID 56566efb for model gpt2medium-355m received
2024-09-10 14:22:58,433 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 14:22:58,433 Adjusted time limit for model gpt2medium-355m: 9.9550 seconds
2024-09-10 14:22:58,433 127.0.0.1 - - [10/Sep/2024 14:22:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:22:58,435 Request with ID 4dca0b20 for model gpt2-124m received
2024-09-10 14:22:58,435 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 14:22:58,435 Adjusted time limit for model gpt2-124m: 13.3502 seconds
2024-09-10 14:22:58,435 127.0.0.1 - - [10/Sep/2024 14:22:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:22:58,470 Request with ID 85cd5e5b for model gpt2-124m received
2024-09-10 14:22:58,470 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 14:22:58,470 127.0.0.1 - - [10/Sep/2024 14:22:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:22:58,592 Request with ID 0a654970 for model gpt2-124m received
2024-09-10 14:22:58,593 Adjusted time limit based on total queue size 4: 11.2500 seconds
2024-09-10 14:22:58,593 127.0.0.1 - - [10/Sep/2024 14:22:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:22:58,744 Request with ID 84d296cf for model gpt2-124m received
2024-09-10 14:22:58,745 Adjusted time limit based on total queue size 5: 11.2500 seconds
2024-09-10 14:22:58,745 127.0.0.1 - - [10/Sep/2024 14:22:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:22:58,993 Request with ID 616186c6 for model distilgpt2-124m received
2024-09-10 14:22:58,994 Adjusted time limit based on total queue size 6: 11.2500 seconds
2024-09-10 14:22:58,994 Adjusted time limit for model distilgpt2-124m: 14.2150 seconds
2024-09-10 14:22:58,994 127.0.0.1 - - [10/Sep/2024 14:22:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:22:59,361 Request with ID cdfc04f1 for model distilgpt2-124m received
2024-09-10 14:22:59,361 Adjusted time limit based on total queue size 7: 11.2500 seconds
2024-09-10 14:22:59,361 127.0.0.1 - - [10/Sep/2024 14:22:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:22:59,702 Request with ID 6468979b for model gpt2medium-355m received
2024-09-10 14:22:59,702 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 14:22:59,703 127.0.0.1 - - [10/Sep/2024 14:22:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:22:59,938 Request with ID db104a24 for model distilgpt2-124m received
2024-09-10 14:22:59,939 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 14:22:59,939 127.0.0.1 - - [10/Sep/2024 14:22:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:00,213 Request with ID 6bb78400 for model gpt2medium-355m received
2024-09-10 14:23:00,214 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 14:23:00,214 127.0.0.1 - - [10/Sep/2024 14:23:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:00,509 Request with ID caf49c8e for model gpt2-124m received
2024-09-10 14:23:00,509 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:23:00,510 127.0.0.1 - - [10/Sep/2024 14:23:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:00,876 Request with ID f65a34f1 for model gpt2medium-355m received
2024-09-10 14:23:00,877 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:23:00,877 127.0.0.1 - - [10/Sep/2024 14:23:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:01,096 Request with ID 61b51ae8 for model gpt2-124m received
2024-09-10 14:23:01,096 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:23:01,096 127.0.0.1 - - [10/Sep/2024 14:23:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:01,299 Request with ID 71e5cd2e for model distilgpt2-124m received
2024-09-10 14:23:01,299 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:23:01,300 127.0.0.1 - - [10/Sep/2024 14:23:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:01,944 Request with ID 2d8f0390 for model gpt2-124m received
2024-09-10 14:23:01,944 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:23:01,944 127.0.0.1 - - [10/Sep/2024 14:23:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:02,663 Request with ID e6786745 for model gpt2-124m received
2024-09-10 14:23:02,663 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:23:02,663 127.0.0.1 - - [10/Sep/2024 14:23:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:03,105 Request with ID 1c76eb7d for model distilgpt2-124m received
2024-09-10 14:23:03,106 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:23:03,106 127.0.0.1 - - [10/Sep/2024 14:23:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:04,796 Request with ID ea6e2fac for model gpt2-124m received
2024-09-10 14:23:04,797 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:23:04,797 127.0.0.1 - - [10/Sep/2024 14:23:04] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:05,544 Request with ID 59e51986 for model gpt2medium-355m received
2024-09-10 14:23:05,545 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:23:05,545 127.0.0.1 - - [10/Sep/2024 14:23:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:05,562 Time limit condition met for model gpt2medium-355m
2024-09-10 14:23:05,563 Updated batch size:8
2024-09-10 14:23:05,563 Loading model gpt2medium-355m
2024-09-10 14:23:06,106 Request with ID 99f95c9b for model gpt2medium-355m received
2024-09-10 14:23:06,106 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:23:06,107 127.0.0.1 - - [10/Sep/2024 14:23:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:06,487 Request with ID 23f0b2d1 for model gpt2medium-355m received
2024-09-10 14:23:06,487 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:23:06,487 127.0.0.1 - - [10/Sep/2024 14:23:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:07,181 Request with ID 2e56f8ca for model gpt2medium-355m received
2024-09-10 14:23:07,181 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:23:07,181 127.0.0.1 - - [10/Sep/2024 14:23:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:07,606 Request with ID 59505c93 for model gpt2-124m received
2024-09-10 14:23:07,606 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:23:07,606 127.0.0.1 - - [10/Sep/2024 14:23:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:07,851 Request with ID 5f60a8e0 for model distilgpt2-124m received
2024-09-10 14:23:07,851 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:23:07,851 127.0.0.1 - - [10/Sep/2024 14:23:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:08,488 Request with ID 901e8f90 for model distilgpt2-124m received
2024-09-10 14:23:08,488 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:23:08,489 127.0.0.1 - - [10/Sep/2024 14:23:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:09,031 Request with ID a62854a2 for model distilgpt2-124m received
2024-09-10 14:23:09,031 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 14:23:09,031 127.0.0.1 - - [10/Sep/2024 14:23:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:09,108 Request with ID 1c8910d0 for model gpt2-124m received
2024-09-10 14:23:09,108 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 14:23:09,108 127.0.0.1 - - [10/Sep/2024 14:23:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:09,814 Request with ID 3c275365 for model gpt2medium-355m received
2024-09-10 14:23:09,814 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 14:23:09,814 127.0.0.1 - - [10/Sep/2024 14:23:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:10,283 Request with ID cd673a77 for model gpt2medium-355m received
2024-09-10 14:23:10,283 Adjusted time limit based on total queue size 24: 3.7500 seconds
2024-09-10 14:23:10,283 127.0.0.1 - - [10/Sep/2024 14:23:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:10,343 Request with ID d57e2a02 for model gpt2medium-355m received
2024-09-10 14:23:10,343 Adjusted time limit based on total queue size 25: 3.7500 seconds
2024-09-10 14:23:10,343 127.0.0.1 - - [10/Sep/2024 14:23:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:10,593 Processed batch: ['56566efb', '6468979b', '6bb78400', 'f65a34f1', '59e51986', '065a', 'f1fb', '325c'] with model gpt2medium-355m in 4.8850 seconds
2024-09-10 14:23:10,593 Latency for request 56566efb with model gpt2medium-355m: 12.1599 seconds
2024-09-10 14:23:10,595 Latency for request 6468979b with model gpt2medium-355m: 10.8912 seconds
2024-09-10 14:23:10,596 Latency for request 6bb78400 with model gpt2medium-355m: 10.3799 seconds
2024-09-10 14:23:10,596 Latency for request f65a34f1 with model gpt2medium-355m: 9.7167 seconds
2024-09-10 14:23:10,596 Latency for request 59e51986 with model gpt2medium-355m: 5.0488 seconds
2024-09-10 14:23:10,597 Latency for request 065a with model gpt2medium-355m: 5.0303 seconds
2024-09-10 14:23:10,597 Latency for request f1fb with model gpt2medium-355m: 5.0303 seconds
2024-09-10 14:23:10,597 Latency for request 325c with model gpt2medium-355m: 5.0303 seconds
2024-09-10 14:23:10,702 Time limit condition met for model gpt2-124m
2024-09-10 14:23:10,702 Updated batch size:16
2024-09-10 14:23:10,702 Loading model gpt2-124m
2024-09-10 14:23:11,232 Request with ID 4dfa55ad for model gpt2medium-355m received
2024-09-10 14:23:11,233 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:23:11,233 Adjusted time limit for model gpt2medium-355m: 9.9482 seconds
2024-09-10 14:23:11,233 127.0.0.1 - - [10/Sep/2024 14:23:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:11,662 Request with ID 1229f05f for model gpt2-124m received
2024-09-10 14:23:11,662 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:23:11,662 127.0.0.1 - - [10/Sep/2024 14:23:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:12,020 Request with ID 4fb9bcfb for model gpt2medium-355m received
2024-09-10 14:23:12,020 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:23:12,020 127.0.0.1 - - [10/Sep/2024 14:23:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:12,283 Request with ID 5aec5c4f for model gpt2medium-355m received
2024-09-10 14:23:12,283 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:23:12,284 127.0.0.1 - - [10/Sep/2024 14:23:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:12,453 Request with ID 66f11d9b for model gpt2-124m received
2024-09-10 14:23:12,454 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:23:12,454 127.0.0.1 - - [10/Sep/2024 14:23:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:12,841 Processed batch: ['4dca0b20', '85cd5e5b', '0a654970', '84d296cf', 'caf49c8e', '61b51ae8', '2d8f0390', 'e6786745', 'ea6e2fac', '59505c93', '1c8910d0', '5fc5', '83a3', '1de5', 'df2d', 'bd6f'] with model gpt2-124m in 2.0728 seconds
2024-09-10 14:23:12,841 Latency for request 4dca0b20 with model gpt2-124m: 14.4064 seconds
2024-09-10 14:23:12,842 Latency for request 85cd5e5b with model gpt2-124m: 14.3711 seconds
2024-09-10 14:23:12,842 Latency for request 0a654970 with model gpt2-124m: 14.2487 seconds
2024-09-10 14:23:12,842 Latency for request 84d296cf with model gpt2-124m: 14.0967 seconds
2024-09-10 14:23:12,843 Latency for request caf49c8e with model gpt2-124m: 12.3326 seconds
2024-09-10 14:23:12,843 Latency for request 61b51ae8 with model gpt2-124m: 11.7455 seconds
2024-09-10 14:23:12,843 Latency for request 2d8f0390 with model gpt2-124m: 10.8976 seconds
2024-09-10 14:23:12,843 Latency for request e6786745 with model gpt2-124m: 10.1786 seconds
2024-09-10 14:23:12,844 Latency for request ea6e2fac with model gpt2-124m: 8.0451 seconds
2024-09-10 14:23:12,844 Latency for request 59505c93 with model gpt2-124m: 5.2349 seconds
2024-09-10 14:23:12,844 Latency for request 1c8910d0 with model gpt2-124m: 3.7335 seconds
2024-09-10 14:23:12,844 Latency for request 5fc5 with model gpt2-124m: 2.1388 seconds
2024-09-10 14:23:12,844 Latency for request 83a3 with model gpt2-124m: 2.1388 seconds
2024-09-10 14:23:12,845 Latency for request 1de5 with model gpt2-124m: 2.1388 seconds
2024-09-10 14:23:12,845 Latency for request df2d with model gpt2-124m: 2.1388 seconds
2024-09-10 14:23:12,845 Latency for request bd6f with model gpt2-124m: 2.1388 seconds
2024-09-10 14:23:12,950 Time limit condition met for model gpt2medium-355m
2024-09-10 14:23:12,950 Updated batch size:16
2024-09-10 14:23:12,950 Loading model gpt2medium-355m
2024-09-10 14:23:13,029 Request with ID b2f94eb8 for model gpt2medium-355m received
2024-09-10 14:23:13,030 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:23:13,030 127.0.0.1 - - [10/Sep/2024 14:23:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:13,650 Request with ID 0d23107e for model distilgpt2-124m received
2024-09-10 14:23:13,650 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:23:13,650 127.0.0.1 - - [10/Sep/2024 14:23:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:14,077 Request with ID 1a0b80f1 for model gpt2-124m received
2024-09-10 14:23:14,077 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:23:14,077 Adjusted time limit for model gpt2-124m: 13.3395 seconds
2024-09-10 14:23:14,077 127.0.0.1 - - [10/Sep/2024 14:23:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:14,249 Request with ID f6b5786e for model gpt2medium-355m received
2024-09-10 14:23:14,249 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:23:14,249 127.0.0.1 - - [10/Sep/2024 14:23:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:14,499 Request with ID 887cb0b7 for model gpt2-124m received
2024-09-10 14:23:14,499 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:23:14,499 127.0.0.1 - - [10/Sep/2024 14:23:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:14,511 Request with ID 632ea938 for model gpt2-124m received
2024-09-10 14:23:14,511 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:23:14,511 127.0.0.1 - - [10/Sep/2024 14:23:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:14,943 Request with ID e2401881 for model gpt2-124m received
2024-09-10 14:23:14,943 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:23:14,943 127.0.0.1 - - [10/Sep/2024 14:23:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:15,169 Request with ID dbeb6209 for model distilgpt2-124m received
2024-09-10 14:23:15,169 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:23:15,169 127.0.0.1 - - [10/Sep/2024 14:23:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:15,376 Request with ID c74429a9 for model distilgpt2-124m received
2024-09-10 14:23:15,377 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:23:15,377 127.0.0.1 - - [10/Sep/2024 14:23:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:15,970 Request with ID 571aaccf for model distilgpt2-124m received
2024-09-10 14:23:15,970 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:23:15,970 127.0.0.1 - - [10/Sep/2024 14:23:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:16,099 Request with ID bb1a4358 for model distilgpt2-124m received
2024-09-10 14:23:16,100 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 14:23:16,100 127.0.0.1 - - [10/Sep/2024 14:23:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:16,450 Request with ID 29a92278 for model distilgpt2-124m received
2024-09-10 14:23:16,450 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 14:23:16,450 127.0.0.1 - - [10/Sep/2024 14:23:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:16,657 Request with ID 418a684f for model distilgpt2-124m received
2024-09-10 14:23:16,658 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 14:23:16,658 127.0.0.1 - - [10/Sep/2024 14:23:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:16,894 Request with ID 05d10a2e for model distilgpt2-124m received
2024-09-10 14:23:16,895 Adjusted time limit based on total queue size 24: 3.7500 seconds
2024-09-10 14:23:16,895 Batch size condition met for model distilgpt2-124m
2024-09-10 14:23:17,177 Request with ID 7d3b09e8 for model distilgpt2-124m received
2024-09-10 14:23:17,177 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 14:23:17,177 127.0.0.1 - - [10/Sep/2024 14:23:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:17,364 Request with ID c49b91d7 for model distilgpt2-124m received
2024-09-10 14:23:17,364 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 14:23:17,364 127.0.0.1 - - [10/Sep/2024 14:23:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:18,122 Request with ID d7e53c03 for model gpt2medium-355m received
2024-09-10 14:23:18,122 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:23:18,123 127.0.0.1 - - [10/Sep/2024 14:23:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:18,366 Request with ID d55bce20 for model gpt2-124m received
2024-09-10 14:23:18,366 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:23:18,367 127.0.0.1 - - [10/Sep/2024 14:23:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:18,602 Processed batch: ['99f95c9b', '23f0b2d1', '2e56f8ca', '3c275365', 'cd673a77', 'd57e2a02', '4dfa55ad', '4fb9bcfb', '5aec5c4f', 'be34', '5d44', '3dce', 'a647', '5ab2', 'f08a', 'd094'] with model gpt2medium-355m in 5.4971 seconds
2024-09-10 14:23:18,602 Latency for request 99f95c9b with model gpt2medium-355m: 12.4960 seconds
2024-09-10 14:23:18,604 Latency for request 23f0b2d1 with model gpt2medium-355m: 12.1154 seconds
2024-09-10 14:23:18,604 Latency for request 2e56f8ca with model gpt2medium-355m: 11.4217 seconds
2024-09-10 14:23:18,604 Latency for request 3c275365 with model gpt2medium-355m: 8.7883 seconds
2024-09-10 14:23:18,604 Latency for request cd673a77 with model gpt2medium-355m: 8.3197 seconds
2024-09-10 14:23:18,605 Latency for request d57e2a02 with model gpt2medium-355m: 8.2591 seconds
2024-09-10 14:23:18,605 Latency for request 4dfa55ad with model gpt2medium-355m: 7.3700 seconds
2024-09-10 14:23:18,605 Latency for request 4fb9bcfb with model gpt2medium-355m: 6.5825 seconds
2024-09-10 14:23:18,605 Latency for request 5aec5c4f with model gpt2medium-355m: 6.3190 seconds
2024-09-10 14:23:18,606 Latency for request be34 with model gpt2medium-355m: 5.6520 seconds
2024-09-10 14:23:18,606 Latency for request 5d44 with model gpt2medium-355m: 5.6520 seconds
2024-09-10 14:23:18,606 Latency for request 3dce with model gpt2medium-355m: 5.6520 seconds
2024-09-10 14:23:18,606 Latency for request a647 with model gpt2medium-355m: 5.6520 seconds
2024-09-10 14:23:18,606 Latency for request 5ab2 with model gpt2medium-355m: 5.6520 seconds
2024-09-10 14:23:18,607 Latency for request f08a with model gpt2medium-355m: 5.6520 seconds
2024-09-10 14:23:18,607 Latency for request d094 with model gpt2medium-355m: 5.6520 seconds
2024-09-10 14:23:18,607 Time limit condition met for model distilgpt2-124m
2024-09-10 14:23:18,607 Updated batch size:4
2024-09-10 14:23:18,607 Loading model distilgpt2-124m
2024-09-10 14:23:19,364 Request with ID 18579efa for model gpt2-124m received
2024-09-10 14:23:19,364 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:23:19,364 127.0.0.1 - - [10/Sep/2024 14:23:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:19,657 Processed batch: ['7d3b09e8', 'c49b91d7', '9de8', 'f850'] with model distilgpt2-124m in 0.9923 seconds
2024-09-10 14:23:19,657 Latency for request 7d3b09e8 with model distilgpt2-124m: 2.4802 seconds
2024-09-10 14:23:19,659 Latency for request c49b91d7 with model distilgpt2-124m: 2.2936 seconds
2024-09-10 14:23:19,659 Latency for request 9de8 with model distilgpt2-124m: 1.0503 seconds
2024-09-10 14:23:19,659 Latency for request f850 with model distilgpt2-124m: 1.0503 seconds
2024-09-10 14:23:19,660 127.0.0.1 - - [10/Sep/2024 14:23:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:19,660 No batch to process for model distilgpt2-124m
2024-09-10 14:23:19,980 Request with ID e7e065c4 for model distilgpt2-124m received
2024-09-10 14:23:19,980 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:23:19,980 Adjusted time limit for model distilgpt2-124m: 14.2087 seconds
2024-09-10 14:23:19,980 127.0.0.1 - - [10/Sep/2024 14:23:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:20,475 Request with ID db38e54d for model distilgpt2-124m received
2024-09-10 14:23:20,476 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:23:20,476 127.0.0.1 - - [10/Sep/2024 14:23:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:20,626 Request with ID c33f72eb for model gpt2-124m received
2024-09-10 14:23:20,627 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:23:20,627 127.0.0.1 - - [10/Sep/2024 14:23:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:21,219 Request with ID a7be2bf6 for model gpt2-124m received
2024-09-10 14:23:21,219 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:23:21,220 127.0.0.1 - - [10/Sep/2024 14:23:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:21,327 Request with ID e798e285 for model gpt2-124m received
2024-09-10 14:23:21,328 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:23:21,328 127.0.0.1 - - [10/Sep/2024 14:23:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:21,586 Request with ID 0719e74f for model gpt2-124m received
2024-09-10 14:23:21,586 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:23:21,587 127.0.0.1 - - [10/Sep/2024 14:23:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:21,869 Request with ID 7e53bcf2 for model gpt2medium-355m received
2024-09-10 14:23:21,870 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:23:21,870 Adjusted time limit for model gpt2medium-355m: 9.9487 seconds
2024-09-10 14:23:21,870 127.0.0.1 - - [10/Sep/2024 14:23:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:22,521 Request with ID 2502b96d for model gpt2medium-355m received
2024-09-10 14:23:22,522 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:23:22,522 127.0.0.1 - - [10/Sep/2024 14:23:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:22,648 Request with ID 130efb07 for model gpt2-124m received
2024-09-10 14:23:22,649 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:23:22,649 127.0.0.1 - - [10/Sep/2024 14:23:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:22,837 Request with ID 38c0664e for model gpt2-124m received
2024-09-10 14:23:22,837 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 14:23:22,837 127.0.0.1 - - [10/Sep/2024 14:23:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:23,237 Request with ID d855b33d for model distilgpt2-124m received
2024-09-10 14:23:23,237 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 14:23:23,238 127.0.0.1 - - [10/Sep/2024 14:23:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:23,619 Request with ID b813b294 for model gpt2-124m received
2024-09-10 14:23:23,619 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 14:23:23,620 127.0.0.1 - - [10/Sep/2024 14:23:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:23,711 Time limit condition met for model gpt2-124m
2024-09-10 14:23:23,711 Updated batch size:16
2024-09-10 14:23:23,712 Loading model gpt2-124m
2024-09-10 14:23:23,733 Request with ID 5f563ef2 for model gpt2medium-355m received
2024-09-10 14:23:23,733 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 14:23:23,734 127.0.0.1 - - [10/Sep/2024 14:23:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:24,061 Request with ID f0af65c8 for model distilgpt2-124m received
2024-09-10 14:23:24,061 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 14:23:24,061 127.0.0.1 - - [10/Sep/2024 14:23:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:24,306 Request with ID 79314790 for model gpt2-124m received
2024-09-10 14:23:24,306 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:23:24,306 127.0.0.1 - - [10/Sep/2024 14:23:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:24,450 Request with ID 9766ecd6 for model gpt2medium-355m received
2024-09-10 14:23:24,450 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:23:24,450 127.0.0.1 - - [10/Sep/2024 14:23:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:25,158 Request with ID edf084b1 for model gpt2-124m received
2024-09-10 14:23:25,158 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:23:25,158 127.0.0.1 - - [10/Sep/2024 14:23:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:25,702 Processed batch: ['1229f05f', '66f11d9b', '1a0b80f1', '887cb0b7', '632ea938', 'e2401881', 'd55bce20', '18579efa', 'c33f72eb', 'a7be2bf6', 'e798e285', '0719e74f', '130efb07', '38c0664e', 'b813b294', '3bd2'] with model gpt2-124m in 1.8944 seconds
2024-09-10 14:23:25,702 Latency for request 1229f05f with model gpt2-124m: 14.0399 seconds
2024-09-10 14:23:25,703 Latency for request 66f11d9b with model gpt2-124m: 13.2484 seconds
2024-09-10 14:23:25,703 Latency for request 1a0b80f1 with model gpt2-124m: 11.6249 seconds
2024-09-10 14:23:25,703 Latency for request 887cb0b7 with model gpt2-124m: 11.2029 seconds
2024-09-10 14:23:25,704 Latency for request 632ea938 with model gpt2-124m: 11.1906 seconds
2024-09-10 14:23:25,704 Latency for request e2401881 with model gpt2-124m: 10.7586 seconds
2024-09-10 14:23:25,704 Latency for request d55bce20 with model gpt2-124m: 7.3356 seconds
2024-09-10 14:23:25,704 Latency for request 18579efa with model gpt2-124m: 6.3376 seconds
2024-09-10 14:23:25,705 Latency for request c33f72eb with model gpt2-124m: 5.0757 seconds
2024-09-10 14:23:25,705 Latency for request a7be2bf6 with model gpt2-124m: 4.4831 seconds
2024-09-10 14:23:25,705 Latency for request e798e285 with model gpt2-124m: 4.3747 seconds
2024-09-10 14:23:25,705 Latency for request 0719e74f with model gpt2-124m: 4.1163 seconds
2024-09-10 14:23:25,705 Latency for request 130efb07 with model gpt2-124m: 3.0534 seconds
2024-09-10 14:23:25,706 Latency for request 38c0664e with model gpt2-124m: 2.8652 seconds
2024-09-10 14:23:25,706 Latency for request b813b294 with model gpt2-124m: 2.0830 seconds
2024-09-10 14:23:25,706 Latency for request 3bd2 with model gpt2-124m: 1.9905 seconds
2024-09-10 14:23:25,775 Request with ID 6ae74998 for model gpt2-124m received
2024-09-10 14:23:25,775 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:23:25,775 Adjusted time limit for model gpt2-124m: 13.3434 seconds
2024-09-10 14:23:25,775 127.0.0.1 - - [10/Sep/2024 14:23:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:25,810 Time limit condition met for model gpt2medium-355m
2024-09-10 14:23:25,810 Updated batch size:8
2024-09-10 14:23:25,810 Loading model gpt2medium-355m
2024-09-10 14:23:26,052 Request with ID d1139065 for model gpt2medium-355m received
2024-09-10 14:23:26,052 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 14:23:26,052 127.0.0.1 - - [10/Sep/2024 14:23:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:26,298 Request with ID 5e61266e for model gpt2medium-355m received
2024-09-10 14:23:26,298 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 14:23:26,298 127.0.0.1 - - [10/Sep/2024 14:23:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:26,781 Request with ID 3aefaa17 for model distilgpt2-124m received
2024-09-10 14:23:26,781 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 14:23:26,781 127.0.0.1 - - [10/Sep/2024 14:23:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:27,113 Request with ID 4188da5d for model gpt2medium-355m received
2024-09-10 14:23:27,113 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:23:27,113 127.0.0.1 - - [10/Sep/2024 14:23:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:27,498 Request with ID 53d4ec2b for model distilgpt2-124m received
2024-09-10 14:23:27,498 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:23:27,498 127.0.0.1 - - [10/Sep/2024 14:23:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:27,802 Request with ID ce46bb09 for model distilgpt2-124m received
2024-09-10 14:23:27,802 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:23:27,802 127.0.0.1 - - [10/Sep/2024 14:23:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:28,367 Request with ID ee762d3a for model gpt2-124m received
2024-09-10 14:23:28,367 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:23:28,367 127.0.0.1 - - [10/Sep/2024 14:23:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:28,511 Request with ID bc9da661 for model distilgpt2-124m received
2024-09-10 14:23:28,511 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:23:28,511 127.0.0.1 - - [10/Sep/2024 14:23:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:28,715 Request with ID f1df0716 for model distilgpt2-124m received
2024-09-10 14:23:28,715 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:23:28,715 127.0.0.1 - - [10/Sep/2024 14:23:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:28,832 Request with ID 21df9bc4 for model distilgpt2-124m received
2024-09-10 14:23:28,832 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:23:28,833 127.0.0.1 - - [10/Sep/2024 14:23:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:29,670 Request with ID 29071bde for model distilgpt2-124m received
2024-09-10 14:23:29,670 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:23:29,671 127.0.0.1 - - [10/Sep/2024 14:23:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:29,760 Request with ID b1539b85 for model distilgpt2-124m received
2024-09-10 14:23:29,760 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:23:29,760 127.0.0.1 - - [10/Sep/2024 14:23:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:29,791 Processed batch: ['b2f94eb8', 'f6b5786e', 'd7e53c03', '7e53bcf2', '2502b96d', '5f563ef2', '9766ecd6', 'f56d'] with model gpt2medium-355m in 3.8634 seconds
2024-09-10 14:23:29,791 Latency for request b2f94eb8 with model gpt2medium-355m: 16.7621 seconds
2024-09-10 14:23:29,793 Latency for request f6b5786e with model gpt2medium-355m: 15.5425 seconds
2024-09-10 14:23:29,793 Latency for request d7e53c03 with model gpt2medium-355m: 11.6691 seconds
2024-09-10 14:23:29,793 Latency for request 7e53bcf2 with model gpt2medium-355m: 7.9221 seconds
2024-09-10 14:23:29,793 Latency for request 2502b96d with model gpt2medium-355m: 7.2702 seconds
2024-09-10 14:23:29,794 Latency for request 5f563ef2 with model gpt2medium-355m: 6.0581 seconds
2024-09-10 14:23:29,794 Latency for request 9766ecd6 with model gpt2medium-355m: 5.3417 seconds
2024-09-10 14:23:29,794 Latency for request f56d with model gpt2medium-355m: 3.9816 seconds
2024-09-10 14:23:29,905 Request with ID 21bbb0f4 for model gpt2medium-355m received
2024-09-10 14:23:29,905 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:23:29,905 Adjusted time limit for model gpt2medium-355m: 9.9443 seconds
2024-09-10 14:23:29,905 127.0.0.1 - - [10/Sep/2024 14:23:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:30,019 Request with ID 87d0bd12 for model gpt2-124m received
2024-09-10 14:23:30,019 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 14:23:30,019 127.0.0.1 - - [10/Sep/2024 14:23:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:30,501 Request with ID a9e908cb for model gpt2-124m received
2024-09-10 14:23:30,502 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 14:23:30,502 127.0.0.1 - - [10/Sep/2024 14:23:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:30,617 Request with ID eaaa7a1e for model gpt2-124m received
2024-09-10 14:23:30,617 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 14:23:30,617 127.0.0.1 - - [10/Sep/2024 14:23:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:30,695 Request with ID 43d5e13c for model gpt2medium-355m received
2024-09-10 14:23:30,695 Adjusted time limit based on total queue size 24: 3.7500 seconds
2024-09-10 14:23:30,695 127.0.0.1 - - [10/Sep/2024 14:23:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:30,936 Request with ID 34ee5046 for model gpt2-124m received
2024-09-10 14:23:30,936 Adjusted time limit based on total queue size 25: 3.7500 seconds
2024-09-10 14:23:30,937 127.0.0.1 - - [10/Sep/2024 14:23:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:31,045 Time limit condition met for model distilgpt2-124m
2024-09-10 14:23:31,045 Updated batch size:16
2024-09-10 14:23:31,045 Loading model distilgpt2-124m
2024-09-10 14:23:31,448 Request with ID d5928f69 for model distilgpt2-124m received
2024-09-10 14:23:31,448 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:23:31,448 127.0.0.1 - - [10/Sep/2024 14:23:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:31,946 Request with ID 96569bcc for model gpt2-124m received
2024-09-10 14:23:31,946 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:23:31,946 127.0.0.1 - - [10/Sep/2024 14:23:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:32,048 Request with ID 77450df2 for model gpt2medium-355m received
2024-09-10 14:23:32,049 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:23:32,049 127.0.0.1 - - [10/Sep/2024 14:23:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:32,221 Request with ID 1df59a51 for model distilgpt2-124m received
2024-09-10 14:23:32,222 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:23:32,222 127.0.0.1 - - [10/Sep/2024 14:23:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:32,361 Processed batch: ['e7e065c4', 'db38e54d', 'd855b33d', 'f0af65c8', '3aefaa17', '53d4ec2b', 'ce46bb09', 'bc9da661', 'f1df0716', '21df9bc4', '29071bde', 'b1539b85', '7491', 'e282', '7272', 'ff7b'] with model distilgpt2-124m in 1.2262 seconds
2024-09-10 14:23:32,361 Latency for request e7e065c4 with model distilgpt2-124m: 12.3812 seconds
2024-09-10 14:23:32,362 Latency for request db38e54d with model distilgpt2-124m: 11.8858 seconds
2024-09-10 14:23:32,362 Latency for request d855b33d with model distilgpt2-124m: 9.1239 seconds
2024-09-10 14:23:32,363 Latency for request f0af65c8 with model distilgpt2-124m: 8.3002 seconds
2024-09-10 14:23:32,363 Latency for request 3aefaa17 with model distilgpt2-124m: 5.5800 seconds
2024-09-10 14:23:32,363 Latency for request 53d4ec2b with model distilgpt2-124m: 4.8630 seconds
2024-09-10 14:23:32,363 Latency for request ce46bb09 with model distilgpt2-124m: 4.5589 seconds
2024-09-10 14:23:32,363 Latency for request bc9da661 with model distilgpt2-124m: 3.8500 seconds
2024-09-10 14:23:32,364 Latency for request f1df0716 with model distilgpt2-124m: 3.6457 seconds
2024-09-10 14:23:32,364 Latency for request 21df9bc4 with model distilgpt2-124m: 3.5286 seconds
2024-09-10 14:23:32,364 Latency for request 29071bde with model distilgpt2-124m: 2.6906 seconds
2024-09-10 14:23:32,364 Latency for request b1539b85 with model distilgpt2-124m: 2.6008 seconds
2024-09-10 14:23:32,364 Latency for request 7491 with model distilgpt2-124m: 1.3159 seconds
2024-09-10 14:23:32,365 Latency for request e282 with model distilgpt2-124m: 1.3159 seconds
2024-09-10 14:23:32,365 Latency for request 7272 with model distilgpt2-124m: 1.3159 seconds
2024-09-10 14:23:32,365 Latency for request ff7b with model distilgpt2-124m: 1.3159 seconds
2024-09-10 14:23:32,470 Time limit condition met for model gpt2medium-355m
2024-09-10 14:23:32,470 Updated batch size:8
2024-09-10 14:23:32,470 Loading model gpt2medium-355m
2024-09-10 14:23:32,678 Request with ID ea633df2 for model distilgpt2-124m received
2024-09-10 14:23:32,678 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:23:32,678 Adjusted time limit for model distilgpt2-124m: 14.2043 seconds
2024-09-10 14:23:32,678 127.0.0.1 - - [10/Sep/2024 14:23:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:32,985 Request with ID cd2b6aec for model distilgpt2-124m received
2024-09-10 14:23:32,986 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:23:32,986 127.0.0.1 - - [10/Sep/2024 14:23:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:33,210 Request with ID b7194997 for model gpt2medium-355m received
2024-09-10 14:23:33,210 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:23:33,210 127.0.0.1 - - [10/Sep/2024 14:23:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:34,248 Request with ID bce59ca2 for model distilgpt2-124m received
2024-09-10 14:23:34,248 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:23:34,249 127.0.0.1 - - [10/Sep/2024 14:23:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:34,437 Request with ID ba4a4356 for model gpt2medium-355m received
2024-09-10 14:23:34,437 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:23:34,438 127.0.0.1 - - [10/Sep/2024 14:23:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:35,467 Request with ID 5029fe47 for model distilgpt2-124m received
2024-09-10 14:23:35,467 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:23:35,467 127.0.0.1 - - [10/Sep/2024 14:23:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:35,917 Request with ID d363807b for model distilgpt2-124m received
2024-09-10 14:23:35,918 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:23:35,918 127.0.0.1 - - [10/Sep/2024 14:23:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:36,005 Processed batch: ['d1139065', '5e61266e', '4188da5d', '21bbb0f4', '43d5e13c', '77450df2', '4ffe', '399a'] with model gpt2medium-355m in 3.4277 seconds
2024-09-10 14:23:36,005 Latency for request d1139065 with model gpt2medium-355m: 9.9534 seconds
2024-09-10 14:23:36,006 Latency for request 5e61266e with model gpt2medium-355m: 9.7067 seconds
2024-09-10 14:23:36,006 Latency for request 4188da5d with model gpt2medium-355m: 8.8921 seconds
2024-09-10 14:23:36,006 Latency for request 21bbb0f4 with model gpt2medium-355m: 6.0997 seconds
2024-09-10 14:23:36,006 Latency for request 43d5e13c with model gpt2medium-355m: 5.3101 seconds
2024-09-10 14:23:36,007 Latency for request 77450df2 with model gpt2medium-355m: 3.9565 seconds
2024-09-10 14:23:36,007 Latency for request 4ffe with model gpt2medium-355m: 3.5346 seconds
2024-09-10 14:23:36,007 Latency for request 399a with model gpt2medium-355m: 3.5346 seconds
2024-09-10 14:23:37,158 Request with ID 0a58f22e for model gpt2medium-355m received
2024-09-10 14:23:37,158 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:23:37,158 Adjusted time limit for model gpt2medium-355m: 9.9443 seconds
2024-09-10 14:23:37,159 127.0.0.1 - - [10/Sep/2024 14:23:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:23:37,469 Time limit condition met for model gpt2-124m
2024-09-10 14:23:37,470 Updated batch size:16
2024-09-10 14:23:37,470 Loading model gpt2-124m
2024-09-10 14:23:40,933 Processed batch: ['79314790', 'edf084b1', '6ae74998', 'ee762d3a', '87d0bd12', 'a9e908cb', 'eaaa7a1e', '34ee5046', '96569bcc', 'dba8', '158a', '1db5', 'c1a1', '1958', '6e81', '14fb'] with model gpt2-124m in 3.3674 seconds
2024-09-10 14:23:40,933 Latency for request 79314790 with model gpt2-124m: 16.6268 seconds
2024-09-10 14:23:40,934 Latency for request edf084b1 with model gpt2-124m: 15.7751 seconds
2024-09-10 14:23:40,934 Latency for request 6ae74998 with model gpt2-124m: 15.1578 seconds
2024-09-10 14:23:40,934 Latency for request ee762d3a with model gpt2-124m: 12.5663 seconds
2024-09-10 14:23:40,935 Latency for request 87d0bd12 with model gpt2-124m: 10.9143 seconds
2024-09-10 14:23:40,935 Latency for request a9e908cb with model gpt2-124m: 10.4316 seconds
2024-09-10 14:23:40,935 Latency for request eaaa7a1e with model gpt2-124m: 10.3163 seconds
2024-09-10 14:23:40,935 Latency for request 34ee5046 with model gpt2-124m: 9.9968 seconds
2024-09-10 14:23:40,936 Latency for request 96569bcc with model gpt2-124m: 8.9872 seconds
2024-09-10 14:23:40,936 Latency for request dba8 with model gpt2-124m: 3.4631 seconds
2024-09-10 14:23:40,936 Latency for request 158a with model gpt2-124m: 3.4631 seconds
2024-09-10 14:23:40,936 Latency for request 1db5 with model gpt2-124m: 3.4631 seconds
2024-09-10 14:23:40,936 Latency for request c1a1 with model gpt2-124m: 3.4631 seconds
2024-09-10 14:23:40,937 Latency for request 1958 with model gpt2-124m: 3.4631 seconds
2024-09-10 14:23:40,937 Latency for request 6e81 with model gpt2-124m: 3.4631 seconds
2024-09-10 14:23:40,937 Latency for request 14fb with model gpt2-124m: 3.4631 seconds
2024-09-10 14:23:45,720 Time limit condition met for model distilgpt2-124m
2024-09-10 14:23:45,721 Updated batch size:8
2024-09-10 14:23:45,721 Loading model distilgpt2-124m
2024-09-10 14:23:46,541 Processed batch: ['d5928f69', '1df59a51', 'ea633df2', 'cd2b6aec', 'bce59ca2', '5029fe47', 'd363807b', '32dc'] with model distilgpt2-124m in 0.7357 seconds
2024-09-10 14:23:46,541 Latency for request d5928f69 with model distilgpt2-124m: 15.0932 seconds
2024-09-10 14:23:46,542 Latency for request 1df59a51 with model distilgpt2-124m: 14.3196 seconds
2024-09-10 14:23:46,542 Latency for request ea633df2 with model distilgpt2-124m: 13.8634 seconds
2024-09-10 14:23:46,542 Latency for request cd2b6aec with model distilgpt2-124m: 13.5555 seconds
2024-09-10 14:23:46,542 Latency for request bce59ca2 with model distilgpt2-124m: 12.2927 seconds
2024-09-10 14:23:46,543 Latency for request 5029fe47 with model distilgpt2-124m: 11.0740 seconds
2024-09-10 14:23:46,543 Latency for request d363807b with model distilgpt2-124m: 10.6236 seconds
2024-09-10 14:23:46,543 Latency for request 32dc with model distilgpt2-124m: 0.8202 seconds
2024-09-10 14:23:47,162 Time limit condition met for model gpt2medium-355m
2024-09-10 14:23:47,163 Updated batch size:4
2024-09-10 14:23:47,163 Loading model gpt2medium-355m
2024-09-10 14:23:50,028 Processed batch: ['b7194997', 'ba4a4356', '0a58f22e', 'ebcf'] with model gpt2medium-355m in 2.7140 seconds
2024-09-10 14:23:50,028 Latency for request b7194997 with model gpt2medium-355m: 16.8181 seconds
2024-09-10 14:23:50,029 Latency for request ba4a4356 with model gpt2medium-355m: 15.5905 seconds
2024-09-10 14:23:50,029 Latency for request 0a58f22e with model gpt2medium-355m: 12.8700 seconds
2024-09-10 14:23:50,029 Latency for request ebcf with model gpt2medium-355m: 2.8652 seconds
