2024-09-17 13:33:52,799 Using device: cuda
2024-09-17 13:33:52,799 Scheduling mode set as FCFS
2024-09-17 13:33:52,799 Monitoring status set to True
2024-09-17 13:34:07,871 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.122.143:5000
2024-09-17 13:34:07,871 [33mPress CTRL+C to quit[0m
2024-09-17 13:34:25,280 Request with ID 0b1123a9 for model llama3-8b received
2024-09-17 13:34:25,281 Batch size condition met for model llama3-8b
2024-09-17 13:34:25,281 Next: call load_model for llama3-8b
2024-09-17 13:34:26,609 Request with ID 383291de for model llama3-8b received
2024-09-17 13:34:26,609 Batch size condition met for model llama3-8b
2024-09-17 13:34:28,866 Request with ID 32816641 for model granite-7b received
2024-09-17 13:34:28,867 Batch size condition met for model granite-7b
2024-09-17 13:34:31,196 Request with ID 3f8b570a for model gemma-7b received
2024-09-17 13:34:31,196 Batch size condition met for model gemma-7b
2024-09-17 13:34:32,631 Request with ID cca4beb0 for model granite-7b received
2024-09-17 13:34:32,632 Batch size condition met for model granite-7b
2024-09-17 13:34:34,814 Request with ID 87a80e1f for model llama3-8b received
2024-09-17 13:34:34,815 Batch size condition met for model llama3-8b
2024-09-17 13:34:37,093 Request with ID f247079f for model llama3-8b received
2024-09-17 13:34:37,093 Batch size condition met for model llama3-8b
2024-09-17 13:34:39,278 Request with ID 0dfc38a9 for model granite-7b received
2024-09-17 13:34:39,279 Batch size condition met for model granite-7b
2024-09-17 13:34:39,977 Request with ID 42a8f117 for model granite-7b received
2024-09-17 13:34:39,978 Batch size condition met for model granite-7b
2024-09-17 13:34:40,274 Loaded model llama3-8b
2024-09-17 13:34:40,277 Batch processing started for model llama3-8b
2024-09-17 13:34:40,644 Request with ID 9096f7ec for model gemma-7b received
2024-09-17 13:34:40,645 Batch size condition met for model gemma-7b
2024-09-17 13:34:41,454 Request with ID 6f76db27 for model llama3-8b received
2024-09-17 13:34:41,454 Batch size condition met for model llama3-8b
2024-09-17 13:34:42,781 Processed batch: ['0b1123a9'] with model llama3-8b in 2.5037 seconds
2024-09-17 13:34:42,781 Saving sys info
2024-09-17 13:34:42,819 Latency for request 0b1123a9 with model llama3-8b: 17.5003 seconds
2024-09-17 13:34:42,820 Saving results with gpu monitoring
2024-09-17 13:34:42,820 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 502, in inference
    completed_inference_ids = process_batch(model_alias, "Batch size", max(allowed_batch_sizes))
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 284, in process_batch
    save_measurements_and_monitor(request_id, model_alias, current_batch_size, latency, batch_throughput, sys_info)
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 172, in save_measurements_and_monitor
    df = pd.DataFrame([datadf0])
NameError: name 'datadf0' is not defined
2024-09-17 13:34:42,820 Next: call load_model for llama3-8b
2024-09-17 13:34:42,821 127.0.0.1 - - [17/Sep/2024 13:34:42] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-17 13:34:42,822 Model llama3-8b already loaded
2024-09-17 13:34:42,827 Batch processing started for model llama3-8b
2024-09-17 13:34:43,066 Request with ID 8f49f30f for model gemma-7b received
2024-09-17 13:34:43,066 Batch size condition met for model gemma-7b
2024-09-17 13:34:44,689 Processed batch: ['6f76db27'] with model llama3-8b in 1.8617 seconds
2024-09-17 13:34:44,689 Saving sys info
2024-09-17 13:34:44,720 Latency for request 6f76db27 with model llama3-8b: 3.2351 seconds
2024-09-17 13:34:44,720 Saving results with gpu monitoring
2024-09-17 13:34:44,720 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 502, in inference
    completed_inference_ids = process_batch(model_alias, "Batch size", max(allowed_batch_sizes))
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 284, in process_batch
    save_measurements_and_monitor(request_id, model_alias, current_batch_size, latency, batch_throughput, sys_info)
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 172, in save_measurements_and_monitor
    df = pd.DataFrame([datadf0])
NameError: name 'datadf0' is not defined
2024-09-17 13:34:44,721 127.0.0.1 - - [17/Sep/2024 13:34:44] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-17 13:34:44,721 Next: call load_model for granite-7b
2024-09-17 13:34:44,721 Unloaded previous model
2024-09-17 13:34:45,303 Waiting for running processes to finish
2024-09-17 13:34:45,439 Waiting for running processes to finish
2024-09-17 13:34:45,629 Waiting for running processes to finish
2024-09-17 13:34:45,817 Waiting for running processes to finish
2024-09-17 13:34:45,950 Waiting for running processes to finish
2024-09-17 13:34:46,051 Waiting for running processes to finish
2024-09-17 13:34:46,152 Waiting for running processes to finish
2024-09-17 13:34:46,253 Waiting for running processes to finish
2024-09-17 13:34:46,353 Waiting for running processes to finish
2024-09-17 13:34:46,454 Waiting for running processes to finish
2024-09-17 13:34:46,554 Waiting for running processes to finish
2024-09-17 13:34:46,655 Waiting for running processes to finish
2024-09-17 13:34:46,756 Waiting for running processes to finish
2024-09-17 13:34:46,856 Waiting for running processes to finish
2024-09-17 13:34:46,957 Waiting for running processes to finish
2024-09-17 13:34:47,058 Waiting for running processes to finish
2024-09-17 13:34:47,158 Waiting for running processes to finish
2024-09-17 13:34:47,259 Waiting for running processes to finish
2024-09-17 13:34:47,360 Waiting for running processes to finish
2024-09-17 13:34:47,460 Waiting for running processes to finish
2024-09-17 13:34:47,561 Waiting for running processes to finish
2024-09-17 13:34:47,662 Waiting for running processes to finish
2024-09-17 13:34:47,762 Waiting for running processes to finish
2024-09-17 13:34:47,863 Waiting for running processes to finish
2024-09-17 13:34:47,964 Waiting for running processes to finish
2024-09-17 13:34:48,065 Waiting for running processes to finish
2024-09-17 13:34:48,165 Waiting for running processes to finish
2024-09-17 13:34:48,266 Waiting for running processes to finish
2024-09-17 13:34:48,475 Waiting for running processes to finish
2024-09-17 13:34:48,575 Waiting for running processes to finish
2024-09-17 13:34:48,676 Waiting for running processes to finish
2024-09-17 13:34:48,777 Waiting for running processes to finish
2024-09-17 13:34:48,878 Waiting for running processes to finish
2024-09-17 13:34:48,978 Waiting for running processes to finish
2024-09-17 13:34:49,079 Waiting for running processes to finish
2024-09-17 13:34:49,179 Waiting for running processes to finish
2024-09-17 13:34:49,280 Waiting for running processes to finish
2024-09-17 13:34:49,381 Waiting for running processes to finish
2024-09-17 13:34:49,481 Waiting for running processes to finish
2024-09-17 13:34:49,582 Waiting for running processes to finish
2024-09-17 13:34:49,682 Waiting for running processes to finish
2024-09-17 13:34:49,783 Waiting for running processes to finish
2024-09-17 13:34:49,884 Waiting for running processes to finish
2024-09-17 13:34:49,984 Waiting for running processes to finish
2024-09-17 13:34:50,085 Waiting for running processes to finish
2024-09-17 13:34:50,186 Waiting for running processes to finish
2024-09-17 13:34:50,286 Waiting for running processes to finish
2024-09-17 13:34:50,387 Waiting for running processes to finish
2024-09-17 13:34:50,488 Waiting for running processes to finish
2024-09-17 13:34:50,588 Waiting for running processes to finish
2024-09-17 13:34:50,689 Waiting for running processes to finish
2024-09-17 13:34:50,790 Waiting for running processes to finish
2024-09-17 13:34:50,891 Waiting for running processes to finish
2024-09-17 13:34:51,039 Waiting for running processes to finish
2024-09-17 13:34:51,140 Waiting for running processes to finish
2024-09-17 13:34:51,241 Waiting for running processes to finish
2024-09-17 13:34:51,342 Waiting for running processes to finish
2024-09-17 13:34:51,442 Waiting for running processes to finish
2024-09-17 13:34:51,543 Waiting for running processes to finish
2024-09-17 13:34:51,644 Waiting for running processes to finish
2024-09-17 13:34:51,744 Waiting for running processes to finish
2024-09-17 13:34:51,845 Waiting for running processes to finish
2024-09-17 13:34:51,946 Waiting for running processes to finish
2024-09-17 13:34:52,047 Waiting for running processes to finish
2024-09-17 13:34:52,147 Waiting for running processes to finish
2024-09-17 13:34:52,248 Waiting for running processes to finish
2024-09-17 13:34:52,349 Waiting for running processes to finish
2024-09-17 13:34:52,449 Waiting for running processes to finish
2024-09-17 13:34:52,550 Waiting for running processes to finish
2024-09-17 13:34:52,651 Waiting for running processes to finish
2024-09-17 13:34:52,751 Waiting for running processes to finish
2024-09-17 13:34:52,852 Waiting for running processes to finish
2024-09-17 13:34:52,953 Waiting for running processes to finish
2024-09-17 13:34:53,053 Waiting for running processes to finish
2024-09-17 13:34:53,154 Waiting for running processes to finish
2024-09-17 13:34:53,255 Waiting for running processes to finish
2024-09-17 13:34:53,356 Waiting for running processes to finish
2024-09-17 13:34:53,461 Waiting for running processes to finish
2024-09-17 13:34:53,561 Waiting for running processes to finish
2024-09-17 13:34:53,662 Waiting for running processes to finish
2024-09-17 13:34:53,763 Waiting for running processes to finish
2024-09-17 13:34:53,863 Waiting for running processes to finish
2024-09-17 13:34:53,964 Waiting for running processes to finish
2024-09-17 13:34:54,065 Waiting for running processes to finish
2024-09-17 13:34:54,165 Waiting for running processes to finish
2024-09-17 13:34:54,266 Waiting for running processes to finish
2024-09-17 13:34:54,367 Waiting for running processes to finish
2024-09-17 13:34:54,468 Waiting for running processes to finish
2024-09-17 13:34:54,568 Waiting for running processes to finish
2024-09-17 13:34:54,669 Waiting for running processes to finish
2024-09-17 13:34:54,770 Waiting for running processes to finish
2024-09-17 13:34:54,870 Waiting for running processes to finish
2024-09-17 13:34:54,971 Waiting for running processes to finish
2024-09-17 13:34:55,072 Waiting for running processes to finish
2024-09-17 13:34:55,173 Waiting for running processes to finish
2024-09-17 13:34:55,273 Waiting for running processes to finish
2024-09-17 13:34:55,374 Waiting for running processes to finish
2024-09-17 13:34:55,475 Waiting for running processes to finish
2024-09-17 13:34:55,575 Waiting for running processes to finish
2024-09-17 13:34:55,676 Waiting for running processes to finish
2024-09-17 13:34:55,777 Waiting for running processes to finish
2024-09-17 13:34:55,878 Waiting for running processes to finish
2024-09-17 13:34:56,074 Waiting for running processes to finish
2024-09-17 13:34:56,175 Waiting for running processes to finish
2024-09-17 13:34:56,275 Waiting for running processes to finish
2024-09-17 13:34:56,376 Waiting for running processes to finish
2024-09-17 13:34:56,477 Waiting for running processes to finish
2024-09-17 13:34:56,577 Waiting for running processes to finish
2024-09-17 13:34:56,678 Waiting for running processes to finish
2024-09-17 13:34:56,779 Waiting for running processes to finish
2024-09-17 13:34:56,880 Waiting for running processes to finish
2024-09-17 13:34:56,980 Waiting for running processes to finish
2024-09-17 13:34:57,081 Waiting for running processes to finish
2024-09-17 13:34:57,182 Waiting for running processes to finish
2024-09-17 13:34:57,282 Waiting for running processes to finish
2024-09-17 13:34:57,383 Waiting for running processes to finish
2024-09-17 13:34:57,484 Waiting for running processes to finish
2024-09-17 13:34:57,584 Waiting for running processes to finish
2024-09-17 13:34:57,685 Waiting for running processes to finish
2024-09-17 13:34:57,786 Waiting for running processes to finish
2024-09-17 13:34:57,887 Waiting for running processes to finish
2024-09-17 13:34:57,987 Waiting for running processes to finish
2024-09-17 13:34:58,088 Waiting for running processes to finish
2024-09-17 13:34:58,189 Waiting for running processes to finish
2024-09-17 13:34:58,290 Waiting for running processes to finish
2024-09-17 13:34:58,391 Waiting for running processes to finish
2024-09-17 13:34:58,491 Waiting for running processes to finish
2024-09-17 13:34:58,675 Waiting for running processes to finish
2024-09-17 13:34:58,775 Waiting for running processes to finish
2024-09-17 13:34:58,876 Waiting for running processes to finish
2024-09-17 13:34:58,977 Waiting for running processes to finish
2024-09-17 13:34:59,078 Waiting for running processes to finish
2024-09-17 13:34:59,178 Waiting for running processes to finish
2024-09-17 13:34:59,279 Waiting for running processes to finish
2024-09-17 13:34:59,380 Waiting for running processes to finish
2024-09-17 13:34:59,481 Waiting for running processes to finish
2024-09-17 13:34:59,581 Waiting for running processes to finish
2024-09-17 13:34:59,682 Waiting for running processes to finish
2024-09-17 13:34:59,783 Waiting for running processes to finish
2024-09-17 13:34:59,883 Waiting for running processes to finish
2024-09-17 13:34:59,980 Loaded model granite-7b
2024-09-17 13:34:59,983 Batch processing started for model granite-7b
2024-09-17 13:34:59,984 Waiting for running processes to finish
2024-09-17 13:35:00,085 Waiting for running processes to finish
2024-09-17 13:35:00,186 Waiting for running processes to finish
2024-09-17 13:35:00,287 Waiting for running processes to finish
2024-09-17 13:35:00,387 Waiting for running processes to finish
2024-09-17 13:35:00,488 Waiting for running processes to finish
2024-09-17 13:35:00,589 Waiting for running processes to finish
2024-09-17 13:35:00,690 Waiting for running processes to finish
2024-09-17 13:35:00,790 Waiting for running processes to finish
2024-09-17 13:35:00,891 Waiting for running processes to finish
2024-09-17 13:35:00,992 Waiting for running processes to finish
2024-09-17 13:35:01,093 Waiting for running processes to finish
2024-09-17 13:35:01,193 Waiting for running processes to finish
2024-09-17 13:35:01,294 Waiting for running processes to finish
2024-09-17 13:35:01,395 Waiting for running processes to finish
2024-09-17 13:35:01,496 Waiting for running processes to finish
2024-09-17 13:35:01,568 Processed batch: ['42a8f117'] with model granite-7b in 1.5845 seconds
2024-09-17 13:35:01,568 Saving sys info
2024-09-17 13:35:01,596 Waiting for running processes to finish
2024-09-17 13:35:01,598 Latency for request 42a8f117 with model granite-7b: 21.5903 seconds
2024-09-17 13:35:01,598 Saving results with gpu monitoring
2024-09-17 13:35:01,599 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 502, in inference
    completed_inference_ids = process_batch(model_alias, "Batch size", max(allowed_batch_sizes))
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 284, in process_batch
    save_measurements_and_monitor(request_id, model_alias, current_batch_size, latency, batch_throughput, sys_info)
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 172, in save_measurements_and_monitor
    df = pd.DataFrame([datadf0])
NameError: name 'datadf0' is not defined
2024-09-17 13:35:01,599 Next: call load_model for gemma-7b
2024-09-17 13:35:01,599 127.0.0.1 - - [17/Sep/2024 13:35:01] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-17 13:35:01,600 Unloaded previous model
2024-09-17 13:35:02,056 Waiting for running processes to finish
2024-09-17 13:35:02,231 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 390, in inference
    total_time = last_batch_processed_time - first_request_time
NameError: name 'last_batch_processed_time' is not defined
2024-09-17 13:35:02,235 127.0.0.1 - - [17/Sep/2024 13:35:02] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-17 13:35:22,311 Loaded model gemma-7b
2024-09-17 13:35:22,314 Batch processing started for model gemma-7b
2024-09-17 13:35:24,116 Processed batch: ['8f49f30f'] with model gemma-7b in 1.8016 seconds
2024-09-17 13:35:24,116 Saving sys info
2024-09-17 13:35:24,150 Latency for request 8f49f30f with model gemma-7b: 41.0499 seconds
2024-09-17 13:35:24,150 Saving results with gpu monitoring
2024-09-17 13:35:24,151 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 502, in inference
    completed_inference_ids = process_batch(model_alias, "Batch size", max(allowed_batch_sizes))
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 284, in process_batch
    save_measurements_and_monitor(request_id, model_alias, current_batch_size, latency, batch_throughput, sys_info)
  File "/home/amartinezi/sincere/api_scheduler_experiments.py", line 172, in save_measurements_and_monitor
    df = pd.DataFrame([datadf0])
NameError: name 'datadf0' is not defined
2024-09-17 13:35:24,151 No batch to process for model granite-7b
2024-09-17 13:35:24,152 127.0.0.1 - - [17/Sep/2024 13:35:24] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-17 13:35:24,153 127.0.0.1 - - [17/Sep/2024 13:35:24] "POST /inference HTTP/1.1" 200 -
2024-09-17 13:35:24,153 No batch to process for model llama3-8b
2024-09-17 13:35:24,155 127.0.0.1 - - [17/Sep/2024 13:35:24] "POST /inference HTTP/1.1" 200 -
2024-09-17 13:35:24,155 No batch to process for model llama3-8b
2024-09-17 13:35:24,155 127.0.0.1 - - [17/Sep/2024 13:35:24] "POST /inference HTTP/1.1" 200 -
2024-09-17 13:35:24,156 No batch to process for model granite-7b
2024-09-17 13:35:24,156 127.0.0.1 - - [17/Sep/2024 13:35:24] "POST /inference HTTP/1.1" 200 -
2024-09-17 13:35:24,156 No batch to process for model granite-7b
2024-09-17 13:35:24,157 127.0.0.1 - - [17/Sep/2024 13:35:24] "POST /inference HTTP/1.1" 200 -
2024-09-17 13:35:24,157 No batch to process for model gemma-7b
2024-09-17 13:35:24,159 127.0.0.1 - - [17/Sep/2024 13:35:24] "POST /inference HTTP/1.1" 200 -
2024-09-17 13:35:24,159 No batch to process for model llama3-8b
2024-09-17 13:35:24,160 127.0.0.1 - - [17/Sep/2024 13:35:24] "POST /inference HTTP/1.1" 200 -
2024-09-17 13:35:24,161 No batch to process for model gemma-7b
2024-09-17 13:35:24,162 127.0.0.1 - - [17/Sep/2024 13:35:24] "POST /inference HTTP/1.1" 200 -
