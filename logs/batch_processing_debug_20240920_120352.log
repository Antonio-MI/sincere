2024-09-20 12:03:52,136 Using device: cuda
2024-09-20 12:03:52,136 Scheduling mode set as BestBatch+SLA
2024-09-20 12:03:52,140 Monitoring status set to True
2024-09-20 12:04:07,214 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.122.143:5000
2024-09-20 12:04:07,214 [33mPress CTRL+C to quit[0m
2024-09-20 12:04:33,917 Request with ID 7a7a10da for model gemma-7b received
2024-09-20 12:04:33,918 Adjusted batch time limit for gemma-7b: 5.0000 seconds
2024-09-20 12:04:33,918 127.0.0.1 - - [20/Sep/2024 12:04:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:34,205 Request with ID f3caa952 for model llama3-8b received
2024-09-20 12:04:34,205 Adjusted batch time limit for llama3-8b: 5.0000 seconds
2024-09-20 12:04:34,205 127.0.0.1 - - [20/Sep/2024 12:04:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:34,227 Request with ID b1bc9658 for model llama3-8b received
2024-09-20 12:04:34,228 127.0.0.1 - - [20/Sep/2024 12:04:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:34,414 Request with ID 9721a5bb for model granite-7b received
2024-09-20 12:04:34,415 Adjusted batch time limit for granite-7b: 5.0000 seconds
2024-09-20 12:04:34,415 127.0.0.1 - - [20/Sep/2024 12:04:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:35,119 Request with ID 9915641b for model llama3-8b received
2024-09-20 12:04:35,121 127.0.0.1 - - [20/Sep/2024 12:04:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:35,121 Request with ID c43f8e31 for model gemma-7b received
2024-09-20 12:04:35,122 127.0.0.1 - - [20/Sep/2024 12:04:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:35,194 Request with ID cc9b157b for model granite-7b received
2024-09-20 12:04:35,195 127.0.0.1 - - [20/Sep/2024 12:04:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:35,199 Request with ID a4f267ca for model llama3-8b received
2024-09-20 12:04:35,199 127.0.0.1 - - [20/Sep/2024 12:04:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:35,230 Request with ID 4e8ffc0a for model gemma-7b received
2024-09-20 12:04:35,230 127.0.0.1 - - [20/Sep/2024 12:04:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:35,250 Request with ID ebb13f99 for model gemma-7b received
2024-09-20 12:04:35,251 127.0.0.1 - - [20/Sep/2024 12:04:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:36,071 Request with ID 234ce3ee for model granite-7b received
2024-09-20 12:04:36,071 127.0.0.1 - - [20/Sep/2024 12:04:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:36,260 Request with ID 64d30e6d for model llama3-8b received
2024-09-20 12:04:36,261 127.0.0.1 - - [20/Sep/2024 12:04:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:36,264 Request with ID 66174ccf for model llama3-8b received
2024-09-20 12:04:36,264 127.0.0.1 - - [20/Sep/2024 12:04:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:36,597 Request with ID 10cec3c6 for model gemma-7b received
2024-09-20 12:04:36,598 127.0.0.1 - - [20/Sep/2024 12:04:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:36,829 Request with ID 46e17574 for model granite-7b received
2024-09-20 12:04:36,829 127.0.0.1 - - [20/Sep/2024 12:04:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:37,312 Request with ID 0658ffcf for model gemma-7b received
2024-09-20 12:04:37,313 127.0.0.1 - - [20/Sep/2024 12:04:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:37,596 Request with ID fe31301c for model llama3-8b received
2024-09-20 12:04:37,596 127.0.0.1 - - [20/Sep/2024 12:04:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:37,756 Request with ID f997f33c for model llama3-8b received
2024-09-20 12:04:37,756 127.0.0.1 - - [20/Sep/2024 12:04:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:38,056 Request with ID 67cc437f for model gemma-7b received
2024-09-20 12:04:38,057 127.0.0.1 - - [20/Sep/2024 12:04:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:38,581 Request with ID 777f85b9 for model gemma-7b received
2024-09-20 12:04:38,581 127.0.0.1 - - [20/Sep/2024 12:04:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:38,752 Request with ID 18c2c308 for model granite-7b received
2024-09-20 12:04:38,752 127.0.0.1 - - [20/Sep/2024 12:04:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:38,832 Request with ID 832ddbf0 for model llama3-8b received
2024-09-20 12:04:38,832 127.0.0.1 - - [20/Sep/2024 12:04:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:39,010 Request with ID a8d36ea8 for model llama3-8b received
2024-09-20 12:04:39,010 127.0.0.1 - - [20/Sep/2024 12:04:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:39,076 Request with ID 2f3791ae for model llama3-8b received
2024-09-20 12:04:39,076 127.0.0.1 - - [20/Sep/2024 12:04:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:39,091 Request with ID bba54955 for model gemma-7b received
2024-09-20 12:04:39,091 127.0.0.1 - - [20/Sep/2024 12:04:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:39,163 Request with ID 644ff4a0 for model gemma-7b received
2024-09-20 12:04:39,164 127.0.0.1 - - [20/Sep/2024 12:04:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:39,413 Request with ID 38dab3de for model llama3-8b received
2024-09-20 12:04:39,414 127.0.0.1 - - [20/Sep/2024 12:04:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:39,429 Request with ID edea1d38 for model llama3-8b received
2024-09-20 12:04:39,429 127.0.0.1 - - [20/Sep/2024 12:04:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:39,812 Request with ID 1fefb234 for model gemma-7b received
2024-09-20 12:04:39,812 127.0.0.1 - - [20/Sep/2024 12:04:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:39,825 Request with ID 19ad2a62 for model llama3-8b received
2024-09-20 12:04:39,825 127.0.0.1 - - [20/Sep/2024 12:04:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:40,007 Request with ID ff6fd4c4 for model llama3-8b received
2024-09-20 12:04:40,007 127.0.0.1 - - [20/Sep/2024 12:04:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:40,032 Request with ID d98b35db for model llama3-8b received
2024-09-20 12:04:40,033 127.0.0.1 - - [20/Sep/2024 12:04:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:40,291 Request with ID 09f50b49 for model llama3-8b received
2024-09-20 12:04:40,292 127.0.0.1 - - [20/Sep/2024 12:04:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:40,430 Request with ID 2b61761b for model llama3-8b received
2024-09-20 12:04:40,430 127.0.0.1 - - [20/Sep/2024 12:04:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:40,453 Request with ID e5f715e2 for model gemma-7b received
2024-09-20 12:04:40,454 127.0.0.1 - - [20/Sep/2024 12:04:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:40,908 Request with ID dd42ca36 for model llama3-8b received
2024-09-20 12:04:40,909 127.0.0.1 - - [20/Sep/2024 12:04:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:41,148 Request with ID bd13d0a9 for model llama3-8b received
2024-09-20 12:04:41,148 127.0.0.1 - - [20/Sep/2024 12:04:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:41,201 Request with ID 680c1f64 for model llama3-8b received
2024-09-20 12:04:41,201 127.0.0.1 - - [20/Sep/2024 12:04:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:41,441 Request with ID b46d980b for model llama3-8b received
2024-09-20 12:04:41,442 127.0.0.1 - - [20/Sep/2024 12:04:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:41,773 Request with ID 649d3a94 for model llama3-8b received
2024-09-20 12:04:41,774 127.0.0.1 - - [20/Sep/2024 12:04:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:41,816 Request with ID d4c589a4 for model llama3-8b received
2024-09-20 12:04:41,816 127.0.0.1 - - [20/Sep/2024 12:04:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:42,147 Request with ID bc2a8b68 for model gemma-7b received
2024-09-20 12:04:42,148 127.0.0.1 - - [20/Sep/2024 12:04:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:42,172 Request with ID 9a6fb215 for model llama3-8b received
2024-09-20 12:04:42,173 Request with ID d6dc295a for model llama3-8b received
2024-09-20 12:04:42,174 127.0.0.1 - - [20/Sep/2024 12:04:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:42,175 127.0.0.1 - - [20/Sep/2024 12:04:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:42,176 Request with ID a4afcfb3 for model llama3-8b received
2024-09-20 12:04:42,177 127.0.0.1 - - [20/Sep/2024 12:04:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:42,310 Request with ID 372682e3 for model gemma-7b received
2024-09-20 12:04:42,310 127.0.0.1 - - [20/Sep/2024 12:04:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:42,885 Request with ID b1ffe8bf for model llama3-8b received
2024-09-20 12:04:42,886 127.0.0.1 - - [20/Sep/2024 12:04:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:42,990 Request with ID 8603dc3e for model llama3-8b received
2024-09-20 12:04:42,991 127.0.0.1 - - [20/Sep/2024 12:04:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:43,649 Request with ID 6f425364 for model gemma-7b received
2024-09-20 12:04:43,650 127.0.0.1 - - [20/Sep/2024 12:04:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:43,657 Request with ID 3456113a for model llama3-8b received
2024-09-20 12:04:43,658 127.0.0.1 - - [20/Sep/2024 12:04:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:43,766 Request with ID 18c11159 for model gemma-7b received
2024-09-20 12:04:43,767 127.0.0.1 - - [20/Sep/2024 12:04:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:44,247 Request with ID ab8f80d0 for model gemma-7b received
2024-09-20 12:04:44,247 127.0.0.1 - - [20/Sep/2024 12:04:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:44,383 Request with ID 0ca55167 for model llama3-8b received
2024-09-20 12:04:44,383 127.0.0.1 - - [20/Sep/2024 12:04:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:44,564 Request with ID 0663fe9a for model gemma-7b received
2024-09-20 12:04:44,564 127.0.0.1 - - [20/Sep/2024 12:04:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:44,622 Request with ID 6c7c0911 for model gemma-7b received
2024-09-20 12:04:44,622 127.0.0.1 - - [20/Sep/2024 12:04:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:44,824 Request with ID 82e4cbc0 for model gemma-7b received
2024-09-20 12:04:44,824 127.0.0.1 - - [20/Sep/2024 12:04:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:45,165 Request with ID 1a4d0ac7 for model gemma-7b received
2024-09-20 12:04:45,166 127.0.0.1 - - [20/Sep/2024 12:04:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:45,308 Request with ID f1bede67 for model llama3-8b received
2024-09-20 12:04:45,309 127.0.0.1 - - [20/Sep/2024 12:04:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:45,537 Request with ID c7030e75 for model llama3-8b received
2024-09-20 12:04:45,537 127.0.0.1 - - [20/Sep/2024 12:04:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:45,589 Request with ID a96de3ea for model gemma-7b received
2024-09-20 12:04:45,590 127.0.0.1 - - [20/Sep/2024 12:04:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:45,826 Request with ID 0e8746b6 for model llama3-8b received
2024-09-20 12:04:45,827 127.0.0.1 - - [20/Sep/2024 12:04:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:46,192 Request with ID b9ac6da2 for model gemma-7b received
2024-09-20 12:04:46,192 127.0.0.1 - - [20/Sep/2024 12:04:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:46,217 Request with ID bb3b92dd for model llama3-8b received
2024-09-20 12:04:46,218 127.0.0.1 - - [20/Sep/2024 12:04:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:46,279 Request with ID b7f94039 for model gemma-7b received
2024-09-20 12:04:46,279 127.0.0.1 - - [20/Sep/2024 12:04:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:47,087 Request with ID 53c6c0c8 for model gemma-7b received
2024-09-20 12:04:47,087 127.0.0.1 - - [20/Sep/2024 12:04:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:47,107 Request with ID 45769f54 for model llama3-8b received
2024-09-20 12:04:47,107 127.0.0.1 - - [20/Sep/2024 12:04:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:47,310 Request with ID d269bd56 for model gemma-7b received
2024-09-20 12:04:47,310 127.0.0.1 - - [20/Sep/2024 12:04:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:47,554 Request with ID d6d9a2da for model llama3-8b received
2024-09-20 12:04:47,555 127.0.0.1 - - [20/Sep/2024 12:04:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:47,659 Request with ID 9cbf8fc4 for model llama3-8b received
2024-09-20 12:04:47,660 127.0.0.1 - - [20/Sep/2024 12:04:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:47,677 Request with ID 76c92e31 for model llama3-8b received
2024-09-20 12:04:47,678 127.0.0.1 - - [20/Sep/2024 12:04:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:47,865 Request with ID 9b57651e for model llama3-8b received
2024-09-20 12:04:47,866 127.0.0.1 - - [20/Sep/2024 12:04:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:47,868 Request with ID 45d8c7ed for model gemma-7b received
2024-09-20 12:04:47,868 127.0.0.1 - - [20/Sep/2024 12:04:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:48,002 Request with ID a996a5a4 for model gemma-7b received
2024-09-20 12:04:48,003 127.0.0.1 - - [20/Sep/2024 12:04:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:48,253 Request with ID fd6711f6 for model gemma-7b received
2024-09-20 12:04:48,254 127.0.0.1 - - [20/Sep/2024 12:04:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:48,529 Request with ID 11830d14 for model llama3-8b received
2024-09-20 12:04:48,530 127.0.0.1 - - [20/Sep/2024 12:04:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:48,787 Request with ID f06b87a1 for model llama3-8b received
2024-09-20 12:04:48,787 127.0.0.1 - - [20/Sep/2024 12:04:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:48,807 Request with ID f0eaad33 for model gemma-7b received
2024-09-20 12:04:48,807 127.0.0.1 - - [20/Sep/2024 12:04:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:48,865 Request with ID 75e36732 for model llama3-8b received
2024-09-20 12:04:48,865 127.0.0.1 - - [20/Sep/2024 12:04:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:49,000 Request with ID 37ad4596 for model llama3-8b received
2024-09-20 12:04:49,000 127.0.0.1 - - [20/Sep/2024 12:04:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:49,318 Request with ID 667843be for model llama3-8b received
2024-09-20 12:04:49,318 127.0.0.1 - - [20/Sep/2024 12:04:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:49,541 Request with ID e913b3d3 for model gemma-7b received
2024-09-20 12:04:49,542 127.0.0.1 - - [20/Sep/2024 12:04:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:49,799 Request with ID 5d14664b for model llama3-8b received
2024-09-20 12:04:49,800 127.0.0.1 - - [20/Sep/2024 12:04:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:50,094 Request with ID 5dc55fd2 for model llama3-8b received
2024-09-20 12:04:50,094 127.0.0.1 - - [20/Sep/2024 12:04:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:50,223 Request with ID 62c187ad for model llama3-8b received
2024-09-20 12:04:50,223 127.0.0.1 - - [20/Sep/2024 12:04:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:50,317 Request with ID 9428f128 for model llama3-8b received
2024-09-20 12:04:50,317 127.0.0.1 - - [20/Sep/2024 12:04:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:50,399 Request with ID 03d04171 for model llama3-8b received
2024-09-20 12:04:50,399 127.0.0.1 - - [20/Sep/2024 12:04:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:51,064 Request with ID 8190246f for model granite-7b received
2024-09-20 12:04:51,065 127.0.0.1 - - [20/Sep/2024 12:04:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:51,138 Request with ID bdce83d5 for model gemma-7b received
2024-09-20 12:04:51,138 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-20 12:04:51,138 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:04:51,138 Next: call load_model for gemma-7b
2024-09-20 12:04:51,680 Request with ID db2623e9 for model llama3-8b received
2024-09-20 12:04:51,681 127.0.0.1 - - [20/Sep/2024 12:04:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:51,867 Request with ID 66318514 for model llama3-8b received
2024-09-20 12:04:51,868 127.0.0.1 - - [20/Sep/2024 12:04:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:51,946 Request with ID dce9a30d for model llama3-8b received
2024-09-20 12:04:51,947 127.0.0.1 - - [20/Sep/2024 12:04:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:52,766 Request with ID 2360f515 for model gemma-7b received
2024-09-20 12:04:52,767 127.0.0.1 - - [20/Sep/2024 12:04:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:52,845 Request with ID d2c21462 for model gemma-7b received
2024-09-20 12:04:52,846 127.0.0.1 - - [20/Sep/2024 12:04:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:52,916 Request with ID 2718bf8f for model llama3-8b received
2024-09-20 12:04:52,916 127.0.0.1 - - [20/Sep/2024 12:04:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:53,321 Request with ID 0caa7f72 for model granite-7b received
2024-09-20 12:04:53,322 Request with ID 69ab4990 for model llama3-8b received
2024-09-20 12:04:53,323 127.0.0.1 - - [20/Sep/2024 12:04:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:53,323 127.0.0.1 - - [20/Sep/2024 12:04:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:53,535 Request with ID 0e3fa546 for model granite-7b received
2024-09-20 12:04:53,535 Moving batch for granite-7b from incoming to running due to dynamic batch size 8
2024-09-20 12:04:53,535 Dynamic batch size condition met for model granite-7b
2024-09-20 12:04:53,972 Request with ID e305c319 for model gemma-7b received
2024-09-20 12:04:53,973 127.0.0.1 - - [20/Sep/2024 12:04:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:53,992 Request with ID 46d40868 for model granite-7b received
2024-09-20 12:04:53,992 127.0.0.1 - - [20/Sep/2024 12:04:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:54,120 Request with ID 763a30d3 for model llama3-8b received
2024-09-20 12:04:54,120 127.0.0.1 - - [20/Sep/2024 12:04:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:54,487 Request with ID 5a240c30 for model granite-7b received
2024-09-20 12:04:54,488 127.0.0.1 - - [20/Sep/2024 12:04:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:54,561 Request with ID ef5f687e for model gemma-7b received
2024-09-20 12:04:54,562 127.0.0.1 - - [20/Sep/2024 12:04:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:54,758 Request with ID 04eb024d for model llama3-8b received
2024-09-20 12:04:54,759 127.0.0.1 - - [20/Sep/2024 12:04:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:54,950 Request with ID df710745 for model llama3-8b received
2024-09-20 12:04:54,951 127.0.0.1 - - [20/Sep/2024 12:04:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:54,952 Request with ID 190c9572 for model llama3-8b received
2024-09-20 12:04:54,953 127.0.0.1 - - [20/Sep/2024 12:04:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:55,087 Request with ID 40d37816 for model llama3-8b received
2024-09-20 12:04:55,087 127.0.0.1 - - [20/Sep/2024 12:04:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:55,151 Request with ID 332f6245 for model granite-7b received
2024-09-20 12:04:55,152 127.0.0.1 - - [20/Sep/2024 12:04:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:55,157 Request with ID 0627f07e for model granite-7b received
2024-09-20 12:04:55,158 127.0.0.1 - - [20/Sep/2024 12:04:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:55,271 Request with ID 6ed07e7c for model llama3-8b received
2024-09-20 12:04:55,272 127.0.0.1 - - [20/Sep/2024 12:04:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:55,311 Request with ID 542c3de3 for model llama3-8b received
2024-09-20 12:04:55,311 127.0.0.1 - - [20/Sep/2024 12:04:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:55,368 Request with ID a13bab91 for model llama3-8b received
2024-09-20 12:04:55,369 127.0.0.1 - - [20/Sep/2024 12:04:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:55,586 Request with ID 135a62c4 for model llama3-8b received
2024-09-20 12:04:55,587 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:04:55,587 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:04:55,858 Request with ID f4779fca for model llama3-8b received
2024-09-20 12:04:55,858 127.0.0.1 - - [20/Sep/2024 12:04:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:56,121 Request with ID 1b5fefcd for model gemma-7b received
2024-09-20 12:04:56,121 127.0.0.1 - - [20/Sep/2024 12:04:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:56,406 Request with ID ec99e8c7 for model granite-7b received
2024-09-20 12:04:56,407 127.0.0.1 - - [20/Sep/2024 12:04:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:56,415 Request with ID 1e65aa3b for model llama3-8b received
2024-09-20 12:04:56,416 127.0.0.1 - - [20/Sep/2024 12:04:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:56,456 Request with ID e4861a65 for model gemma-7b received
2024-09-20 12:04:56,457 127.0.0.1 - - [20/Sep/2024 12:04:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:56,583 Request with ID 78d8ffd5 for model gemma-7b received
2024-09-20 12:04:56,584 127.0.0.1 - - [20/Sep/2024 12:04:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:56,823 Request with ID 645d14b2 for model llama3-8b received
2024-09-20 12:04:56,824 127.0.0.1 - - [20/Sep/2024 12:04:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:56,994 Request with ID 36bb84fb for model llama3-8b received
2024-09-20 12:04:56,995 127.0.0.1 - - [20/Sep/2024 12:04:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:57,573 Request with ID 96f45e6f for model llama3-8b received
2024-09-20 12:04:57,573 127.0.0.1 - - [20/Sep/2024 12:04:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:57,777 Request with ID 69814848 for model llama3-8b received
2024-09-20 12:04:57,777 127.0.0.1 - - [20/Sep/2024 12:04:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:57,877 Request with ID 12c63e4c for model llama3-8b received
2024-09-20 12:04:57,878 127.0.0.1 - - [20/Sep/2024 12:04:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:58,036 Request with ID 969cf549 for model llama3-8b received
2024-09-20 12:04:58,037 127.0.0.1 - - [20/Sep/2024 12:04:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:58,382 Request with ID f931454f for model llama3-8b received
2024-09-20 12:04:58,383 127.0.0.1 - - [20/Sep/2024 12:04:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:58,426 Request with ID b115de11 for model gemma-7b received
2024-09-20 12:04:58,427 127.0.0.1 - - [20/Sep/2024 12:04:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:58,430 Request with ID b534e2b3 for model llama3-8b received
2024-09-20 12:04:58,431 127.0.0.1 - - [20/Sep/2024 12:04:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:58,448 Request with ID 77cf6ec9 for model gemma-7b received
2024-09-20 12:04:58,449 127.0.0.1 - - [20/Sep/2024 12:04:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:58,791 Request with ID 2fd4d9c3 for model gemma-7b received
2024-09-20 12:04:58,792 127.0.0.1 - - [20/Sep/2024 12:04:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:58,817 Request with ID ad3d6acd for model llama3-8b received
2024-09-20 12:04:58,818 127.0.0.1 - - [20/Sep/2024 12:04:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:59,018 Request with ID dc6435cc for model granite-7b received
2024-09-20 12:04:59,019 127.0.0.1 - - [20/Sep/2024 12:04:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:59,128 Request with ID e9e74c65 for model gemma-7b received
2024-09-20 12:04:59,129 127.0.0.1 - - [20/Sep/2024 12:04:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:59,408 Request with ID baef77d9 for model llama3-8b received
2024-09-20 12:04:59,408 127.0.0.1 - - [20/Sep/2024 12:04:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:04:59,502 Request with ID 5666ee4c for model gemma-7b received
2024-09-20 12:04:59,502 127.0.0.1 - - [20/Sep/2024 12:04:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:00,039 Request with ID 10c31fa1 for model gemma-7b received
2024-09-20 12:05:00,039 127.0.0.1 - - [20/Sep/2024 12:05:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:00,268 Request with ID 0e49aa6f for model gemma-7b received
2024-09-20 12:05:00,268 127.0.0.1 - - [20/Sep/2024 12:05:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:00,422 Request with ID b29ed074 for model llama3-8b received
2024-09-20 12:05:00,423 127.0.0.1 - - [20/Sep/2024 12:05:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:00,501 Request with ID cd790160 for model granite-7b received
2024-09-20 12:05:00,502 127.0.0.1 - - [20/Sep/2024 12:05:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:00,513 Request with ID 8891747b for model gemma-7b received
2024-09-20 12:05:00,513 127.0.0.1 - - [20/Sep/2024 12:05:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:01,144 Request with ID d511fb13 for model llama3-8b received
2024-09-20 12:05:01,144 127.0.0.1 - - [20/Sep/2024 12:05:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:01,161 Request with ID a50bd981 for model gemma-7b received
2024-09-20 12:05:01,162 127.0.0.1 - - [20/Sep/2024 12:05:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:01,387 Request with ID 7b0fc89b for model llama3-8b received
2024-09-20 12:05:01,388 127.0.0.1 - - [20/Sep/2024 12:05:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:01,407 Request with ID 4bd5a9fa for model llama3-8b received
2024-09-20 12:05:01,407 127.0.0.1 - - [20/Sep/2024 12:05:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:02,512 Request with ID 003a92dc for model llama3-8b received
2024-09-20 12:05:02,512 127.0.0.1 - - [20/Sep/2024 12:05:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:02,951 Request with ID 7f8ca695 for model llama3-8b received
2024-09-20 12:05:02,952 127.0.0.1 - - [20/Sep/2024 12:05:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:03,646 Request with ID 7574ace6 for model llama3-8b received
2024-09-20 12:05:03,647 127.0.0.1 - - [20/Sep/2024 12:05:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:03,669 Request with ID 6ca6379b for model llama3-8b received
2024-09-20 12:05:03,670 127.0.0.1 - - [20/Sep/2024 12:05:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:03,721 Request with ID d94ff35d for model llama3-8b received
2024-09-20 12:05:03,721 127.0.0.1 - - [20/Sep/2024 12:05:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:03,968 Request with ID 50517e67 for model llama3-8b received
2024-09-20 12:05:03,969 127.0.0.1 - - [20/Sep/2024 12:05:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:04,022 Request with ID bc5d685b for model llama3-8b received
2024-09-20 12:05:04,023 127.0.0.1 - - [20/Sep/2024 12:05:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:04,450 Request with ID 108c26a6 for model llama3-8b received
2024-09-20 12:05:04,450 127.0.0.1 - - [20/Sep/2024 12:05:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:05,306 Request with ID 3a0a177b for model gemma-7b received
2024-09-20 12:05:05,306 127.0.0.1 - - [20/Sep/2024 12:05:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:05,554 Request with ID df429a82 for model llama3-8b received
2024-09-20 12:05:05,555 127.0.0.1 - - [20/Sep/2024 12:05:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:05,720 Request with ID 1a79ac94 for model gemma-7b received
2024-09-20 12:05:05,720 127.0.0.1 - - [20/Sep/2024 12:05:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:05,801 Request with ID 61ef750b for model granite-7b received
2024-09-20 12:05:05,801 Moving batch for granite-7b from incoming to running due to dynamic batch size 8
2024-09-20 12:05:05,801 Dynamic batch size condition met for model granite-7b
2024-09-20 12:05:05,930 Request with ID 2aae10d2 for model llama3-8b received
2024-09-20 12:05:05,930 127.0.0.1 - - [20/Sep/2024 12:05:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:06,224 Request with ID 1645ec34 for model llama3-8b received
2024-09-20 12:05:06,225 127.0.0.1 - - [20/Sep/2024 12:05:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:06,500 Request with ID adc57fa7 for model gemma-7b received
2024-09-20 12:05:06,501 127.0.0.1 - - [20/Sep/2024 12:05:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:06,604 Request with ID 900cfaef for model gemma-7b received
2024-09-20 12:05:06,605 127.0.0.1 - - [20/Sep/2024 12:05:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:07,011 Request with ID 0fe2c931 for model llama3-8b received
2024-09-20 12:05:07,012 127.0.0.1 - - [20/Sep/2024 12:05:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:07,090 Loaded model gemma-7b
2024-09-20 12:05:07,092 Batch processing started for model gemma-7b
2024-09-20 12:05:07,338 Request with ID 586812cc for model llama3-8b received
2024-09-20 12:05:07,339 127.0.0.1 - - [20/Sep/2024 12:05:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:07,347 Request with ID 9770e06f for model granite-7b received
2024-09-20 12:05:07,349 127.0.0.1 - - [20/Sep/2024 12:05:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:07,867 Request with ID 338a0413 for model gemma-7b received
2024-09-20 12:05:07,868 127.0.0.1 - - [20/Sep/2024 12:05:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:08,106 Request with ID bb7fb45e for model llama3-8b received
2024-09-20 12:05:08,107 127.0.0.1 - - [20/Sep/2024 12:05:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:08,347 Request with ID 45d2b9c5 for model llama3-8b received
2024-09-20 12:05:08,347 127.0.0.1 - - [20/Sep/2024 12:05:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:08,446 Request with ID 0f58c859 for model granite-7b received
2024-09-20 12:05:08,446 127.0.0.1 - - [20/Sep/2024 12:05:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:08,513 Request with ID b9242057 for model gemma-7b received
2024-09-20 12:05:08,514 127.0.0.1 - - [20/Sep/2024 12:05:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:08,537 Request with ID 9a6feb24 for model gemma-7b received
2024-09-20 12:05:08,537 127.0.0.1 - - [20/Sep/2024 12:05:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:08,581 Request with ID b2e9edee for model gemma-7b received
2024-09-20 12:05:08,581 127.0.0.1 - - [20/Sep/2024 12:05:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:08,634 Request with ID 4af39bcd for model granite-7b received
2024-09-20 12:05:08,634 127.0.0.1 - - [20/Sep/2024 12:05:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:09,370 Request with ID c8df27fe for model llama3-8b received
2024-09-20 12:05:09,370 127.0.0.1 - - [20/Sep/2024 12:05:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:09,525 Request with ID 92643110 for model llama3-8b received
2024-09-20 12:05:09,525 127.0.0.1 - - [20/Sep/2024 12:05:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:09,711 Request with ID 0a118fcb for model gemma-7b received
2024-09-20 12:05:09,712 127.0.0.1 - - [20/Sep/2024 12:05:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:09,727 Request with ID d73bd857 for model llama3-8b received
2024-09-20 12:05:09,727 127.0.0.1 - - [20/Sep/2024 12:05:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:09,988 Request with ID b2155358 for model llama3-8b received
2024-09-20 12:05:09,989 127.0.0.1 - - [20/Sep/2024 12:05:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:10,006 Request with ID 359a6c4e for model llama3-8b received
2024-09-20 12:05:10,007 127.0.0.1 - - [20/Sep/2024 12:05:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:10,016 Request with ID 754003cd for model gemma-7b received
2024-09-20 12:05:10,017 127.0.0.1 - - [20/Sep/2024 12:05:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:10,353 Request with ID e791202e for model llama3-8b received
2024-09-20 12:05:10,353 127.0.0.1 - - [20/Sep/2024 12:05:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:10,449 Request with ID 66b90efe for model gemma-7b received
2024-09-20 12:05:10,449 127.0.0.1 - - [20/Sep/2024 12:05:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:10,805 Request with ID 7c7eebb3 for model llama3-8b received
2024-09-20 12:05:10,806 127.0.0.1 - - [20/Sep/2024 12:05:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:10,934 Request with ID 0b49b47a for model gemma-7b received
2024-09-20 12:05:10,934 127.0.0.1 - - [20/Sep/2024 12:05:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:10,945 Request with ID d47ae27b for model llama3-8b received
2024-09-20 12:05:10,945 127.0.0.1 - - [20/Sep/2024 12:05:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:11,101 Request with ID c35c8231 for model llama3-8b received
2024-09-20 12:05:11,101 127.0.0.1 - - [20/Sep/2024 12:05:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:11,270 Request with ID a0ddff84 for model llama3-8b received
2024-09-20 12:05:11,289 Processed batch: ['7a7a10da', 'c43f8e31', '4e8ffc0a', 'ebb13f99', '10cec3c6', '0658ffcf', '67cc437f', '777f85b9', 'bba54955', '644ff4a0', '1fefb234', 'e5f715e2', 'bc2a8b68', '372682e3', '6f425364', '18c11159', 'ab8f80d0', '0663fe9a', '6c7c0911', '82e4cbc0', '1a4d0ac7', 'a96de3ea', 'b9ac6da2', 'b7f94039', '53c6c0c8', 'd269bd56', '45d8c7ed', 'a996a5a4', 'fd6711f6', 'f0eaad33', 'e913b3d3', 'bdce83d5'] with model gemma-7b in 4.1964 seconds
2024-09-20 12:05:11,289 127.0.0.1 - - [20/Sep/2024 12:05:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:11,289 Saving sys info
2024-09-20 12:05:11,322 Request with ID d0d51e79 for model gemma-7b received
2024-09-20 12:05:11,323 127.0.0.1 - - [20/Sep/2024 12:05:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:11,330 Latency for request 7a7a10da with model gemma-7b: 37.3710 seconds
2024-09-20 12:05:11,330 Saving results with gpu monitoring
2024-09-20 12:05:11,334 Latency for request c43f8e31 with model gemma-7b: 36.1680 seconds
2024-09-20 12:05:11,334 Saving results with gpu monitoring
2024-09-20 12:05:11,336 Latency for request 4e8ffc0a with model gemma-7b: 36.0590 seconds
2024-09-20 12:05:11,337 Saving results with gpu monitoring
2024-09-20 12:05:11,339 Latency for request ebb13f99 with model gemma-7b: 36.0380 seconds
2024-09-20 12:05:11,339 Saving results with gpu monitoring
2024-09-20 12:05:11,341 Latency for request 10cec3c6 with model gemma-7b: 34.6920 seconds
2024-09-20 12:05:11,341 Saving results with gpu monitoring
2024-09-20 12:05:11,343 Latency for request 0658ffcf with model gemma-7b: 33.9770 seconds
2024-09-20 12:05:11,343 Saving results with gpu monitoring
2024-09-20 12:05:11,345 Latency for request 67cc437f with model gemma-7b: 33.2330 seconds
2024-09-20 12:05:11,345 Saving results with gpu monitoring
2024-09-20 12:05:11,347 Latency for request 777f85b9 with model gemma-7b: 32.7080 seconds
2024-09-20 12:05:11,347 Saving results with gpu monitoring
2024-09-20 12:05:11,349 Latency for request bba54955 with model gemma-7b: 32.1980 seconds
2024-09-20 12:05:11,349 Saving results with gpu monitoring
2024-09-20 12:05:11,351 Latency for request 644ff4a0 with model gemma-7b: 32.1250 seconds
2024-09-20 12:05:11,351 Saving results with gpu monitoring
2024-09-20 12:05:11,353 Latency for request 1fefb234 with model gemma-7b: 31.4770 seconds
2024-09-20 12:05:11,353 Saving results with gpu monitoring
2024-09-20 12:05:11,355 Latency for request e5f715e2 with model gemma-7b: 30.8360 seconds
2024-09-20 12:05:11,355 Saving results with gpu monitoring
2024-09-20 12:05:11,357 Latency for request bc2a8b68 with model gemma-7b: 29.1420 seconds
2024-09-20 12:05:11,357 Saving results with gpu monitoring
2024-09-20 12:05:11,359 Latency for request 372682e3 with model gemma-7b: 28.9790 seconds
2024-09-20 12:05:11,359 Saving results with gpu monitoring
2024-09-20 12:05:11,361 Latency for request 6f425364 with model gemma-7b: 27.6400 seconds
2024-09-20 12:05:11,361 Saving results with gpu monitoring
2024-09-20 12:05:11,363 Latency for request 18c11159 with model gemma-7b: 27.5230 seconds
2024-09-20 12:05:11,363 Saving results with gpu monitoring
2024-09-20 12:05:11,365 Latency for request ab8f80d0 with model gemma-7b: 27.0420 seconds
2024-09-20 12:05:11,365 Saving results with gpu monitoring
2024-09-20 12:05:11,367 Latency for request 0663fe9a with model gemma-7b: 26.7250 seconds
2024-09-20 12:05:11,367 Saving results with gpu monitoring
2024-09-20 12:05:11,369 Latency for request 6c7c0911 with model gemma-7b: 26.6670 seconds
2024-09-20 12:05:11,369 Saving results with gpu monitoring
2024-09-20 12:05:11,371 Latency for request 82e4cbc0 with model gemma-7b: 26.4650 seconds
2024-09-20 12:05:11,371 Saving results with gpu monitoring
2024-09-20 12:05:11,373 Latency for request 1a4d0ac7 with model gemma-7b: 26.1240 seconds
2024-09-20 12:05:11,373 Saving results with gpu monitoring
2024-09-20 12:05:11,375 Latency for request a96de3ea with model gemma-7b: 25.7000 seconds
2024-09-20 12:05:11,375 Saving results with gpu monitoring
2024-09-20 12:05:11,376 Latency for request b9ac6da2 with model gemma-7b: 25.0970 seconds
2024-09-20 12:05:11,377 Saving results with gpu monitoring
2024-09-20 12:05:11,378 Latency for request b7f94039 with model gemma-7b: 25.0100 seconds
2024-09-20 12:05:11,378 Saving results with gpu monitoring
2024-09-20 12:05:11,380 Latency for request 53c6c0c8 with model gemma-7b: 24.2020 seconds
2024-09-20 12:05:11,380 Saving results with gpu monitoring
2024-09-20 12:05:11,382 Latency for request d269bd56 with model gemma-7b: 23.9790 seconds
2024-09-20 12:05:11,382 Saving results with gpu monitoring
2024-09-20 12:05:11,384 Latency for request 45d8c7ed with model gemma-7b: 23.4210 seconds
2024-09-20 12:05:11,384 Saving results with gpu monitoring
2024-09-20 12:05:11,386 Latency for request a996a5a4 with model gemma-7b: 23.2870 seconds
2024-09-20 12:05:11,386 Saving results with gpu monitoring
2024-09-20 12:05:11,388 Latency for request fd6711f6 with model gemma-7b: 23.0360 seconds
2024-09-20 12:05:11,388 Saving results with gpu monitoring
2024-09-20 12:05:11,391 Latency for request f0eaad33 with model gemma-7b: 22.4820 seconds
2024-09-20 12:05:11,391 Saving results with gpu monitoring
2024-09-20 12:05:11,393 Latency for request e913b3d3 with model gemma-7b: 21.7480 seconds
2024-09-20 12:05:11,393 Saving results with gpu monitoring
2024-09-20 12:05:11,395 Latency for request bdce83d5 with model gemma-7b: 20.1510 seconds
2024-09-20 12:05:11,395 Saving results with gpu monitoring
2024-09-20 12:05:11,398 127.0.0.1 - - [20/Sep/2024 12:05:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:11,398 Next: call load_model for granite-7b
2024-09-20 12:05:11,400 Request with ID 12e7b06b for model llama3-8b received
2024-09-20 12:05:11,400 127.0.0.1 - - [20/Sep/2024 12:05:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:11,512 Unloaded previous model
2024-09-20 12:05:11,683 Request with ID 56a8e968 for model gemma-7b received
2024-09-20 12:05:11,690 Adjusted batch time limit for gemma-7b: 5.0000 seconds
2024-09-20 12:05:11,690 127.0.0.1 - - [20/Sep/2024 12:05:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:11,708 Request with ID cfe21175 for model llama3-8b received
2024-09-20 12:05:11,711 127.0.0.1 - - [20/Sep/2024 12:05:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:12,012 Request with ID f291a2f9 for model llama3-8b received
2024-09-20 12:05:12,016 127.0.0.1 - - [20/Sep/2024 12:05:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:12,710 Request with ID b8bf78c8 for model llama3-8b received
2024-09-20 12:05:12,711 127.0.0.1 - - [20/Sep/2024 12:05:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:12,738 Request with ID 4d281559 for model llama3-8b received
2024-09-20 12:05:12,746 127.0.0.1 - - [20/Sep/2024 12:05:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:12,972 Request with ID 7f895a9b for model llama3-8b received
2024-09-20 12:05:12,978 127.0.0.1 - - [20/Sep/2024 12:05:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:13,246 Request with ID a85a0d37 for model llama3-8b received
2024-09-20 12:05:13,246 127.0.0.1 - - [20/Sep/2024 12:05:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:13,277 Request with ID c01347b0 for model llama3-8b received
2024-09-20 12:05:13,277 127.0.0.1 - - [20/Sep/2024 12:05:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:13,432 Request with ID 08797f0d for model gemma-7b received
2024-09-20 12:05:13,433 127.0.0.1 - - [20/Sep/2024 12:05:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:13,615 Request with ID 1b1c81e2 for model llama3-8b received
2024-09-20 12:05:13,616 127.0.0.1 - - [20/Sep/2024 12:05:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:13,648 Request with ID d00beacf for model llama3-8b received
2024-09-20 12:05:13,648 127.0.0.1 - - [20/Sep/2024 12:05:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:13,662 Request with ID c8989215 for model llama3-8b received
2024-09-20 12:05:13,663 127.0.0.1 - - [20/Sep/2024 12:05:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:13,800 Request with ID 46336033 for model gemma-7b received
2024-09-20 12:05:13,801 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-20 12:05:13,801 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:05:13,975 Request with ID 0e278016 for model llama3-8b received
2024-09-20 12:05:13,976 127.0.0.1 - - [20/Sep/2024 12:05:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:14,100 Request with ID f41cb99b for model llama3-8b received
2024-09-20 12:05:14,100 127.0.0.1 - - [20/Sep/2024 12:05:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:14,342 Request with ID 6d997652 for model gemma-7b received
2024-09-20 12:05:14,342 127.0.0.1 - - [20/Sep/2024 12:05:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:14,428 Request with ID 4f621c5e for model llama3-8b received
2024-09-20 12:05:14,429 127.0.0.1 - - [20/Sep/2024 12:05:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:14,649 Request with ID 6ca2896f for model llama3-8b received
2024-09-20 12:05:14,650 127.0.0.1 - - [20/Sep/2024 12:05:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:14,701 Request with ID 3e51f1dc for model gemma-7b received
2024-09-20 12:05:14,702 127.0.0.1 - - [20/Sep/2024 12:05:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:14,788 Request with ID 8d3b4254 for model llama3-8b received
2024-09-20 12:05:14,788 127.0.0.1 - - [20/Sep/2024 12:05:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:14,944 Request with ID eb541330 for model gemma-7b received
2024-09-20 12:05:14,945 127.0.0.1 - - [20/Sep/2024 12:05:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:15,035 Request with ID 0a33412e for model gemma-7b received
2024-09-20 12:05:15,036 127.0.0.1 - - [20/Sep/2024 12:05:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:15,114 Request with ID ec332e2e for model llama3-8b received
2024-09-20 12:05:15,115 127.0.0.1 - - [20/Sep/2024 12:05:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:15,132 Request with ID 0c76091f for model llama3-8b received
2024-09-20 12:05:15,133 127.0.0.1 - - [20/Sep/2024 12:05:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:15,144 Request with ID 44ccf60c for model llama3-8b received
2024-09-20 12:05:15,145 127.0.0.1 - - [20/Sep/2024 12:05:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:15,164 Request with ID 94a5b6c1 for model gemma-7b received
2024-09-20 12:05:15,165 127.0.0.1 - - [20/Sep/2024 12:05:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:15,213 Request with ID 6e4bce33 for model llama3-8b received
2024-09-20 12:05:15,213 127.0.0.1 - - [20/Sep/2024 12:05:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:15,267 Request with ID 49784de9 for model gemma-7b received
2024-09-20 12:05:15,268 127.0.0.1 - - [20/Sep/2024 12:05:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:15,393 Request with ID d4958579 for model granite-7b received
2024-09-20 12:05:15,394 127.0.0.1 - - [20/Sep/2024 12:05:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:15,426 Request with ID 214f583e for model llama3-8b received
2024-09-20 12:05:15,427 127.0.0.1 - - [20/Sep/2024 12:05:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:15,880 Request with ID d4fdc2fd for model granite-7b received
2024-09-20 12:05:15,881 127.0.0.1 - - [20/Sep/2024 12:05:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:16,286 Request with ID bfbe5348 for model gemma-7b received
2024-09-20 12:05:16,286 127.0.0.1 - - [20/Sep/2024 12:05:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:16,350 Request with ID 3d17f84d for model gemma-7b received
2024-09-20 12:05:16,351 127.0.0.1 - - [20/Sep/2024 12:05:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:16,518 Request with ID bb36e2f0 for model gemma-7b received
2024-09-20 12:05:16,519 127.0.0.1 - - [20/Sep/2024 12:05:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:16,599 Request with ID aff551a3 for model llama3-8b received
2024-09-20 12:05:16,600 127.0.0.1 - - [20/Sep/2024 12:05:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:16,783 Request with ID 6ba236c3 for model gemma-7b received
2024-09-20 12:05:16,784 127.0.0.1 - - [20/Sep/2024 12:05:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:17,138 Request with ID c8a47786 for model granite-7b received
2024-09-20 12:05:17,138 127.0.0.1 - - [20/Sep/2024 12:05:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:17,148 Request with ID af7d8858 for model llama3-8b received
2024-09-20 12:05:17,148 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:05:17,149 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:05:17,327 Request with ID 46adca1f for model llama3-8b received
2024-09-20 12:05:17,327 127.0.0.1 - - [20/Sep/2024 12:05:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:17,515 Request with ID 0de85439 for model llama3-8b received
2024-09-20 12:05:17,516 127.0.0.1 - - [20/Sep/2024 12:05:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:17,596 Request with ID 8a319646 for model granite-7b received
2024-09-20 12:05:17,596 127.0.0.1 - - [20/Sep/2024 12:05:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:17,648 Request with ID be89e9fa for model gemma-7b received
2024-09-20 12:05:17,649 127.0.0.1 - - [20/Sep/2024 12:05:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:17,684 Request with ID 5afa0d1d for model granite-7b received
2024-09-20 12:05:17,684 Moving batch for granite-7b from incoming to running due to dynamic batch size 8
2024-09-20 12:05:17,684 Dynamic batch size condition met for model granite-7b
2024-09-20 12:05:18,057 Request with ID 34aabb56 for model granite-7b received
2024-09-20 12:05:18,058 127.0.0.1 - - [20/Sep/2024 12:05:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:18,297 Request with ID 60f20dd3 for model gemma-7b received
2024-09-20 12:05:18,297 127.0.0.1 - - [20/Sep/2024 12:05:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:18,400 Request with ID 38e13b6b for model llama3-8b received
2024-09-20 12:05:18,400 127.0.0.1 - - [20/Sep/2024 12:05:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:18,402 Request with ID 43f09170 for model gemma-7b received
2024-09-20 12:05:18,403 127.0.0.1 - - [20/Sep/2024 12:05:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:18,440 Request with ID 4128da7e for model llama3-8b received
2024-09-20 12:05:18,441 127.0.0.1 - - [20/Sep/2024 12:05:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:18,696 Request with ID 9bd9adf8 for model llama3-8b received
2024-09-20 12:05:18,697 127.0.0.1 - - [20/Sep/2024 12:05:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:19,063 Request with ID 0be67930 for model gemma-7b received
2024-09-20 12:05:19,063 127.0.0.1 - - [20/Sep/2024 12:05:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:19,143 Request with ID 1cd15c83 for model gemma-7b received
2024-09-20 12:05:19,144 127.0.0.1 - - [20/Sep/2024 12:05:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:19,410 Request with ID ac0ad1e8 for model llama3-8b received
2024-09-20 12:05:19,411 127.0.0.1 - - [20/Sep/2024 12:05:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:19,705 Request with ID f5e9a52a for model llama3-8b received
2024-09-20 12:05:19,705 127.0.0.1 - - [20/Sep/2024 12:05:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:19,739 Request with ID 4adc6c86 for model llama3-8b received
2024-09-20 12:05:19,739 127.0.0.1 - - [20/Sep/2024 12:05:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:19,834 Request with ID e0ae379e for model gemma-7b received
2024-09-20 12:05:19,834 127.0.0.1 - - [20/Sep/2024 12:05:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:19,849 Request with ID c50b5ee5 for model llama3-8b received
2024-09-20 12:05:19,849 127.0.0.1 - - [20/Sep/2024 12:05:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:19,867 Request with ID 34428fe8 for model llama3-8b received
2024-09-20 12:05:19,867 127.0.0.1 - - [20/Sep/2024 12:05:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:20,240 Request with ID 979bda8e for model llama3-8b received
2024-09-20 12:05:20,240 127.0.0.1 - - [20/Sep/2024 12:05:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:20,343 Request with ID 155d22de for model llama3-8b received
2024-09-20 12:05:20,344 127.0.0.1 - - [20/Sep/2024 12:05:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:20,701 Request with ID b3d89934 for model llama3-8b received
2024-09-20 12:05:20,701 127.0.0.1 - - [20/Sep/2024 12:05:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:21,245 Request with ID a1f4e283 for model gemma-7b received
2024-09-20 12:05:21,247 127.0.0.1 - - [20/Sep/2024 12:05:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:21,340 Request with ID 230ee88b for model llama3-8b received
2024-09-20 12:05:21,341 127.0.0.1 - - [20/Sep/2024 12:05:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:21,350 Request with ID e4d0d961 for model gemma-7b received
2024-09-20 12:05:21,350 127.0.0.1 - - [20/Sep/2024 12:05:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:21,670 Request with ID 20f314ce for model gemma-7b received
2024-09-20 12:05:21,670 127.0.0.1 - - [20/Sep/2024 12:05:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:21,706 Request with ID 53bae645 for model gemma-7b received
2024-09-20 12:05:21,706 127.0.0.1 - - [20/Sep/2024 12:05:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:21,909 Request with ID f57cab38 for model gemma-7b received
2024-09-20 12:05:21,909 127.0.0.1 - - [20/Sep/2024 12:05:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:22,089 Request with ID 356f9320 for model llama3-8b received
2024-09-20 12:05:22,089 127.0.0.1 - - [20/Sep/2024 12:05:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:22,186 Request with ID 04ae97ff for model llama3-8b received
2024-09-20 12:05:22,186 127.0.0.1 - - [20/Sep/2024 12:05:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:22,327 Request with ID e43913fc for model gemma-7b received
2024-09-20 12:05:22,327 127.0.0.1 - - [20/Sep/2024 12:05:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:22,481 Request with ID 369a8ec2 for model llama3-8b received
2024-09-20 12:05:22,482 127.0.0.1 - - [20/Sep/2024 12:05:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:22,678 Request with ID 7065492e for model llama3-8b received
2024-09-20 12:05:22,678 127.0.0.1 - - [20/Sep/2024 12:05:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:22,760 Request with ID ed6c153f for model gemma-7b received
2024-09-20 12:05:22,760 127.0.0.1 - - [20/Sep/2024 12:05:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:22,791 Request with ID a3a9fca4 for model llama3-8b received
2024-09-20 12:05:22,791 127.0.0.1 - - [20/Sep/2024 12:05:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:22,946 Request with ID cc1e1e7d for model llama3-8b received
2024-09-20 12:05:22,946 127.0.0.1 - - [20/Sep/2024 12:05:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:24,163 Request with ID 98878602 for model llama3-8b received
2024-09-20 12:05:24,164 127.0.0.1 - - [20/Sep/2024 12:05:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:24,467 Request with ID 6e2fddd3 for model gemma-7b received
2024-09-20 12:05:24,467 127.0.0.1 - - [20/Sep/2024 12:05:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:24,720 Request with ID fb90f84b for model llama3-8b received
2024-09-20 12:05:24,721 127.0.0.1 - - [20/Sep/2024 12:05:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:24,805 Request with ID 27f9d291 for model gemma-7b received
2024-09-20 12:05:24,806 127.0.0.1 - - [20/Sep/2024 12:05:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:25,181 Request with ID bd9b4c4e for model llama3-8b received
2024-09-20 12:05:25,181 127.0.0.1 - - [20/Sep/2024 12:05:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:25,214 Request with ID 47f706ec for model llama3-8b received
2024-09-20 12:05:25,214 127.0.0.1 - - [20/Sep/2024 12:05:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:25,512 Request with ID d744831a for model llama3-8b received
2024-09-20 12:05:25,512 127.0.0.1 - - [20/Sep/2024 12:05:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:25,680 Request with ID 866f4eef for model gemma-7b received
2024-09-20 12:05:25,680 127.0.0.1 - - [20/Sep/2024 12:05:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:25,767 Request with ID 33e80148 for model llama3-8b received
2024-09-20 12:05:25,767 127.0.0.1 - - [20/Sep/2024 12:05:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:25,852 Request with ID 2a8030c4 for model llama3-8b received
2024-09-20 12:05:25,852 127.0.0.1 - - [20/Sep/2024 12:05:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:25,921 Request with ID edd48e69 for model gemma-7b received
2024-09-20 12:05:25,922 127.0.0.1 - - [20/Sep/2024 12:05:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:26,100 Request with ID 010523be for model gemma-7b received
2024-09-20 12:05:26,100 127.0.0.1 - - [20/Sep/2024 12:05:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:26,361 Request with ID d413bbd7 for model llama3-8b received
2024-09-20 12:05:26,361 127.0.0.1 - - [20/Sep/2024 12:05:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:26,675 Request with ID fcb9ef71 for model llama3-8b received
2024-09-20 12:05:26,675 127.0.0.1 - - [20/Sep/2024 12:05:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:26,972 Request with ID 4790a282 for model llama3-8b received
2024-09-20 12:05:26,973 127.0.0.1 - - [20/Sep/2024 12:05:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:27,241 Request with ID 35fd7aa6 for model gemma-7b received
2024-09-20 12:05:27,241 127.0.0.1 - - [20/Sep/2024 12:05:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:27,296 Request with ID 955d1316 for model gemma-7b received
2024-09-20 12:05:27,297 127.0.0.1 - - [20/Sep/2024 12:05:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:27,661 Request with ID ea0359c5 for model gemma-7b received
2024-09-20 12:05:27,661 127.0.0.1 - - [20/Sep/2024 12:05:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:27,713 Request with ID e11859f4 for model gemma-7b received
2024-09-20 12:05:27,714 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-20 12:05:27,714 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:05:27,725 Request with ID 752fd26d for model llama3-8b received
2024-09-20 12:05:27,726 127.0.0.1 - - [20/Sep/2024 12:05:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:27,728 Request with ID 667e61f0 for model gemma-7b received
2024-09-20 12:05:27,729 127.0.0.1 - - [20/Sep/2024 12:05:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:27,835 Request with ID b16a8660 for model llama3-8b received
2024-09-20 12:05:27,836 127.0.0.1 - - [20/Sep/2024 12:05:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:27,922 Request with ID 2f462ff5 for model llama3-8b received
2024-09-20 12:05:27,923 127.0.0.1 - - [20/Sep/2024 12:05:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:28,043 Request with ID 33144740 for model granite-7b received
2024-09-20 12:05:28,044 127.0.0.1 - - [20/Sep/2024 12:05:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:28,533 Request with ID a5e23005 for model gemma-7b received
2024-09-20 12:05:28,533 127.0.0.1 - - [20/Sep/2024 12:05:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:28,673 Request with ID f0cbea27 for model granite-7b received
2024-09-20 12:05:28,673 127.0.0.1 - - [20/Sep/2024 12:05:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:28,750 Request with ID 206de113 for model llama3-8b received
2024-09-20 12:05:28,751 127.0.0.1 - - [20/Sep/2024 12:05:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:28,953 Request with ID 28c2ffce for model llama3-8b received
2024-09-20 12:05:28,954 127.0.0.1 - - [20/Sep/2024 12:05:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:29,696 Request with ID 46c56cf0 for model llama3-8b received
2024-09-20 12:05:29,697 127.0.0.1 - - [20/Sep/2024 12:05:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:30,093 Request with ID f4f6152d for model llama3-8b received
2024-09-20 12:05:30,093 127.0.0.1 - - [20/Sep/2024 12:05:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:30,234 Request with ID fd56a50e for model gemma-7b received
2024-09-20 12:05:30,234 127.0.0.1 - - [20/Sep/2024 12:05:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:30,337 Request with ID 66d9fbb8 for model llama3-8b received
2024-09-20 12:05:30,337 127.0.0.1 - - [20/Sep/2024 12:05:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:30,383 Request with ID ed20982c for model gemma-7b received
2024-09-20 12:05:30,384 127.0.0.1 - - [20/Sep/2024 12:05:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:30,748 Request with ID 9caf677f for model gemma-7b received
2024-09-20 12:05:30,749 127.0.0.1 - - [20/Sep/2024 12:05:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:31,059 Loaded model granite-7b
2024-09-20 12:05:31,061 Request with ID 8d7f7ff8 for model llama3-8b received
2024-09-20 12:05:31,062 127.0.0.1 - - [20/Sep/2024 12:05:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:31,066 Batch processing started for model granite-7b
2024-09-20 12:05:31,133 Request with ID 45ad7fbf for model llama3-8b received
2024-09-20 12:05:31,134 127.0.0.1 - - [20/Sep/2024 12:05:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:31,156 Request with ID d9fb0249 for model llama3-8b received
2024-09-20 12:05:31,156 127.0.0.1 - - [20/Sep/2024 12:05:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:31,252 Request with ID a1c1ac05 for model llama3-8b received
2024-09-20 12:05:31,253 127.0.0.1 - - [20/Sep/2024 12:05:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:31,403 Request with ID 1f23a0bf for model llama3-8b received
2024-09-20 12:05:31,404 127.0.0.1 - - [20/Sep/2024 12:05:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:31,772 Request with ID 1ea53b7b for model llama3-8b received
2024-09-20 12:05:31,772 127.0.0.1 - - [20/Sep/2024 12:05:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:31,831 Request with ID aa791a9e for model llama3-8b received
2024-09-20 12:05:31,832 127.0.0.1 - - [20/Sep/2024 12:05:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:31,836 Request with ID 4d81ea82 for model granite-7b received
2024-09-20 12:05:31,836 127.0.0.1 - - [20/Sep/2024 12:05:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:31,894 Request with ID ec7f985f for model llama3-8b received
2024-09-20 12:05:31,895 127.0.0.1 - - [20/Sep/2024 12:05:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:32,252 Request with ID 7aab94f9 for model llama3-8b received
2024-09-20 12:05:32,252 127.0.0.1 - - [20/Sep/2024 12:05:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:32,283 Request with ID 14c5d2ff for model gemma-7b received
2024-09-20 12:05:32,283 127.0.0.1 - - [20/Sep/2024 12:05:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:32,739 Request with ID d4ed2794 for model llama3-8b received
2024-09-20 12:05:32,740 127.0.0.1 - - [20/Sep/2024 12:05:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:33,008 Request with ID 87d73960 for model gemma-7b received
2024-09-20 12:05:33,008 127.0.0.1 - - [20/Sep/2024 12:05:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:33,132 Processed batch: ['46d40868', '5a240c30', '332f6245', '0627f07e', 'ec99e8c7', 'dc6435cc', 'cd790160', '61ef750b'] with model granite-7b in 2.0658 seconds
2024-09-20 12:05:33,132 Saving sys info
2024-09-20 12:05:33,164 Latency for request 46d40868 with model granite-7b: 39.1400 seconds
2024-09-20 12:05:33,164 Saving results with gpu monitoring
2024-09-20 12:05:33,166 Latency for request 5a240c30 with model granite-7b: 38.6450 seconds
2024-09-20 12:05:33,166 Saving results with gpu monitoring
2024-09-20 12:05:33,168 Latency for request 332f6245 with model granite-7b: 37.9810 seconds
2024-09-20 12:05:33,168 Saving results with gpu monitoring
2024-09-20 12:05:33,170 Latency for request 0627f07e with model granite-7b: 37.9750 seconds
2024-09-20 12:05:33,170 Saving results with gpu monitoring
2024-09-20 12:05:33,172 Latency for request ec99e8c7 with model granite-7b: 36.7260 seconds
2024-09-20 12:05:33,172 Saving results with gpu monitoring
2024-09-20 12:05:33,174 Latency for request dc6435cc with model granite-7b: 34.1140 seconds
2024-09-20 12:05:33,174 Saving results with gpu monitoring
2024-09-20 12:05:33,176 Latency for request cd790160 with model granite-7b: 32.6310 seconds
2024-09-20 12:05:33,176 Saving results with gpu monitoring
2024-09-20 12:05:33,178 Latency for request 61ef750b with model granite-7b: 27.3310 seconds
2024-09-20 12:05:33,178 Saving results with gpu monitoring
2024-09-20 12:05:33,181 127.0.0.1 - - [20/Sep/2024 12:05:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:33,181 Next: call load_model for llama3-8b
2024-09-20 12:05:33,265 Unloaded previous model
2024-09-20 12:05:33,492 Request with ID 51d92cb6 for model llama3-8b received
2024-09-20 12:05:33,493 127.0.0.1 - - [20/Sep/2024 12:05:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:33,882 Request with ID afae692f for model gemma-7b received
2024-09-20 12:05:33,889 127.0.0.1 - - [20/Sep/2024 12:05:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:34,287 Request with ID 9ea9a83f for model llama3-8b received
2024-09-20 12:05:34,289 127.0.0.1 - - [20/Sep/2024 12:05:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:34,300 Request with ID 9ca59e3f for model llama3-8b received
2024-09-20 12:05:34,303 127.0.0.1 - - [20/Sep/2024 12:05:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:34,471 Request with ID a5376f19 for model gemma-7b received
2024-09-20 12:05:34,472 127.0.0.1 - - [20/Sep/2024 12:05:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:35,048 Request with ID 3ba675eb for model gemma-7b received
2024-09-20 12:05:35,049 127.0.0.1 - - [20/Sep/2024 12:05:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:35,454 Request with ID 9ba81a32 for model llama3-8b received
2024-09-20 12:05:35,455 127.0.0.1 - - [20/Sep/2024 12:05:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:35,779 Request with ID b5d12888 for model llama3-8b received
2024-09-20 12:05:35,780 127.0.0.1 - - [20/Sep/2024 12:05:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:35,981 Request with ID e6e0d36c for model llama3-8b received
2024-09-20 12:05:35,981 127.0.0.1 - - [20/Sep/2024 12:05:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:36,092 Request with ID 0f8f90d8 for model llama3-8b received
2024-09-20 12:05:36,093 127.0.0.1 - - [20/Sep/2024 12:05:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:36,329 Request with ID 039ef071 for model granite-7b received
2024-09-20 12:05:36,329 Adjusted batch time limit for granite-7b: 5.0000 seconds
2024-09-20 12:05:36,329 127.0.0.1 - - [20/Sep/2024 12:05:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:36,822 Request with ID 882e3947 for model llama3-8b received
2024-09-20 12:05:36,822 127.0.0.1 - - [20/Sep/2024 12:05:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:36,889 Request with ID 47a62096 for model llama3-8b received
2024-09-20 12:05:36,890 127.0.0.1 - - [20/Sep/2024 12:05:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:37,246 Request with ID 1ba2162d for model gemma-7b received
2024-09-20 12:05:37,246 127.0.0.1 - - [20/Sep/2024 12:05:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:37,276 Request with ID be310644 for model llama3-8b received
2024-09-20 12:05:37,276 127.0.0.1 - - [20/Sep/2024 12:05:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:37,693 Request with ID 4094c23f for model gemma-7b received
2024-09-20 12:05:37,694 127.0.0.1 - - [20/Sep/2024 12:05:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:37,995 Request with ID fb386388 for model llama3-8b received
2024-09-20 12:05:37,996 127.0.0.1 - - [20/Sep/2024 12:05:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:38,262 Request with ID d7ca5843 for model llama3-8b received
2024-09-20 12:05:38,262 127.0.0.1 - - [20/Sep/2024 12:05:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:38,271 Request with ID 7a994599 for model llama3-8b received
2024-09-20 12:05:38,271 127.0.0.1 - - [20/Sep/2024 12:05:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:38,290 Request with ID bbe83319 for model gemma-7b received
2024-09-20 12:05:38,291 127.0.0.1 - - [20/Sep/2024 12:05:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:38,390 Request with ID 97f5788e for model llama3-8b received
2024-09-20 12:05:38,391 127.0.0.1 - - [20/Sep/2024 12:05:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:38,887 Request with ID c767cdd6 for model gemma-7b received
2024-09-20 12:05:38,887 127.0.0.1 - - [20/Sep/2024 12:05:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:39,056 Request with ID 84e0da99 for model gemma-7b received
2024-09-20 12:05:39,057 127.0.0.1 - - [20/Sep/2024 12:05:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:39,674 Request with ID 8a25a8b0 for model llama3-8b received
2024-09-20 12:05:39,675 127.0.0.1 - - [20/Sep/2024 12:05:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:39,724 Request with ID 60bb394f for model gemma-7b received
2024-09-20 12:05:39,725 127.0.0.1 - - [20/Sep/2024 12:05:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:39,907 Request with ID b447035f for model gemma-7b received
2024-09-20 12:05:39,908 127.0.0.1 - - [20/Sep/2024 12:05:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:40,104 Request with ID 83bc173d for model gemma-7b received
2024-09-20 12:05:40,105 127.0.0.1 - - [20/Sep/2024 12:05:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:40,192 Request with ID 0880b183 for model llama3-8b received
2024-09-20 12:05:40,193 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:05:40,193 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:05:40,427 Request with ID 6f5f7116 for model llama3-8b received
2024-09-20 12:05:40,428 127.0.0.1 - - [20/Sep/2024 12:05:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:40,443 Request with ID 1949aee2 for model granite-7b received
2024-09-20 12:05:40,443 127.0.0.1 - - [20/Sep/2024 12:05:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:41,133 Request with ID 00ceded2 for model llama3-8b received
2024-09-20 12:05:41,134 127.0.0.1 - - [20/Sep/2024 12:05:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:41,224 Request with ID e30ca79b for model llama3-8b received
2024-09-20 12:05:41,225 127.0.0.1 - - [20/Sep/2024 12:05:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:41,344 Request with ID 3bb5525c for model llama3-8b received
2024-09-20 12:05:41,345 127.0.0.1 - - [20/Sep/2024 12:05:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:41,759 Request with ID c2169c42 for model llama3-8b received
2024-09-20 12:05:41,760 127.0.0.1 - - [20/Sep/2024 12:05:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:42,045 Request with ID 370cabc3 for model llama3-8b received
2024-09-20 12:05:42,046 127.0.0.1 - - [20/Sep/2024 12:05:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:42,426 Request with ID 10092e72 for model llama3-8b received
2024-09-20 12:05:42,426 127.0.0.1 - - [20/Sep/2024 12:05:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:42,665 Request with ID 11a3fafb for model llama3-8b received
2024-09-20 12:05:42,666 127.0.0.1 - - [20/Sep/2024 12:05:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:42,672 Request with ID 8b12d3a3 for model llama3-8b received
2024-09-20 12:05:42,673 127.0.0.1 - - [20/Sep/2024 12:05:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:44,146 Request with ID 743ec452 for model llama3-8b received
2024-09-20 12:05:44,146 127.0.0.1 - - [20/Sep/2024 12:05:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:44,641 Request with ID c6229816 for model llama3-8b received
2024-09-20 12:05:44,642 127.0.0.1 - - [20/Sep/2024 12:05:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:44,714 Request with ID 42142d54 for model llama3-8b received
2024-09-20 12:05:44,715 127.0.0.1 - - [20/Sep/2024 12:05:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:45,033 Request with ID e2164103 for model granite-7b received
2024-09-20 12:05:45,033 127.0.0.1 - - [20/Sep/2024 12:05:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:45,156 Request with ID 9bdbed13 for model llama3-8b received
2024-09-20 12:05:45,157 127.0.0.1 - - [20/Sep/2024 12:05:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:45,164 Request with ID 6a477639 for model gemma-7b received
2024-09-20 12:05:45,165 127.0.0.1 - - [20/Sep/2024 12:05:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:45,330 Request with ID a9002e00 for model llama3-8b received
2024-09-20 12:05:45,331 127.0.0.1 - - [20/Sep/2024 12:05:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:45,484 Request with ID 1d504925 for model llama3-8b received
2024-09-20 12:05:45,484 127.0.0.1 - - [20/Sep/2024 12:05:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:45,655 Request with ID 14165a72 for model llama3-8b received
2024-09-20 12:05:45,656 127.0.0.1 - - [20/Sep/2024 12:05:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:45,924 Request with ID 4cc8e4a8 for model llama3-8b received
2024-09-20 12:05:45,925 127.0.0.1 - - [20/Sep/2024 12:05:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:46,345 Request with ID 10f9075f for model llama3-8b received
2024-09-20 12:05:46,345 127.0.0.1 - - [20/Sep/2024 12:05:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:47,276 Request with ID 5f3351cb for model llama3-8b received
2024-09-20 12:05:47,276 127.0.0.1 - - [20/Sep/2024 12:05:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:47,428 Request with ID d5cfc754 for model llama3-8b received
2024-09-20 12:05:47,428 127.0.0.1 - - [20/Sep/2024 12:05:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:48,669 Request with ID 917fcaa7 for model llama3-8b received
2024-09-20 12:05:48,670 127.0.0.1 - - [20/Sep/2024 12:05:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:48,772 Request with ID 31b536a1 for model llama3-8b received
2024-09-20 12:05:48,772 127.0.0.1 - - [20/Sep/2024 12:05:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:48,948 Request with ID 78e800f6 for model llama3-8b received
2024-09-20 12:05:48,948 127.0.0.1 - - [20/Sep/2024 12:05:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:49,242 Request with ID e4b579d9 for model gemma-7b received
2024-09-20 12:05:49,243 127.0.0.1 - - [20/Sep/2024 12:05:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:49,394 Request with ID b7e30ed6 for model llama3-8b received
2024-09-20 12:05:49,394 127.0.0.1 - - [20/Sep/2024 12:05:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:49,465 Request with ID 6479ff88 for model gemma-7b received
2024-09-20 12:05:49,466 127.0.0.1 - - [20/Sep/2024 12:05:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:49,520 Request with ID 4c058eb8 for model granite-7b received
2024-09-20 12:05:49,520 Moving batch for granite-7b from incoming to running due to dynamic batch size 8
2024-09-20 12:05:49,520 Dynamic batch size condition met for model granite-7b
2024-09-20 12:05:50,497 Request with ID fcb6bbba for model gemma-7b received
2024-09-20 12:05:50,497 127.0.0.1 - - [20/Sep/2024 12:05:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:50,630 Request with ID 56122d6a for model llama3-8b received
2024-09-20 12:05:50,631 127.0.0.1 - - [20/Sep/2024 12:05:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:50,692 Request with ID bf289f0d for model llama3-8b received
2024-09-20 12:05:50,692 127.0.0.1 - - [20/Sep/2024 12:05:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:51,126 Request with ID 75511420 for model llama3-8b received
2024-09-20 12:05:51,127 127.0.0.1 - - [20/Sep/2024 12:05:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:52,033 Request with ID 9ee9a636 for model gemma-7b received
2024-09-20 12:05:52,034 127.0.0.1 - - [20/Sep/2024 12:05:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:52,609 Request with ID 4d1b2659 for model llama3-8b received
2024-09-20 12:05:52,609 127.0.0.1 - - [20/Sep/2024 12:05:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:52,755 Request with ID 1cd2996a for model gemma-7b received
2024-09-20 12:05:52,755 127.0.0.1 - - [20/Sep/2024 12:05:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:52,761 Request with ID 44bd0ca5 for model gemma-7b received
2024-09-20 12:05:52,762 127.0.0.1 - - [20/Sep/2024 12:05:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:52,775 Request with ID c3028b21 for model llama3-8b received
2024-09-20 12:05:52,776 127.0.0.1 - - [20/Sep/2024 12:05:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:53,304 Request with ID e22013bd for model llama3-8b received
2024-09-20 12:05:53,305 127.0.0.1 - - [20/Sep/2024 12:05:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:53,365 Request with ID 1080b697 for model llama3-8b received
2024-09-20 12:05:53,365 127.0.0.1 - - [20/Sep/2024 12:05:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:53,399 Request with ID 662efaa1 for model llama3-8b received
2024-09-20 12:05:53,399 Moving batch for llama3-8b from incoming to running due to dynamic batch size 32
2024-09-20 12:05:53,399 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:05:53,596 Request with ID 270d39da for model llama3-8b received
2024-09-20 12:05:53,596 127.0.0.1 - - [20/Sep/2024 12:05:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:53,778 Request with ID b0fc62fc for model llama3-8b received
2024-09-20 12:05:53,778 127.0.0.1 - - [20/Sep/2024 12:05:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:53,991 Request with ID a0c8d83b for model gemma-7b received
2024-09-20 12:05:53,991 127.0.0.1 - - [20/Sep/2024 12:05:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:53,993 Request with ID 1d52c44a for model llama3-8b received
2024-09-20 12:05:53,993 127.0.0.1 - - [20/Sep/2024 12:05:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:54,330 Request with ID 9dcc115b for model gemma-7b received
2024-09-20 12:05:54,330 127.0.0.1 - - [20/Sep/2024 12:05:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:54,870 Request with ID c503b5b3 for model granite-7b received
2024-09-20 12:05:54,871 127.0.0.1 - - [20/Sep/2024 12:05:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:54,977 Request with ID 73df0321 for model granite-7b received
2024-09-20 12:05:54,978 127.0.0.1 - - [20/Sep/2024 12:05:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:55,214 Request with ID 967ec4ab for model llama3-8b received
2024-09-20 12:05:55,215 127.0.0.1 - - [20/Sep/2024 12:05:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:55,232 Request with ID fc4e245d for model llama3-8b received
2024-09-20 12:05:55,233 127.0.0.1 - - [20/Sep/2024 12:05:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:55,250 Request with ID 11adedb7 for model granite-7b received
2024-09-20 12:05:55,250 127.0.0.1 - - [20/Sep/2024 12:05:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:55,683 Request with ID b140cd02 for model llama3-8b received
2024-09-20 12:05:55,684 127.0.0.1 - - [20/Sep/2024 12:05:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:55,879 Loaded model llama3-8b
2024-09-20 12:05:55,882 Batch processing started for model llama3-8b
2024-09-20 12:05:56,032 Request with ID 0c6c5ad6 for model llama3-8b received
2024-09-20 12:05:56,033 127.0.0.1 - - [20/Sep/2024 12:05:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:56,191 Request with ID f1777c8d for model gemma-7b received
2024-09-20 12:05:56,191 127.0.0.1 - - [20/Sep/2024 12:05:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:56,614 Request with ID f7255383 for model llama3-8b received
2024-09-20 12:05:56,614 127.0.0.1 - - [20/Sep/2024 12:05:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:57,020 Request with ID 49da7f30 for model gemma-7b received
2024-09-20 12:05:57,021 127.0.0.1 - - [20/Sep/2024 12:05:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:57,076 Request with ID 842773c0 for model llama3-8b received
2024-09-20 12:05:57,076 127.0.0.1 - - [20/Sep/2024 12:05:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:57,271 Request with ID ee21e068 for model gemma-7b received
2024-09-20 12:05:57,271 127.0.0.1 - - [20/Sep/2024 12:05:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:57,698 Request with ID 672aaaad for model llama3-8b received
2024-09-20 12:05:57,698 127.0.0.1 - - [20/Sep/2024 12:05:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:58,122 Request with ID cbab7cf1 for model gemma-7b received
2024-09-20 12:05:58,123 127.0.0.1 - - [20/Sep/2024 12:05:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:58,206 Request with ID 6a97c341 for model gemma-7b received
2024-09-20 12:05:58,206 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-20 12:05:58,206 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:05:58,548 Request with ID ebba9d87 for model llama3-8b received
2024-09-20 12:05:58,549 127.0.0.1 - - [20/Sep/2024 12:05:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:58,551 Request with ID 7f9a0094 for model granite-7b received
2024-09-20 12:05:58,551 127.0.0.1 - - [20/Sep/2024 12:05:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:58,631 Request with ID be19ce15 for model llama3-8b received
2024-09-20 12:05:58,631 127.0.0.1 - - [20/Sep/2024 12:05:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:58,692 Request with ID c5eda819 for model granite-7b received
2024-09-20 12:05:58,692 127.0.0.1 - - [20/Sep/2024 12:05:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:59,036 Request with ID e32b1dd8 for model gemma-7b received
2024-09-20 12:05:59,037 127.0.0.1 - - [20/Sep/2024 12:05:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:59,325 Request with ID d3e1ce64 for model llama3-8b received
2024-09-20 12:05:59,325 127.0.0.1 - - [20/Sep/2024 12:05:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:05:59,693 Request with ID 217f37c9 for model llama3-8b received
2024-09-20 12:05:59,693 127.0.0.1 - - [20/Sep/2024 12:05:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:00,234 Request with ID ed5adcb1 for model llama3-8b received
2024-09-20 12:06:00,234 127.0.0.1 - - [20/Sep/2024 12:06:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:00,273 Request with ID d89921bc for model granite-7b received
2024-09-20 12:06:00,273 127.0.0.1 - - [20/Sep/2024 12:06:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:00,346 Request with ID 7f92b413 for model llama3-8b received
2024-09-20 12:06:00,347 127.0.0.1 - - [20/Sep/2024 12:06:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:00,595 Request with ID c9f9fa4c for model gemma-7b received
2024-09-20 12:06:00,595 127.0.0.1 - - [20/Sep/2024 12:06:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:00,791 Request with ID b97371df for model llama3-8b received
2024-09-20 12:06:00,792 127.0.0.1 - - [20/Sep/2024 12:06:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:00,911 Request with ID f368f084 for model gemma-7b received
2024-09-20 12:06:00,912 127.0.0.1 - - [20/Sep/2024 12:06:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:01,197 Request with ID d8a63b4e for model granite-7b received
2024-09-20 12:06:01,197 127.0.0.1 - - [20/Sep/2024 12:06:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:01,543 Request with ID 8cd20758 for model llama3-8b received
2024-09-20 12:06:01,544 127.0.0.1 - - [20/Sep/2024 12:06:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:01,603 Request with ID 365bf21f for model llama3-8b received
2024-09-20 12:06:01,603 127.0.0.1 - - [20/Sep/2024 12:06:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:01,668 Request with ID 3ebd566b for model llama3-8b received
2024-09-20 12:06:01,669 127.0.0.1 - - [20/Sep/2024 12:06:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:01,790 Request with ID fc0ac90f for model llama3-8b received
2024-09-20 12:06:01,791 127.0.0.1 - - [20/Sep/2024 12:06:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:02,142 Request with ID f64c731a for model gemma-7b received
2024-09-20 12:06:02,142 127.0.0.1 - - [20/Sep/2024 12:06:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:02,159 Request with ID d81ac2b0 for model gemma-7b received
2024-09-20 12:06:02,159 127.0.0.1 - - [20/Sep/2024 12:06:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:02,190 Request with ID d4418996 for model llama3-8b received
2024-09-20 12:06:02,190 127.0.0.1 - - [20/Sep/2024 12:06:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:02,301 Request with ID 63bb34ef for model gemma-7b received
2024-09-20 12:06:02,302 127.0.0.1 - - [20/Sep/2024 12:06:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:02,367 Request with ID 421f4da2 for model gemma-7b received
2024-09-20 12:06:02,367 127.0.0.1 - - [20/Sep/2024 12:06:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:02,446 Request with ID c621072d for model gemma-7b received
2024-09-20 12:06:02,446 127.0.0.1 - - [20/Sep/2024 12:06:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:02,495 Request with ID 9c2e96de for model llama3-8b received
2024-09-20 12:06:02,495 127.0.0.1 - - [20/Sep/2024 12:06:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:02,748 Request with ID 56ef066e for model llama3-8b received
2024-09-20 12:06:02,749 127.0.0.1 - - [20/Sep/2024 12:06:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:02,878 Request with ID 71d98bf6 for model gemma-7b received
2024-09-20 12:06:02,879 127.0.0.1 - - [20/Sep/2024 12:06:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:02,924 Request with ID a6c23f22 for model llama3-8b received
2024-09-20 12:06:02,925 127.0.0.1 - - [20/Sep/2024 12:06:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:03,300 Request with ID a3e4d51d for model granite-7b received
2024-09-20 12:06:03,300 Moving batch for granite-7b from incoming to running due to dynamic batch size 8
2024-09-20 12:06:03,300 Dynamic batch size condition met for model granite-7b
2024-09-20 12:06:03,621 Request with ID e0d1363e for model granite-7b received
2024-09-20 12:06:03,621 127.0.0.1 - - [20/Sep/2024 12:06:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:04,130 Request with ID 6dd8a239 for model llama3-8b received
2024-09-20 12:06:04,130 127.0.0.1 - - [20/Sep/2024 12:06:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:04,155 Request with ID 7457739f for model gemma-7b received
2024-09-20 12:06:04,155 127.0.0.1 - - [20/Sep/2024 12:06:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:04,321 Request with ID fd3ae09c for model gemma-7b received
2024-09-20 12:06:04,321 127.0.0.1 - - [20/Sep/2024 12:06:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:04,535 Request with ID 7a2bea51 for model llama3-8b received
2024-09-20 12:06:04,535 127.0.0.1 - - [20/Sep/2024 12:06:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:04,650 Request with ID 0f75576d for model llama3-8b received
2024-09-20 12:06:04,650 127.0.0.1 - - [20/Sep/2024 12:06:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:04,652 Request with ID 37dfbe2a for model llama3-8b received
2024-09-20 12:06:04,653 127.0.0.1 - - [20/Sep/2024 12:06:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:04,756 Request with ID b7ba0c9f for model llama3-8b received
2024-09-20 12:06:04,756 127.0.0.1 - - [20/Sep/2024 12:06:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:04,972 Request with ID 46a49700 for model llama3-8b received
2024-09-20 12:06:04,972 127.0.0.1 - - [20/Sep/2024 12:06:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:05,276 Request with ID 9aeb814e for model llama3-8b received
2024-09-20 12:06:05,277 127.0.0.1 - - [20/Sep/2024 12:06:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:05,554 Request with ID 625c50e5 for model gemma-7b received
2024-09-20 12:06:05,555 127.0.0.1 - - [20/Sep/2024 12:06:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:06,419 Request with ID 93d17440 for model granite-7b received
2024-09-20 12:06:06,420 127.0.0.1 - - [20/Sep/2024 12:06:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:06,552 Request with ID c8de453c for model llama3-8b received
2024-09-20 12:06:06,552 Moving batch for llama3-8b from incoming to running due to dynamic batch size 32
2024-09-20 12:06:06,553 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:06:06,717 Request with ID 0f5c5381 for model llama3-8b received
2024-09-20 12:06:06,718 127.0.0.1 - - [20/Sep/2024 12:06:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:06,733 Request with ID 1278c166 for model gemma-7b received
2024-09-20 12:06:06,734 127.0.0.1 - - [20/Sep/2024 12:06:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:06,741 Request with ID 98a4bbf0 for model gemma-7b received
2024-09-20 12:06:06,741 127.0.0.1 - - [20/Sep/2024 12:06:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:06,821 Request with ID 6d0932c7 for model llama3-8b received
2024-09-20 12:06:06,822 127.0.0.1 - - [20/Sep/2024 12:06:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:07,001 Processed batch: ['f4779fca', '1e65aa3b', '645d14b2', '36bb84fb', '96f45e6f', '69814848', '12c63e4c', '969cf549', 'f931454f', 'b534e2b3', 'ad3d6acd', 'baef77d9', 'b29ed074', 'd511fb13', '7b0fc89b', '4bd5a9fa', '003a92dc', '7f8ca695', '7574ace6', '6ca6379b', 'd94ff35d', '50517e67', 'bc5d685b', '108c26a6', 'df429a82', '2aae10d2', '1645ec34', '0fe2c931', '586812cc', 'bb7fb45e', '45d2b9c5', 'c8df27fe', '92643110', 'd73bd857', 'b2155358', '359a6c4e', 'e791202e', '7c7eebb3', 'd47ae27b', 'c35c8231', 'a0ddff84', '12e7b06b', 'cfe21175', 'f291a2f9', 'b8bf78c8', '4d281559', '7f895a9b', 'a85a0d37', 'c01347b0', '1b1c81e2', 'd00beacf', 'c8989215', '0e278016', 'f41cb99b', '4f621c5e', '6ca2896f', '8d3b4254', 'ec332e2e', '0c76091f', '44ccf60c', '6e4bce33', '214f583e', 'aff551a3', 'af7d8858'] with model llama3-8b in 11.1182 seconds
2024-09-20 12:06:07,001 Saving sys info
2024-09-20 12:06:07,037 Latency for request f4779fca with model llama3-8b: 71.1430 seconds
2024-09-20 12:06:07,037 Saving results with gpu monitoring
2024-09-20 12:06:07,042 Latency for request 1e65aa3b with model llama3-8b: 70.5850 seconds
2024-09-20 12:06:07,042 Saving results with gpu monitoring
2024-09-20 12:06:07,044 Latency for request 645d14b2 with model llama3-8b: 70.1770 seconds
2024-09-20 12:06:07,044 Saving results with gpu monitoring
2024-09-20 12:06:07,046 Latency for request 36bb84fb with model llama3-8b: 70.0070 seconds
2024-09-20 12:06:07,046 Saving results with gpu monitoring
2024-09-20 12:06:07,048 Latency for request 96f45e6f with model llama3-8b: 69.4280 seconds
2024-09-20 12:06:07,048 Saving results with gpu monitoring
2024-09-20 12:06:07,050 Latency for request 69814848 with model llama3-8b: 69.2240 seconds
2024-09-20 12:06:07,050 Saving results with gpu monitoring
2024-09-20 12:06:07,052 Latency for request 12c63e4c with model llama3-8b: 69.1230 seconds
2024-09-20 12:06:07,052 Saving results with gpu monitoring
2024-09-20 12:06:07,054 Latency for request 969cf549 with model llama3-8b: 68.9640 seconds
2024-09-20 12:06:07,054 Saving results with gpu monitoring
2024-09-20 12:06:07,056 Latency for request f931454f with model llama3-8b: 68.6190 seconds
2024-09-20 12:06:07,056 Saving results with gpu monitoring
2024-09-20 12:06:07,058 Latency for request b534e2b3 with model llama3-8b: 68.5700 seconds
2024-09-20 12:06:07,058 Saving results with gpu monitoring
2024-09-20 12:06:07,060 Latency for request ad3d6acd with model llama3-8b: 68.1830 seconds
2024-09-20 12:06:07,060 Saving results with gpu monitoring
2024-09-20 12:06:07,062 Latency for request baef77d9 with model llama3-8b: 67.5930 seconds
2024-09-20 12:06:07,062 Saving results with gpu monitoring
2024-09-20 12:06:07,064 Latency for request b29ed074 with model llama3-8b: 66.5790 seconds
2024-09-20 12:06:07,064 Saving results with gpu monitoring
2024-09-20 12:06:07,066 Latency for request d511fb13 with model llama3-8b: 65.8570 seconds
2024-09-20 12:06:07,066 Saving results with gpu monitoring
2024-09-20 12:06:07,068 Latency for request 7b0fc89b with model llama3-8b: 65.6130 seconds
2024-09-20 12:06:07,068 Saving results with gpu monitoring
2024-09-20 12:06:07,070 Latency for request 4bd5a9fa with model llama3-8b: 65.5940 seconds
2024-09-20 12:06:07,070 Saving results with gpu monitoring
2024-09-20 12:06:07,072 Latency for request 003a92dc with model llama3-8b: 64.4890 seconds
2024-09-20 12:06:07,072 Saving results with gpu monitoring
2024-09-20 12:06:07,074 Latency for request 7f8ca695 with model llama3-8b: 64.0490 seconds
2024-09-20 12:06:07,074 Saving results with gpu monitoring
2024-09-20 12:06:07,076 Latency for request 7574ace6 with model llama3-8b: 63.3550 seconds
2024-09-20 12:06:07,076 Saving results with gpu monitoring
2024-09-20 12:06:07,078 Latency for request 6ca6379b with model llama3-8b: 63.3310 seconds
2024-09-20 12:06:07,078 Saving results with gpu monitoring
2024-09-20 12:06:07,080 Latency for request d94ff35d with model llama3-8b: 63.2800 seconds
2024-09-20 12:06:07,080 Saving results with gpu monitoring
2024-09-20 12:06:07,082 Latency for request 50517e67 with model llama3-8b: 63.0330 seconds
2024-09-20 12:06:07,082 Saving results with gpu monitoring
2024-09-20 12:06:07,084 Latency for request bc5d685b with model llama3-8b: 62.9780 seconds
2024-09-20 12:06:07,084 Saving results with gpu monitoring
2024-09-20 12:06:07,086 Latency for request 108c26a6 with model llama3-8b: 62.5510 seconds
2024-09-20 12:06:07,086 Saving results with gpu monitoring
2024-09-20 12:06:07,088 Latency for request df429a82 with model llama3-8b: 61.4460 seconds
2024-09-20 12:06:07,088 Saving results with gpu monitoring
2024-09-20 12:06:07,090 Latency for request 2aae10d2 with model llama3-8b: 61.0710 seconds
2024-09-20 12:06:07,090 Saving results with gpu monitoring
2024-09-20 12:06:07,092 Latency for request 1645ec34 with model llama3-8b: 60.7760 seconds
2024-09-20 12:06:07,092 Saving results with gpu monitoring
2024-09-20 12:06:07,094 Latency for request 0fe2c931 with model llama3-8b: 59.9890 seconds
2024-09-20 12:06:07,094 Saving results with gpu monitoring
2024-09-20 12:06:07,096 Latency for request 586812cc with model llama3-8b: 59.6630 seconds
2024-09-20 12:06:07,096 Saving results with gpu monitoring
2024-09-20 12:06:07,098 Latency for request bb7fb45e with model llama3-8b: 58.8940 seconds
2024-09-20 12:06:07,098 Saving results with gpu monitoring
2024-09-20 12:06:07,100 Latency for request 45d2b9c5 with model llama3-8b: 58.6540 seconds
2024-09-20 12:06:07,100 Saving results with gpu monitoring
2024-09-20 12:06:07,102 Latency for request c8df27fe with model llama3-8b: 57.6310 seconds
2024-09-20 12:06:07,102 Saving results with gpu monitoring
2024-09-20 12:06:07,104 Latency for request 92643110 with model llama3-8b: 57.4760 seconds
2024-09-20 12:06:07,104 Saving results with gpu monitoring
2024-09-20 12:06:07,106 Latency for request d73bd857 with model llama3-8b: 57.2740 seconds
2024-09-20 12:06:07,106 Saving results with gpu monitoring
2024-09-20 12:06:07,108 Latency for request b2155358 with model llama3-8b: 57.0120 seconds
2024-09-20 12:06:07,108 Saving results with gpu monitoring
2024-09-20 12:06:07,110 Latency for request 359a6c4e with model llama3-8b: 56.9940 seconds
2024-09-20 12:06:07,110 Saving results with gpu monitoring
2024-09-20 12:06:07,112 Latency for request e791202e with model llama3-8b: 56.6480 seconds
2024-09-20 12:06:07,112 Saving results with gpu monitoring
2024-09-20 12:06:07,114 Latency for request 7c7eebb3 with model llama3-8b: 56.1950 seconds
2024-09-20 12:06:07,114 Saving results with gpu monitoring
2024-09-20 12:06:07,116 Latency for request d47ae27b with model llama3-8b: 56.0560 seconds
2024-09-20 12:06:07,116 Saving results with gpu monitoring
2024-09-20 12:06:07,118 Latency for request c35c8231 with model llama3-8b: 55.9000 seconds
2024-09-20 12:06:07,118 Saving results with gpu monitoring
2024-09-20 12:06:07,120 Latency for request a0ddff84 with model llama3-8b: 55.7310 seconds
2024-09-20 12:06:07,120 Saving results with gpu monitoring
2024-09-20 12:06:07,122 Latency for request 12e7b06b with model llama3-8b: 55.6010 seconds
2024-09-20 12:06:07,122 Saving results with gpu monitoring
2024-09-20 12:06:07,124 Latency for request cfe21175 with model llama3-8b: 55.2930 seconds
2024-09-20 12:06:07,124 Saving results with gpu monitoring
2024-09-20 12:06:07,126 Latency for request f291a2f9 with model llama3-8b: 54.9890 seconds
2024-09-20 12:06:07,126 Saving results with gpu monitoring
2024-09-20 12:06:07,128 Latency for request b8bf78c8 with model llama3-8b: 54.2910 seconds
2024-09-20 12:06:07,128 Saving results with gpu monitoring
2024-09-20 12:06:07,130 Latency for request 4d281559 with model llama3-8b: 54.2620 seconds
2024-09-20 12:06:07,130 Saving results with gpu monitoring
2024-09-20 12:06:07,132 Latency for request 7f895a9b with model llama3-8b: 54.0280 seconds
2024-09-20 12:06:07,132 Saving results with gpu monitoring
2024-09-20 12:06:07,134 Latency for request a85a0d37 with model llama3-8b: 53.7550 seconds
2024-09-20 12:06:07,134 Saving results with gpu monitoring
2024-09-20 12:06:07,136 Latency for request c01347b0 with model llama3-8b: 53.7240 seconds
2024-09-20 12:06:07,136 Saving results with gpu monitoring
2024-09-20 12:06:07,138 Latency for request 1b1c81e2 with model llama3-8b: 53.3860 seconds
2024-09-20 12:06:07,138 Saving results with gpu monitoring
2024-09-20 12:06:07,140 Latency for request d00beacf with model llama3-8b: 53.3530 seconds
2024-09-20 12:06:07,140 Saving results with gpu monitoring
2024-09-20 12:06:07,142 Latency for request c8989215 with model llama3-8b: 53.3390 seconds
2024-09-20 12:06:07,142 Saving results with gpu monitoring
2024-09-20 12:06:07,145 Latency for request 0e278016 with model llama3-8b: 53.0260 seconds
2024-09-20 12:06:07,145 Saving results with gpu monitoring
2024-09-20 12:06:07,147 Latency for request f41cb99b with model llama3-8b: 52.9010 seconds
2024-09-20 12:06:07,147 Saving results with gpu monitoring
2024-09-20 12:06:07,150 Request with ID 235a2c5a for model gemma-7b received
2024-09-20 12:06:07,150 Latency for request 4f621c5e with model llama3-8b: 52.5730 seconds
2024-09-20 12:06:07,151 Saving results with gpu monitoring
2024-09-20 12:06:07,151 127.0.0.1 - - [20/Sep/2024 12:06:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:07,153 Latency for request 6ca2896f with model llama3-8b: 52.3510 seconds
2024-09-20 12:06:07,153 Saving results with gpu monitoring
2024-09-20 12:06:07,155 Latency for request 8d3b4254 with model llama3-8b: 52.2130 seconds
2024-09-20 12:06:07,156 Saving results with gpu monitoring
2024-09-20 12:06:07,158 Latency for request ec332e2e with model llama3-8b: 51.8870 seconds
2024-09-20 12:06:07,158 Saving results with gpu monitoring
2024-09-20 12:06:07,160 Latency for request 0c76091f with model llama3-8b: 51.8690 seconds
2024-09-20 12:06:07,160 Saving results with gpu monitoring
2024-09-20 12:06:07,162 Latency for request 44ccf60c with model llama3-8b: 51.8560 seconds
2024-09-20 12:06:07,162 Saving results with gpu monitoring
2024-09-20 12:06:07,164 Latency for request 6e4bce33 with model llama3-8b: 51.7880 seconds
2024-09-20 12:06:07,164 Saving results with gpu monitoring
2024-09-20 12:06:07,166 Latency for request 214f583e with model llama3-8b: 51.5740 seconds
2024-09-20 12:06:07,166 Saving results with gpu monitoring
2024-09-20 12:06:07,168 Latency for request aff551a3 with model llama3-8b: 50.4020 seconds
2024-09-20 12:06:07,168 Saving results with gpu monitoring
2024-09-20 12:06:07,172 Request with ID 57af8081 for model gemma-7b received
2024-09-20 12:06:07,172 Latency for request af7d8858 with model llama3-8b: 49.8530 seconds
2024-09-20 12:06:07,172 Moving batch for gemma-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:06:07,172 Saving results with gpu monitoring
2024-09-20 12:06:07,173 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:06:07,175 127.0.0.1 - - [20/Sep/2024 12:06:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:07,175 Next: call load_model for granite-7b
2024-09-20 12:06:07,280 Unloaded previous model
2024-09-20 12:06:07,628 Request with ID 2e259d96 for model llama3-8b received
2024-09-20 12:06:07,632 Adjusted batch time limit for llama3-8b: 5.0000 seconds
2024-09-20 12:06:07,632 127.0.0.1 - - [20/Sep/2024 12:06:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:07,639 Request with ID 895e915b for model gemma-7b received
2024-09-20 12:06:07,641 127.0.0.1 - - [20/Sep/2024 12:06:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:08,185 Request with ID 83188452 for model llama3-8b received
2024-09-20 12:06:08,186 127.0.0.1 - - [20/Sep/2024 12:06:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:08,493 Request with ID 078bb61d for model llama3-8b received
2024-09-20 12:06:08,494 127.0.0.1 - - [20/Sep/2024 12:06:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:08,511 Request with ID 0bf8b17a for model llama3-8b received
2024-09-20 12:06:08,511 127.0.0.1 - - [20/Sep/2024 12:06:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:08,696 Request with ID bc18b646 for model llama3-8b received
2024-09-20 12:06:08,696 127.0.0.1 - - [20/Sep/2024 12:06:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:08,904 Request with ID 1afdc8a9 for model gemma-7b received
2024-09-20 12:06:08,904 127.0.0.1 - - [20/Sep/2024 12:06:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:09,021 Request with ID 35634e8f for model llama3-8b received
2024-09-20 12:06:09,022 127.0.0.1 - - [20/Sep/2024 12:06:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:09,154 Request with ID ce832787 for model gemma-7b received
2024-09-20 12:06:09,154 127.0.0.1 - - [20/Sep/2024 12:06:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:09,900 Request with ID 8c9a2ded for model gemma-7b received
2024-09-20 12:06:09,901 127.0.0.1 - - [20/Sep/2024 12:06:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:10,304 Request with ID 4b1fa8ea for model granite-7b received
2024-09-20 12:06:10,305 127.0.0.1 - - [20/Sep/2024 12:06:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:10,306 Request with ID d2945c39 for model llama3-8b received
2024-09-20 12:06:10,307 Request with ID 56654378 for model llama3-8b received
2024-09-20 12:06:10,308 127.0.0.1 - - [20/Sep/2024 12:06:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:10,308 127.0.0.1 - - [20/Sep/2024 12:06:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:10,514 Request with ID 80dd4179 for model llama3-8b received
2024-09-20 12:06:10,515 127.0.0.1 - - [20/Sep/2024 12:06:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:10,565 Request with ID 21da7462 for model gemma-7b received
2024-09-20 12:06:10,566 127.0.0.1 - - [20/Sep/2024 12:06:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:10,935 Request with ID 8fcf1424 for model llama3-8b received
2024-09-20 12:06:10,935 127.0.0.1 - - [20/Sep/2024 12:06:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:11,209 Request with ID 7db180b9 for model llama3-8b received
2024-09-20 12:06:11,210 127.0.0.1 - - [20/Sep/2024 12:06:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:11,476 Request with ID 754d448a for model granite-7b received
2024-09-20 12:06:11,477 127.0.0.1 - - [20/Sep/2024 12:06:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:11,882 Request with ID 9a887ea9 for model llama3-8b received
2024-09-20 12:06:11,882 127.0.0.1 - - [20/Sep/2024 12:06:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:11,888 Request with ID 32e13a9b for model llama3-8b received
2024-09-20 12:06:11,888 127.0.0.1 - - [20/Sep/2024 12:06:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:12,072 Request with ID e4e41a37 for model llama3-8b received
2024-09-20 12:06:12,073 127.0.0.1 - - [20/Sep/2024 12:06:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:13,044 Request with ID 6e512feb for model llama3-8b received
2024-09-20 12:06:13,045 127.0.0.1 - - [20/Sep/2024 12:06:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:13,093 Request with ID 9fb5ef9b for model llama3-8b received
2024-09-20 12:06:13,093 127.0.0.1 - - [20/Sep/2024 12:06:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:13,359 Request with ID b7a0c20a for model llama3-8b received
2024-09-20 12:06:13,360 127.0.0.1 - - [20/Sep/2024 12:06:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:13,842 Request with ID b43fdb64 for model llama3-8b received
2024-09-20 12:06:13,843 127.0.0.1 - - [20/Sep/2024 12:06:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:13,937 Request with ID 59dc983b for model gemma-7b received
2024-09-20 12:06:13,938 127.0.0.1 - - [20/Sep/2024 12:06:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:14,394 Request with ID 6848e059 for model gemma-7b received
2024-09-20 12:06:14,394 127.0.0.1 - - [20/Sep/2024 12:06:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:14,736 Request with ID 7dbc8ee2 for model llama3-8b received
2024-09-20 12:06:14,736 127.0.0.1 - - [20/Sep/2024 12:06:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:14,911 Request with ID 26b67f00 for model granite-7b received
2024-09-20 12:06:14,911 127.0.0.1 - - [20/Sep/2024 12:06:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:15,125 Request with ID ce82b6e1 for model gemma-7b received
2024-09-20 12:06:15,126 127.0.0.1 - - [20/Sep/2024 12:06:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:15,518 Request with ID 4f1d44f8 for model gemma-7b received
2024-09-20 12:06:15,518 127.0.0.1 - - [20/Sep/2024 12:06:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:15,816 Request with ID 305ce715 for model gemma-7b received
2024-09-20 12:06:15,817 127.0.0.1 - - [20/Sep/2024 12:06:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:15,870 Request with ID 13ffbb20 for model gemma-7b received
2024-09-20 12:06:15,871 127.0.0.1 - - [20/Sep/2024 12:06:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:16,020 Request with ID 9f809b23 for model llama3-8b received
2024-09-20 12:06:16,021 127.0.0.1 - - [20/Sep/2024 12:06:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:16,052 Request with ID 16ffcc56 for model llama3-8b received
2024-09-20 12:06:16,053 127.0.0.1 - - [20/Sep/2024 12:06:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:16,300 Request with ID efbfabb9 for model gemma-7b received
2024-09-20 12:06:16,301 127.0.0.1 - - [20/Sep/2024 12:06:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:16,397 Request with ID 111a2af9 for model gemma-7b received
2024-09-20 12:06:16,398 127.0.0.1 - - [20/Sep/2024 12:06:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:16,614 Request with ID 6792ea59 for model llama3-8b received
2024-09-20 12:06:16,614 127.0.0.1 - - [20/Sep/2024 12:06:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:16,729 Request with ID 763fd340 for model llama3-8b received
2024-09-20 12:06:16,729 127.0.0.1 - - [20/Sep/2024 12:06:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:16,886 Request with ID 64c38122 for model gemma-7b received
2024-09-20 12:06:16,886 127.0.0.1 - - [20/Sep/2024 12:06:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:16,899 Request with ID 28d87adf for model llama3-8b received
2024-09-20 12:06:16,899 127.0.0.1 - - [20/Sep/2024 12:06:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:16,908 Request with ID 6046bd7b for model gemma-7b received
2024-09-20 12:06:16,909 127.0.0.1 - - [20/Sep/2024 12:06:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:16,950 Request with ID d56661e9 for model gemma-7b received
2024-09-20 12:06:16,950 127.0.0.1 - - [20/Sep/2024 12:06:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:17,094 Request with ID 8b89a5be for model llama3-8b received
2024-09-20 12:06:17,094 127.0.0.1 - - [20/Sep/2024 12:06:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:17,197 Request with ID a3ff751d for model llama3-8b received
2024-09-20 12:06:17,197 127.0.0.1 - - [20/Sep/2024 12:06:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:17,200 Request with ID a9b8f299 for model llama3-8b received
2024-09-20 12:06:17,201 127.0.0.1 - - [20/Sep/2024 12:06:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:17,608 Request with ID 6624267a for model gemma-7b received
2024-09-20 12:06:17,608 127.0.0.1 - - [20/Sep/2024 12:06:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:17,757 Request with ID 67cd9746 for model llama3-8b received
2024-09-20 12:06:17,758 127.0.0.1 - - [20/Sep/2024 12:06:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:17,789 Request with ID 012253dd for model gemma-7b received
2024-09-20 12:06:17,789 127.0.0.1 - - [20/Sep/2024 12:06:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:18,035 Request with ID 5e6d2cee for model llama3-8b received
2024-09-20 12:06:18,035 127.0.0.1 - - [20/Sep/2024 12:06:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:18,738 Request with ID 1f035fba for model llama3-8b received
2024-09-20 12:06:18,738 127.0.0.1 - - [20/Sep/2024 12:06:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:18,905 Request with ID 1696ccb1 for model llama3-8b received
2024-09-20 12:06:18,906 127.0.0.1 - - [20/Sep/2024 12:06:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:18,907 Request with ID 6ca125c4 for model llama3-8b received
2024-09-20 12:06:18,908 127.0.0.1 - - [20/Sep/2024 12:06:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:19,045 Request with ID 25ac7f3b for model gemma-7b received
2024-09-20 12:06:19,045 127.0.0.1 - - [20/Sep/2024 12:06:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:19,402 Request with ID f526ff9a for model llama3-8b received
2024-09-20 12:06:19,403 127.0.0.1 - - [20/Sep/2024 12:06:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:19,408 Request with ID 39d64e03 for model llama3-8b received
2024-09-20 12:06:19,409 127.0.0.1 - - [20/Sep/2024 12:06:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:19,913 Request with ID f132f7ee for model llama3-8b received
2024-09-20 12:06:19,913 127.0.0.1 - - [20/Sep/2024 12:06:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:20,095 Loaded model granite-7b
2024-09-20 12:06:20,096 Request with ID c026901e for model llama3-8b received
2024-09-20 12:06:20,097 127.0.0.1 - - [20/Sep/2024 12:06:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:20,102 Request with ID 98f3b9b2 for model llama3-8b received
2024-09-20 12:06:20,102 Batch processing started for model granite-7b
2024-09-20 12:06:20,103 127.0.0.1 - - [20/Sep/2024 12:06:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:20,180 Request with ID 3a27c648 for model llama3-8b received
2024-09-20 12:06:20,181 127.0.0.1 - - [20/Sep/2024 12:06:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:20,488 Request with ID 0021e2f3 for model gemma-7b received
2024-09-20 12:06:20,488 127.0.0.1 - - [20/Sep/2024 12:06:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:20,701 Request with ID fa242528 for model llama3-8b received
2024-09-20 12:06:20,702 127.0.0.1 - - [20/Sep/2024 12:06:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:20,819 Request with ID 20968ebe for model gemma-7b received
2024-09-20 12:06:20,819 127.0.0.1 - - [20/Sep/2024 12:06:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:21,228 Request with ID f17c0ba0 for model gemma-7b received
2024-09-20 12:06:21,228 127.0.0.1 - - [20/Sep/2024 12:06:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:21,440 Request with ID d3327857 for model llama3-8b received
2024-09-20 12:06:21,441 127.0.0.1 - - [20/Sep/2024 12:06:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:21,538 Request with ID af01d4a2 for model llama3-8b received
2024-09-20 12:06:21,538 127.0.0.1 - - [20/Sep/2024 12:06:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:21,697 Request with ID c2c738d1 for model granite-7b received
2024-09-20 12:06:21,697 127.0.0.1 - - [20/Sep/2024 12:06:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:21,875 Request with ID 844fabdd for model llama3-8b received
2024-09-20 12:06:21,876 127.0.0.1 - - [20/Sep/2024 12:06:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:21,973 Request with ID 5a16ad15 for model llama3-8b received
2024-09-20 12:06:21,973 127.0.0.1 - - [20/Sep/2024 12:06:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:21,977 Request with ID 8e448bc9 for model gemma-7b received
2024-09-20 12:06:21,978 127.0.0.1 - - [20/Sep/2024 12:06:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:22,011 Request with ID c6e2f218 for model llama3-8b received
2024-09-20 12:06:22,012 127.0.0.1 - - [20/Sep/2024 12:06:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:22,167 Request with ID cdd30737 for model llama3-8b received
2024-09-20 12:06:22,167 127.0.0.1 - - [20/Sep/2024 12:06:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:22,175 Processed batch: ['c503b5b3', '73df0321', '11adedb7', '7f9a0094', 'c5eda819', 'd89921bc', 'd8a63b4e', 'a3e4d51d'] with model granite-7b in 2.0732 seconds
2024-09-20 12:06:22,175 Saving sys info
2024-09-20 12:06:22,207 Latency for request c503b5b3 with model granite-7b: 27.3050 seconds
2024-09-20 12:06:22,207 Saving results with gpu monitoring
2024-09-20 12:06:22,210 Latency for request 73df0321 with model granite-7b: 27.1980 seconds
2024-09-20 12:06:22,210 Saving results with gpu monitoring
2024-09-20 12:06:22,212 Latency for request 11adedb7 with model granite-7b: 26.9250 seconds
2024-09-20 12:06:22,212 Saving results with gpu monitoring
2024-09-20 12:06:22,214 Latency for request 7f9a0094 with model granite-7b: 23.6250 seconds
2024-09-20 12:06:22,214 Saving results with gpu monitoring
2024-09-20 12:06:22,216 Latency for request c5eda819 with model granite-7b: 23.4830 seconds
2024-09-20 12:06:22,216 Saving results with gpu monitoring
2024-09-20 12:06:22,218 Latency for request d89921bc with model granite-7b: 21.9030 seconds
2024-09-20 12:06:22,218 Saving results with gpu monitoring
2024-09-20 12:06:22,220 Latency for request d8a63b4e with model granite-7b: 20.9790 seconds
2024-09-20 12:06:22,220 Saving results with gpu monitoring
2024-09-20 12:06:22,222 Latency for request a3e4d51d with model granite-7b: 18.8760 seconds
2024-09-20 12:06:22,222 Saving results with gpu monitoring
2024-09-20 12:06:22,224 127.0.0.1 - - [20/Sep/2024 12:06:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:22,225 Next: call load_model for gemma-7b
2024-09-20 12:06:22,305 Unloaded previous model
2024-09-20 12:06:22,863 Request with ID abbb0a45 for model llama3-8b received
2024-09-20 12:06:22,865 127.0.0.1 - - [20/Sep/2024 12:06:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:22,867 Request with ID 2b06ef73 for model llama3-8b received
2024-09-20 12:06:22,870 Request with ID ab2c33c5 for model llama3-8b received
2024-09-20 12:06:22,870 127.0.0.1 - - [20/Sep/2024 12:06:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:22,871 127.0.0.1 - - [20/Sep/2024 12:06:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:22,882 Request with ID e061fbe7 for model llama3-8b received
2024-09-20 12:06:22,883 127.0.0.1 - - [20/Sep/2024 12:06:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:22,929 Request with ID 5dd1a643 for model llama3-8b received
2024-09-20 12:06:22,932 127.0.0.1 - - [20/Sep/2024 12:06:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:23,044 Request with ID fabd79e2 for model llama3-8b received
2024-09-20 12:06:23,047 127.0.0.1 - - [20/Sep/2024 12:06:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:23,245 Request with ID 6cba7222 for model llama3-8b received
2024-09-20 12:06:23,248 127.0.0.1 - - [20/Sep/2024 12:06:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:23,456 Request with ID e8c02dcd for model gemma-7b received
2024-09-20 12:06:23,460 127.0.0.1 - - [20/Sep/2024 12:06:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:23,466 Request with ID 311a2a9e for model llama3-8b received
2024-09-20 12:06:23,467 127.0.0.1 - - [20/Sep/2024 12:06:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:23,702 Request with ID 19d3b9ba for model gemma-7b received
2024-09-20 12:06:23,708 127.0.0.1 - - [20/Sep/2024 12:06:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:24,348 Request with ID 349dec15 for model granite-7b received
2024-09-20 12:06:24,348 Adjusted batch time limit for granite-7b: 5.0000 seconds
2024-09-20 12:06:24,349 127.0.0.1 - - [20/Sep/2024 12:06:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:24,689 Request with ID e28b8252 for model granite-7b received
2024-09-20 12:06:24,689 Moving batch for granite-7b from incoming to running due to dynamic batch size 8
2024-09-20 12:06:24,689 Dynamic batch size condition met for model granite-7b
2024-09-20 12:06:24,891 Request with ID 2a30b466 for model llama3-8b received
2024-09-20 12:06:24,892 127.0.0.1 - - [20/Sep/2024 12:06:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:24,944 Request with ID c59c1d35 for model llama3-8b received
2024-09-20 12:06:24,944 127.0.0.1 - - [20/Sep/2024 12:06:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:24,983 Request with ID b98646d6 for model llama3-8b received
2024-09-20 12:06:24,983 127.0.0.1 - - [20/Sep/2024 12:06:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:25,446 Request with ID f1f2208c for model llama3-8b received
2024-09-20 12:06:25,447 127.0.0.1 - - [20/Sep/2024 12:06:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:25,507 Request with ID 17237ac2 for model gemma-7b received
2024-09-20 12:06:25,507 127.0.0.1 - - [20/Sep/2024 12:06:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:25,855 Request with ID 1a49bb06 for model llama3-8b received
2024-09-20 12:06:25,856 127.0.0.1 - - [20/Sep/2024 12:06:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:25,888 Request with ID 66802616 for model llama3-8b received
2024-09-20 12:06:25,889 127.0.0.1 - - [20/Sep/2024 12:06:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:25,927 Request with ID 0571c1df for model llama3-8b received
2024-09-20 12:06:25,927 127.0.0.1 - - [20/Sep/2024 12:06:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:26,058 Request with ID 3f2de694 for model granite-7b received
2024-09-20 12:06:26,058 127.0.0.1 - - [20/Sep/2024 12:06:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:26,265 Request with ID ab9304c5 for model gemma-7b received
2024-09-20 12:06:26,265 127.0.0.1 - - [20/Sep/2024 12:06:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:26,471 Request with ID 49a309a3 for model gemma-7b received
2024-09-20 12:06:26,472 127.0.0.1 - - [20/Sep/2024 12:06:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:26,653 Request with ID 3e609d85 for model llama3-8b received
2024-09-20 12:06:26,654 127.0.0.1 - - [20/Sep/2024 12:06:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:26,684 Request with ID f5069181 for model llama3-8b received
2024-09-20 12:06:26,684 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:06:26,685 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:06:26,938 Request with ID 58e7be9d for model gemma-7b received
2024-09-20 12:06:26,938 127.0.0.1 - - [20/Sep/2024 12:06:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:27,281 Request with ID 23f539c0 for model llama3-8b received
2024-09-20 12:06:27,282 127.0.0.1 - - [20/Sep/2024 12:06:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:27,456 Request with ID d2833f4b for model llama3-8b received
2024-09-20 12:06:27,456 127.0.0.1 - - [20/Sep/2024 12:06:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:27,519 Request with ID 617cb4fa for model llama3-8b received
2024-09-20 12:06:27,519 127.0.0.1 - - [20/Sep/2024 12:06:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:27,562 Request with ID a44b124d for model gemma-7b received
2024-09-20 12:06:27,563 127.0.0.1 - - [20/Sep/2024 12:06:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:27,651 Request with ID b3b44c44 for model llama3-8b received
2024-09-20 12:06:27,652 127.0.0.1 - - [20/Sep/2024 12:06:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:28,010 Request with ID 60a07e2d for model llama3-8b received
2024-09-20 12:06:28,011 127.0.0.1 - - [20/Sep/2024 12:06:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:28,064 Request with ID b0062f93 for model llama3-8b received
2024-09-20 12:06:28,064 127.0.0.1 - - [20/Sep/2024 12:06:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:28,218 Request with ID 4a5aed85 for model gemma-7b received
2024-09-20 12:06:28,218 127.0.0.1 - - [20/Sep/2024 12:06:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:28,441 Request with ID f1d0fafc for model llama3-8b received
2024-09-20 12:06:28,441 127.0.0.1 - - [20/Sep/2024 12:06:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:28,606 Request with ID e081f1a4 for model llama3-8b received
2024-09-20 12:06:28,607 127.0.0.1 - - [20/Sep/2024 12:06:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:28,620 Request with ID 407ad720 for model llama3-8b received
2024-09-20 12:06:28,621 127.0.0.1 - - [20/Sep/2024 12:06:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:28,660 Request with ID ca6740fa for model gemma-7b received
2024-09-20 12:06:28,660 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-20 12:06:28,661 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:06:28,769 Request with ID 3f4b4a7e for model llama3-8b received
2024-09-20 12:06:28,770 127.0.0.1 - - [20/Sep/2024 12:06:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:28,771 Request with ID 76f26ecb for model llama3-8b received
2024-09-20 12:06:28,772 127.0.0.1 - - [20/Sep/2024 12:06:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:29,089 Request with ID 619124bc for model gemma-7b received
2024-09-20 12:06:29,090 127.0.0.1 - - [20/Sep/2024 12:06:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:29,116 Request with ID 93e9fdab for model llama3-8b received
2024-09-20 12:06:29,117 127.0.0.1 - - [20/Sep/2024 12:06:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:29,642 Request with ID 4eb5f839 for model gemma-7b received
2024-09-20 12:06:29,642 127.0.0.1 - - [20/Sep/2024 12:06:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:29,867 Request with ID e9816a6b for model llama3-8b received
2024-09-20 12:06:29,868 127.0.0.1 - - [20/Sep/2024 12:06:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:29,885 Request with ID 1fb5ef8a for model llama3-8b received
2024-09-20 12:06:29,886 127.0.0.1 - - [20/Sep/2024 12:06:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:30,188 Request with ID d4944931 for model llama3-8b received
2024-09-20 12:06:30,188 127.0.0.1 - - [20/Sep/2024 12:06:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:30,190 Request with ID 756d9505 for model gemma-7b received
2024-09-20 12:06:30,191 127.0.0.1 - - [20/Sep/2024 12:06:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:30,192 Request with ID 5e787246 for model gemma-7b received
2024-09-20 12:06:30,193 127.0.0.1 - - [20/Sep/2024 12:06:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:30,223 Request with ID ce74a361 for model llama3-8b received
2024-09-20 12:06:30,224 127.0.0.1 - - [20/Sep/2024 12:06:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:30,291 Request with ID 84d2a52c for model llama3-8b received
2024-09-20 12:06:30,292 127.0.0.1 - - [20/Sep/2024 12:06:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:30,439 Request with ID 3a784cbb for model llama3-8b received
2024-09-20 12:06:30,440 127.0.0.1 - - [20/Sep/2024 12:06:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:30,612 Request with ID f684c6eb for model llama3-8b received
2024-09-20 12:06:30,613 127.0.0.1 - - [20/Sep/2024 12:06:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:30,661 Request with ID 5c7099d0 for model gemma-7b received
2024-09-20 12:06:30,662 127.0.0.1 - - [20/Sep/2024 12:06:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:31,002 Request with ID 2c924a62 for model llama3-8b received
2024-09-20 12:06:31,003 127.0.0.1 - - [20/Sep/2024 12:06:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:31,156 Request with ID 0d70142c for model gemma-7b received
2024-09-20 12:06:31,157 127.0.0.1 - - [20/Sep/2024 12:06:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:31,205 Request with ID c70634ca for model gemma-7b received
2024-09-20 12:06:31,206 127.0.0.1 - - [20/Sep/2024 12:06:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:31,210 Request with ID fa5838c2 for model gemma-7b received
2024-09-20 12:06:31,210 127.0.0.1 - - [20/Sep/2024 12:06:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:31,843 Request with ID 19f46703 for model llama3-8b received
2024-09-20 12:06:31,844 127.0.0.1 - - [20/Sep/2024 12:06:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:32,191 Request with ID eedb11ea for model llama3-8b received
2024-09-20 12:06:32,192 127.0.0.1 - - [20/Sep/2024 12:06:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:32,269 Request with ID d8e8f3c9 for model llama3-8b received
2024-09-20 12:06:32,270 127.0.0.1 - - [20/Sep/2024 12:06:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:32,457 Request with ID 51a419d0 for model llama3-8b received
2024-09-20 12:06:32,458 127.0.0.1 - - [20/Sep/2024 12:06:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:32,536 Request with ID 285cd99b for model llama3-8b received
2024-09-20 12:06:32,537 127.0.0.1 - - [20/Sep/2024 12:06:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:32,757 Request with ID 31804e16 for model gemma-7b received
2024-09-20 12:06:32,757 127.0.0.1 - - [20/Sep/2024 12:06:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:33,420 Request with ID 316d520d for model llama3-8b received
2024-09-20 12:06:33,420 127.0.0.1 - - [20/Sep/2024 12:06:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:33,447 Request with ID d126e780 for model gemma-7b received
2024-09-20 12:06:33,447 127.0.0.1 - - [20/Sep/2024 12:06:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:33,590 Request with ID 0131d404 for model gemma-7b received
2024-09-20 12:06:33,590 127.0.0.1 - - [20/Sep/2024 12:06:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:33,902 Waiting for running processes to finish
2024-09-20 12:06:35,905 Waiting for running processes to finish
2024-09-20 12:06:37,907 Waiting for running processes to finish
2024-09-20 12:06:39,910 Waiting for running processes to finish
2024-09-20 12:06:41,913 Waiting for running processes to finish
2024-09-20 12:06:43,916 Waiting for running processes to finish
2024-09-20 12:06:45,160 Loaded model gemma-7b
2024-09-20 12:06:45,164 Batch processing started for model gemma-7b
2024-09-20 12:06:45,919 Waiting for running processes to finish
2024-09-20 12:06:47,921 Waiting for running processes to finish
2024-09-20 12:06:48,434 Processed batch: ['e32b1dd8', 'c9f9fa4c', 'f368f084', 'f64c731a', 'd81ac2b0', '63bb34ef', '421f4da2', 'c621072d', '71d98bf6', '7457739f', 'fd3ae09c', '625c50e5', '1278c166', '98a4bbf0', '235a2c5a', '57af8081'] with model gemma-7b in 3.2703 seconds
2024-09-20 12:06:48,434 Saving sys info
2024-09-20 12:06:48,465 Latency for request e32b1dd8 with model gemma-7b: 49.3980 seconds
2024-09-20 12:06:48,466 Saving results with gpu monitoring
2024-09-20 12:06:48,468 Latency for request c9f9fa4c with model gemma-7b: 47.8390 seconds
2024-09-20 12:06:48,468 Saving results with gpu monitoring
2024-09-20 12:06:48,470 Latency for request f368f084 with model gemma-7b: 47.5230 seconds
2024-09-20 12:06:48,471 Saving results with gpu monitoring
2024-09-20 12:06:48,472 Latency for request f64c731a with model gemma-7b: 46.2920 seconds
2024-09-20 12:06:48,473 Saving results with gpu monitoring
2024-09-20 12:06:48,474 Latency for request d81ac2b0 with model gemma-7b: 46.2750 seconds
2024-09-20 12:06:48,475 Saving results with gpu monitoring
2024-09-20 12:06:48,476 Latency for request 63bb34ef with model gemma-7b: 46.1330 seconds
2024-09-20 12:06:48,477 Saving results with gpu monitoring
2024-09-20 12:06:48,478 Latency for request 421f4da2 with model gemma-7b: 46.0670 seconds
2024-09-20 12:06:48,478 Saving results with gpu monitoring
2024-09-20 12:06:48,480 Latency for request c621072d with model gemma-7b: 45.9880 seconds
2024-09-20 12:06:48,480 Saving results with gpu monitoring
2024-09-20 12:06:48,482 Latency for request 71d98bf6 with model gemma-7b: 45.5560 seconds
2024-09-20 12:06:48,482 Saving results with gpu monitoring
2024-09-20 12:06:48,484 Latency for request 7457739f with model gemma-7b: 44.2790 seconds
2024-09-20 12:06:48,484 Saving results with gpu monitoring
2024-09-20 12:06:48,486 Latency for request fd3ae09c with model gemma-7b: 44.1130 seconds
2024-09-20 12:06:48,486 Saving results with gpu monitoring
2024-09-20 12:06:48,488 Latency for request 625c50e5 with model gemma-7b: 42.8800 seconds
2024-09-20 12:06:48,488 Saving results with gpu monitoring
2024-09-20 12:06:48,490 Latency for request 1278c166 with model gemma-7b: 41.7010 seconds
2024-09-20 12:06:48,490 Saving results with gpu monitoring
2024-09-20 12:06:48,492 Latency for request 98a4bbf0 with model gemma-7b: 41.6930 seconds
2024-09-20 12:06:48,492 Saving results with gpu monitoring
2024-09-20 12:06:48,494 Latency for request 235a2c5a with model gemma-7b: 41.2840 seconds
2024-09-20 12:06:48,494 Saving results with gpu monitoring
2024-09-20 12:06:48,497 Latency for request 57af8081 with model gemma-7b: 41.2620 seconds
2024-09-20 12:06:48,497 Saving results with gpu monitoring
2024-09-20 12:06:48,499 127.0.0.1 - - [20/Sep/2024 12:06:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:06:48,499 Next: call load_model for llama3-8b
2024-09-20 12:06:48,613 Unloaded previous model
2024-09-20 12:06:50,020 Waiting for running processes to finish
2024-09-20 12:06:52,023 Waiting for running processes to finish
2024-09-20 12:06:54,026 Waiting for running processes to finish
2024-09-20 12:06:56,028 Waiting for running processes to finish
2024-09-20 12:06:58,031 Waiting for running processes to finish
2024-09-20 12:07:00,034 Waiting for running processes to finish
2024-09-20 12:07:02,036 Waiting for running processes to finish
2024-09-20 12:07:04,039 Waiting for running processes to finish
2024-09-20 12:07:06,042 Waiting for running processes to finish
2024-09-20 12:07:08,045 Waiting for running processes to finish
2024-09-20 12:07:10,048 Waiting for running processes to finish
2024-09-20 12:07:10,948 Loaded model llama3-8b
2024-09-20 12:07:10,951 Batch processing started for model llama3-8b
2024-09-20 12:07:12,050 Waiting for running processes to finish
2024-09-20 12:07:14,053 Waiting for running processes to finish
2024-09-20 12:07:16,056 Waiting for running processes to finish
2024-09-20 12:07:18,058 Waiting for running processes to finish
2024-09-20 12:07:20,069 Waiting for running processes to finish
2024-09-20 12:07:20,096 Processed batch: ['0f5c5381', '6d0932c7', '2e259d96', '83188452', '078bb61d', '0bf8b17a', 'bc18b646', '35634e8f', 'd2945c39', '56654378', '80dd4179', '8fcf1424', '7db180b9', '9a887ea9', '32e13a9b', 'e4e41a37', '6e512feb', '9fb5ef9b', 'b7a0c20a', 'b43fdb64', '7dbc8ee2', '9f809b23', '16ffcc56', '6792ea59', '763fd340', '28d87adf', '8b89a5be', 'a3ff751d', 'a9b8f299', '67cd9746', '5e6d2cee', '1f035fba', '1696ccb1', '6ca125c4', 'f526ff9a', '39d64e03', 'f132f7ee', 'c026901e', '98f3b9b2', '3a27c648', 'fa242528', 'd3327857', 'af01d4a2', '844fabdd', '5a16ad15', 'c6e2f218', 'cdd30737', 'abbb0a45', '2b06ef73', 'ab2c33c5', 'e061fbe7', '5dd1a643', 'fabd79e2', '6cba7222', '311a2a9e', '2a30b466', 'c59c1d35', 'b98646d6', 'f1f2208c', '1a49bb06', '66802616', '0571c1df', '3e609d85', 'f5069181'] with model llama3-8b in 9.1449 seconds
2024-09-20 12:07:20,096 Saving sys info
2024-09-20 12:07:20,129 Latency for request 0f5c5381 with model llama3-8b: 73.3790 seconds
2024-09-20 12:07:20,129 Saving results with gpu monitoring
2024-09-20 12:07:20,133 Latency for request 6d0932c7 with model llama3-8b: 73.2750 seconds
2024-09-20 12:07:20,133 Saving results with gpu monitoring
2024-09-20 12:07:20,135 Latency for request 2e259d96 with model llama3-8b: 72.4680 seconds
2024-09-20 12:07:20,135 Saving results with gpu monitoring
2024-09-20 12:07:20,137 Latency for request 83188452 with model llama3-8b: 71.9110 seconds
2024-09-20 12:07:20,137 Saving results with gpu monitoring
2024-09-20 12:07:20,139 Latency for request 078bb61d with model llama3-8b: 71.6030 seconds
2024-09-20 12:07:20,139 Saving results with gpu monitoring
2024-09-20 12:07:20,141 Latency for request 0bf8b17a with model llama3-8b: 71.5850 seconds
2024-09-20 12:07:20,141 Saving results with gpu monitoring
2024-09-20 12:07:20,143 Latency for request bc18b646 with model llama3-8b: 71.4000 seconds
2024-09-20 12:07:20,143 Saving results with gpu monitoring
2024-09-20 12:07:20,145 Latency for request 35634e8f with model llama3-8b: 71.0750 seconds
2024-09-20 12:07:20,145 Saving results with gpu monitoring
2024-09-20 12:07:20,147 Latency for request d2945c39 with model llama3-8b: 69.7900 seconds
2024-09-20 12:07:20,147 Saving results with gpu monitoring
2024-09-20 12:07:20,149 Latency for request 56654378 with model llama3-8b: 69.7890 seconds
2024-09-20 12:07:20,149 Saving results with gpu monitoring
2024-09-20 12:07:20,151 Latency for request 80dd4179 with model llama3-8b: 69.5820 seconds
2024-09-20 12:07:20,151 Saving results with gpu monitoring
2024-09-20 12:07:20,153 Latency for request 8fcf1424 with model llama3-8b: 69.1610 seconds
2024-09-20 12:07:20,153 Saving results with gpu monitoring
2024-09-20 12:07:20,155 Latency for request 7db180b9 with model llama3-8b: 68.8870 seconds
2024-09-20 12:07:20,155 Saving results with gpu monitoring
2024-09-20 12:07:20,157 Latency for request 9a887ea9 with model llama3-8b: 68.2140 seconds
2024-09-20 12:07:20,157 Saving results with gpu monitoring
2024-09-20 12:07:20,159 Latency for request 32e13a9b with model llama3-8b: 68.2080 seconds
2024-09-20 12:07:20,159 Saving results with gpu monitoring
2024-09-20 12:07:20,161 Latency for request e4e41a37 with model llama3-8b: 68.0240 seconds
2024-09-20 12:07:20,161 Saving results with gpu monitoring
2024-09-20 12:07:20,163 Latency for request 6e512feb with model llama3-8b: 67.0520 seconds
2024-09-20 12:07:20,163 Saving results with gpu monitoring
2024-09-20 12:07:20,165 Latency for request 9fb5ef9b with model llama3-8b: 67.0030 seconds
2024-09-20 12:07:20,165 Saving results with gpu monitoring
2024-09-20 12:07:20,167 Latency for request b7a0c20a with model llama3-8b: 66.7370 seconds
2024-09-20 12:07:20,167 Saving results with gpu monitoring
2024-09-20 12:07:20,169 Latency for request b43fdb64 with model llama3-8b: 66.2540 seconds
2024-09-20 12:07:20,169 Saving results with gpu monitoring
2024-09-20 12:07:20,171 Latency for request 7dbc8ee2 with model llama3-8b: 65.3600 seconds
2024-09-20 12:07:20,171 Saving results with gpu monitoring
2024-09-20 12:07:20,173 Latency for request 9f809b23 with model llama3-8b: 64.0760 seconds
2024-09-20 12:07:20,174 Saving results with gpu monitoring
2024-09-20 12:07:20,175 Latency for request 16ffcc56 with model llama3-8b: 64.0440 seconds
2024-09-20 12:07:20,176 Saving results with gpu monitoring
2024-09-20 12:07:20,177 Latency for request 6792ea59 with model llama3-8b: 63.4820 seconds
2024-09-20 12:07:20,178 Saving results with gpu monitoring
2024-09-20 12:07:20,179 Latency for request 763fd340 with model llama3-8b: 63.3670 seconds
2024-09-20 12:07:20,180 Saving results with gpu monitoring
2024-09-20 12:07:20,181 Latency for request 28d87adf with model llama3-8b: 63.1970 seconds
2024-09-20 12:07:20,182 Saving results with gpu monitoring
2024-09-20 12:07:20,183 Latency for request 8b89a5be with model llama3-8b: 63.0020 seconds
2024-09-20 12:07:20,184 Saving results with gpu monitoring
2024-09-20 12:07:20,185 Latency for request a3ff751d with model llama3-8b: 62.8990 seconds
2024-09-20 12:07:20,186 Saving results with gpu monitoring
2024-09-20 12:07:20,187 Latency for request a9b8f299 with model llama3-8b: 62.8960 seconds
2024-09-20 12:07:20,188 Saving results with gpu monitoring
2024-09-20 12:07:20,189 Latency for request 67cd9746 with model llama3-8b: 62.3390 seconds
2024-09-20 12:07:20,190 Saving results with gpu monitoring
2024-09-20 12:07:20,191 Latency for request 5e6d2cee with model llama3-8b: 62.0610 seconds
2024-09-20 12:07:20,192 Saving results with gpu monitoring
2024-09-20 12:07:20,193 Latency for request 1f035fba with model llama3-8b: 61.3580 seconds
2024-09-20 12:07:20,194 Saving results with gpu monitoring
2024-09-20 12:07:20,195 Latency for request 1696ccb1 with model llama3-8b: 61.1910 seconds
2024-09-20 12:07:20,195 Saving results with gpu monitoring
2024-09-20 12:07:20,197 Latency for request 6ca125c4 with model llama3-8b: 61.1890 seconds
2024-09-20 12:07:20,197 Saving results with gpu monitoring
2024-09-20 12:07:20,199 Latency for request f526ff9a with model llama3-8b: 60.6940 seconds
2024-09-20 12:07:20,199 Saving results with gpu monitoring
2024-09-20 12:07:20,201 Latency for request 39d64e03 with model llama3-8b: 60.6880 seconds
2024-09-20 12:07:20,201 Saving results with gpu monitoring
2024-09-20 12:07:20,203 Latency for request f132f7ee with model llama3-8b: 60.1840 seconds
2024-09-20 12:07:20,203 Saving results with gpu monitoring
2024-09-20 12:07:20,205 Latency for request c026901e with model llama3-8b: 60.0000 seconds
2024-09-20 12:07:20,205 Saving results with gpu monitoring
2024-09-20 12:07:20,207 Latency for request 98f3b9b2 with model llama3-8b: 59.9950 seconds
2024-09-20 12:07:20,207 Saving results with gpu monitoring
2024-09-20 12:07:20,209 Latency for request 3a27c648 with model llama3-8b: 59.9160 seconds
2024-09-20 12:07:20,209 Saving results with gpu monitoring
2024-09-20 12:07:20,211 Latency for request fa242528 with model llama3-8b: 59.3950 seconds
2024-09-20 12:07:20,211 Saving results with gpu monitoring
2024-09-20 12:07:20,213 Latency for request d3327857 with model llama3-8b: 58.6560 seconds
2024-09-20 12:07:20,213 Saving results with gpu monitoring
2024-09-20 12:07:20,215 Latency for request af01d4a2 with model llama3-8b: 58.5590 seconds
2024-09-20 12:07:20,215 Saving results with gpu monitoring
2024-09-20 12:07:20,217 Latency for request 844fabdd with model llama3-8b: 58.2210 seconds
2024-09-20 12:07:20,217 Saving results with gpu monitoring
2024-09-20 12:07:20,219 Latency for request 5a16ad15 with model llama3-8b: 58.1230 seconds
2024-09-20 12:07:20,219 Saving results with gpu monitoring
2024-09-20 12:07:20,221 Latency for request c6e2f218 with model llama3-8b: 58.0850 seconds
2024-09-20 12:07:20,221 Saving results with gpu monitoring
2024-09-20 12:07:20,223 Latency for request cdd30737 with model llama3-8b: 57.9300 seconds
2024-09-20 12:07:20,223 Saving results with gpu monitoring
2024-09-20 12:07:20,225 Latency for request abbb0a45 with model llama3-8b: 57.2330 seconds
2024-09-20 12:07:20,225 Saving results with gpu monitoring
2024-09-20 12:07:20,227 Latency for request 2b06ef73 with model llama3-8b: 57.2290 seconds
2024-09-20 12:07:20,227 Saving results with gpu monitoring
2024-09-20 12:07:20,229 Latency for request ab2c33c5 with model llama3-8b: 57.2260 seconds
2024-09-20 12:07:20,229 Saving results with gpu monitoring
2024-09-20 12:07:20,231 Latency for request e061fbe7 with model llama3-8b: 57.2140 seconds
2024-09-20 12:07:20,231 Saving results with gpu monitoring
2024-09-20 12:07:20,233 Latency for request 5dd1a643 with model llama3-8b: 57.1670 seconds
2024-09-20 12:07:20,233 Saving results with gpu monitoring
2024-09-20 12:07:20,235 Latency for request fabd79e2 with model llama3-8b: 57.0520 seconds
2024-09-20 12:07:20,235 Saving results with gpu monitoring
2024-09-20 12:07:20,237 Latency for request 6cba7222 with model llama3-8b: 56.8510 seconds
2024-09-20 12:07:20,237 Saving results with gpu monitoring
2024-09-20 12:07:20,239 Latency for request 311a2a9e with model llama3-8b: 56.6300 seconds
2024-09-20 12:07:20,239 Saving results with gpu monitoring
2024-09-20 12:07:20,241 Latency for request 2a30b466 with model llama3-8b: 55.2050 seconds
2024-09-20 12:07:20,241 Saving results with gpu monitoring
2024-09-20 12:07:20,243 Latency for request c59c1d35 with model llama3-8b: 55.1520 seconds
2024-09-20 12:07:20,243 Saving results with gpu monitoring
2024-09-20 12:07:20,245 Latency for request b98646d6 with model llama3-8b: 55.1130 seconds
2024-09-20 12:07:20,245 Saving results with gpu monitoring
2024-09-20 12:07:20,247 Latency for request f1f2208c with model llama3-8b: 54.6500 seconds
2024-09-20 12:07:20,247 Saving results with gpu monitoring
2024-09-20 12:07:20,249 Latency for request 1a49bb06 with model llama3-8b: 54.2410 seconds
2024-09-20 12:07:20,249 Saving results with gpu monitoring
2024-09-20 12:07:20,251 Latency for request 66802616 with model llama3-8b: 54.2080 seconds
2024-09-20 12:07:20,251 Saving results with gpu monitoring
2024-09-20 12:07:20,253 Latency for request 0571c1df with model llama3-8b: 54.1700 seconds
2024-09-20 12:07:20,253 Saving results with gpu monitoring
2024-09-20 12:07:20,255 Latency for request 3e609d85 with model llama3-8b: 53.4430 seconds
2024-09-20 12:07:20,255 Saving results with gpu monitoring
2024-09-20 12:07:20,257 Latency for request f5069181 with model llama3-8b: 53.4130 seconds
2024-09-20 12:07:20,257 Saving results with gpu monitoring
2024-09-20 12:07:20,260 127.0.0.1 - - [20/Sep/2024 12:07:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:07:20,260 Next: call load_model for granite-7b
2024-09-20 12:07:20,367 Unloaded previous model
2024-09-20 12:07:22,073 Waiting for running processes to finish
2024-09-20 12:07:24,075 Waiting for running processes to finish
2024-09-20 12:07:26,083 Waiting for running processes to finish
2024-09-20 12:07:28,085 Waiting for running processes to finish
2024-09-20 12:07:30,088 Waiting for running processes to finish
2024-09-20 12:07:32,091 Waiting for running processes to finish
2024-09-20 12:07:34,093 Waiting for running processes to finish
2024-09-20 12:07:36,096 Waiting for running processes to finish
2024-09-20 12:07:38,084 Loaded model granite-7b
2024-09-20 12:07:38,087 Batch processing started for model granite-7b
2024-09-20 12:07:38,099 Waiting for running processes to finish
2024-09-20 12:07:40,026 Processed batch: ['e0d1363e', '93d17440', '4b1fa8ea', '754d448a', '26b67f00', 'c2c738d1', '349dec15', 'e28b8252'] with model granite-7b in 1.9393 seconds
2024-09-20 12:07:40,027 Saving sys info
2024-09-20 12:07:40,059 Latency for request e0d1363e with model granite-7b: 96.4060 seconds
2024-09-20 12:07:40,059 Saving results with gpu monitoring
2024-09-20 12:07:40,062 Latency for request 93d17440 with model granite-7b: 93.6070 seconds
2024-09-20 12:07:40,062 Saving results with gpu monitoring
2024-09-20 12:07:40,064 Latency for request 4b1fa8ea with model granite-7b: 89.7220 seconds
2024-09-20 12:07:40,064 Saving results with gpu monitoring
2024-09-20 12:07:40,066 Latency for request 754d448a with model granite-7b: 88.5500 seconds
2024-09-20 12:07:40,066 Saving results with gpu monitoring
2024-09-20 12:07:40,068 Latency for request 26b67f00 with model granite-7b: 85.1150 seconds
2024-09-20 12:07:40,068 Saving results with gpu monitoring
2024-09-20 12:07:40,070 Latency for request c2c738d1 with model granite-7b: 78.3300 seconds
2024-09-20 12:07:40,070 Saving results with gpu monitoring
2024-09-20 12:07:40,072 Latency for request 349dec15 with model granite-7b: 75.6780 seconds
2024-09-20 12:07:40,072 Saving results with gpu monitoring
2024-09-20 12:07:40,074 Latency for request e28b8252 with model granite-7b: 75.3380 seconds
2024-09-20 12:07:40,074 Saving results with gpu monitoring
2024-09-20 12:07:40,076 127.0.0.1 - - [20/Sep/2024 12:07:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:07:40,076 Next: call load_model for gemma-7b
2024-09-20 12:07:40,159 Waiting for running processes to finish
2024-09-20 12:07:40,159 Unloaded previous model
2024-09-20 12:07:43,163 Total time: 186.1585 seconds
2024-09-20 12:07:43,164 Total inference time: 33.8070 seconds
2024-09-20 12:07:43,164 Inference time as percentage of total time: 18.16%
2024-09-20 12:07:43,164 END
2024-09-20 12:07:43,165 127.0.0.1 - - [20/Sep/2024 12:07:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:08:02,178 Loaded model gemma-7b
2024-09-20 12:08:02,181 Batch processing started for model gemma-7b
2024-09-20 12:08:06,195 Processed batch: ['895e915b', '1afdc8a9', 'ce832787', '8c9a2ded', '21da7462', '59dc983b', '6848e059', 'ce82b6e1', '4f1d44f8', '305ce715', '13ffbb20', 'efbfabb9', '111a2af9', '64c38122', '6046bd7b', 'd56661e9', '6624267a', '012253dd', '25ac7f3b', '0021e2f3', '20968ebe', 'f17c0ba0', '8e448bc9', 'e8c02dcd', '19d3b9ba', '17237ac2', 'ab9304c5', '49a309a3', '58e7be9d', 'a44b124d', '4a5aed85', 'ca6740fa'] with model gemma-7b in 4.0141 seconds
2024-09-20 12:08:06,195 Saving sys info
2024-09-20 12:08:06,229 Latency for request 895e915b with model gemma-7b: 118.5550 seconds
2024-09-20 12:08:06,229 Saving results with gpu monitoring
2024-09-20 12:08:06,237 Latency for request 1afdc8a9 with model gemma-7b: 117.2910 seconds
2024-09-20 12:08:06,237 Saving results with gpu monitoring
2024-09-20 12:08:06,239 Latency for request ce832787 with model gemma-7b: 117.0410 seconds
2024-09-20 12:08:06,239 Saving results with gpu monitoring
2024-09-20 12:08:06,241 Latency for request 8c9a2ded with model gemma-7b: 116.2940 seconds
2024-09-20 12:08:06,241 Saving results with gpu monitoring
2024-09-20 12:08:06,243 Latency for request 21da7462 with model gemma-7b: 115.6300 seconds
2024-09-20 12:08:06,243 Saving results with gpu monitoring
2024-09-20 12:08:06,245 Latency for request 59dc983b with model gemma-7b: 112.2580 seconds
2024-09-20 12:08:06,245 Saving results with gpu monitoring
2024-09-20 12:08:06,247 Latency for request 6848e059 with model gemma-7b: 111.8010 seconds
2024-09-20 12:08:06,247 Saving results with gpu monitoring
2024-09-20 12:08:06,249 Latency for request ce82b6e1 with model gemma-7b: 111.0700 seconds
2024-09-20 12:08:06,249 Saving results with gpu monitoring
2024-09-20 12:08:06,251 Latency for request 4f1d44f8 with model gemma-7b: 110.6770 seconds
2024-09-20 12:08:06,251 Saving results with gpu monitoring
2024-09-20 12:08:06,253 Latency for request 305ce715 with model gemma-7b: 110.3790 seconds
2024-09-20 12:08:06,253 Saving results with gpu monitoring
2024-09-20 12:08:06,255 Latency for request 13ffbb20 with model gemma-7b: 110.3240 seconds
2024-09-20 12:08:06,255 Saving results with gpu monitoring
2024-09-20 12:08:06,257 Latency for request efbfabb9 with model gemma-7b: 109.8950 seconds
2024-09-20 12:08:06,257 Saving results with gpu monitoring
2024-09-20 12:08:06,259 Latency for request 111a2af9 with model gemma-7b: 109.7980 seconds
2024-09-20 12:08:06,259 Saving results with gpu monitoring
2024-09-20 12:08:06,261 Latency for request 64c38122 with model gemma-7b: 109.3090 seconds
2024-09-20 12:08:06,261 Saving results with gpu monitoring
2024-09-20 12:08:06,263 Latency for request 6046bd7b with model gemma-7b: 109.2860 seconds
2024-09-20 12:08:06,263 Saving results with gpu monitoring
2024-09-20 12:08:06,265 Latency for request d56661e9 with model gemma-7b: 109.2450 seconds
2024-09-20 12:08:06,265 Saving results with gpu monitoring
2024-09-20 12:08:06,267 Latency for request 6624267a with model gemma-7b: 108.5870 seconds
2024-09-20 12:08:06,267 Saving results with gpu monitoring
2024-09-20 12:08:06,269 Latency for request 012253dd with model gemma-7b: 108.4060 seconds
2024-09-20 12:08:06,269 Saving results with gpu monitoring
2024-09-20 12:08:06,271 Latency for request 25ac7f3b with model gemma-7b: 107.1500 seconds
2024-09-20 12:08:06,271 Saving results with gpu monitoring
2024-09-20 12:08:06,273 Latency for request 0021e2f3 with model gemma-7b: 105.7070 seconds
2024-09-20 12:08:06,273 Saving results with gpu monitoring
2024-09-20 12:08:06,275 Latency for request 20968ebe with model gemma-7b: 105.3760 seconds
2024-09-20 12:08:06,275 Saving results with gpu monitoring
2024-09-20 12:08:06,277 Latency for request f17c0ba0 with model gemma-7b: 104.9670 seconds
2024-09-20 12:08:06,277 Saving results with gpu monitoring
2024-09-20 12:08:06,279 Latency for request 8e448bc9 with model gemma-7b: 104.2170 seconds
2024-09-20 12:08:06,279 Saving results with gpu monitoring
2024-09-20 12:08:06,281 Latency for request e8c02dcd with model gemma-7b: 102.7390 seconds
2024-09-20 12:08:06,281 Saving results with gpu monitoring
2024-09-20 12:08:06,283 Latency for request 19d3b9ba with model gemma-7b: 102.4930 seconds
2024-09-20 12:08:06,283 Saving results with gpu monitoring
2024-09-20 12:08:06,285 Latency for request 17237ac2 with model gemma-7b: 100.6880 seconds
2024-09-20 12:08:06,285 Saving results with gpu monitoring
2024-09-20 12:08:06,287 Latency for request ab9304c5 with model gemma-7b: 99.9300 seconds
2024-09-20 12:08:06,287 Saving results with gpu monitoring
2024-09-20 12:08:06,289 Latency for request 49a309a3 with model gemma-7b: 99.7240 seconds
2024-09-20 12:08:06,289 Saving results with gpu monitoring
2024-09-20 12:08:06,291 Latency for request 58e7be9d with model gemma-7b: 99.2570 seconds
2024-09-20 12:08:06,291 Saving results with gpu monitoring
2024-09-20 12:08:06,293 Latency for request a44b124d with model gemma-7b: 98.6330 seconds
2024-09-20 12:08:06,293 Saving results with gpu monitoring
2024-09-20 12:08:06,295 Latency for request 4a5aed85 with model gemma-7b: 97.9770 seconds
2024-09-20 12:08:06,295 Saving results with gpu monitoring
2024-09-20 12:08:06,297 Latency for request ca6740fa with model gemma-7b: 97.5350 seconds
2024-09-20 12:08:06,297 Saving results with gpu monitoring
2024-09-20 12:08:06,299 127.0.0.1 - - [20/Sep/2024 12:08:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:08:06,300 No batch to process for model llama3-8b
2024-09-20 12:08:06,301 127.0.0.1 - - [20/Sep/2024 12:08:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:08:06,301 No batch to process for model granite-7b
2024-09-20 12:08:06,302 127.0.0.1 - - [20/Sep/2024 12:08:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:08:06,303 No batch to process for model llama3-8b
2024-09-20 12:08:06,303 127.0.0.1 - - [20/Sep/2024 12:08:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:08:06,303 No batch to process for model gemma-7b
2024-09-20 12:08:06,304 127.0.0.1 - - [20/Sep/2024 12:08:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:08:06,304 No batch to process for model granite-7b
2024-09-20 12:08:06,305 127.0.0.1 - - [20/Sep/2024 12:08:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:08:06,305 No batch to process for model llama3-8b
2024-09-20 12:08:06,305 127.0.0.1 - - [20/Sep/2024 12:08:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:08:06,306 No batch to process for model gemma-7b
2024-09-20 12:08:06,307 127.0.0.1 - - [20/Sep/2024 12:08:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:08:06,308 No batch to process for model granite-7b
2024-09-20 12:08:06,308 127.0.0.1 - - [20/Sep/2024 12:08:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:08:06,308 No batch to process for model llama3-8b
2024-09-20 12:08:06,309 127.0.0.1 - - [20/Sep/2024 12:08:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:08:06,309 No batch to process for model gemma-7b
2024-09-20 12:08:06,310 127.0.0.1 - - [20/Sep/2024 12:08:06] "POST /inference HTTP/1.1" 200 -
