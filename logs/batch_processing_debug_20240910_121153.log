2024-09-10 12:11:58,845 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.11.77:5000
2024-09-10 12:11:58,846 [33mPress CTRL+C to quit[0m
2024-09-10 12:12:14,992 Request with ID b635acb5 for model gpt2-124m received
2024-09-10 12:12:14,992 Adjusted time limit based on total queue size 1: 6.0000 seconds
2024-09-10 12:12:14,992 Adjusted time limit for model gpt2-124m: 5.7760 seconds
2024-09-10 12:12:14,992 127.0.0.1 - - [10/Sep/2024 12:12:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:15,615 Request with ID 7220c6b9 for model gpt2-124m received
2024-09-10 12:12:15,615 Adjusted time limit based on total queue size 2: 6.0000 seconds
2024-09-10 12:12:15,616 127.0.0.1 - - [10/Sep/2024 12:12:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:15,862 Request with ID 253e6e6c for model gpt2medium-355m received
2024-09-10 12:12:15,862 Adjusted time limit based on total queue size 3: 6.0000 seconds
2024-09-10 12:12:15,862 Adjusted time limit for model gpt2medium-355m: 5.8947 seconds
2024-09-10 12:12:15,863 127.0.0.1 - - [10/Sep/2024 12:12:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:15,910 Request with ID ffb1622f for model gpt2-124m received
2024-09-10 12:12:15,910 Adjusted time limit based on total queue size 4: 4.5000 seconds
2024-09-10 12:12:15,911 127.0.0.1 - - [10/Sep/2024 12:12:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:16,188 Request with ID f57c9241 for model gpt2-124m received
2024-09-10 12:12:16,188 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:12:16,188 127.0.0.1 - - [10/Sep/2024 12:12:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:16,689 Request with ID f1d018e6 for model distilgpt2-124m received
2024-09-10 12:12:16,689 Adjusted time limit based on total queue size 6: 4.5000 seconds
2024-09-10 12:12:16,689 Adjusted time limit for model distilgpt2-124m: 5.9589 seconds
2024-09-10 12:12:16,690 127.0.0.1 - - [10/Sep/2024 12:12:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:17,147 Request with ID 3fee78c0 for model distilgpt2-124m received
2024-09-10 12:12:17,147 Adjusted time limit based on total queue size 7: 4.5000 seconds
2024-09-10 12:12:17,148 127.0.0.1 - - [10/Sep/2024 12:12:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:17,573 Request with ID cf7f5396 for model gpt2medium-355m received
2024-09-10 12:12:17,574 Adjusted time limit based on total queue size 8: 3.0000 seconds
2024-09-10 12:12:17,574 127.0.0.1 - - [10/Sep/2024 12:12:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:17,866 Request with ID e1993c62 for model distilgpt2-124m received
2024-09-10 12:12:17,867 Adjusted time limit based on total queue size 9: 3.0000 seconds
2024-09-10 12:12:17,867 127.0.0.1 - - [10/Sep/2024 12:12:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:18,211 Request with ID a29a4b76 for model gpt2medium-355m received
2024-09-10 12:12:18,211 Adjusted time limit based on total queue size 10: 3.0000 seconds
2024-09-10 12:12:18,212 127.0.0.1 - - [10/Sep/2024 12:12:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:18,579 Request with ID 34ef8d33 for model gpt2-124m received
2024-09-10 12:12:18,579 Adjusted time limit based on total queue size 11: 3.0000 seconds
2024-09-10 12:12:18,580 127.0.0.1 - - [10/Sep/2024 12:12:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:19,043 Request with ID 705fb944 for model gpt2medium-355m received
2024-09-10 12:12:19,044 Adjusted time limit based on total queue size 12: 3.0000 seconds
2024-09-10 12:12:19,044 127.0.0.1 - - [10/Sep/2024 12:12:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:19,316 Request with ID 64a95e27 for model gpt2-124m received
2024-09-10 12:12:19,317 Adjusted time limit based on total queue size 13: 3.0000 seconds
2024-09-10 12:12:19,317 127.0.0.1 - - [10/Sep/2024 12:12:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:19,569 Request with ID 98c08fad for model distilgpt2-124m received
2024-09-10 12:12:19,570 Adjusted time limit based on total queue size 14: 3.0000 seconds
2024-09-10 12:12:19,570 127.0.0.1 - - [10/Sep/2024 12:12:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:20,373 Request with ID 92b935f5 for model gpt2-124m received
2024-09-10 12:12:20,373 Adjusted time limit based on total queue size 15: 3.0000 seconds
2024-09-10 12:12:20,373 127.0.0.1 - - [10/Sep/2024 12:12:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:20,864 Time limit condition met for model gpt2-124m
2024-09-10 12:12:20,864 Updated batch size:8
2024-09-10 12:12:20,864 Loading model gpt2-124m
2024-09-10 12:12:21,272 Request with ID d4be938c for model gpt2-124m received
2024-09-10 12:12:21,272 Adjusted time limit based on total queue size 9: 3.0000 seconds
2024-09-10 12:12:21,272 127.0.0.1 - - [10/Sep/2024 12:12:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:21,822 Request with ID 147f84e5 for model distilgpt2-124m received
2024-09-10 12:12:21,822 Adjusted time limit based on total queue size 10: 3.0000 seconds
2024-09-10 12:12:21,822 127.0.0.1 - - [10/Sep/2024 12:12:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:22,173 Processed batch: ['b635acb5', '7220c6b9', 'ffb1622f', 'f57c9241', '34ef8d33', '64a95e27', '92b935f5', 'ef64'] with model gpt2-124m in 1.2057 seconds
2024-09-10 12:12:22,173 Latency for request b635acb5 with model gpt2-124m: 7.1813 seconds
2024-09-10 12:12:22,175 Latency for request 7220c6b9 with model gpt2-124m: 6.5588 seconds
2024-09-10 12:12:22,176 Latency for request ffb1622f with model gpt2-124m: 6.2633 seconds
2024-09-10 12:12:22,176 Latency for request f57c9241 with model gpt2-124m: 5.9852 seconds
2024-09-10 12:12:22,176 Latency for request 34ef8d33 with model gpt2-124m: 3.5946 seconds
2024-09-10 12:12:22,177 Latency for request 64a95e27 with model gpt2-124m: 2.8573 seconds
2024-09-10 12:12:22,177 Latency for request 92b935f5 with model gpt2-124m: 1.8007 seconds
2024-09-10 12:12:22,177 Latency for request ef64 with model gpt2-124m: 1.3092 seconds
2024-09-10 12:12:22,282 Time limit condition met for model gpt2medium-355m
2024-09-10 12:12:22,282 Updated batch size:4
2024-09-10 12:12:22,282 Loading model gpt2medium-355m
2024-09-10 12:12:23,934 Request with ID 2155a374 for model gpt2-124m received
2024-09-10 12:12:23,934 Adjusted time limit based on total queue size 7: 4.5000 seconds
2024-09-10 12:12:23,934 Adjusted time limit for model gpt2-124m: 5.7653 seconds
2024-09-10 12:12:23,934 127.0.0.1 - - [10/Sep/2024 12:12:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:24,868 Request with ID c9f11d99 for model gpt2medium-355m received
2024-09-10 12:12:24,868 Adjusted time limit based on total queue size 8: 3.0000 seconds
2024-09-10 12:12:24,868 127.0.0.1 - - [10/Sep/2024 12:12:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:25,002 Processed batch: ['253e6e6c', 'cf7f5396', 'a29a4b76', '705fb944'] with model gpt2medium-355m in 2.6145 seconds
2024-09-10 12:12:25,002 Latency for request 253e6e6c with model gpt2medium-355m: 9.1402 seconds
2024-09-10 12:12:25,003 Latency for request cf7f5396 with model gpt2medium-355m: 7.4291 seconds
2024-09-10 12:12:25,004 Latency for request a29a4b76 with model gpt2medium-355m: 6.7916 seconds
2024-09-10 12:12:25,004 Latency for request 705fb944 with model gpt2medium-355m: 5.9590 seconds
2024-09-10 12:12:25,108 Time limit condition met for model distilgpt2-124m
2024-09-10 12:12:25,108 Updated batch size:8
2024-09-10 12:12:25,108 Loading model distilgpt2-124m
2024-09-10 12:12:25,572 Request with ID 7de9fae3 for model gpt2medium-355m received
2024-09-10 12:12:25,572 Adjusted time limit based on total queue size 4: 4.5000 seconds
2024-09-10 12:12:25,572 Adjusted time limit for model gpt2medium-355m: 5.8884 seconds
2024-09-10 12:12:25,572 127.0.0.1 - - [10/Sep/2024 12:12:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:26,003 Processed batch: ['f1d018e6', '3fee78c0', 'e1993c62', '98c08fad', '147f84e5', 'b52a', '3bbc', '0087'] with model distilgpt2-124m in 0.8439 seconds
2024-09-10 12:12:26,003 Latency for request f1d018e6 with model distilgpt2-124m: 9.3147 seconds
2024-09-10 12:12:26,004 Latency for request 3fee78c0 with model distilgpt2-124m: 8.8565 seconds
2024-09-10 12:12:26,005 Latency for request e1993c62 with model distilgpt2-124m: 8.1370 seconds
2024-09-10 12:12:26,005 Latency for request 98c08fad with model distilgpt2-124m: 6.4342 seconds
2024-09-10 12:12:26,005 Latency for request 147f84e5 with model distilgpt2-124m: 4.1814 seconds
2024-09-10 12:12:26,005 Latency for request b52a with model distilgpt2-124m: 0.8949 seconds
2024-09-10 12:12:26,006 Latency for request 3bbc with model distilgpt2-124m: 0.8949 seconds
2024-09-10 12:12:26,006 Latency for request 0087 with model distilgpt2-124m: 0.8949 seconds
2024-09-10 12:12:26,047 Request with ID d5a08951 for model gpt2medium-355m received
2024-09-10 12:12:26,047 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:12:26,048 127.0.0.1 - - [10/Sep/2024 12:12:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:26,919 Request with ID 9c5640e5 for model gpt2medium-355m received
2024-09-10 12:12:26,919 Adjusted time limit based on total queue size 6: 4.5000 seconds
2024-09-10 12:12:26,920 127.0.0.1 - - [10/Sep/2024 12:12:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:27,451 Request with ID 17d311bb for model gpt2-124m received
2024-09-10 12:12:27,452 Adjusted time limit based on total queue size 7: 4.5000 seconds
2024-09-10 12:12:27,452 127.0.0.1 - - [10/Sep/2024 12:12:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:27,757 Request with ID 2338e941 for model distilgpt2-124m received
2024-09-10 12:12:27,758 Adjusted time limit based on total queue size 8: 3.0000 seconds
2024-09-10 12:12:27,758 Adjusted time limit for model distilgpt2-124m: 5.9526 seconds
2024-09-10 12:12:27,758 127.0.0.1 - - [10/Sep/2024 12:12:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:28,554 Request with ID 4c9726fa for model distilgpt2-124m received
2024-09-10 12:12:28,555 Adjusted time limit based on total queue size 9: 3.0000 seconds
2024-09-10 12:12:28,555 127.0.0.1 - - [10/Sep/2024 12:12:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:29,232 Request with ID 444656f7 for model distilgpt2-124m received
2024-09-10 12:12:29,233 Adjusted time limit based on total queue size 10: 3.0000 seconds
2024-09-10 12:12:29,233 127.0.0.1 - - [10/Sep/2024 12:12:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:29,330 Request with ID aafdd724 for model gpt2-124m received
2024-09-10 12:12:29,330 Adjusted time limit based on total queue size 11: 3.0000 seconds
2024-09-10 12:12:29,331 127.0.0.1 - - [10/Sep/2024 12:12:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:29,737 Time limit condition met for model gpt2-124m
2024-09-10 12:12:29,737 Updated batch size:4
2024-09-10 12:12:29,738 Loading model gpt2-124m
2024-09-10 12:12:30,211 Request with ID 8cd4b956 for model gpt2medium-355m received
2024-09-10 12:12:30,211 Adjusted time limit based on total queue size 8: 3.0000 seconds
2024-09-10 12:12:30,211 127.0.0.1 - - [10/Sep/2024 12:12:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:30,704 Processed batch: ['d4be938c', '2155a374', '17d311bb', 'aafdd724'] with model gpt2-124m in 0.8733 seconds
2024-09-10 12:12:30,704 Latency for request d4be938c with model gpt2-124m: 9.4325 seconds
2024-09-10 12:12:30,705 Latency for request 2155a374 with model gpt2-124m: 6.7701 seconds
2024-09-10 12:12:30,705 Latency for request 17d311bb with model gpt2-124m: 3.2528 seconds
2024-09-10 12:12:30,706 Latency for request aafdd724 with model gpt2-124m: 1.3741 seconds
2024-09-10 12:12:30,795 Request with ID 8f811d07 for model gpt2medium-355m received
2024-09-10 12:12:30,795 Adjusted time limit based on total queue size 9: 3.0000 seconds
2024-09-10 12:12:30,795 127.0.0.1 - - [10/Sep/2024 12:12:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:30,871 Request with ID a6df4f6d for model gpt2medium-355m received
2024-09-10 12:12:30,871 Adjusted time limit based on total queue size 10: 3.0000 seconds
2024-09-10 12:12:30,871 127.0.0.1 - - [10/Sep/2024 12:12:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:31,543 Time limit condition met for model gpt2medium-355m
2024-09-10 12:12:31,544 Updated batch size:8
2024-09-10 12:12:31,544 Loading model gpt2medium-355m
2024-09-10 12:12:31,982 Request with ID 79df835c for model gpt2medium-355m received
2024-09-10 12:12:31,982 Adjusted time limit based on total queue size 4: 4.5000 seconds
2024-09-10 12:12:31,982 127.0.0.1 - - [10/Sep/2024 12:12:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:32,519 Request with ID 60d38b77 for model gpt2-124m received
2024-09-10 12:12:32,519 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:12:32,519 Adjusted time limit for model gpt2-124m: 5.7653 seconds
2024-09-10 12:12:32,519 127.0.0.1 - - [10/Sep/2024 12:12:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:32,966 Request with ID 207904a8 for model gpt2medium-355m received
2024-09-10 12:12:32,966 Adjusted time limit based on total queue size 6: 4.5000 seconds
2024-09-10 12:12:32,966 127.0.0.1 - - [10/Sep/2024 12:12:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:33,294 Request with ID cfcc2466 for model gpt2medium-355m received
2024-09-10 12:12:33,295 Adjusted time limit based on total queue size 7: 4.5000 seconds
2024-09-10 12:12:33,295 127.0.0.1 - - [10/Sep/2024 12:12:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:33,506 Request with ID 38a3511b for model gpt2-124m received
2024-09-10 12:12:33,506 Adjusted time limit based on total queue size 8: 3.0000 seconds
2024-09-10 12:12:33,506 127.0.0.1 - - [10/Sep/2024 12:12:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:34,214 Request with ID af96953c for model gpt2medium-355m received
2024-09-10 12:12:34,214 Adjusted time limit based on total queue size 9: 3.0000 seconds
2024-09-10 12:12:34,214 127.0.0.1 - - [10/Sep/2024 12:12:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:35,002 Request with ID dfa971ad for model distilgpt2-124m received
2024-09-10 12:12:35,002 Adjusted time limit based on total queue size 10: 3.0000 seconds
2024-09-10 12:12:35,002 127.0.0.1 - - [10/Sep/2024 12:12:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:35,156 Processed batch: ['c9f11d99', '7de9fae3', 'd5a08951', '9c5640e5', '8cd4b956', '8f811d07', 'a6df4f6d', '161c'] with model gpt2medium-355m in 3.4910 seconds
2024-09-10 12:12:35,156 Latency for request c9f11d99 with model gpt2medium-355m: 10.2878 seconds
2024-09-10 12:12:35,157 Latency for request 7de9fae3 with model gpt2medium-355m: 9.5838 seconds
2024-09-10 12:12:35,157 Latency for request d5a08951 with model gpt2medium-355m: 9.1084 seconds
2024-09-10 12:12:35,157 Latency for request 9c5640e5 with model gpt2medium-355m: 8.2372 seconds
2024-09-10 12:12:35,157 Latency for request 8cd4b956 with model gpt2medium-355m: 4.9451 seconds
2024-09-10 12:12:35,158 Latency for request 8f811d07 with model gpt2medium-355m: 4.3606 seconds
2024-09-10 12:12:35,158 Latency for request a6df4f6d with model gpt2medium-355m: 4.2850 seconds
2024-09-10 12:12:35,158 Latency for request 161c with model gpt2medium-355m: 3.6118 seconds
2024-09-10 12:12:35,263 Time limit condition met for model distilgpt2-124m
2024-09-10 12:12:35,263 Updated batch size:4
2024-09-10 12:12:35,263 Loading model distilgpt2-124m
2024-09-10 12:12:35,535 Request with ID d37b31b2 for model gpt2-124m received
2024-09-10 12:12:35,535 Adjusted time limit based on total queue size 7: 4.5000 seconds
2024-09-10 12:12:35,536 127.0.0.1 - - [10/Sep/2024 12:12:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:35,750 Request with ID fb209fbe for model gpt2medium-355m received
2024-09-10 12:12:35,750 Adjusted time limit based on total queue size 8: 3.0000 seconds
2024-09-10 12:12:35,750 Adjusted time limit for model gpt2medium-355m: 5.8884 seconds
2024-09-10 12:12:35,750 127.0.0.1 - - [10/Sep/2024 12:12:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:36,040 Processed batch: ['2338e941', '4c9726fa', '444656f7', 'dfa971ad'] with model distilgpt2-124m in 0.6803 seconds
2024-09-10 12:12:36,040 Latency for request 2338e941 with model distilgpt2-124m: 8.2827 seconds
2024-09-10 12:12:36,041 Latency for request 4c9726fa with model distilgpt2-124m: 7.4857 seconds
2024-09-10 12:12:36,042 Latency for request 444656f7 with model distilgpt2-124m: 6.8077 seconds
2024-09-10 12:12:36,042 Latency for request dfa971ad with model distilgpt2-124m: 1.0381 seconds
2024-09-10 12:12:36,062 Request with ID 65673a60 for model gpt2-124m received
2024-09-10 12:12:36,062 Adjusted time limit based on total queue size 9: 3.0000 seconds
2024-09-10 12:12:36,062 127.0.0.1 - - [10/Sep/2024 12:12:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:36,077 Request with ID 00d8ed02 for model gpt2-124m received
2024-09-10 12:12:36,077 Adjusted time limit based on total queue size 10: 3.0000 seconds
2024-09-10 12:12:36,077 127.0.0.1 - - [10/Sep/2024 12:12:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:36,618 Request with ID 4f1fb71c for model gpt2-124m received
2024-09-10 12:12:36,619 Adjusted time limit based on total queue size 11: 3.0000 seconds
2024-09-10 12:12:36,619 127.0.0.1 - - [10/Sep/2024 12:12:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:36,900 Request with ID bb9f2e27 for model distilgpt2-124m received
2024-09-10 12:12:36,901 Adjusted time limit based on total queue size 12: 3.0000 seconds
2024-09-10 12:12:36,901 Adjusted time limit for model distilgpt2-124m: 5.9526 seconds
2024-09-10 12:12:36,901 127.0.0.1 - - [10/Sep/2024 12:12:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:37,161 Request with ID 3b19d5a9 for model distilgpt2-124m received
2024-09-10 12:12:37,162 Adjusted time limit based on total queue size 13: 3.0000 seconds
2024-09-10 12:12:37,162 127.0.0.1 - - [10/Sep/2024 12:12:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:37,902 Request with ID 02831daf for model distilgpt2-124m received
2024-09-10 12:12:37,902 Adjusted time limit based on total queue size 14: 3.0000 seconds
2024-09-10 12:12:37,902 127.0.0.1 - - [10/Sep/2024 12:12:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:38,065 Request with ID c66818a2 for model distilgpt2-124m received
2024-09-10 12:12:38,065 Adjusted time limit based on total queue size 15: 3.0000 seconds
2024-09-10 12:12:38,065 127.0.0.1 - - [10/Sep/2024 12:12:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:38,317 Time limit condition met for model gpt2-124m
2024-09-10 12:12:38,317 Updated batch size:8
2024-09-10 12:12:38,317 Loading model gpt2-124m
2024-09-10 12:12:38,501 Request with ID 45d14add for model distilgpt2-124m received
2024-09-10 12:12:38,501 Adjusted time limit based on total queue size 10: 3.0000 seconds
2024-09-10 12:12:38,501 127.0.0.1 - - [10/Sep/2024 12:12:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:38,760 Request with ID 5be96531 for model distilgpt2-124m received
2024-09-10 12:12:38,760 Adjusted time limit based on total queue size 11: 3.0000 seconds
2024-09-10 12:12:38,760 127.0.0.1 - - [10/Sep/2024 12:12:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:39,056 Request with ID f401be58 for model distilgpt2-124m received
2024-09-10 12:12:39,056 Adjusted time limit based on total queue size 12: 3.0000 seconds
2024-09-10 12:12:39,057 127.0.0.1 - - [10/Sep/2024 12:12:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:39,410 Request with ID fbdbfdd0 for model distilgpt2-124m received
2024-09-10 12:12:39,410 Adjusted time limit based on total queue size 13: 3.0000 seconds
2024-09-10 12:12:39,410 127.0.0.1 - - [10/Sep/2024 12:12:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:39,642 Request with ID 2bb8dd5e for model distilgpt2-124m received
2024-09-10 12:12:39,642 Adjusted time limit based on total queue size 14: 3.0000 seconds
2024-09-10 12:12:39,642 127.0.0.1 - - [10/Sep/2024 12:12:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:39,670 Processed batch: ['60d38b77', '38a3511b', 'd37b31b2', '65673a60', '00d8ed02', '4f1fb71c', 'a548', 'c0a9'] with model gpt2-124m in 1.2683 seconds
2024-09-10 12:12:39,670 Latency for request 60d38b77 with model gpt2-124m: 7.1508 seconds
2024-09-10 12:12:39,671 Latency for request 38a3511b with model gpt2-124m: 6.1635 seconds
2024-09-10 12:12:39,671 Latency for request d37b31b2 with model gpt2-124m: 4.1344 seconds
2024-09-10 12:12:39,671 Latency for request 65673a60 with model gpt2-124m: 3.6082 seconds
2024-09-10 12:12:39,672 Latency for request 00d8ed02 with model gpt2-124m: 3.5930 seconds
2024-09-10 12:12:39,672 Latency for request 4f1fb71c with model gpt2-124m: 3.0514 seconds
2024-09-10 12:12:39,672 Latency for request a548 with model gpt2-124m: 1.3527 seconds
2024-09-10 12:12:39,672 Latency for request c0a9 with model gpt2-124m: 1.3527 seconds
2024-09-10 12:12:40,592 Request with ID 95f4dbc9 for model gpt2medium-355m received
2024-09-10 12:12:40,592 Adjusted time limit based on total queue size 15: 3.0000 seconds
2024-09-10 12:12:40,592 127.0.0.1 - - [10/Sep/2024 12:12:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:40,898 Request with ID 1de3b984 for model gpt2-124m received
2024-09-10 12:12:40,898 Adjusted time limit based on total queue size 16: 1.5000 seconds
2024-09-10 12:12:40,898 Adjusted time limit for model gpt2-124m: 5.7692 seconds
2024-09-10 12:12:40,899 127.0.0.1 - - [10/Sep/2024 12:12:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:41,649 Time limit condition met for model gpt2medium-355m
2024-09-10 12:12:41,649 Updated batch size:8
2024-09-10 12:12:41,649 Loading model gpt2medium-355m
2024-09-10 12:12:42,142 Request with ID 52c92e76 for model gpt2-124m received
2024-09-10 12:12:42,142 Adjusted time limit based on total queue size 11: 3.0000 seconds
2024-09-10 12:12:42,143 127.0.0.1 - - [10/Sep/2024 12:12:42] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:42,911 Request with ID b72438b8 for model distilgpt2-124m received
2024-09-10 12:12:42,911 Adjusted time limit based on total queue size 12: 3.0000 seconds
2024-09-10 12:12:42,911 127.0.0.1 - - [10/Sep/2024 12:12:42] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:43,527 Request with ID f433fbd1 for model distilgpt2-124m received
2024-09-10 12:12:43,527 Adjusted time limit based on total queue size 13: 3.0000 seconds
2024-09-10 12:12:43,528 127.0.0.1 - - [10/Sep/2024 12:12:43] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:43,714 Request with ID b2e7cf03 for model gpt2-124m received
2024-09-10 12:12:43,714 Adjusted time limit based on total queue size 14: 3.0000 seconds
2024-09-10 12:12:43,714 127.0.0.1 - - [10/Sep/2024 12:12:43] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:44,454 Request with ID 371485b3 for model gpt2-124m received
2024-09-10 12:12:44,454 Adjusted time limit based on total queue size 15: 3.0000 seconds
2024-09-10 12:12:44,454 127.0.0.1 - - [10/Sep/2024 12:12:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:44,587 Request with ID f3ed9242 for model gpt2-124m received
2024-09-10 12:12:44,587 Adjusted time limit based on total queue size 16: 1.5000 seconds
2024-09-10 12:12:44,587 127.0.0.1 - - [10/Sep/2024 12:12:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:44,910 Request with ID 63ec3b0e for model gpt2-124m received
2024-09-10 12:12:44,910 Adjusted time limit based on total queue size 17: 1.5000 seconds
2024-09-10 12:12:44,910 127.0.0.1 - - [10/Sep/2024 12:12:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:12:45,583 Processed batch: ['79df835c', '207904a8', 'cfcc2466', 'af96953c', 'fb209fbe', '95f4dbc9', 'cd9d', '99fe'] with model gpt2medium-355m in 3.8068 seconds
2024-09-10 12:12:45,583 Latency for request 79df835c with model gpt2medium-355m: 13.6008 seconds
2024-09-10 12:12:45,584 Latency for request 207904a8 with model gpt2medium-355m: 12.6170 seconds
2024-09-10 12:12:45,584 Latency for request cfcc2466 with model gpt2medium-355m: 12.2882 seconds
2024-09-10 12:12:45,584 Latency for request af96953c with model gpt2medium-355m: 11.3692 seconds
2024-09-10 12:12:45,585 Latency for request fb209fbe with model gpt2medium-355m: 9.8331 seconds
2024-09-10 12:12:45,585 Latency for request 95f4dbc9 with model gpt2medium-355m: 4.9906 seconds
2024-09-10 12:12:45,585 Latency for request cd9d with model gpt2medium-355m: 3.9338 seconds
2024-09-10 12:12:45,585 Latency for request 99fe with model gpt2medium-355m: 3.9337 seconds
2024-09-10 12:12:45,690 Time limit condition met for model distilgpt2-124m
2024-09-10 12:12:45,690 Updated batch size:16
2024-09-10 12:12:45,690 Loading model distilgpt2-124m
2024-09-10 12:12:46,881 Processed batch: ['bb9f2e27', '3b19d5a9', '02831daf', 'c66818a2', '45d14add', '5be96531', 'f401be58', 'fbdbfdd0', '2bb8dd5e', 'b72438b8', 'f433fbd1', '27cb', '576a', '18b4', '000f', '55bd'] with model distilgpt2-124m in 1.1308 seconds
2024-09-10 12:12:46,882 Latency for request bb9f2e27 with model distilgpt2-124m: 9.9813 seconds
2024-09-10 12:12:46,882 Latency for request 3b19d5a9 with model distilgpt2-124m: 9.7202 seconds
2024-09-10 12:12:46,883 Latency for request 02831daf with model distilgpt2-124m: 8.9798 seconds
2024-09-10 12:12:46,883 Latency for request c66818a2 with model distilgpt2-124m: 8.8165 seconds
2024-09-10 12:12:46,883 Latency for request 45d14add with model distilgpt2-124m: 8.3802 seconds
2024-09-10 12:12:46,884 Latency for request 5be96531 with model distilgpt2-124m: 8.1216 seconds
2024-09-10 12:12:46,884 Latency for request f401be58 with model distilgpt2-124m: 7.8252 seconds
2024-09-10 12:12:46,884 Latency for request fbdbfdd0 with model distilgpt2-124m: 7.4715 seconds
2024-09-10 12:12:46,884 Latency for request 2bb8dd5e with model distilgpt2-124m: 7.2397 seconds
2024-09-10 12:12:46,884 Latency for request b72438b8 with model distilgpt2-124m: 3.9702 seconds
2024-09-10 12:12:46,885 Latency for request f433fbd1 with model distilgpt2-124m: 3.3542 seconds
2024-09-10 12:12:46,885 Latency for request 27cb with model distilgpt2-124m: 1.1918 seconds
2024-09-10 12:12:46,885 Latency for request 576a with model distilgpt2-124m: 1.1918 seconds
2024-09-10 12:12:46,885 Latency for request 18b4 with model distilgpt2-124m: 1.1918 seconds
2024-09-10 12:12:46,886 Latency for request 000f with model distilgpt2-124m: 1.1918 seconds
2024-09-10 12:12:46,886 Latency for request 55bd with model distilgpt2-124m: 1.1918 seconds
2024-09-10 12:12:46,990 Time limit condition met for model gpt2-124m
2024-09-10 12:12:46,990 Updated batch size:8
2024-09-10 12:12:46,991 Loading model gpt2-124m
2024-09-10 12:12:48,241 Processed batch: ['1de3b984', '52c92e76', 'b2e7cf03', '371485b3', 'f3ed9242', '63ec3b0e', '9dc6', '2e98'] with model gpt2-124m in 1.1864 seconds
2024-09-10 12:12:48,241 Latency for request 1de3b984 with model gpt2-124m: 7.3437 seconds
2024-09-10 12:12:48,243 Latency for request 52c92e76 with model gpt2-124m: 6.0990 seconds
2024-09-10 12:12:48,243 Latency for request b2e7cf03 with model gpt2-124m: 4.5275 seconds
2024-09-10 12:12:48,243 Latency for request 371485b3 with model gpt2-124m: 3.7876 seconds
2024-09-10 12:12:48,243 Latency for request f3ed9242 with model gpt2-124m: 3.6541 seconds
2024-09-10 12:12:48,244 Latency for request 63ec3b0e with model gpt2-124m: 3.3313 seconds
2024-09-10 12:12:48,244 Latency for request 9dc6 with model gpt2-124m: 1.2508 seconds
2024-09-10 12:12:48,244 Latency for request 2e98 with model gpt2-124m: 1.2508 seconds
