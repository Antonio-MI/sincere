2024-09-11 11:39:39,835 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.212:5000
2024-09-11 11:39:39,835 [33mPress CTRL+C to quit[0m
2024-09-11 11:39:43,288 Request with ID 0b972cae for model gpt2-124m received
2024-09-11 11:39:43,288 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-11 11:39:43,288 Adjusted time limit for model gpt2-124m: 13.6926 seconds
2024-09-11 11:39:43,288 127.0.0.1 - - [11/Sep/2024 11:39:43] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:39:43,309 Remaining requests condition met for model gpt2-124m
2024-09-11 11:39:43,309 Updated batch size:1
2024-09-11 11:39:43,309 Loading model gpt2-124m
2024-09-11 11:39:43,769 Processed batch: ['0b972cae'] with model gpt2-124m in 0.3820 seconds
2024-09-11 11:39:43,769 Latency for request 0b972cae with model gpt2-124m: 0.4813 seconds
2024-09-11 11:39:44,113 Request with ID a30fbebb for model gpt2-124m received
2024-09-11 11:39:44,113 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-11 11:39:44,113 Adjusted time limit for model gpt2-124m: 13.6858 seconds
2024-09-11 11:39:44,114 127.0.0.1 - - [11/Sep/2024 11:39:44] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:39:44,448 Request with ID a8f2b204 for model gpt2medium-355m received
2024-09-11 11:39:44,449 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-11 11:39:44,449 Adjusted time limit for model gpt2medium-355m: 11.8798 seconds
2024-09-11 11:39:44,450 127.0.0.1 - - [11/Sep/2024 11:39:44] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:39:44,511 Request with ID f412374a for model gpt2-124m received
2024-09-11 11:39:44,511 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-11 11:39:44,511 127.0.0.1 - - [11/Sep/2024 11:39:44] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:39:44,883 Request with ID 6d8f7c4f for model gpt2-124m received
2024-09-11 11:39:44,883 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-11 11:39:44,883 127.0.0.1 - - [11/Sep/2024 11:39:44] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:39:45,547 Request with ID e8f9780f for model distilgpt2-124m received
2024-09-11 11:39:45,547 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-11 11:39:45,547 Adjusted time limit for model distilgpt2-124m: 14.1814 seconds
2024-09-11 11:39:45,547 127.0.0.1 - - [11/Sep/2024 11:39:45] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:39:46,156 Request with ID 36e91002 for model distilgpt2-124m received
2024-09-11 11:39:46,156 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-11 11:39:46,157 127.0.0.1 - - [11/Sep/2024 11:39:46] "POST /inference HTTP/1.1" 200 -
