2024-09-10 12:06:32,894 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.11.77:5000
2024-09-10 12:06:32,894 [33mPress CTRL+C to quit[0m
2024-09-10 12:06:32,924 Request with ID b02bff3a for model gpt2-124m received
2024-09-10 12:06:32,925 Adjusted time limit based on total queue size 1: 6.0000 seconds
2024-09-10 12:06:32,925 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 12:06:32,926 127.0.0.1 - - [10/Sep/2024 12:06:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:33,003 Time limit condition met for model gpt2-124m
2024-09-10 12:06:33,003 Updated batch size:4
2024-09-10 12:06:33,003 Loading model gpt2-124m
2024-09-10 12:06:33,065 Request with ID b56738a0 for model gpt2-124m received
2024-09-10 12:06:33,066 Adjusted time limit based on total queue size 1: 6.0000 seconds
2024-09-10 12:06:33,066 127.0.0.1 - - [10/Sep/2024 12:06:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:33,285 Request with ID 47a9e940 for model gpt2medium-355m received
2024-09-10 12:06:33,286 Adjusted time limit based on total queue size 2: 6.0000 seconds
2024-09-10 12:06:33,286 Adjusted time limit for model gpt2medium-355m: 0.0000 seconds
2024-09-10 12:06:33,286 127.0.0.1 - - [10/Sep/2024 12:06:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:33,333 Request with ID 4c1821c9 for model gpt2-124m received
2024-09-10 12:06:33,333 Adjusted time limit based on total queue size 3: 6.0000 seconds
2024-09-10 12:06:33,333 127.0.0.1 - - [10/Sep/2024 12:06:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:33,611 Request with ID 1bd74161 for model gpt2-124m received
2024-09-10 12:06:33,612 Adjusted time limit based on total queue size 4: 4.5000 seconds
2024-09-10 12:06:33,612 127.0.0.1 - - [10/Sep/2024 12:06:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:33,827 Processed batch: ['b02bff3a', '0ee2', 'af35', '9b06'] with model gpt2-124m in 0.6763 seconds
2024-09-10 12:06:33,827 Latency for request b02bff3a with model gpt2-124m: 0.9029 seconds
2024-09-10 12:06:33,829 Latency for request 0ee2 with model gpt2-124m: 0.8241 seconds
2024-09-10 12:06:33,829 Latency for request af35 with model gpt2-124m: 0.8240 seconds
2024-09-10 12:06:33,830 Latency for request 9b06 with model gpt2-124m: 0.8240 seconds
2024-09-10 12:06:33,932 Time limit condition met for model gpt2medium-355m
2024-09-10 12:06:33,932 Updated batch size:4
2024-09-10 12:06:33,932 Loading model gpt2medium-355m
2024-09-10 12:06:34,110 Request with ID cadd593f for model distilgpt2-124m received
2024-09-10 12:06:34,110 Adjusted time limit based on total queue size 4: 4.5000 seconds
2024-09-10 12:06:34,110 Adjusted time limit for model distilgpt2-124m: 1.9511 seconds
2024-09-10 12:06:34,110 127.0.0.1 - - [10/Sep/2024 12:06:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:34,566 Request with ID f9cfa938 for model distilgpt2-124m received
2024-09-10 12:06:34,567 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:06:34,567 127.0.0.1 - - [10/Sep/2024 12:06:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:34,991 Request with ID 73285b8c for model gpt2medium-355m received
2024-09-10 12:06:34,991 Adjusted time limit based on total queue size 6: 4.5000 seconds
2024-09-10 12:06:34,991 127.0.0.1 - - [10/Sep/2024 12:06:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:35,286 Request with ID c1ad4629 for model distilgpt2-124m received
2024-09-10 12:06:35,286 Adjusted time limit based on total queue size 7: 4.5000 seconds
2024-09-10 12:06:35,286 127.0.0.1 - - [10/Sep/2024 12:06:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:35,628 Request with ID 17c985f2 for model gpt2medium-355m received
2024-09-10 12:06:35,628 Adjusted time limit based on total queue size 8: 2.4000 seconds
2024-09-10 12:06:35,628 127.0.0.1 - - [10/Sep/2024 12:06:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:35,995 Request with ID 30c6c0a1 for model gpt2-124m received
2024-09-10 12:06:35,995 Adjusted time limit based on total queue size 9: 2.4000 seconds
2024-09-10 12:06:35,996 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 12:06:35,996 127.0.0.1 - - [10/Sep/2024 12:06:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:36,454 Request with ID 2a70004b for model gpt2medium-355m received
2024-09-10 12:06:36,454 Adjusted time limit based on total queue size 10: 2.4000 seconds
2024-09-10 12:06:36,455 127.0.0.1 - - [10/Sep/2024 12:06:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:36,727 Request with ID 93f18bd8 for model gpt2-124m received
2024-09-10 12:06:36,727 Adjusted time limit based on total queue size 11: 2.4000 seconds
2024-09-10 12:06:36,727 127.0.0.1 - - [10/Sep/2024 12:06:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:36,980 Request with ID 9e401586 for model distilgpt2-124m received
2024-09-10 12:06:36,980 Adjusted time limit based on total queue size 12: 2.4000 seconds
2024-09-10 12:06:36,980 127.0.0.1 - - [10/Sep/2024 12:06:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:37,299 Processed batch: ['47a9e940', '30dd', '8f73', '836e'] with model gpt2medium-355m in 3.2560 seconds
2024-09-10 12:06:37,299 Latency for request 47a9e940 with model gpt2medium-355m: 4.0137 seconds
2024-09-10 12:06:37,300 Latency for request 30dd with model gpt2medium-355m: 3.3670 seconds
2024-09-10 12:06:37,300 Latency for request 8f73 with model gpt2medium-355m: 3.3670 seconds
2024-09-10 12:06:37,300 Latency for request 836e with model gpt2medium-355m: 3.3670 seconds
2024-09-10 12:06:37,402 Time limit condition met for model gpt2-124m
2024-09-10 12:06:37,402 Updated batch size:8
2024-09-10 12:06:37,403 Loading model gpt2-124m
2024-09-10 12:06:37,784 Request with ID 5046c608 for model gpt2-124m received
2024-09-10 12:06:37,785 Adjusted time limit based on total queue size 8: 2.4000 seconds
2024-09-10 12:06:37,785 127.0.0.1 - - [10/Sep/2024 12:06:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:38,606 Processed batch: ['b56738a0', '4c1821c9', '1bd74161', '30c6c0a1', '93f18bd8', '7991', '02d9', '57d1'] with model gpt2-124m in 1.1434 seconds
2024-09-10 12:06:38,607 Latency for request b56738a0 with model gpt2-124m: 5.5411 seconds
2024-09-10 12:06:38,607 Latency for request 4c1821c9 with model gpt2-124m: 5.2733 seconds
2024-09-10 12:06:38,608 Latency for request 1bd74161 with model gpt2-124m: 4.9950 seconds
2024-09-10 12:06:38,608 Latency for request 30c6c0a1 with model gpt2-124m: 2.6111 seconds
2024-09-10 12:06:38,608 Latency for request 93f18bd8 with model gpt2-124m: 1.8796 seconds
2024-09-10 12:06:38,608 Latency for request 7991 with model gpt2-124m: 1.2040 seconds
2024-09-10 12:06:38,609 Latency for request 02d9 with model gpt2-124m: 1.2040 seconds
2024-09-10 12:06:38,609 Latency for request 57d1 with model gpt2-124m: 1.2040 seconds
2024-09-10 12:06:38,609 Time limit condition met for model distilgpt2-124m
2024-09-10 12:06:38,609 Updated batch size:4
2024-09-10 12:06:38,609 Loading model distilgpt2-124m
2024-09-10 12:06:38,684 Request with ID 6991bced for model gpt2-124m received
2024-09-10 12:06:38,684 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:06:38,684 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 12:06:38,684 127.0.0.1 - - [10/Sep/2024 12:06:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:39,235 Request with ID 630e01ea for model distilgpt2-124m received
2024-09-10 12:06:39,235 Adjusted time limit based on total queue size 6: 4.5000 seconds
2024-09-10 12:06:39,235 127.0.0.1 - - [10/Sep/2024 12:06:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:39,311 Processed batch: ['cadd593f', 'f9cfa938', 'c1ad4629', '9e401586'] with model distilgpt2-124m in 0.6310 seconds
2024-09-10 12:06:39,311 Latency for request cadd593f with model distilgpt2-124m: 5.2015 seconds
2024-09-10 12:06:39,312 Latency for request f9cfa938 with model distilgpt2-124m: 4.7445 seconds
2024-09-10 12:06:39,312 Latency for request c1ad4629 with model distilgpt2-124m: 4.0253 seconds
2024-09-10 12:06:39,313 Latency for request 9e401586 with model distilgpt2-124m: 2.3312 seconds
2024-09-10 12:06:39,415 Time limit condition met for model gpt2-124m
2024-09-10 12:06:39,415 Updated batch size:4
2024-09-10 12:06:39,415 Loading model gpt2-124m
2024-09-10 12:06:40,216 Processed batch: ['5046c608', '6991bced', '7e9b', '04aa'] with model gpt2-124m in 0.7397 seconds
2024-09-10 12:06:40,216 Latency for request 5046c608 with model gpt2-124m: 2.4312 seconds
2024-09-10 12:06:40,217 Latency for request 6991bced with model gpt2-124m: 1.5315 seconds
2024-09-10 12:06:40,217 Latency for request 7e9b with model gpt2-124m: 0.8004 seconds
2024-09-10 12:06:40,217 Latency for request 04aa with model gpt2-124m: 0.8004 seconds
2024-09-10 12:06:41,349 Request with ID 70c9bb8c for model gpt2-124m received
2024-09-10 12:06:41,349 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:06:41,349 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 12:06:41,350 127.0.0.1 - - [10/Sep/2024 12:06:41] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:41,363 Time limit condition met for model gpt2-124m
2024-09-10 12:06:41,363 Updated batch size:4
2024-09-10 12:06:41,363 Loading model gpt2-124m
2024-09-10 12:06:42,052 Processed batch: ['70c9bb8c', 'f285', '8e86', '76a5'] with model gpt2-124m in 0.6879 seconds
2024-09-10 12:06:42,052 Latency for request 70c9bb8c with model gpt2-124m: 0.7030 seconds
2024-09-10 12:06:42,053 Latency for request f285 with model gpt2-124m: 0.6886 seconds
2024-09-10 12:06:42,053 Latency for request 8e86 with model gpt2-124m: 0.6886 seconds
2024-09-10 12:06:42,053 Latency for request 76a5 with model gpt2-124m: 0.6886 seconds
2024-09-10 12:06:42,282 Request with ID 31b240dd for model gpt2medium-355m received
2024-09-10 12:06:42,282 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:06:42,282 Adjusted time limit for model gpt2medium-355m: 0.0000 seconds
2024-09-10 12:06:42,282 127.0.0.1 - - [10/Sep/2024 12:06:42] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:42,365 Time limit condition met for model gpt2medium-355m
2024-09-10 12:06:42,365 Updated batch size:4
2024-09-10 12:06:42,365 Loading model gpt2medium-355m
2024-09-10 12:06:42,986 Request with ID 41a984d0 for model gpt2medium-355m received
2024-09-10 12:06:42,986 Adjusted time limit based on total queue size 2: 6.0000 seconds
2024-09-10 12:06:42,986 127.0.0.1 - - [10/Sep/2024 12:06:42] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:43,462 Request with ID f2ad56aa for model gpt2medium-355m received
2024-09-10 12:06:43,462 Adjusted time limit based on total queue size 3: 6.0000 seconds
2024-09-10 12:06:43,462 127.0.0.1 - - [10/Sep/2024 12:06:43] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:44,330 Request with ID 108167c5 for model gpt2medium-355m received
2024-09-10 12:06:44,330 Adjusted time limit based on total queue size 4: 4.5000 seconds
2024-09-10 12:06:44,330 127.0.0.1 - - [10/Sep/2024 12:06:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:44,861 Request with ID 34173766 for model gpt2-124m received
2024-09-10 12:06:44,862 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:06:44,862 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 12:06:44,862 127.0.0.1 - - [10/Sep/2024 12:06:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:44,956 Processed batch: ['73285b8c', '17c985f2', '2a70004b', '31b240dd'] with model gpt2medium-355m in 2.4285 seconds
2024-09-10 12:06:44,956 Latency for request 73285b8c with model gpt2medium-355m: 9.9647 seconds
2024-09-10 12:06:44,957 Latency for request 17c985f2 with model gpt2medium-355m: 9.3277 seconds
2024-09-10 12:06:44,957 Latency for request 2a70004b with model gpt2medium-355m: 8.5014 seconds
2024-09-10 12:06:44,958 Latency for request 31b240dd with model gpt2medium-355m: 2.6741 seconds
2024-09-10 12:06:45,063 Time limit condition met for model gpt2-124m
2024-09-10 12:06:45,063 Updated batch size:4
2024-09-10 12:06:45,063 Loading model gpt2-124m
2024-09-10 12:06:45,166 Request with ID 13b49216 for model distilgpt2-124m received
2024-09-10 12:06:45,167 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:06:45,167 Adjusted time limit for model distilgpt2-124m: 1.9550 seconds
2024-09-10 12:06:45,167 127.0.0.1 - - [10/Sep/2024 12:06:45] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:45,962 Request with ID f2c313a8 for model distilgpt2-124m received
2024-09-10 12:06:45,963 Adjusted time limit based on total queue size 6: 4.5000 seconds
2024-09-10 12:06:45,963 127.0.0.1 - - [10/Sep/2024 12:06:45] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:46,022 Processed batch: ['34173766', '5337', '19ba', '968e'] with model gpt2-124m in 0.8987 seconds
2024-09-10 12:06:46,022 Latency for request 34173766 with model gpt2-124m: 1.1609 seconds
2024-09-10 12:06:46,024 Latency for request 5337 with model gpt2-124m: 0.9593 seconds
2024-09-10 12:06:46,024 Latency for request 19ba with model gpt2-124m: 0.9593 seconds
2024-09-10 12:06:46,024 Latency for request 968e with model gpt2-124m: 0.9593 seconds
2024-09-10 12:06:46,641 Request with ID 97c16485 for model distilgpt2-124m received
2024-09-10 12:06:46,641 Adjusted time limit based on total queue size 7: 4.5000 seconds
2024-09-10 12:06:46,641 127.0.0.1 - - [10/Sep/2024 12:06:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:46,738 Request with ID c65138ff for model gpt2-124m received
2024-09-10 12:06:46,739 Adjusted time limit based on total queue size 8: 2.4000 seconds
2024-09-10 12:06:46,739 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 12:06:46,739 127.0.0.1 - - [10/Sep/2024 12:06:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:46,749 Time limit condition met for model gpt2-124m
2024-09-10 12:06:46,749 Updated batch size:4
2024-09-10 12:06:46,749 Loading model gpt2-124m
2024-09-10 12:06:47,361 Processed batch: ['c65138ff', 'fa76', '4043', '1f6e'] with model gpt2-124m in 0.6113 seconds
2024-09-10 12:06:47,361 Latency for request c65138ff with model gpt2-124m: 0.6224 seconds
2024-09-10 12:06:47,362 Latency for request fa76 with model gpt2-124m: 0.6118 seconds
2024-09-10 12:06:47,362 Latency for request 4043 with model gpt2-124m: 0.6118 seconds
2024-09-10 12:06:47,362 Latency for request 1f6e with model gpt2-124m: 0.6118 seconds
2024-09-10 12:06:47,465 Time limit condition met for model distilgpt2-124m
2024-09-10 12:06:47,465 Updated batch size:4
2024-09-10 12:06:47,465 Loading model distilgpt2-124m
2024-09-10 12:06:47,620 Request with ID d5fd1499 for model gpt2medium-355m received
2024-09-10 12:06:47,620 Adjusted time limit based on total queue size 4: 4.5000 seconds
2024-09-10 12:06:47,620 Adjusted time limit for model gpt2medium-355m: 0.0000 seconds
2024-09-10 12:06:47,620 127.0.0.1 - - [10/Sep/2024 12:06:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:48,156 Processed batch: ['630e01ea', '13b49216', 'f2c313a8', '97c16485'] with model distilgpt2-124m in 0.6436 seconds
2024-09-10 12:06:48,156 Latency for request 630e01ea with model distilgpt2-124m: 8.9210 seconds
2024-09-10 12:06:48,157 Latency for request 13b49216 with model distilgpt2-124m: 2.9896 seconds
2024-09-10 12:06:48,157 Latency for request f2c313a8 with model distilgpt2-124m: 2.1936 seconds
2024-09-10 12:06:48,158 Latency for request 97c16485 with model distilgpt2-124m: 1.5154 seconds
2024-09-10 12:06:48,204 Request with ID 8ff7aba4 for model gpt2medium-355m received
2024-09-10 12:06:48,204 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:06:48,204 127.0.0.1 - - [10/Sep/2024 12:06:48] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:48,263 Time limit condition met for model gpt2medium-355m
2024-09-10 12:06:48,263 Updated batch size:8
2024-09-10 12:06:48,263 Loading model gpt2medium-355m
2024-09-10 12:06:48,300 Request with ID 02b8353e for model gpt2medium-355m received
2024-09-10 12:06:48,301 Adjusted time limit based on total queue size 1: 6.0000 seconds
2024-09-10 12:06:48,320 127.0.0.1 - - [10/Sep/2024 12:06:48] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:49,392 Request with ID 1b3fefda for model gpt2medium-355m received
2024-09-10 12:06:49,393 Adjusted time limit based on total queue size 2: 6.0000 seconds
2024-09-10 12:06:49,393 127.0.0.1 - - [10/Sep/2024 12:06:49] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:49,928 Request with ID 1b6e7856 for model gpt2-124m received
2024-09-10 12:06:49,928 Adjusted time limit based on total queue size 3: 6.0000 seconds
2024-09-10 12:06:49,928 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 12:06:49,928 127.0.0.1 - - [10/Sep/2024 12:06:49] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:50,375 Request with ID 17a56487 for model gpt2medium-355m received
2024-09-10 12:06:50,375 Adjusted time limit based on total queue size 4: 4.5000 seconds
2024-09-10 12:06:50,375 127.0.0.1 - - [10/Sep/2024 12:06:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:50,704 Request with ID c5a59f94 for model gpt2medium-355m received
2024-09-10 12:06:50,704 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:06:50,704 127.0.0.1 - - [10/Sep/2024 12:06:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:50,915 Request with ID 0fc47f38 for model gpt2-124m received
2024-09-10 12:06:50,916 Adjusted time limit based on total queue size 6: 4.5000 seconds
2024-09-10 12:06:50,916 127.0.0.1 - - [10/Sep/2024 12:06:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:51,623 Request with ID a82c1510 for model gpt2medium-355m received
2024-09-10 12:06:51,623 Adjusted time limit based on total queue size 7: 4.5000 seconds
2024-09-10 12:06:51,623 127.0.0.1 - - [10/Sep/2024 12:06:51] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:51,771 Processed batch: ['41a984d0', 'f2ad56aa', '108167c5', 'd5fd1499', '8ff7aba4', '5f48', 'c1a1', 'f764'] with model gpt2medium-355m in 3.3899 seconds
2024-09-10 12:06:51,771 Latency for request 41a984d0 with model gpt2medium-355m: 8.7852 seconds
2024-09-10 12:06:51,772 Latency for request f2ad56aa with model gpt2medium-355m: 8.3094 seconds
2024-09-10 12:06:51,772 Latency for request 108167c5 with model gpt2medium-355m: 7.4413 seconds
2024-09-10 12:06:51,773 Latency for request d5fd1499 with model gpt2medium-355m: 4.1512 seconds
2024-09-10 12:06:51,773 Latency for request 8ff7aba4 with model gpt2medium-355m: 3.5676 seconds
2024-09-10 12:06:51,773 Latency for request 5f48 with model gpt2medium-355m: 3.5080 seconds
2024-09-10 12:06:51,773 Latency for request c1a1 with model gpt2medium-355m: 3.5080 seconds
2024-09-10 12:06:51,773 Latency for request f764 with model gpt2medium-355m: 3.5080 seconds
2024-09-10 12:06:51,875 Time limit condition met for model gpt2-124m
2024-09-10 12:06:51,875 Updated batch size:4
2024-09-10 12:06:51,875 Loading model gpt2-124m
2024-09-10 12:06:52,412 Request with ID 5e1a2cd8 for model distilgpt2-124m received
2024-09-10 12:06:52,412 Adjusted time limit based on total queue size 6: 4.5000 seconds
2024-09-10 12:06:52,412 Adjusted time limit for model distilgpt2-124m: 1.9550 seconds
2024-09-10 12:06:52,412 127.0.0.1 - - [10/Sep/2024 12:06:52] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:52,816 Processed batch: ['1b6e7856', '0fc47f38', 'd4dc', 'eea9'] with model gpt2-124m in 0.8703 seconds
2024-09-10 12:06:52,816 Latency for request 1b6e7856 with model gpt2-124m: 2.8877 seconds
2024-09-10 12:06:52,817 Latency for request 0fc47f38 with model gpt2-124m: 1.9005 seconds
2024-09-10 12:06:52,817 Latency for request d4dc with model gpt2-124m: 0.9407 seconds
2024-09-10 12:06:52,818 Latency for request eea9 with model gpt2-124m: 0.9407 seconds
2024-09-10 12:06:52,945 Request with ID f99e0eb9 for model gpt2-124m received
2024-09-10 12:06:52,945 Adjusted time limit based on total queue size 7: 4.5000 seconds
2024-09-10 12:06:52,945 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 12:06:52,945 127.0.0.1 - - [10/Sep/2024 12:06:52] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:53,028 Time limit condition met for model gpt2-124m
2024-09-10 12:06:53,028 Updated batch size:4
2024-09-10 12:06:53,028 Loading model gpt2-124m
2024-09-10 12:06:53,160 Request with ID 68beea5b for model gpt2medium-355m received
2024-09-10 12:06:53,160 Adjusted time limit based on total queue size 7: 4.5000 seconds
2024-09-10 12:06:53,160 Adjusted time limit for model gpt2medium-355m: 0.0000 seconds
2024-09-10 12:06:53,160 127.0.0.1 - - [10/Sep/2024 12:06:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:53,473 Request with ID 480d1808 for model gpt2-124m received
2024-09-10 12:06:53,473 Adjusted time limit based on total queue size 8: 2.4000 seconds
2024-09-10 12:06:53,473 127.0.0.1 - - [10/Sep/2024 12:06:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:53,485 Request with ID 5468840a for model gpt2-124m received
2024-09-10 12:06:53,486 Adjusted time limit based on total queue size 9: 2.4000 seconds
2024-09-10 12:06:53,486 127.0.0.1 - - [10/Sep/2024 12:06:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:53,809 Processed batch: ['f99e0eb9', '3aa7', '45a9', 'c5cb'] with model gpt2-124m in 0.7810 seconds
2024-09-10 12:06:53,810 Latency for request f99e0eb9 with model gpt2-124m: 0.8649 seconds
2024-09-10 12:06:53,810 Latency for request 3aa7 with model gpt2-124m: 0.7812 seconds
2024-09-10 12:06:53,811 Latency for request 45a9 with model gpt2-124m: 0.7812 seconds
2024-09-10 12:06:53,811 Latency for request c5cb with model gpt2-124m: 0.7812 seconds
2024-09-10 12:06:53,913 Time limit condition met for model gpt2medium-355m
2024-09-10 12:06:53,913 Updated batch size:8
2024-09-10 12:06:53,914 Loading model gpt2medium-355m
2024-09-10 12:06:54,025 Request with ID 6db1b9a3 for model gpt2-124m received
2024-09-10 12:06:54,025 Adjusted time limit based on total queue size 4: 4.5000 seconds
2024-09-10 12:06:54,025 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 12:06:54,025 127.0.0.1 - - [10/Sep/2024 12:06:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:54,306 Request with ID 63972d20 for model distilgpt2-124m received
2024-09-10 12:06:54,306 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:06:54,306 127.0.0.1 - - [10/Sep/2024 12:06:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:54,566 Request with ID 2f638480 for model distilgpt2-124m received
2024-09-10 12:06:54,566 Adjusted time limit based on total queue size 6: 4.5000 seconds
2024-09-10 12:06:54,567 127.0.0.1 - - [10/Sep/2024 12:06:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:55,308 Request with ID a08a088c for model distilgpt2-124m received
2024-09-10 12:06:55,308 Adjusted time limit based on total queue size 7: 4.5000 seconds
2024-09-10 12:06:55,308 127.0.0.1 - - [10/Sep/2024 12:06:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:55,470 Request with ID 316f768f for model distilgpt2-124m received
2024-09-10 12:06:55,470 Adjusted time limit based on total queue size 8: 2.4000 seconds
2024-09-10 12:06:55,470 127.0.0.1 - - [10/Sep/2024 12:06:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:55,907 Request with ID 8450d4f6 for model distilgpt2-124m received
2024-09-10 12:06:55,908 Adjusted time limit based on total queue size 9: 2.4000 seconds
2024-09-10 12:06:55,908 127.0.0.1 - - [10/Sep/2024 12:06:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:56,166 Request with ID 971f50f1 for model distilgpt2-124m received
2024-09-10 12:06:56,166 Adjusted time limit based on total queue size 10: 2.4000 seconds
2024-09-10 12:06:56,167 127.0.0.1 - - [10/Sep/2024 12:06:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:56,462 Request with ID be89fd5d for model distilgpt2-124m received
2024-09-10 12:06:56,463 Adjusted time limit based on total queue size 11: 2.4000 seconds
2024-09-10 12:06:56,463 127.0.0.1 - - [10/Sep/2024 12:06:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:56,816 Request with ID 71400627 for model distilgpt2-124m received
2024-09-10 12:06:56,816 Adjusted time limit based on total queue size 12: 2.4000 seconds
2024-09-10 12:06:56,816 127.0.0.1 - - [10/Sep/2024 12:06:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:57,048 Request with ID d7f636d2 for model distilgpt2-124m received
2024-09-10 12:06:57,048 Adjusted time limit based on total queue size 13: 2.4000 seconds
2024-09-10 12:06:57,048 127.0.0.1 - - [10/Sep/2024 12:06:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:57,975 Processed batch: ['02b8353e', '1b3fefda', '17a56487', 'c5a59f94', 'a82c1510', '68beea5b', 'be29', 'db45'] with model gpt2medium-355m in 3.9477 seconds
2024-09-10 12:06:57,975 Latency for request 02b8353e with model gpt2medium-355m: 9.6747 seconds
2024-09-10 12:06:57,976 Latency for request 1b3fefda with model gpt2medium-355m: 8.5831 seconds
2024-09-10 12:06:57,976 Latency for request 17a56487 with model gpt2medium-355m: 7.6000 seconds
2024-09-10 12:06:57,977 Latency for request c5a59f94 with model gpt2medium-355m: 7.2713 seconds
2024-09-10 12:06:57,977 Latency for request a82c1510 with model gpt2medium-355m: 6.3526 seconds
2024-09-10 12:06:57,977 Latency for request 68beea5b with model gpt2medium-355m: 4.8152 seconds
2024-09-10 12:06:57,977 Latency for request be29 with model gpt2medium-355m: 4.0616 seconds
2024-09-10 12:06:57,978 Latency for request db45 with model gpt2medium-355m: 4.0616 seconds
2024-09-10 12:06:57,996 Request with ID be81554b for model gpt2medium-355m received
2024-09-10 12:06:57,996 Adjusted time limit based on total queue size 14: 2.4000 seconds
2024-09-10 12:06:57,996 Adjusted time limit for model gpt2medium-355m: 0.0000 seconds
2024-09-10 12:06:57,996 127.0.0.1 - - [10/Sep/2024 12:06:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:58,082 Time limit condition met for model gpt2-124m
2024-09-10 12:06:58,082 Updated batch size:4
2024-09-10 12:06:58,082 Loading model gpt2-124m
2024-09-10 12:06:58,300 Request with ID 53a70439 for model gpt2-124m received
2024-09-10 12:06:58,300 Adjusted time limit based on total queue size 12: 2.4000 seconds
2024-09-10 12:06:58,300 127.0.0.1 - - [10/Sep/2024 12:06:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:06:59,022 Processed batch: ['480d1808', '5468840a', '6db1b9a3', '1fa2'] with model gpt2-124m in 0.8659 seconds
2024-09-10 12:06:59,022 Latency for request 480d1808 with model gpt2-124m: 5.5492 seconds
2024-09-10 12:06:59,023 Latency for request 5468840a with model gpt2-124m: 5.5370 seconds
2024-09-10 12:06:59,023 Latency for request 6db1b9a3 with model gpt2-124m: 4.9973 seconds
2024-09-10 12:06:59,024 Latency for request 1fa2 with model gpt2-124m: 0.9404 seconds
2024-09-10 12:06:59,024 Time limit condition met for model gpt2medium-355m
2024-09-10 12:06:59,024 Updated batch size:4
2024-09-10 12:06:59,024 Loading model gpt2medium-355m
2024-09-10 12:06:59,547 Request with ID e9c3c330 for model gpt2-124m received
2024-09-10 12:06:59,547 Adjusted time limit based on total queue size 12: 2.4000 seconds
2024-09-10 12:06:59,547 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 12:06:59,547 127.0.0.1 - - [10/Sep/2024 12:06:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:07:00,316 Request with ID 4cde5452 for model distilgpt2-124m received
2024-09-10 12:07:00,316 Adjusted time limit based on total queue size 13: 2.4000 seconds
2024-09-10 12:07:00,317 127.0.0.1 - - [10/Sep/2024 12:07:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:07:00,932 Request with ID b330b689 for model distilgpt2-124m received
2024-09-10 12:07:00,933 Adjusted time limit based on total queue size 14: 2.4000 seconds
2024-09-10 12:07:00,933 127.0.0.1 - - [10/Sep/2024 12:07:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:07:01,119 Request with ID df595b0c for model gpt2-124m received
2024-09-10 12:07:01,119 Adjusted time limit based on total queue size 15: 2.4000 seconds
2024-09-10 12:07:01,119 127.0.0.1 - - [10/Sep/2024 12:07:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:07:01,592 Processed batch: ['be81554b', '6f6e', 'fce7', 'c772'] with model gpt2medium-355m in 2.4539 seconds
2024-09-10 12:07:01,592 Latency for request be81554b with model gpt2medium-355m: 3.5962 seconds
2024-09-10 12:07:01,593 Latency for request 6f6e with model gpt2medium-355m: 2.5682 seconds
2024-09-10 12:07:01,594 Latency for request fce7 with model gpt2medium-355m: 2.5682 seconds
2024-09-10 12:07:01,594 Latency for request c772 with model gpt2medium-355m: 2.5682 seconds
2024-09-10 12:07:01,594 Time limit condition met for model distilgpt2-124m
2024-09-10 12:07:01,594 Updated batch size:16
2024-09-10 12:07:01,594 Loading model distilgpt2-124m
2024-09-10 12:07:01,859 Request with ID afd78bdf for model gpt2-124m received
2024-09-10 12:07:01,859 Adjusted time limit based on total queue size 4: 4.5000 seconds
2024-09-10 12:07:01,859 127.0.0.1 - - [10/Sep/2024 12:07:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:07:01,992 Request with ID 71dd07bb for model gpt2-124m received
2024-09-10 12:07:01,992 Adjusted time limit based on total queue size 5: 4.5000 seconds
2024-09-10 12:07:01,992 127.0.0.1 - - [10/Sep/2024 12:07:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:07:02,314 Request with ID 102441cb for model gpt2-124m received
2024-09-10 12:07:02,314 Adjusted time limit based on total queue size 6: 4.5000 seconds
2024-09-10 12:07:02,314 127.0.0.1 - - [10/Sep/2024 12:07:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 12:07:02,821 Processed batch: ['5e1a2cd8', '63972d20', '2f638480', 'a08a088c', '316f768f', '8450d4f6', '971f50f1', 'be89fd5d', '71400627', 'd7f636d2', '4cde5452', 'b330b689', 'cf86', '9a48', '13ef', '52e3'] with model distilgpt2-124m in 1.1681 seconds
2024-09-10 12:07:02,821 Latency for request 5e1a2cd8 with model distilgpt2-124m: 10.4089 seconds
2024-09-10 12:07:02,822 Latency for request 63972d20 with model distilgpt2-124m: 8.5147 seconds
2024-09-10 12:07:02,822 Latency for request 2f638480 with model distilgpt2-124m: 8.2543 seconds
2024-09-10 12:07:02,822 Latency for request a08a088c with model distilgpt2-124m: 7.5126 seconds
2024-09-10 12:07:02,822 Latency for request 316f768f with model distilgpt2-124m: 7.3509 seconds
2024-09-10 12:07:02,823 Latency for request 8450d4f6 with model distilgpt2-124m: 6.9131 seconds
2024-09-10 12:07:02,823 Latency for request 971f50f1 with model distilgpt2-124m: 6.6543 seconds
2024-09-10 12:07:02,823 Latency for request be89fd5d with model distilgpt2-124m: 6.3581 seconds
2024-09-10 12:07:02,823 Latency for request 71400627 with model distilgpt2-124m: 6.0048 seconds
2024-09-10 12:07:02,824 Latency for request d7f636d2 with model distilgpt2-124m: 5.7724 seconds
2024-09-10 12:07:02,824 Latency for request 4cde5452 with model distilgpt2-124m: 2.5043 seconds
2024-09-10 12:07:02,824 Latency for request b330b689 with model distilgpt2-124m: 1.8882 seconds
2024-09-10 12:07:02,824 Latency for request cf86 with model distilgpt2-124m: 1.2264 seconds
2024-09-10 12:07:02,825 Latency for request 9a48 with model distilgpt2-124m: 1.2264 seconds
2024-09-10 12:07:02,825 Latency for request 13ef with model distilgpt2-124m: 1.2264 seconds
2024-09-10 12:07:02,825 Latency for request 52e3 with model distilgpt2-124m: 1.2264 seconds
2024-09-10 12:07:02,930 Time limit condition met for model gpt2-124m
2024-09-10 12:07:02,930 Updated batch size:8
2024-09-10 12:07:02,930 Loading model gpt2-124m
2024-09-10 12:07:04,069 Processed batch: ['53a70439', 'e9c3c330', 'df595b0c', 'afd78bdf', '71dd07bb', '102441cb', 'b813', '8822'] with model gpt2-124m in 1.0753 seconds
2024-09-10 12:07:04,069 Latency for request 53a70439 with model gpt2-124m: 5.7690 seconds
2024-09-10 12:07:04,070 Latency for request e9c3c330 with model gpt2-124m: 4.5220 seconds
2024-09-10 12:07:04,071 Latency for request df595b0c with model gpt2-124m: 2.9504 seconds
2024-09-10 12:07:04,071 Latency for request afd78bdf with model gpt2-124m: 2.2105 seconds
2024-09-10 12:07:04,071 Latency for request 71dd07bb with model gpt2-124m: 2.0770 seconds
2024-09-10 12:07:04,072 Latency for request 102441cb with model gpt2-124m: 1.7551 seconds
2024-09-10 12:07:04,072 Latency for request b813 with model gpt2-124m: 1.1387 seconds
2024-09-10 12:07:04,072 Latency for request 8822 with model gpt2-124m: 1.1387 seconds
