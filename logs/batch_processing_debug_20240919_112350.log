2024-09-19 11:23:50,582 Using device: cpu
2024-09-19 11:23:50,582 Scheduling mode set as batchedFCFS+SLA
2024-09-19 11:23:50,588 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.10.97:5000
2024-09-19 11:23:50,588 [33mPress CTRL+C to quit[0m
2024-09-19 11:23:59,247 Request with ID b21d8c15 for model gpt2-124m received
2024-09-19 11:23:59,247 127.0.0.1 - - [19/Sep/2024 11:23:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:23:59,400 Request with ID e2caa80d for model gpt2-124m received
2024-09-19 11:23:59,401 127.0.0.1 - - [19/Sep/2024 11:23:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:23:59,410 Request with ID aa17925c for model gpt2medium-355m received
2024-09-19 11:23:59,411 127.0.0.1 - - [19/Sep/2024 11:23:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:23:59,508 Request with ID 1cf6e46f for model gpt2-124m received
2024-09-19 11:23:59,508 127.0.0.1 - - [19/Sep/2024 11:23:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:23:59,861 Request with ID faaa37b4 for model gpt2medium-355m received
2024-09-19 11:23:59,861 127.0.0.1 - - [19/Sep/2024 11:23:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:23:59,862 Request with ID 420e6e1e for model gpt2-124m received
2024-09-19 11:23:59,862 127.0.0.1 - - [19/Sep/2024 11:23:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:23:59,901 Request with ID 38b58f7c for model gpt2-124m received
2024-09-19 11:23:59,901 Request with ID 1767e373 for model distilgpt2-124m received
2024-09-19 11:23:59,902 127.0.0.1 - - [19/Sep/2024 11:23:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:23:59,902 127.0.0.1 - - [19/Sep/2024 11:23:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:23:59,919 Request with ID a113da27 for model gpt2-124m received
2024-09-19 11:23:59,919 127.0.0.1 - - [19/Sep/2024 11:23:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:23:59,929 Request with ID aa633eda for model gpt2-124m received
2024-09-19 11:23:59,930 127.0.0.1 - - [19/Sep/2024 11:23:59] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:00,342 Request with ID 95657240 for model gpt2-124m received
2024-09-19 11:24:00,343 127.0.0.1 - - [19/Sep/2024 11:24:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:00,439 Request with ID 15dcfebe for model gpt2-124m received
2024-09-19 11:24:00,439 Request with ID 19ae90f1 for model gpt2medium-355m received
2024-09-19 11:24:00,440 127.0.0.1 - - [19/Sep/2024 11:24:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:00,440 127.0.0.1 - - [19/Sep/2024 11:24:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:00,607 Request with ID 54fb8101 for model gpt2-124m received
2024-09-19 11:24:00,607 127.0.0.1 - - [19/Sep/2024 11:24:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:00,726 Request with ID 16b86319 for model gpt2-124m received
2024-09-19 11:24:00,727 127.0.0.1 - - [19/Sep/2024 11:24:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:00,969 Request with ID e93b7c56 for model gpt2-124m received
2024-09-19 11:24:00,970 127.0.0.1 - - [19/Sep/2024 11:24:00] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:01,112 Request with ID fa0e7301 for model distilgpt2-124m received
2024-09-19 11:24:01,113 127.0.0.1 - - [19/Sep/2024 11:24:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:01,193 Request with ID f59a4cfe for model gpt2medium-355m received
2024-09-19 11:24:01,194 127.0.0.1 - - [19/Sep/2024 11:24:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:01,345 Request with ID b918e3d4 for model gpt2-124m received
2024-09-19 11:24:01,346 127.0.0.1 - - [19/Sep/2024 11:24:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:01,609 Request with ID 1a8e8e60 for model gpt2-124m received
2024-09-19 11:24:01,610 127.0.0.1 - - [19/Sep/2024 11:24:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:01,696 Request with ID 55786133 for model gpt2-124m received
2024-09-19 11:24:01,697 127.0.0.1 - - [19/Sep/2024 11:24:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:01,737 Request with ID e9aa6e61 for model distilgpt2-124m received
2024-09-19 11:24:01,737 127.0.0.1 - - [19/Sep/2024 11:24:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:01,828 Request with ID 9edfc46f for model distilgpt2-124m received
2024-09-19 11:24:01,828 127.0.0.1 - - [19/Sep/2024 11:24:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:01,862 Request with ID e63816fd for model gpt2medium-355m received
2024-09-19 11:24:01,863 127.0.0.1 - - [19/Sep/2024 11:24:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:01,870 Request with ID 686eeb52 for model gpt2-124m received
2024-09-19 11:24:01,871 127.0.0.1 - - [19/Sep/2024 11:24:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:01,909 Request with ID 8cf8f00c for model gpt2-124m received
2024-09-19 11:24:01,910 127.0.0.1 - - [19/Sep/2024 11:24:01] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:02,031 Request with ID b7134f5a for model distilgpt2-124m received
2024-09-19 11:24:02,031 127.0.0.1 - - [19/Sep/2024 11:24:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:02,040 Request with ID 906807b5 for model gpt2medium-355m received
2024-09-19 11:24:02,040 127.0.0.1 - - [19/Sep/2024 11:24:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:02,235 Request with ID 743448bc for model gpt2-124m received
2024-09-19 11:24:02,236 127.0.0.1 - - [19/Sep/2024 11:24:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:02,240 Request with ID 59d53ef0 for model distilgpt2-124m received
2024-09-19 11:24:02,240 127.0.0.1 - - [19/Sep/2024 11:24:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:02,334 Request with ID 117013c3 for model gpt2-124m received
2024-09-19 11:24:02,335 127.0.0.1 - - [19/Sep/2024 11:24:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:02,348 Request with ID 72da3ec4 for model gpt2medium-355m received
2024-09-19 11:24:02,349 127.0.0.1 - - [19/Sep/2024 11:24:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:02,478 Request with ID 9e1b7f96 for model distilgpt2-124m received
2024-09-19 11:24:02,479 127.0.0.1 - - [19/Sep/2024 11:24:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:02,549 Request with ID eed9775e for model distilgpt2-124m received
2024-09-19 11:24:02,549 127.0.0.1 - - [19/Sep/2024 11:24:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:02,562 Request with ID 0323559b for model gpt2-124m received
2024-09-19 11:24:02,562 127.0.0.1 - - [19/Sep/2024 11:24:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:02,791 Request with ID 39ceecee for model distilgpt2-124m received
2024-09-19 11:24:02,791 127.0.0.1 - - [19/Sep/2024 11:24:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:02,912 Request with ID 946d355c for model distilgpt2-124m received
2024-09-19 11:24:02,913 127.0.0.1 - - [19/Sep/2024 11:24:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:02,940 Request with ID 964b5d30 for model distilgpt2-124m received
2024-09-19 11:24:02,940 127.0.0.1 - - [19/Sep/2024 11:24:02] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:03,060 Request with ID c675c188 for model gpt2medium-355m received
2024-09-19 11:24:03,061 127.0.0.1 - - [19/Sep/2024 11:24:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:03,226 Request with ID 6e93a408 for model gpt2medium-355m received
2024-09-19 11:24:03,227 127.0.0.1 - - [19/Sep/2024 11:24:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:03,249 Request with ID f71f90d4 for model distilgpt2-124m received
2024-09-19 11:24:03,250 127.0.0.1 - - [19/Sep/2024 11:24:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:03,414 Request with ID 50eff4f6 for model gpt2-124m received
2024-09-19 11:24:03,414 127.0.0.1 - - [19/Sep/2024 11:24:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:03,428 Request with ID 5e42a83b for model distilgpt2-124m received
2024-09-19 11:24:03,429 127.0.0.1 - - [19/Sep/2024 11:24:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:03,430 Request with ID ab1933e2 for model gpt2medium-355m received
2024-09-19 11:24:03,430 Request with ID f4eba508 for model distilgpt2-124m received
2024-09-19 11:24:03,430 127.0.0.1 - - [19/Sep/2024 11:24:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:03,431 127.0.0.1 - - [19/Sep/2024 11:24:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:03,500 Request with ID 55b80d6b for model gpt2-124m received
2024-09-19 11:24:03,500 127.0.0.1 - - [19/Sep/2024 11:24:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:03,790 Request with ID 838aa0e5 for model distilgpt2-124m received
2024-09-19 11:24:03,791 127.0.0.1 - - [19/Sep/2024 11:24:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:03,845 Request with ID 86b356ac for model gpt2medium-355m received
2024-09-19 11:24:03,846 127.0.0.1 - - [19/Sep/2024 11:24:03] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:04,173 Request with ID a11fe300 for model gpt2-124m received
2024-09-19 11:24:04,174 127.0.0.1 - - [19/Sep/2024 11:24:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:04,177 Request with ID d66ebb49 for model gpt2medium-355m received
2024-09-19 11:24:04,178 127.0.0.1 - - [19/Sep/2024 11:24:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:04,233 Request with ID b036e4bc for model gpt2-124m received
2024-09-19 11:24:04,234 127.0.0.1 - - [19/Sep/2024 11:24:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:04,476 Request with ID 0ea20004 for model gpt2-124m received
2024-09-19 11:24:04,477 127.0.0.1 - - [19/Sep/2024 11:24:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:04,545 Request with ID cfa3a10d for model distilgpt2-124m received
2024-09-19 11:24:04,545 127.0.0.1 - - [19/Sep/2024 11:24:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:04,638 Request with ID 0349d6d2 for model gpt2-124m received
2024-09-19 11:24:04,638 127.0.0.1 - - [19/Sep/2024 11:24:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:04,668 Request with ID f2e0cc70 for model gpt2-124m received
2024-09-19 11:24:04,669 127.0.0.1 - - [19/Sep/2024 11:24:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:04,770 Request with ID 6ab97368 for model gpt2-124m received
2024-09-19 11:24:04,771 127.0.0.1 - - [19/Sep/2024 11:24:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:04,943 Request with ID fb262a31 for model gpt2-124m received
2024-09-19 11:24:04,943 127.0.0.1 - - [19/Sep/2024 11:24:04] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:05,016 Request with ID cf14ad55 for model distilgpt2-124m received
2024-09-19 11:24:05,017 127.0.0.1 - - [19/Sep/2024 11:24:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:05,132 Request with ID caa74ade for model distilgpt2-124m received
2024-09-19 11:24:05,133 127.0.0.1 - - [19/Sep/2024 11:24:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:05,160 Request with ID fe080222 for model gpt2-124m received
2024-09-19 11:24:05,160 127.0.0.1 - - [19/Sep/2024 11:24:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:05,279 Request with ID ecafb704 for model distilgpt2-124m received
2024-09-19 11:24:05,279 127.0.0.1 - - [19/Sep/2024 11:24:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:05,463 Request with ID 5cb183d9 for model gpt2-124m received
2024-09-19 11:24:05,464 127.0.0.1 - - [19/Sep/2024 11:24:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:05,476 Request with ID 70b17aa0 for model gpt2medium-355m received
2024-09-19 11:24:05,476 127.0.0.1 - - [19/Sep/2024 11:24:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:05,508 Request with ID 792731f3 for model gpt2-124m received
2024-09-19 11:24:05,508 Moving batch for gpt2-124m from incoming to running due to dynamic batch size 32
2024-09-19 11:24:05,509 Dynamic batch size condition met for model gpt2-124m
2024-09-19 11:24:05,509 Next: call load_model for gpt2-124m
2024-09-19 11:24:05,641 Loaded model gpt2-124m
2024-09-19 11:24:05,641 Batch processing started for model gpt2-124m
2024-09-19 11:24:05,910 Request with ID 81a19755 for model gpt2-124m received
2024-09-19 11:24:05,910 127.0.0.1 - - [19/Sep/2024 11:24:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:05,920 Request with ID 864da807 for model gpt2medium-355m received
2024-09-19 11:24:05,920 127.0.0.1 - - [19/Sep/2024 11:24:05] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,022 Request with ID 2d6fedf6 for model gpt2-124m received
2024-09-19 11:24:06,022 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,144 Request with ID bee23808 for model gpt2medium-355m received
2024-09-19 11:24:06,144 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,196 Request with ID db6b344e for model distilgpt2-124m received
2024-09-19 11:24:06,197 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,206 Request with ID 4498b454 for model gpt2medium-355m received
2024-09-19 11:24:06,206 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,301 Request with ID bccaea48 for model distilgpt2-124m received
2024-09-19 11:24:06,301 Request with ID 939f4eed for model gpt2-124m received
2024-09-19 11:24:06,301 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,301 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,371 Request with ID 29078904 for model gpt2-124m received
2024-09-19 11:24:06,371 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,497 Request with ID c5cdb116 for model gpt2-124m received
2024-09-19 11:24:06,497 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,636 Request with ID 67e594a1 for model distilgpt2-124m received
2024-09-19 11:24:06,636 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,765 Request with ID 00ed55e8 for model distilgpt2-124m received
2024-09-19 11:24:06,765 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,776 Request with ID a7c25793 for model gpt2-124m received
2024-09-19 11:24:06,776 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,805 Request with ID 0db6f41b for model gpt2medium-355m received
2024-09-19 11:24:06,805 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:06,812 Processing batch for gpt2-124m due to time limit with batch size 6
2024-09-19 11:24:06,812 Time limit condition met for model gpt2-124m
2024-09-19 11:24:06,872 Request with ID 81a0e228 for model distilgpt2-124m received
2024-09-19 11:24:06,873 127.0.0.1 - - [19/Sep/2024 11:24:06] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:07,033 Request with ID d4f46849 for model distilgpt2-124m received
2024-09-19 11:24:07,034 127.0.0.1 - - [19/Sep/2024 11:24:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:07,144 Request with ID 507ab414 for model gpt2-124m received
2024-09-19 11:24:07,145 127.0.0.1 - - [19/Sep/2024 11:24:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:07,274 Request with ID abcf3840 for model distilgpt2-124m received
2024-09-19 11:24:07,274 127.0.0.1 - - [19/Sep/2024 11:24:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:07,422 Request with ID 95c6f968 for model gpt2medium-355m received
2024-09-19 11:24:07,422 127.0.0.1 - - [19/Sep/2024 11:24:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:07,486 Request with ID 2083c60a for model gpt2medium-355m received
2024-09-19 11:24:07,486 127.0.0.1 - - [19/Sep/2024 11:24:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:07,534 Request with ID 849b8ecb for model gpt2medium-355m received
2024-09-19 11:24:07,534 127.0.0.1 - - [19/Sep/2024 11:24:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:07,576 Request with ID 2ad8e4ed for model gpt2medium-355m received
2024-09-19 11:24:07,576 127.0.0.1 - - [19/Sep/2024 11:24:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:07,908 Request with ID 82a1ac28 for model gpt2-124m received
2024-09-19 11:24:07,908 127.0.0.1 - - [19/Sep/2024 11:24:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:07,946 Request with ID b509c478 for model gpt2-124m received
2024-09-19 11:24:07,946 127.0.0.1 - - [19/Sep/2024 11:24:07] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:08,014 Request with ID 74f99be4 for model distilgpt2-124m received
2024-09-19 11:24:08,014 127.0.0.1 - - [19/Sep/2024 11:24:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:08,290 Request with ID 7428d44e for model gpt2medium-355m received
2024-09-19 11:24:08,291 127.0.0.1 - - [19/Sep/2024 11:24:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:08,299 Request with ID bb9c8d7b for model distilgpt2-124m received
2024-09-19 11:24:08,299 127.0.0.1 - - [19/Sep/2024 11:24:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:08,761 Request with ID fd236159 for model gpt2-124m received
2024-09-19 11:24:08,761 127.0.0.1 - - [19/Sep/2024 11:24:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:08,802 Request with ID 753144df for model gpt2-124m received
2024-09-19 11:24:08,802 127.0.0.1 - - [19/Sep/2024 11:24:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:08,838 Request with ID c44a53a6 for model gpt2medium-355m received
2024-09-19 11:24:08,838 127.0.0.1 - - [19/Sep/2024 11:24:08] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:09,043 Request with ID 614041e1 for model gpt2-124m received
2024-09-19 11:24:09,043 Request with ID 2534197c for model distilgpt2-124m received
2024-09-19 11:24:09,043 127.0.0.1 - - [19/Sep/2024 11:24:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:09,043 127.0.0.1 - - [19/Sep/2024 11:24:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:09,149 Request with ID 40a3d590 for model gpt2-124m received
2024-09-19 11:24:09,149 127.0.0.1 - - [19/Sep/2024 11:24:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:09,247 Waiting for running processes to finish
2024-09-19 11:24:10,252 Waiting for running processes to finish
2024-09-19 11:24:11,257 Waiting for running processes to finish
2024-09-19 11:24:12,260 Waiting for running processes to finish
2024-09-19 11:24:13,265 Waiting for running processes to finish
2024-09-19 11:24:13,281 Processed batch: ['b21d8c15', 'e2caa80d', '1cf6e46f', '420e6e1e', '38b58f7c', 'a113da27', 'aa633eda', '95657240', '15dcfebe', '54fb8101', '16b86319', 'e93b7c56', 'b918e3d4', '1a8e8e60', '55786133', '686eeb52', '8cf8f00c', '743448bc', '117013c3', '0323559b', '50eff4f6', '55b80d6b', 'a11fe300', 'b036e4bc', '0ea20004', '0349d6d2', 'f2e0cc70', '6ab97368', 'fb262a31', 'fe080222', '5cb183d9', '792731f3'] with model gpt2-124m in 7.6399 seconds
2024-09-19 11:24:13,281 Latency for request b21d8c15 with model gpt2-124m: 14.0340 seconds
2024-09-19 11:24:13,281 Saving results without gpu monitoring
2024-09-19 11:24:13,283 Latency for request e2caa80d with model gpt2-124m: 13.8800 seconds
2024-09-19 11:24:13,283 Saving results without gpu monitoring
2024-09-19 11:24:13,283 Latency for request 1cf6e46f with model gpt2-124m: 13.7730 seconds
2024-09-19 11:24:13,283 Saving results without gpu monitoring
2024-09-19 11:24:13,284 Latency for request 420e6e1e with model gpt2-124m: 13.4190 seconds
2024-09-19 11:24:13,284 Saving results without gpu monitoring
2024-09-19 11:24:13,284 Latency for request 38b58f7c with model gpt2-124m: 13.3800 seconds
2024-09-19 11:24:13,284 Saving results without gpu monitoring
2024-09-19 11:24:13,284 Latency for request a113da27 with model gpt2-124m: 13.3620 seconds
2024-09-19 11:24:13,284 Saving results without gpu monitoring
2024-09-19 11:24:13,284 Latency for request aa633eda with model gpt2-124m: 13.3510 seconds
2024-09-19 11:24:13,284 Saving results without gpu monitoring
2024-09-19 11:24:13,285 Latency for request 95657240 with model gpt2-124m: 12.9390 seconds
2024-09-19 11:24:13,285 Saving results without gpu monitoring
2024-09-19 11:24:13,285 Latency for request 15dcfebe with model gpt2-124m: 12.8420 seconds
2024-09-19 11:24:13,285 Saving results without gpu monitoring
2024-09-19 11:24:13,285 Latency for request 54fb8101 with model gpt2-124m: 12.6740 seconds
2024-09-19 11:24:13,285 Saving results without gpu monitoring
2024-09-19 11:24:13,285 Latency for request 16b86319 with model gpt2-124m: 12.5550 seconds
2024-09-19 11:24:13,285 Saving results without gpu monitoring
2024-09-19 11:24:13,286 Latency for request e93b7c56 with model gpt2-124m: 12.3120 seconds
2024-09-19 11:24:13,286 Saving results without gpu monitoring
2024-09-19 11:24:13,286 Latency for request b918e3d4 with model gpt2-124m: 11.9360 seconds
2024-09-19 11:24:13,286 Saving results without gpu monitoring
2024-09-19 11:24:13,286 Latency for request 1a8e8e60 with model gpt2-124m: 11.6720 seconds
2024-09-19 11:24:13,286 Saving results without gpu monitoring
2024-09-19 11:24:13,286 Latency for request 55786133 with model gpt2-124m: 11.5840 seconds
2024-09-19 11:24:13,286 Saving results without gpu monitoring
2024-09-19 11:24:13,286 Latency for request 686eeb52 with model gpt2-124m: 11.4110 seconds
2024-09-19 11:24:13,286 Saving results without gpu monitoring
2024-09-19 11:24:13,287 Latency for request 8cf8f00c with model gpt2-124m: 11.3720 seconds
2024-09-19 11:24:13,287 Saving results without gpu monitoring
2024-09-19 11:24:13,287 Latency for request 743448bc with model gpt2-124m: 11.0460 seconds
2024-09-19 11:24:13,287 Saving results without gpu monitoring
2024-09-19 11:24:13,287 Latency for request 117013c3 with model gpt2-124m: 10.9470 seconds
2024-09-19 11:24:13,287 Saving results without gpu monitoring
2024-09-19 11:24:13,287 Latency for request 0323559b with model gpt2-124m: 10.7190 seconds
2024-09-19 11:24:13,287 Saving results without gpu monitoring
2024-09-19 11:24:13,288 Latency for request 50eff4f6 with model gpt2-124m: 9.8670 seconds
2024-09-19 11:24:13,288 Saving results without gpu monitoring
2024-09-19 11:24:13,288 Latency for request 55b80d6b with model gpt2-124m: 9.7810 seconds
2024-09-19 11:24:13,288 Saving results without gpu monitoring
2024-09-19 11:24:13,288 Latency for request a11fe300 with model gpt2-124m: 9.1080 seconds
2024-09-19 11:24:13,288 Saving results without gpu monitoring
2024-09-19 11:24:13,288 Latency for request b036e4bc with model gpt2-124m: 9.0480 seconds
2024-09-19 11:24:13,288 Saving results without gpu monitoring
2024-09-19 11:24:13,288 Latency for request 0ea20004 with model gpt2-124m: 8.8050 seconds
2024-09-19 11:24:13,288 Saving results without gpu monitoring
2024-09-19 11:24:13,289 Latency for request 0349d6d2 with model gpt2-124m: 8.6430 seconds
2024-09-19 11:24:13,289 Saving results without gpu monitoring
2024-09-19 11:24:13,289 Latency for request f2e0cc70 with model gpt2-124m: 8.6130 seconds
2024-09-19 11:24:13,289 Saving results without gpu monitoring
2024-09-19 11:24:13,289 Latency for request 6ab97368 with model gpt2-124m: 8.5110 seconds
2024-09-19 11:24:13,289 Saving results without gpu monitoring
2024-09-19 11:24:13,289 Latency for request fb262a31 with model gpt2-124m: 8.3380 seconds
2024-09-19 11:24:13,289 Saving results without gpu monitoring
2024-09-19 11:24:13,289 Latency for request fe080222 with model gpt2-124m: 8.1210 seconds
2024-09-19 11:24:13,290 Saving results without gpu monitoring
2024-09-19 11:24:13,290 Latency for request 5cb183d9 with model gpt2-124m: 7.8180 seconds
2024-09-19 11:24:13,290 Saving results without gpu monitoring
2024-09-19 11:24:13,290 Latency for request 792731f3 with model gpt2-124m: 7.7730 seconds
2024-09-19 11:24:13,290 Saving results without gpu monitoring
2024-09-19 11:24:13,290 127.0.0.1 - - [19/Sep/2024 11:24:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:13,290 Next: call load_model for gpt2-124m
2024-09-19 11:24:13,290 Model gpt2-124m already loaded
2024-09-19 11:24:13,290 Batch processing started for model gpt2-124m
2024-09-19 11:24:14,271 Waiting for running processes to finish
2024-09-19 11:24:15,053 Processed batch: ['81a19755', '2d6fedf6', '939f4eed', '29078904', 'c5cdb116', 'a7c25793'] with model gpt2-124m in 1.7630 seconds
2024-09-19 11:24:15,054 Latency for request 81a19755 with model gpt2-124m: 9.1440 seconds
2024-09-19 11:24:15,054 Saving results without gpu monitoring
2024-09-19 11:24:15,054 Latency for request 2d6fedf6 with model gpt2-124m: 9.0310 seconds
2024-09-19 11:24:15,054 Saving results without gpu monitoring
2024-09-19 11:24:15,055 Latency for request 939f4eed with model gpt2-124m: 8.7520 seconds
2024-09-19 11:24:15,055 Saving results without gpu monitoring
2024-09-19 11:24:15,055 Latency for request 29078904 with model gpt2-124m: 8.6820 seconds
2024-09-19 11:24:15,055 Saving results without gpu monitoring
2024-09-19 11:24:15,055 Latency for request c5cdb116 with model gpt2-124m: 8.5560 seconds
2024-09-19 11:24:15,055 Saving results without gpu monitoring
2024-09-19 11:24:15,055 Latency for request a7c25793 with model gpt2-124m: 8.2780 seconds
2024-09-19 11:24:15,055 Saving results without gpu monitoring
2024-09-19 11:24:15,161 Processing batch for gpt2medium-355m due to time limit with batch size 23
2024-09-19 11:24:15,161 Time limit condition met for model gpt2medium-355m
2024-09-19 11:24:15,161 Next: call load_model for gpt2medium-355m
2024-09-19 11:24:15,168 Unloaded previous model
2024-09-19 11:24:15,257 Loaded model gpt2medium-355m
2024-09-19 11:24:15,257 Batch processing started for model gpt2medium-355m
2024-09-19 11:24:16,281 Total time: 15.8086 seconds
2024-09-19 11:24:16,281 Total inference time: 9.4030 seconds
2024-09-19 11:24:16,281 Inference time as percentage of total time: 59.48%
2024-09-19 11:24:16,281 END
2024-09-19 11:24:16,281 127.0.0.1 - - [19/Sep/2024 11:24:16] "POST /inference HTTP/1.1" 200 -
2024-09-19 11:24:37,777 Processed batch: ['aa17925c', 'faaa37b4', '19ae90f1', 'f59a4cfe', 'e63816fd', '906807b5', '72da3ec4', 'c675c188', '6e93a408', 'ab1933e2', '86b356ac', 'd66ebb49', '70b17aa0', '864da807', 'bee23808', '4498b454', '0db6f41b', '95c6f968', '2083c60a', '849b8ecb', '2ad8e4ed', '7428d44e', 'c44a53a6'] with model gpt2medium-355m in 22.5206 seconds
2024-09-19 11:24:37,777 Latency for request aa17925c with model gpt2medium-355m: 38.3670 seconds
2024-09-19 11:24:37,778 Saving results without gpu monitoring
2024-09-19 11:24:37,779 Latency for request faaa37b4 with model gpt2medium-355m: 37.9170 seconds
2024-09-19 11:24:37,779 Saving results without gpu monitoring
2024-09-19 11:24:37,779 Latency for request 19ae90f1 with model gpt2medium-355m: 37.3380 seconds
2024-09-19 11:24:37,779 Saving results without gpu monitoring
2024-09-19 11:24:37,780 Latency for request f59a4cfe with model gpt2medium-355m: 36.5840 seconds
2024-09-19 11:24:37,780 Saving results without gpu monitoring
2024-09-19 11:24:37,780 Latency for request e63816fd with model gpt2medium-355m: 35.9150 seconds
2024-09-19 11:24:37,780 Saving results without gpu monitoring
2024-09-19 11:24:37,780 Latency for request 906807b5 with model gpt2medium-355m: 35.7380 seconds
2024-09-19 11:24:37,780 Saving results without gpu monitoring
2024-09-19 11:24:37,780 Latency for request 72da3ec4 with model gpt2medium-355m: 35.4300 seconds
2024-09-19 11:24:37,781 Saving results without gpu monitoring
2024-09-19 11:24:37,781 Latency for request c675c188 with model gpt2medium-355m: 34.7170 seconds
2024-09-19 11:24:37,781 Saving results without gpu monitoring
2024-09-19 11:24:37,781 Latency for request 6e93a408 with model gpt2medium-355m: 34.5510 seconds
2024-09-19 11:24:37,781 Saving results without gpu monitoring
2024-09-19 11:24:37,781 Latency for request ab1933e2 with model gpt2medium-355m: 34.3480 seconds
2024-09-19 11:24:37,781 Saving results without gpu monitoring
2024-09-19 11:24:37,782 Latency for request 86b356ac with model gpt2medium-355m: 33.9320 seconds
2024-09-19 11:24:37,782 Saving results without gpu monitoring
2024-09-19 11:24:37,782 Latency for request d66ebb49 with model gpt2medium-355m: 33.6000 seconds
2024-09-19 11:24:37,782 Saving results without gpu monitoring
2024-09-19 11:24:37,782 Latency for request 70b17aa0 with model gpt2medium-355m: 32.3020 seconds
2024-09-19 11:24:37,782 Saving results without gpu monitoring
2024-09-19 11:24:37,782 Latency for request 864da807 with model gpt2medium-355m: 31.8570 seconds
2024-09-19 11:24:37,782 Saving results without gpu monitoring
2024-09-19 11:24:37,783 Latency for request bee23808 with model gpt2medium-355m: 31.6340 seconds
2024-09-19 11:24:37,783 Saving results without gpu monitoring
2024-09-19 11:24:37,783 Latency for request 4498b454 with model gpt2medium-355m: 31.5720 seconds
2024-09-19 11:24:37,783 Saving results without gpu monitoring
2024-09-19 11:24:37,783 Latency for request 0db6f41b with model gpt2medium-355m: 30.9730 seconds
2024-09-19 11:24:37,783 Saving results without gpu monitoring
2024-09-19 11:24:37,784 Latency for request 95c6f968 with model gpt2medium-355m: 30.3560 seconds
2024-09-19 11:24:37,784 Saving results without gpu monitoring
2024-09-19 11:24:37,784 Latency for request 2083c60a with model gpt2medium-355m: 30.2910 seconds
2024-09-19 11:24:37,784 Saving results without gpu monitoring
2024-09-19 11:24:37,784 Latency for request 849b8ecb with model gpt2medium-355m: 30.2440 seconds
2024-09-19 11:24:37,784 Saving results without gpu monitoring
2024-09-19 11:24:37,784 Latency for request 2ad8e4ed with model gpt2medium-355m: 30.2020 seconds
2024-09-19 11:24:37,784 Saving results without gpu monitoring
2024-09-19 11:24:37,785 Latency for request 7428d44e with model gpt2medium-355m: 29.4870 seconds
2024-09-19 11:24:37,785 Saving results without gpu monitoring
2024-09-19 11:24:37,785 Latency for request c44a53a6 with model gpt2medium-355m: 28.9390 seconds
2024-09-19 11:24:37,785 Saving results without gpu monitoring
2024-09-19 11:24:37,785 Processing batch for distilgpt2-124m due to time limit with batch size 29
2024-09-19 11:24:37,785 Time limit condition met for model distilgpt2-124m
2024-09-19 11:24:37,785 Next: call load_model for distilgpt2-124m
2024-09-19 11:24:37,794 Unloaded previous model
2024-09-19 11:24:37,846 Loaded model distilgpt2-124m
2024-09-19 11:24:37,846 Batch processing started for model distilgpt2-124m
2024-09-19 11:24:42,008 Processed batch: ['1767e373', 'fa0e7301', 'e9aa6e61', '9edfc46f', 'b7134f5a', '59d53ef0', '9e1b7f96', 'eed9775e', '39ceecee', '946d355c', '964b5d30', 'f71f90d4', '5e42a83b', 'f4eba508', '838aa0e5', 'cfa3a10d', 'cf14ad55', 'caa74ade', 'ecafb704', 'db6b344e', 'bccaea48', '67e594a1', '00ed55e8', '81a0e228', 'd4f46849', 'abcf3840', '74f99be4', 'bb9c8d7b', '2534197c'] with model distilgpt2-124m in 4.1619 seconds
2024-09-19 11:24:42,008 Latency for request 1767e373 with model distilgpt2-124m: 42.1070 seconds
2024-09-19 11:24:42,008 Saving results without gpu monitoring
2024-09-19 11:24:42,009 Latency for request fa0e7301 with model distilgpt2-124m: 40.8960 seconds
2024-09-19 11:24:42,009 Saving results without gpu monitoring
2024-09-19 11:24:42,010 Latency for request e9aa6e61 with model distilgpt2-124m: 40.2720 seconds
2024-09-19 11:24:42,010 Saving results without gpu monitoring
2024-09-19 11:24:42,010 Latency for request 9edfc46f with model distilgpt2-124m: 40.1810 seconds
2024-09-19 11:24:42,010 Saving results without gpu monitoring
2024-09-19 11:24:42,010 Latency for request b7134f5a with model distilgpt2-124m: 39.9780 seconds
2024-09-19 11:24:42,010 Saving results without gpu monitoring
2024-09-19 11:24:42,010 Latency for request 59d53ef0 with model distilgpt2-124m: 39.7690 seconds
2024-09-19 11:24:42,010 Saving results without gpu monitoring
2024-09-19 11:24:42,011 Latency for request 9e1b7f96 with model distilgpt2-124m: 39.5300 seconds
2024-09-19 11:24:42,011 Saving results without gpu monitoring
2024-09-19 11:24:42,011 Latency for request eed9775e with model distilgpt2-124m: 39.4600 seconds
2024-09-19 11:24:42,011 Saving results without gpu monitoring
2024-09-19 11:24:42,011 Latency for request 39ceecee with model distilgpt2-124m: 39.2180 seconds
2024-09-19 11:24:42,011 Saving results without gpu monitoring
2024-09-19 11:24:42,011 Latency for request 946d355c with model distilgpt2-124m: 39.0960 seconds
2024-09-19 11:24:42,011 Saving results without gpu monitoring
2024-09-19 11:24:42,012 Latency for request 964b5d30 with model distilgpt2-124m: 39.0690 seconds
2024-09-19 11:24:42,012 Saving results without gpu monitoring
2024-09-19 11:24:42,012 Latency for request f71f90d4 with model distilgpt2-124m: 38.7590 seconds
2024-09-19 11:24:42,012 Saving results without gpu monitoring
2024-09-19 11:24:42,012 Latency for request 5e42a83b with model distilgpt2-124m: 38.5800 seconds
2024-09-19 11:24:42,012 Saving results without gpu monitoring
2024-09-19 11:24:42,012 Latency for request f4eba508 with model distilgpt2-124m: 38.5780 seconds
2024-09-19 11:24:42,012 Saving results without gpu monitoring
2024-09-19 11:24:42,013 Latency for request 838aa0e5 with model distilgpt2-124m: 38.2180 seconds
2024-09-19 11:24:42,013 Saving results without gpu monitoring
2024-09-19 11:24:42,013 Latency for request cfa3a10d with model distilgpt2-124m: 37.4630 seconds
2024-09-19 11:24:42,013 Saving results without gpu monitoring
2024-09-19 11:24:42,013 Latency for request cf14ad55 with model distilgpt2-124m: 36.9920 seconds
2024-09-19 11:24:42,013 Saving results without gpu monitoring
2024-09-19 11:24:42,013 Latency for request caa74ade with model distilgpt2-124m: 36.8760 seconds
2024-09-19 11:24:42,013 Saving results without gpu monitoring
2024-09-19 11:24:42,014 Latency for request ecafb704 with model distilgpt2-124m: 36.7300 seconds
2024-09-19 11:24:42,014 Saving results without gpu monitoring
2024-09-19 11:24:42,014 Latency for request db6b344e with model distilgpt2-124m: 35.8120 seconds
2024-09-19 11:24:42,014 Saving results without gpu monitoring
2024-09-19 11:24:42,014 Latency for request bccaea48 with model distilgpt2-124m: 35.7070 seconds
2024-09-19 11:24:42,014 Saving results without gpu monitoring
2024-09-19 11:24:42,014 Latency for request 67e594a1 with model distilgpt2-124m: 35.3720 seconds
2024-09-19 11:24:42,014 Saving results without gpu monitoring
2024-09-19 11:24:42,015 Latency for request 00ed55e8 with model distilgpt2-124m: 35.2430 seconds
2024-09-19 11:24:42,015 Saving results without gpu monitoring
2024-09-19 11:24:42,015 Latency for request 81a0e228 with model distilgpt2-124m: 35.1360 seconds
2024-09-19 11:24:42,015 Saving results without gpu monitoring
2024-09-19 11:24:42,015 Latency for request d4f46849 with model distilgpt2-124m: 34.9750 seconds
2024-09-19 11:24:42,015 Saving results without gpu monitoring
2024-09-19 11:24:42,015 Latency for request abcf3840 with model distilgpt2-124m: 34.7340 seconds
2024-09-19 11:24:42,015 Saving results without gpu monitoring
2024-09-19 11:24:42,016 Latency for request 74f99be4 with model distilgpt2-124m: 33.9940 seconds
2024-09-19 11:24:42,016 Saving results without gpu monitoring
2024-09-19 11:24:42,016 Latency for request bb9c8d7b with model distilgpt2-124m: 33.7100 seconds
2024-09-19 11:24:42,016 Saving results without gpu monitoring
2024-09-19 11:24:42,016 Latency for request 2534197c with model distilgpt2-124m: 32.9660 seconds
2024-09-19 11:24:42,016 Saving results without gpu monitoring
