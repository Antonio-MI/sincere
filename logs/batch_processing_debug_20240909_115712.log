2024-09-09 11:57:12,044 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.212:5000
2024-09-09 11:57:12,044 [33mPress CTRL+C to quit[0m
2024-09-09 11:57:14,467 127.0.0.1 - - [09/Sep/2024 11:57:14] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:14,514 Time limit reached for model gpt2-124m at 1725897434.5146
2024-09-09 11:57:14,514 Moving batch for gpt2-124m from incoming to running due to time limit with batch size 1
2024-09-09 11:57:14,514 Time limit condition met for model gpt2-124m
2024-09-09 11:57:14,514 1
2024-09-09 11:57:14,515 Padding requests generated in 0.0000 seconds
2024-09-09 11:57:14,515 Loading model gpt2-124m
2024-09-09 11:57:14,574 Batch processing started at 356213.5889 for model gpt2-124m
2024-09-09 11:57:15,947 Processed request ID c125d170 with model gpt2-124m
2024-09-09 11:57:15,948 Processed request ID 8930 with model gpt2-124m
2024-09-09 11:57:15,948 Processed request ID 1e0a with model gpt2-124m
2024-09-09 11:57:15,948 Processed request ID 8423 with model gpt2-124m
2024-09-09 11:57:15,948 Processed batch: ['c125d170', '8930', '1e0a', '8423'] with model gpt2-124m in 1.3739 seconds
2024-09-09 11:57:15,948 Latency for request c125d170 with model gpt2-124m: 1.4816 seconds
2024-09-09 11:57:15,950 Latency for request 8930 with model gpt2-124m: 1.4335 seconds
2024-09-09 11:57:15,950 Latency for request 1e0a with model gpt2-124m: 1.4335 seconds
2024-09-09 11:57:15,950 Latency for request 8423 with model gpt2-124m: 1.4335 seconds
2024-09-09 11:57:16,944 127.0.0.1 - - [09/Sep/2024 11:57:16] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:16,987 Time limit reached for model gpt2-124m at 1725897436.9873
2024-09-09 11:57:16,987 Moving batch for gpt2-124m from incoming to running due to time limit with batch size 1
2024-09-09 11:57:16,987 Time limit condition met for model gpt2-124m
2024-09-09 11:57:16,987 1
2024-09-09 11:57:16,987 Padding requests generated in 0.0000 seconds
2024-09-09 11:57:16,987 Loading model gpt2-124m
2024-09-09 11:57:16,988 Batch processing started at 356216.0024 for model gpt2-124m
2024-09-09 11:57:17,578 Processed request ID 5bb8ab0f with model gpt2-124m
2024-09-09 11:57:17,578 Processed request ID 2c15 with model gpt2-124m
2024-09-09 11:57:17,578 Processed request ID 37cc with model gpt2-124m
2024-09-09 11:57:17,578 Processed request ID 81f0 with model gpt2-124m
2024-09-09 11:57:17,578 Processed batch: ['5bb8ab0f', '2c15', '37cc', '81f0'] with model gpt2-124m in 0.5906 seconds
2024-09-09 11:57:17,578 Latency for request 5bb8ab0f with model gpt2-124m: 0.6353 seconds
2024-09-09 11:57:17,579 Latency for request 2c15 with model gpt2-124m: 0.5909 seconds
2024-09-09 11:57:17,579 Latency for request 37cc with model gpt2-124m: 0.5909 seconds
2024-09-09 11:57:17,579 Latency for request 81f0 with model gpt2-124m: 0.5909 seconds
2024-09-09 11:57:17,936 127.0.0.1 - - [09/Sep/2024 11:57:17] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:17,991 Time limit reached for model gpt2medium-355m at 1725897437.9918
2024-09-09 11:57:17,992 Moving batch for gpt2medium-355m from incoming to running due to time limit with batch size 1
2024-09-09 11:57:17,992 Time limit condition met for model gpt2medium-355m
2024-09-09 11:57:17,992 1
2024-09-09 11:57:17,992 Padding requests generated in 0.0000 seconds
2024-09-09 11:57:17,992 Loading model gpt2medium-355m
2024-09-09 11:57:18,106 Batch processing started at 356217.1211 for model gpt2medium-355m
2024-09-09 11:57:18,120 127.0.0.1 - - [09/Sep/2024 11:57:18] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:19,229 127.0.0.1 - - [09/Sep/2024 11:57:19] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:21,216 127.0.0.1 - - [09/Sep/2024 11:57:21] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:23,004 Processed request ID 3bd40135 with model gpt2medium-355m
2024-09-09 11:57:23,005 Processed request ID 498a with model gpt2medium-355m
2024-09-09 11:57:23,005 Processed request ID 1cbd with model gpt2medium-355m
2024-09-09 11:57:23,005 Processed request ID e814 with model gpt2medium-355m
2024-09-09 11:57:23,005 Processed batch: ['3bd40135', '498a', '1cbd', 'e814'] with model gpt2medium-355m in 4.8991 seconds
2024-09-09 11:57:23,005 Latency for request 3bd40135 with model gpt2medium-355m: 5.0701 seconds
2024-09-09 11:57:23,006 Latency for request 498a with model gpt2medium-355m: 5.0136 seconds
2024-09-09 11:57:23,006 Latency for request 1cbd with model gpt2medium-355m: 5.0136 seconds
2024-09-09 11:57:23,007 Latency for request e814 with model gpt2medium-355m: 5.0136 seconds
2024-09-09 11:57:23,040 127.0.0.1 - - [09/Sep/2024 11:57:23] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:23,109 Time limit reached for model gpt2-124m at 1725897443.1091
2024-09-09 11:57:23,109 Moving batch for gpt2-124m from incoming to running due to time limit with batch size 2
2024-09-09 11:57:23,109 Time limit condition met for model gpt2-124m
2024-09-09 11:57:23,109 2
2024-09-09 11:57:23,109 Padding requests generated in 0.0000 seconds
2024-09-09 11:57:23,109 Loading model gpt2-124m
2024-09-09 11:57:23,180 Batch processing started at 356222.1947 for model gpt2-124m
2024-09-09 11:57:23,981 Processed request ID e6ed976f with model gpt2-124m
2024-09-09 11:57:23,982 Processed request ID 9170ea6c with model gpt2-124m
2024-09-09 11:57:23,982 Processed request ID e719 with model gpt2-124m
2024-09-09 11:57:23,982 Processed request ID e949 with model gpt2-124m
2024-09-09 11:57:23,982 Processed batch: ['e6ed976f', '9170ea6c', 'e719', 'e949'] with model gpt2-124m in 0.8021 seconds
2024-09-09 11:57:23,982 Latency for request e6ed976f with model gpt2-124m: 5.8623 seconds
2024-09-09 11:57:23,983 Latency for request 9170ea6c with model gpt2-124m: 4.7536 seconds
2024-09-09 11:57:23,983 Latency for request e719 with model gpt2-124m: 0.8731 seconds
2024-09-09 11:57:23,984 Latency for request e949 with model gpt2-124m: 0.8731 seconds
2024-09-09 11:57:23,984 Time limit reached for model distilgpt2-124m at 1725897443.1091
2024-09-09 11:57:23,984 Moving batch for distilgpt2-124m from incoming to running due to time limit with batch size 2
2024-09-09 11:57:23,984 Time limit condition met for model distilgpt2-124m
2024-09-09 11:57:23,984 2
2024-09-09 11:57:23,984 Padding requests generated in 0.0000 seconds
2024-09-09 11:57:23,984 Loading model distilgpt2-124m
2024-09-09 11:57:24,041 Batch processing started at 356223.0556 for model distilgpt2-124m
2024-09-09 11:57:24,738 127.0.0.1 - - [09/Sep/2024 11:57:24] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:25,245 Processed request ID 044825bc with model distilgpt2-124m
2024-09-09 11:57:25,246 Processed request ID 4017445e with model distilgpt2-124m
2024-09-09 11:57:25,246 Processed request ID 6ac0 with model distilgpt2-124m
2024-09-09 11:57:25,247 Processed request ID 7a41 with model distilgpt2-124m
2024-09-09 11:57:25,247 Processed batch: ['044825bc', '4017445e', '6ac0', '7a41'] with model distilgpt2-124m in 1.2061 seconds
2024-09-09 11:57:25,247 Latency for request 044825bc with model distilgpt2-124m: 4.0310 seconds
2024-09-09 11:57:25,248 Latency for request 4017445e with model distilgpt2-124m: 2.2065 seconds
2024-09-09 11:57:25,248 Latency for request 6ac0 with model distilgpt2-124m: 1.2629 seconds
2024-09-09 11:57:25,249 Latency for request 7a41 with model distilgpt2-124m: 1.2629 seconds
2024-09-09 11:57:25,355 Time limit reached for model gpt2medium-355m at 1725897445.3551
2024-09-09 11:57:25,355 Moving batch for gpt2medium-355m from incoming to running due to time limit with batch size 1
2024-09-09 11:57:25,355 Time limit condition met for model gpt2medium-355m
2024-09-09 11:57:25,355 1
2024-09-09 11:57:25,355 Padding requests generated in 0.0000 seconds
2024-09-09 11:57:25,355 Loading model gpt2medium-355m
2024-09-09 11:57:25,473 Batch processing started at 356224.4882 for model gpt2medium-355m
2024-09-09 11:57:25,912 127.0.0.1 - - [09/Sep/2024 11:57:25] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:27,277 127.0.0.1 - - [09/Sep/2024 11:57:27] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:27,783 Processed request ID b9453441 with model gpt2medium-355m
2024-09-09 11:57:27,783 Processed request ID 2cdf with model gpt2medium-355m
2024-09-09 11:57:27,783 Processed request ID 94ba with model gpt2medium-355m
2024-09-09 11:57:27,783 Processed request ID 657a with model gpt2medium-355m
2024-09-09 11:57:27,784 Processed batch: ['b9453441', '2cdf', '94ba', '657a'] with model gpt2medium-355m in 2.3101 seconds
2024-09-09 11:57:27,784 Latency for request b9453441 with model gpt2medium-355m: 3.0455 seconds
2024-09-09 11:57:27,784 Latency for request 2cdf with model gpt2medium-355m: 2.4288 seconds
2024-09-09 11:57:27,785 Latency for request 94ba with model gpt2medium-355m: 2.4288 seconds
2024-09-09 11:57:27,785 Latency for request 657a with model gpt2medium-355m: 2.4288 seconds
2024-09-09 11:57:27,887 Time limit reached for model distilgpt2-124m at 1725897447.8870
2024-09-09 11:57:27,887 Moving batch for distilgpt2-124m from incoming to running due to time limit with batch size 1
2024-09-09 11:57:27,887 Time limit condition met for model distilgpt2-124m
2024-09-09 11:57:27,887 1
2024-09-09 11:57:27,887 Padding requests generated in 0.0000 seconds
2024-09-09 11:57:27,887 Loading model distilgpt2-124m
2024-09-09 11:57:27,987 Batch processing started at 356227.0019 for model distilgpt2-124m
2024-09-09 11:57:28,644 Processed request ID a9bf6054 with model distilgpt2-124m
2024-09-09 11:57:28,644 Processed request ID 80cb with model distilgpt2-124m
2024-09-09 11:57:28,644 Processed request ID 94b4 with model distilgpt2-124m
2024-09-09 11:57:28,645 Processed request ID 3713 with model distilgpt2-124m
2024-09-09 11:57:28,645 Processed batch: ['a9bf6054', '80cb', '94b4', '3713'] with model distilgpt2-124m in 0.6576 seconds
2024-09-09 11:57:28,645 Latency for request a9bf6054 with model distilgpt2-124m: 2.7326 seconds
2024-09-09 11:57:28,645 Latency for request 80cb with model distilgpt2-124m: 0.7580 seconds
2024-09-09 11:57:28,646 Latency for request 94b4 with model distilgpt2-124m: 0.7580 seconds
2024-09-09 11:57:28,646 Latency for request 3713 with model distilgpt2-124m: 0.7580 seconds
2024-09-09 11:57:28,742 127.0.0.1 - - [09/Sep/2024 11:57:28] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:28,747 Time limit reached for model gpt2-124m at 1725897448.7476
2024-09-09 11:57:28,747 Moving batch for gpt2-124m from incoming to running due to time limit with batch size 1
2024-09-09 11:57:28,747 Time limit condition met for model gpt2-124m
2024-09-09 11:57:28,747 1
2024-09-09 11:57:28,747 Padding requests generated in 0.0000 seconds
2024-09-09 11:57:28,747 Loading model gpt2-124m
2024-09-09 11:57:28,815 Batch processing started at 356227.8299 for model gpt2-124m
2024-09-09 11:57:29,700 Processed request ID bc9cf06f with model gpt2-124m
2024-09-09 11:57:29,700 Processed request ID 0c3b with model gpt2-124m
2024-09-09 11:57:29,700 Processed request ID 88c6 with model gpt2-124m
2024-09-09 11:57:29,701 Processed request ID 5ff2 with model gpt2-124m
2024-09-09 11:57:29,701 Processed batch: ['bc9cf06f', '0c3b', '88c6', '5ff2'] with model gpt2-124m in 0.8857 seconds
2024-09-09 11:57:29,701 Latency for request bc9cf06f with model gpt2-124m: 0.9593 seconds
2024-09-09 11:57:29,702 Latency for request 0c3b with model gpt2-124m: 0.9536 seconds
2024-09-09 11:57:29,702 Latency for request 88c6 with model gpt2-124m: 0.9536 seconds
2024-09-09 11:57:29,702 Latency for request 5ff2 with model gpt2-124m: 0.9536 seconds
2024-09-09 11:57:30,577 127.0.0.1 - - [09/Sep/2024 11:57:30] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:30,638 Time limit reached for model gpt2medium-355m at 1725897450.6387
2024-09-09 11:57:30,638 Moving batch for gpt2medium-355m from incoming to running due to time limit with batch size 2
2024-09-09 11:57:30,639 Time limit condition met for model gpt2medium-355m
2024-09-09 11:57:30,639 2
2024-09-09 11:57:30,639 Padding requests generated in 0.0000 seconds
2024-09-09 11:57:30,639 Loading model gpt2medium-355m
2024-09-09 11:57:30,812 Batch processing started at 356229.8263 for model gpt2medium-355m
2024-09-09 11:57:31,662 127.0.0.1 - - [09/Sep/2024 11:57:31] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:32,668 127.0.0.1 - - [09/Sep/2024 11:57:32] "POST /inference HTTP/1.1" 200 -
2024-09-09 11:57:33,604 Processed request ID 8a4e7c30 with model gpt2medium-355m
2024-09-09 11:57:33,604 Processed request ID 662d8d64 with model gpt2medium-355m
2024-09-09 11:57:33,604 Processed request ID 4d6d with model gpt2medium-355m
2024-09-09 11:57:33,604 Processed request ID e421 with model gpt2medium-355m
2024-09-09 11:57:33,605 Processed batch: ['8a4e7c30', '662d8d64', '4d6d', 'e421'] with model gpt2medium-355m in 2.7930 seconds
2024-09-09 11:57:33,605 Latency for request 8a4e7c30 with model gpt2medium-355m: 6.3279 seconds
2024-09-09 11:57:33,605 Latency for request 662d8d64 with model gpt2medium-355m: 3.0282 seconds
2024-09-09 11:57:33,606 Latency for request 4d6d with model gpt2medium-355m: 2.9659 seconds
2024-09-09 11:57:33,606 Latency for request e421 with model gpt2medium-355m: 2.9659 seconds
2024-09-09 11:57:33,709 Time limit reached for model gpt2-124m at 1725897453.7091
2024-09-09 11:57:33,709 Moving batch for gpt2-124m from incoming to running due to time limit with batch size 1
2024-09-09 11:57:33,709 Time limit condition met for model gpt2-124m
2024-09-09 11:57:33,709 1
2024-09-09 11:57:33,709 Padding requests generated in 0.0000 seconds
2024-09-09 11:57:33,709 Loading model gpt2-124m
2024-09-09 11:57:33,782 Batch processing started at 356232.7966 for model gpt2-124m
2024-09-09 11:57:34,540 Processed request ID e9bb6e7a with model gpt2-124m
2024-09-09 11:57:34,540 Processed request ID 07d6 with model gpt2-124m
2024-09-09 11:57:34,540 Processed request ID 2ddd with model gpt2-124m
2024-09-09 11:57:34,540 Processed request ID 0202 with model gpt2-124m
2024-09-09 11:57:34,540 Processed batch: ['e9bb6e7a', '07d6', '2ddd', '0202'] with model gpt2-124m in 0.7586 seconds
2024-09-09 11:57:34,540 Latency for request e9bb6e7a with model gpt2-124m: 2.8788 seconds
2024-09-09 11:57:34,541 Latency for request 07d6 with model gpt2-124m: 0.8317 seconds
2024-09-09 11:57:34,541 Latency for request 2ddd with model gpt2-124m: 0.8317 seconds
2024-09-09 11:57:34,542 Latency for request 0202 with model gpt2-124m: 0.8317 seconds
2024-09-09 11:57:34,542 Time limit reached for model distilgpt2-124m at 1725897453.7091
2024-09-09 11:57:34,542 Moving batch for distilgpt2-124m from incoming to running due to time limit with batch size 1
2024-09-09 11:57:34,542 Time limit condition met for model distilgpt2-124m
2024-09-09 11:57:34,542 1
2024-09-09 11:57:34,542 Padding requests generated in 0.0000 seconds
2024-09-09 11:57:34,542 Loading model distilgpt2-124m
2024-09-09 11:57:34,603 Batch processing started at 356233.6179 for model distilgpt2-124m
2024-09-09 11:57:35,192 Processed request ID 54d27d2c with model distilgpt2-124m
2024-09-09 11:57:35,192 Processed request ID 2c84 with model distilgpt2-124m
2024-09-09 11:57:35,193 Processed request ID 5ac3 with model distilgpt2-124m
2024-09-09 11:57:35,193 Processed request ID 5130 with model distilgpt2-124m
2024-09-09 11:57:35,193 Processed batch: ['54d27d2c', '2c84', '5ac3', '5130'] with model distilgpt2-124m in 0.5899 seconds
2024-09-09 11:57:35,193 Latency for request 54d27d2c with model distilgpt2-124m: 2.5249 seconds
2024-09-09 11:57:35,194 Latency for request 2c84 with model distilgpt2-124m: 0.6509 seconds
2024-09-09 11:57:35,194 Latency for request 5ac3 with model distilgpt2-124m: 0.6509 seconds
2024-09-09 11:57:35,194 Latency for request 5130 with model distilgpt2-124m: 0.6509 seconds
