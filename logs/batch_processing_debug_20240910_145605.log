2024-09-10 14:56:10,869 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.11.77:5000
2024-09-10 14:56:10,869 [33mPress CTRL+C to quit[0m
2024-09-10 14:56:13,814 Request with ID 2e9baf4d for model gpt2-124m received
2024-09-10 14:56:13,814 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 14:56:13,814 Adjusted time limit for model gpt2-124m: 13.3502 seconds
2024-09-10 14:56:13,814 127.0.0.1 - - [10/Sep/2024 14:56:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:14,314 Request with ID ecd32d63 for model gpt2-124m received
2024-09-10 14:56:14,314 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 14:56:14,315 127.0.0.1 - - [10/Sep/2024 14:56:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:14,514 Request with ID 7fea59a8 for model gpt2medium-355m received
2024-09-10 14:56:14,514 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 14:56:14,514 Adjusted time limit for model gpt2medium-355m: 9.9550 seconds
2024-09-10 14:56:14,515 127.0.0.1 - - [10/Sep/2024 14:56:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:14,551 Request with ID 3a9ca0b7 for model gpt2-124m received
2024-09-10 14:56:14,551 Adjusted time limit based on total queue size 4: 11.2500 seconds
2024-09-10 14:56:14,551 127.0.0.1 - - [10/Sep/2024 14:56:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:14,773 Request with ID d994fb23 for model gpt2-124m received
2024-09-10 14:56:14,773 Adjusted time limit based on total queue size 5: 11.2500 seconds
2024-09-10 14:56:14,773 127.0.0.1 - - [10/Sep/2024 14:56:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:15,174 Request with ID a26c2d9f for model distilgpt2-124m received
2024-09-10 14:56:15,175 Adjusted time limit based on total queue size 6: 11.2500 seconds
2024-09-10 14:56:15,175 Adjusted time limit for model distilgpt2-124m: 14.2150 seconds
2024-09-10 14:56:15,175 127.0.0.1 - - [10/Sep/2024 14:56:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:15,540 Request with ID 20083ef1 for model distilgpt2-124m received
2024-09-10 14:56:15,540 Adjusted time limit based on total queue size 7: 11.2500 seconds
2024-09-10 14:56:15,541 127.0.0.1 - - [10/Sep/2024 14:56:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:15,882 Request with ID b4b2b55d for model gpt2medium-355m received
2024-09-10 14:56:15,882 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 14:56:15,883 127.0.0.1 - - [10/Sep/2024 14:56:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:16,118 Request with ID 2ed0cbb6 for model distilgpt2-124m received
2024-09-10 14:56:16,119 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 14:56:16,119 127.0.0.1 - - [10/Sep/2024 14:56:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:16,392 Request with ID dccac22d for model gpt2medium-355m received
2024-09-10 14:56:16,392 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 14:56:16,393 127.0.0.1 - - [10/Sep/2024 14:56:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:16,688 Request with ID b52dc6b5 for model gpt2-124m received
2024-09-10 14:56:16,688 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:56:16,689 127.0.0.1 - - [10/Sep/2024 14:56:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:17,055 Request with ID 46ad2395 for model gpt2medium-355m received
2024-09-10 14:56:17,055 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:56:17,056 127.0.0.1 - - [10/Sep/2024 14:56:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:17,275 Request with ID 0a941008 for model gpt2-124m received
2024-09-10 14:56:17,275 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:56:17,276 127.0.0.1 - - [10/Sep/2024 14:56:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:17,478 Request with ID e0b71b55 for model distilgpt2-124m received
2024-09-10 14:56:17,478 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:56:17,479 127.0.0.1 - - [10/Sep/2024 14:56:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:18,123 Request with ID a396ccc0 for model gpt2-124m received
2024-09-10 14:56:18,123 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:56:18,123 127.0.0.1 - - [10/Sep/2024 14:56:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:18,844 Request with ID ef603c35 for model gpt2-124m received
2024-09-10 14:56:18,845 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:56:18,845 127.0.0.1 - - [10/Sep/2024 14:56:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:19,284 Request with ID 207c7874 for model distilgpt2-124m received
2024-09-10 14:56:19,285 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:56:19,285 127.0.0.1 - - [10/Sep/2024 14:56:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:20,976 Request with ID 5d2f9f03 for model gpt2-124m received
2024-09-10 14:56:20,976 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:56:20,977 127.0.0.1 - - [10/Sep/2024 14:56:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:21,724 Request with ID 47a321bb for model gpt2medium-355m received
2024-09-10 14:56:21,725 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:56:21,725 127.0.0.1 - - [10/Sep/2024 14:56:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:21,745 Time limit condition met for model gpt2medium-355m
2024-09-10 14:56:21,746 Updated batch size:8
2024-09-10 14:56:21,746 Loading model gpt2medium-355m
2024-09-10 14:56:22,286 Request with ID 9b117e9a for model gpt2medium-355m received
2024-09-10 14:56:22,286 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:56:22,286 127.0.0.1 - - [10/Sep/2024 14:56:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:22,666 Request with ID 15820a05 for model gpt2medium-355m received
2024-09-10 14:56:22,666 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:56:22,666 127.0.0.1 - - [10/Sep/2024 14:56:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:23,361 Request with ID b1607e14 for model gpt2medium-355m received
2024-09-10 14:56:23,361 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:56:23,361 127.0.0.1 - - [10/Sep/2024 14:56:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:23,786 Request with ID 3263c39f for model gpt2-124m received
2024-09-10 14:56:23,787 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:56:23,787 127.0.0.1 - - [10/Sep/2024 14:56:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:24,031 Request with ID a434eb35 for model distilgpt2-124m received
2024-09-10 14:56:24,031 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:56:24,031 127.0.0.1 - - [10/Sep/2024 14:56:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:24,669 Request with ID 7a5c9476 for model distilgpt2-124m received
2024-09-10 14:56:24,669 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:56:24,669 127.0.0.1 - - [10/Sep/2024 14:56:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:25,053 Processed batch: ['7fea59a8', 'b4b2b55d', 'dccac22d', '46ad2395', '47a321bb', '1c58', '2c7a', 'ad49'] with model gpt2medium-355m in 3.1561 seconds
2024-09-10 14:56:25,053 Latency for request 7fea59a8 with model gpt2medium-355m: 10.5397 seconds
2024-09-10 14:56:25,055 Latency for request b4b2b55d with model gpt2medium-355m: 9.1716 seconds
2024-09-10 14:56:25,055 Latency for request dccac22d with model gpt2medium-355m: 8.6614 seconds
2024-09-10 14:56:25,056 Latency for request 46ad2395 with model gpt2medium-355m: 7.9983 seconds
2024-09-10 14:56:25,056 Latency for request 47a321bb with model gpt2medium-355m: 3.3290 seconds
2024-09-10 14:56:25,056 Latency for request 1c58 with model gpt2medium-355m: 3.3078 seconds
2024-09-10 14:56:25,056 Latency for request 2c7a with model gpt2medium-355m: 3.3077 seconds
2024-09-10 14:56:25,057 Latency for request ad49 with model gpt2medium-355m: 3.3077 seconds
2024-09-10 14:56:25,162 Time limit condition met for model gpt2-124m
2024-09-10 14:56:25,162 Updated batch size:16
2024-09-10 14:56:25,162 Loading model gpt2-124m
2024-09-10 14:56:25,211 Request with ID 0e8d3ce2 for model distilgpt2-124m received
2024-09-10 14:56:25,212 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:56:25,212 127.0.0.1 - - [10/Sep/2024 14:56:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:25,288 Request with ID 2c280977 for model gpt2-124m received
2024-09-10 14:56:25,288 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:56:25,288 127.0.0.1 - - [10/Sep/2024 14:56:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:25,995 Request with ID e44f3add for model gpt2medium-355m received
2024-09-10 14:56:25,995 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:56:25,995 Adjusted time limit for model gpt2medium-355m: 9.9482 seconds
2024-09-10 14:56:25,995 127.0.0.1 - - [10/Sep/2024 14:56:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:26,463 Request with ID c2a4be1b for model gpt2medium-355m received
2024-09-10 14:56:26,463 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:56:26,464 127.0.0.1 - - [10/Sep/2024 14:56:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:26,524 Request with ID 5ed56822 for model gpt2medium-355m received
2024-09-10 14:56:26,524 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:56:26,524 127.0.0.1 - - [10/Sep/2024 14:56:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:27,103 Processed batch: ['2e9baf4d', 'ecd32d63', '3a9ca0b7', 'd994fb23', 'b52dc6b5', '0a941008', 'a396ccc0', 'ef603c35', '5d2f9f03', '3263c39f', 'fb42', 'de80', '41e7', 'de75', 'c383', '6b25'] with model gpt2-124m in 1.8724 seconds
2024-09-10 14:56:27,103 Latency for request 2e9baf4d with model gpt2-124m: 13.2895 seconds
2024-09-10 14:56:27,104 Latency for request ecd32d63 with model gpt2-124m: 12.7896 seconds
2024-09-10 14:56:27,104 Latency for request 3a9ca0b7 with model gpt2-124m: 12.5526 seconds
2024-09-10 14:56:27,105 Latency for request d994fb23 with model gpt2-124m: 12.3303 seconds
2024-09-10 14:56:27,105 Latency for request b52dc6b5 with model gpt2-124m: 10.4156 seconds
2024-09-10 14:56:27,105 Latency for request 0a941008 with model gpt2-124m: 9.8282 seconds
2024-09-10 14:56:27,105 Latency for request a396ccc0 with model gpt2-124m: 8.9806 seconds
2024-09-10 14:56:27,106 Latency for request ef603c35 with model gpt2-124m: 8.2588 seconds
2024-09-10 14:56:27,106 Latency for request 5d2f9f03 with model gpt2-124m: 6.1273 seconds
2024-09-10 14:56:27,106 Latency for request 3263c39f with model gpt2-124m: 3.3167 seconds
2024-09-10 14:56:27,106 Latency for request fb42 with model gpt2-124m: 1.9412 seconds
2024-09-10 14:56:27,106 Latency for request de80 with model gpt2-124m: 1.9412 seconds
2024-09-10 14:56:27,107 Latency for request 41e7 with model gpt2-124m: 1.9412 seconds
2024-09-10 14:56:27,107 Latency for request de75 with model gpt2-124m: 1.9412 seconds
2024-09-10 14:56:27,107 Latency for request c383 with model gpt2-124m: 1.9412 seconds
2024-09-10 14:56:27,107 Latency for request 6b25 with model gpt2-124m: 1.9412 seconds
2024-09-10 14:56:27,213 Time limit condition met for model gpt2medium-355m
2024-09-10 14:56:27,213 Updated batch size:8
2024-09-10 14:56:27,213 Loading model gpt2medium-355m
2024-09-10 14:56:27,413 Request with ID eaa40a2c for model gpt2medium-355m received
2024-09-10 14:56:27,413 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 14:56:27,413 127.0.0.1 - - [10/Sep/2024 14:56:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:27,843 Request with ID c7d7657d for model gpt2-124m received
2024-09-10 14:56:27,843 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:56:27,843 Adjusted time limit for model gpt2-124m: 13.3395 seconds
2024-09-10 14:56:27,843 127.0.0.1 - - [10/Sep/2024 14:56:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:28,200 Request with ID 47e8a34d for model gpt2medium-355m received
2024-09-10 14:56:28,200 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:56:28,201 127.0.0.1 - - [10/Sep/2024 14:56:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:28,464 Request with ID e15a3a96 for model gpt2medium-355m received
2024-09-10 14:56:28,464 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:56:28,464 127.0.0.1 - - [10/Sep/2024 14:56:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:28,634 Request with ID 82b60521 for model gpt2-124m received
2024-09-10 14:56:28,634 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:56:28,634 127.0.0.1 - - [10/Sep/2024 14:56:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:29,199 Request with ID 663959c3 for model gpt2medium-355m received
2024-09-10 14:56:29,199 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:56:29,199 127.0.0.1 - - [10/Sep/2024 14:56:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:29,830 Request with ID bb491b34 for model distilgpt2-124m received
2024-09-10 14:56:29,830 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:56:29,830 127.0.0.1 - - [10/Sep/2024 14:56:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:30,257 Request with ID 3820f472 for model gpt2-124m received
2024-09-10 14:56:30,257 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:56:30,257 127.0.0.1 - - [10/Sep/2024 14:56:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:30,430 Request with ID 385cb65e for model gpt2medium-355m received
2024-09-10 14:56:30,430 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:56:30,430 127.0.0.1 - - [10/Sep/2024 14:56:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:30,680 Request with ID c65927c8 for model gpt2-124m received
2024-09-10 14:56:30,680 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:56:30,681 127.0.0.1 - - [10/Sep/2024 14:56:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:30,691 Request with ID 0348d35d for model gpt2-124m received
2024-09-10 14:56:30,691 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:56:30,691 127.0.0.1 - - [10/Sep/2024 14:56:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:30,836 Processed batch: ['9b117e9a', '15820a05', 'b1607e14', 'e44f3add', 'c2a4be1b', '5ed56822', '1f71', 'd542'] with model gpt2medium-355m in 3.4762 seconds
2024-09-10 14:56:30,836 Latency for request 9b117e9a with model gpt2medium-355m: 8.5494 seconds
2024-09-10 14:56:30,837 Latency for request 15820a05 with model gpt2medium-355m: 8.1694 seconds
2024-09-10 14:56:30,837 Latency for request b1607e14 with model gpt2medium-355m: 7.4746 seconds
2024-09-10 14:56:30,837 Latency for request e44f3add with model gpt2medium-355m: 4.8408 seconds
2024-09-10 14:56:30,838 Latency for request c2a4be1b with model gpt2medium-355m: 4.3722 seconds
2024-09-10 14:56:30,838 Latency for request 5ed56822 with model gpt2medium-355m: 4.3119 seconds
2024-09-10 14:56:30,838 Latency for request 1f71 with model gpt2medium-355m: 3.6228 seconds
2024-09-10 14:56:30,838 Latency for request d542 with model gpt2medium-355m: 3.6228 seconds
2024-09-10 14:56:30,939 Time limit condition met for model distilgpt2-124m
2024-09-10 14:56:30,940 Updated batch size:16
2024-09-10 14:56:30,940 Loading model distilgpt2-124m
2024-09-10 14:56:31,123 Request with ID cc31d566 for model gpt2-124m received
2024-09-10 14:56:31,123 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:56:31,123 127.0.0.1 - - [10/Sep/2024 14:56:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:31,348 Request with ID fde86589 for model distilgpt2-124m received
2024-09-10 14:56:31,348 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:56:31,348 127.0.0.1 - - [10/Sep/2024 14:56:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:31,555 Request with ID 9979bab4 for model distilgpt2-124m received
2024-09-10 14:56:31,555 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:56:31,555 127.0.0.1 - - [10/Sep/2024 14:56:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:32,149 Request with ID 492a0f50 for model distilgpt2-124m received
2024-09-10 14:56:32,149 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:56:32,150 127.0.0.1 - - [10/Sep/2024 14:56:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:32,279 Request with ID 3cf3ce4b for model distilgpt2-124m received
2024-09-10 14:56:32,279 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:56:32,280 127.0.0.1 - - [10/Sep/2024 14:56:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:32,629 Request with ID 40f0aadc for model distilgpt2-124m received
2024-09-10 14:56:32,629 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:56:32,629 127.0.0.1 - - [10/Sep/2024 14:56:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:32,724 Processed batch: ['a26c2d9f', '20083ef1', '2ed0cbb6', 'e0b71b55', '207c7874', 'a434eb35', '7a5c9476', '0e8d3ce2', 'bb491b34', '9d1a', '9b81', '00de', 'daf5', 'c4e8', 'd09b', '95e4'] with model distilgpt2-124m in 1.7258 seconds
2024-09-10 14:56:32,724 Latency for request a26c2d9f with model distilgpt2-124m: 17.5499 seconds
2024-09-10 14:56:32,725 Latency for request 20083ef1 with model distilgpt2-124m: 17.1842 seconds
2024-09-10 14:56:32,726 Latency for request 2ed0cbb6 with model distilgpt2-124m: 16.6061 seconds
2024-09-10 14:56:32,726 Latency for request e0b71b55 with model distilgpt2-124m: 15.2463 seconds
2024-09-10 14:56:32,726 Latency for request 207c7874 with model distilgpt2-124m: 13.4400 seconds
2024-09-10 14:56:32,727 Latency for request a434eb35 with model distilgpt2-124m: 8.6930 seconds
2024-09-10 14:56:32,727 Latency for request 7a5c9476 with model distilgpt2-124m: 8.0556 seconds
2024-09-10 14:56:32,727 Latency for request 0e8d3ce2 with model distilgpt2-124m: 7.5133 seconds
2024-09-10 14:56:32,727 Latency for request bb491b34 with model distilgpt2-124m: 2.8940 seconds
2024-09-10 14:56:32,728 Latency for request 9d1a with model distilgpt2-124m: 1.7847 seconds
2024-09-10 14:56:32,728 Latency for request 9b81 with model distilgpt2-124m: 1.7847 seconds
2024-09-10 14:56:32,728 Latency for request 00de with model distilgpt2-124m: 1.7847 seconds
2024-09-10 14:56:32,728 Latency for request daf5 with model distilgpt2-124m: 1.7847 seconds
2024-09-10 14:56:32,728 Latency for request c4e8 with model distilgpt2-124m: 1.7847 seconds
2024-09-10 14:56:32,729 Latency for request d09b with model distilgpt2-124m: 1.7847 seconds
2024-09-10 14:56:32,729 Latency for request 95e4 with model distilgpt2-124m: 1.7847 seconds
2024-09-10 14:56:32,835 Request with ID c5f9d626 for model distilgpt2-124m received
2024-09-10 14:56:32,835 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:56:32,835 Adjusted time limit for model distilgpt2-124m: 14.2087 seconds
2024-09-10 14:56:32,835 127.0.0.1 - - [10/Sep/2024 14:56:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:33,074 Request with ID 5f4154f8 for model distilgpt2-124m received
2024-09-10 14:56:33,074 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:56:33,074 127.0.0.1 - - [10/Sep/2024 14:56:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:33,358 Request with ID 21d8d9d7 for model distilgpt2-124m received
2024-09-10 14:56:33,358 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:56:33,359 127.0.0.1 - - [10/Sep/2024 14:56:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:33,546 Request with ID f2c20b5f for model distilgpt2-124m received
2024-09-10 14:56:33,546 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 14:56:33,547 127.0.0.1 - - [10/Sep/2024 14:56:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:34,304 Request with ID 6aaafc78 for model gpt2medium-355m received
2024-09-10 14:56:34,305 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 14:56:34,305 Adjusted time limit for model gpt2medium-355m: 9.9487 seconds
2024-09-10 14:56:34,305 127.0.0.1 - - [10/Sep/2024 14:56:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:34,549 Request with ID ab33c9c2 for model gpt2-124m received
2024-09-10 14:56:34,549 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 14:56:34,550 127.0.0.1 - - [10/Sep/2024 14:56:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:35,548 Request with ID 335b68fa for model gpt2-124m received
2024-09-10 14:56:35,548 Adjusted time limit based on total queue size 24: 3.7500 seconds
2024-09-10 14:56:35,549 127.0.0.1 - - [10/Sep/2024 14:56:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:36,163 Request with ID e6bf5781 for model distilgpt2-124m received
2024-09-10 14:56:36,164 Adjusted time limit based on total queue size 25: 3.7500 seconds
2024-09-10 14:56:36,164 127.0.0.1 - - [10/Sep/2024 14:56:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:36,656 Request with ID 9b062286 for model distilgpt2-124m received
2024-09-10 14:56:36,656 Adjusted time limit based on total queue size 26: 3.7500 seconds
2024-09-10 14:56:36,656 127.0.0.1 - - [10/Sep/2024 14:56:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:36,805 Request with ID c95ac5ed for model gpt2-124m received
2024-09-10 14:56:36,805 Adjusted time limit based on total queue size 27: 3.7500 seconds
2024-09-10 14:56:36,805 127.0.0.1 - - [10/Sep/2024 14:56:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:37,400 Request with ID 1c99d375 for model gpt2-124m received
2024-09-10 14:56:37,400 Adjusted time limit based on total queue size 28: 3.7500 seconds
2024-09-10 14:56:37,401 127.0.0.1 - - [10/Sep/2024 14:56:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:37,508 Request with ID f32d1533 for model gpt2-124m received
2024-09-10 14:56:37,508 Adjusted time limit based on total queue size 29: 3.7500 seconds
2024-09-10 14:56:37,509 127.0.0.1 - - [10/Sep/2024 14:56:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:37,767 Request with ID d052fe3e for model gpt2-124m received
2024-09-10 14:56:37,767 Adjusted time limit based on total queue size 30: 3.7500 seconds
2024-09-10 14:56:37,768 127.0.0.1 - - [10/Sep/2024 14:56:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:38,051 Request with ID 7b4f964b for model gpt2medium-355m received
2024-09-10 14:56:38,052 Adjusted time limit based on total queue size 31: 3.7500 seconds
2024-09-10 14:56:38,052 127.0.0.1 - - [10/Sep/2024 14:56:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:38,124 Time limit condition met for model gpt2-124m
2024-09-10 14:56:38,125 Updated batch size:16
2024-09-10 14:56:38,126 Loading model gpt2-124m
2024-09-10 14:56:38,701 Request with ID e375f15e for model gpt2medium-355m received
2024-09-10 14:56:38,701 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:56:38,701 127.0.0.1 - - [10/Sep/2024 14:56:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:38,828 Request with ID 7f662e79 for model gpt2-124m received
2024-09-10 14:56:38,828 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:56:38,829 127.0.0.1 - - [10/Sep/2024 14:56:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:39,016 Request with ID e81e58eb for model gpt2-124m received
2024-09-10 14:56:39,017 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 14:56:39,017 127.0.0.1 - - [10/Sep/2024 14:56:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:39,415 Request with ID a36a26f5 for model distilgpt2-124m received
2024-09-10 14:56:39,415 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 14:56:39,415 127.0.0.1 - - [10/Sep/2024 14:56:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:39,797 Request with ID d3fa77f5 for model gpt2-124m received
2024-09-10 14:56:39,797 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 14:56:39,797 127.0.0.1 - - [10/Sep/2024 14:56:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:39,906 Request with ID 5fc82a0d for model gpt2medium-355m received
2024-09-10 14:56:39,906 Adjusted time limit based on total queue size 24: 3.7500 seconds
2024-09-10 14:56:39,906 127.0.0.1 - - [10/Sep/2024 14:56:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:40,239 Request with ID b3cf65a4 for model distilgpt2-124m received
2024-09-10 14:56:40,239 Adjusted time limit based on total queue size 25: 3.7500 seconds
2024-09-10 14:56:40,239 127.0.0.1 - - [10/Sep/2024 14:56:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:40,273 Processed batch: ['2c280977', 'c7d7657d', '82b60521', '3820f472', 'c65927c8', '0348d35d', 'cc31d566', 'ab33c9c2', '335b68fa', 'c95ac5ed', '1c99d375', 'f32d1533', 'd052fe3e', 'c56d', 'b5ce', 'e259'] with model gpt2-124m in 2.0556 seconds
2024-09-10 14:56:40,273 Latency for request 2c280977 with model gpt2-124m: 14.9853 seconds
2024-09-10 14:56:40,275 Latency for request c7d7657d with model gpt2-124m: 12.4307 seconds
2024-09-10 14:56:40,275 Latency for request 82b60521 with model gpt2-124m: 11.6394 seconds
2024-09-10 14:56:40,275 Latency for request 3820f472 with model gpt2-124m: 10.0163 seconds
2024-09-10 14:56:40,275 Latency for request c65927c8 with model gpt2-124m: 9.5930 seconds
2024-09-10 14:56:40,276 Latency for request 0348d35d with model gpt2-124m: 9.5822 seconds
2024-09-10 14:56:40,276 Latency for request cc31d566 with model gpt2-124m: 9.1501 seconds
2024-09-10 14:56:40,276 Latency for request ab33c9c2 with model gpt2-124m: 5.7243 seconds
2024-09-10 14:56:40,276 Latency for request 335b68fa with model gpt2-124m: 4.7258 seconds
2024-09-10 14:56:40,276 Latency for request c95ac5ed with model gpt2-124m: 3.4684 seconds
2024-09-10 14:56:40,277 Latency for request 1c99d375 with model gpt2-124m: 2.8734 seconds
2024-09-10 14:56:40,277 Latency for request f32d1533 with model gpt2-124m: 2.7656 seconds
2024-09-10 14:56:40,277 Latency for request d052fe3e with model gpt2-124m: 2.5066 seconds
2024-09-10 14:56:40,277 Latency for request c56d with model gpt2-124m: 2.1481 seconds
2024-09-10 14:56:40,277 Latency for request b5ce with model gpt2-124m: 2.1481 seconds
2024-09-10 14:56:40,278 Latency for request e259 with model gpt2-124m: 2.1481 seconds
2024-09-10 14:56:40,278 Time limit condition met for model gpt2medium-355m
2024-09-10 14:56:40,278 Updated batch size:16
2024-09-10 14:56:40,278 Loading model gpt2medium-355m
2024-09-10 14:56:40,484 Request with ID 6c967233 for model gpt2-124m received
2024-09-10 14:56:40,485 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:56:40,485 Adjusted time limit for model gpt2-124m: 13.3395 seconds
2024-09-10 14:56:40,485 127.0.0.1 - - [10/Sep/2024 14:56:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:40,628 Request with ID 3e38d49f for model gpt2medium-355m received
2024-09-10 14:56:40,628 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:56:40,628 127.0.0.1 - - [10/Sep/2024 14:56:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:41,336 Request with ID 1ab73639 for model gpt2-124m received
2024-09-10 14:56:41,336 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:56:41,337 127.0.0.1 - - [10/Sep/2024 14:56:41] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:41,953 Request with ID d0d3aa3d for model gpt2-124m received
2024-09-10 14:56:41,953 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:56:41,953 127.0.0.1 - - [10/Sep/2024 14:56:41] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:42,229 Request with ID f828650e for model gpt2medium-355m received
2024-09-10 14:56:42,229 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 14:56:42,229 127.0.0.1 - - [10/Sep/2024 14:56:42] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:42,478 Request with ID e6348d3f for model gpt2medium-355m received
2024-09-10 14:56:42,478 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 14:56:42,478 127.0.0.1 - - [10/Sep/2024 14:56:42] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:42,959 Request with ID 350baf2d for model distilgpt2-124m received
2024-09-10 14:56:42,959 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 14:56:42,959 127.0.0.1 - - [10/Sep/2024 14:56:42] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:43,291 Request with ID 446060c0 for model gpt2medium-355m received
2024-09-10 14:56:43,291 Adjusted time limit based on total queue size 24: 3.7500 seconds
2024-09-10 14:56:43,291 127.0.0.1 - - [10/Sep/2024 14:56:43] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:43,678 Request with ID a8006311 for model distilgpt2-124m received
2024-09-10 14:56:43,678 Adjusted time limit based on total queue size 25: 3.7500 seconds
2024-09-10 14:56:43,678 127.0.0.1 - - [10/Sep/2024 14:56:43] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:56:47,405 Processed batch: ['eaa40a2c', '47e8a34d', 'e15a3a96', '663959c3', '385cb65e', '6aaafc78', '7b4f964b', 'e375f15e', '5fc82a0d', '7037', 'd3ab', '67ae', '6bb1', '22f3', '687f', '59e4'] with model gpt2medium-355m in 7.0148 seconds
2024-09-10 14:56:47,405 Latency for request eaa40a2c with model gpt2medium-355m: 19.9924 seconds
2024-09-10 14:56:47,407 Latency for request 47e8a34d with model gpt2medium-355m: 19.2049 seconds
2024-09-10 14:56:47,407 Latency for request e15a3a96 with model gpt2medium-355m: 18.9415 seconds
2024-09-10 14:56:47,408 Latency for request 663959c3 with model gpt2medium-355m: 18.2062 seconds
2024-09-10 14:56:47,408 Latency for request 385cb65e with model gpt2medium-355m: 16.9753 seconds
2024-09-10 14:56:47,408 Latency for request 6aaafc78 with model gpt2medium-355m: 13.1012 seconds
2024-09-10 14:56:47,408 Latency for request 7b4f964b with model gpt2medium-355m: 9.3541 seconds
2024-09-10 14:56:47,409 Latency for request e375f15e with model gpt2medium-355m: 8.7043 seconds
2024-09-10 14:56:47,409 Latency for request 5fc82a0d with model gpt2medium-355m: 7.4993 seconds
2024-09-10 14:56:47,409 Latency for request 7037 with model gpt2medium-355m: 7.1274 seconds
2024-09-10 14:56:47,409 Latency for request d3ab with model gpt2medium-355m: 7.1274 seconds
2024-09-10 14:56:47,409 Latency for request 67ae with model gpt2medium-355m: 7.1274 seconds
2024-09-10 14:56:47,410 Latency for request 6bb1 with model gpt2medium-355m: 7.1274 seconds
2024-09-10 14:56:47,410 Latency for request 22f3 with model gpt2medium-355m: 7.1274 seconds
2024-09-10 14:56:47,410 Latency for request 687f with model gpt2medium-355m: 7.1274 seconds
2024-09-10 14:56:47,410 Latency for request 59e4 with model gpt2medium-355m: 7.1274 seconds
2024-09-10 14:56:47,516 Time limit condition met for model distilgpt2-124m
2024-09-10 14:56:47,516 Updated batch size:16
2024-09-10 14:56:47,516 Loading model distilgpt2-124m
2024-09-10 14:56:48,802 Processed batch: ['fde86589', '9979bab4', '492a0f50', '3cf3ce4b', '40f0aadc', 'c5f9d626', '5f4154f8', '21d8d9d7', 'f2c20b5f', 'e6bf5781', '9b062286', 'a36a26f5', 'b3cf65a4', '350baf2d', 'a8006311', '1869'] with model distilgpt2-124m in 1.2248 seconds
2024-09-10 14:56:48,802 Latency for request fde86589 with model distilgpt2-124m: 17.4542 seconds
2024-09-10 14:56:48,803 Latency for request 9979bab4 with model distilgpt2-124m: 17.2472 seconds
2024-09-10 14:56:48,803 Latency for request 492a0f50 with model distilgpt2-124m: 16.6530 seconds
2024-09-10 14:56:48,804 Latency for request 3cf3ce4b with model distilgpt2-124m: 16.5229 seconds
2024-09-10 14:56:48,804 Latency for request 40f0aadc with model distilgpt2-124m: 16.1731 seconds
2024-09-10 14:56:48,804 Latency for request c5f9d626 with model distilgpt2-124m: 15.9671 seconds
2024-09-10 14:56:48,804 Latency for request 5f4154f8 with model distilgpt2-124m: 15.7287 seconds
2024-09-10 14:56:48,805 Latency for request 21d8d9d7 with model distilgpt2-124m: 15.4442 seconds
2024-09-10 14:56:48,805 Latency for request f2c20b5f with model distilgpt2-124m: 15.2566 seconds
2024-09-10 14:56:48,805 Latency for request e6bf5781 with model distilgpt2-124m: 12.6389 seconds
2024-09-10 14:56:48,805 Latency for request 9b062286 with model distilgpt2-124m: 12.1466 seconds
2024-09-10 14:56:48,805 Latency for request a36a26f5 with model distilgpt2-124m: 9.3872 seconds
2024-09-10 14:56:48,806 Latency for request b3cf65a4 with model distilgpt2-124m: 8.5635 seconds
2024-09-10 14:56:48,806 Latency for request 350baf2d with model distilgpt2-124m: 5.8430 seconds
2024-09-10 14:56:48,806 Latency for request a8006311 with model distilgpt2-124m: 5.1245 seconds
2024-09-10 14:56:48,806 Latency for request 1869 with model distilgpt2-124m: 1.2865 seconds
2024-09-10 14:56:53,181 Time limit condition met for model gpt2-124m
2024-09-10 14:56:53,182 Updated batch size:8
2024-09-10 14:56:53,182 Loading model gpt2-124m
2024-09-10 14:56:54,636 Processed batch: ['7f662e79', 'e81e58eb', 'd3fa77f5', '6c967233', '1ab73639', 'd0d3aa3d', '43af', 'b13f'] with model gpt2-124m in 1.3562 seconds
2024-09-10 14:56:54,636 Latency for request 7f662e79 with model gpt2-124m: 15.8079 seconds
2024-09-10 14:56:54,638 Latency for request e81e58eb with model gpt2-124m: 15.6198 seconds
2024-09-10 14:56:54,638 Latency for request d3fa77f5 with model gpt2-124m: 14.8394 seconds
2024-09-10 14:56:54,638 Latency for request 6c967233 with model gpt2-124m: 14.1518 seconds
2024-09-10 14:56:54,639 Latency for request 1ab73639 with model gpt2-124m: 13.3000 seconds
2024-09-10 14:56:54,639 Latency for request d0d3aa3d with model gpt2-124m: 12.6834 seconds
2024-09-10 14:56:54,639 Latency for request 43af with model gpt2-124m: 1.4546 seconds
2024-09-10 14:56:54,639 Latency for request b13f with model gpt2-124m: 1.4546 seconds
