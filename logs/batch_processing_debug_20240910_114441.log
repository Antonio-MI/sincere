2024-09-10 11:44:46,360 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.11.77:5000
2024-09-10 11:44:46,360 [33mPress CTRL+C to quit[0m
2024-09-10 11:44:46,398 Request with ID 36ad03ea for model distilgpt2-124m received
2024-09-10 11:44:46,399 Adjusted time limit for model distilgpt2-124m: 1.9618 seconds
2024-09-10 11:44:46,400 127.0.0.1 - - [10/Sep/2024 11:44:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:46,400 Request with ID 8e10449e for model gpt2-124m received
2024-09-10 11:44:46,402 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 11:44:46,402 127.0.0.1 - - [10/Sep/2024 11:44:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:46,410 Request with ID 9f5fb097 for model gpt2-124m received
2024-09-10 11:44:46,410 127.0.0.1 - - [10/Sep/2024 11:44:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:46,438 Time limit condition met for model gpt2-124m
2024-09-10 11:44:46,438 Updated batch size:4
2024-09-10 11:44:46,438 Loading model gpt2-124m
2024-09-10 11:44:46,488 Request with ID 85de31a6 for model gpt2medium-355m received
2024-09-10 11:44:46,488 Adjusted time limit for model gpt2medium-355m: 0.0000 seconds
2024-09-10 11:44:46,488 127.0.0.1 - - [10/Sep/2024 11:44:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:46,526 Request with ID 5d4179a9 for model gpt2-124m received
2024-09-10 11:44:46,526 127.0.0.1 - - [10/Sep/2024 11:44:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:46,650 Request with ID 8b1ef93c for model distilgpt2-124m received
2024-09-10 11:44:46,650 127.0.0.1 - - [10/Sep/2024 11:44:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:47,025 Request with ID 8752d81b for model gpt2-124m received
2024-09-10 11:44:47,025 127.0.0.1 - - [10/Sep/2024 11:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:47,076 Request with ID 0baff78d for model gpt2medium-355m received
2024-09-10 11:44:47,076 127.0.0.1 - - [10/Sep/2024 11:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:47,239 Processed batch: ['8e10449e', '9f5fb097', 'fa87', 'a255'] with model gpt2-124m in 0.6974 seconds
2024-09-10 11:44:47,239 Latency for request 8e10449e with model gpt2-124m: 0.8384 seconds
2024-09-10 11:44:47,240 Latency for request 9f5fb097 with model gpt2-124m: 0.8289 seconds
2024-09-10 11:44:47,241 Latency for request fa87 with model gpt2-124m: 0.8005 seconds
2024-09-10 11:44:47,241 Latency for request a255 with model gpt2-124m: 0.8005 seconds
2024-09-10 11:44:47,346 Time limit condition met for model gpt2medium-355m
2024-09-10 11:44:47,346 Updated batch size:4
2024-09-10 11:44:47,346 Loading model gpt2medium-355m
2024-09-10 11:44:47,384 Request with ID 71643a5c for model distilgpt2-124m received
2024-09-10 11:44:47,384 127.0.0.1 - - [10/Sep/2024 11:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:47,712 Request with ID eac9204f for model gpt2medium-355m received
2024-09-10 11:44:47,712 127.0.0.1 - - [10/Sep/2024 11:44:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:48,079 Request with ID b0ee23a8 for model gpt2-124m received
2024-09-10 11:44:48,079 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 11:44:48,079 127.0.0.1 - - [10/Sep/2024 11:44:48] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:48,538 Request with ID b7aeb8a5 for model gpt2medium-355m received
2024-09-10 11:44:48,538 127.0.0.1 - - [10/Sep/2024 11:44:48] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:48,811 Request with ID 0bbcc4fe for model gpt2-124m received
2024-09-10 11:44:48,811 127.0.0.1 - - [10/Sep/2024 11:44:48] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:49,063 Request with ID f747aa2d for model distilgpt2-124m received
2024-09-10 11:44:49,063 127.0.0.1 - - [10/Sep/2024 11:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:49,868 Request with ID 56857111 for model gpt2-124m received
2024-09-10 11:44:49,868 127.0.0.1 - - [10/Sep/2024 11:44:49] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:50,767 Request with ID 8cfb6de0 for model gpt2-124m received
2024-09-10 11:44:50,768 127.0.0.1 - - [10/Sep/2024 11:44:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:51,318 Request with ID 4561cd7f for model distilgpt2-124m received
2024-09-10 11:44:51,318 127.0.0.1 - - [10/Sep/2024 11:44:51] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:52,298 Processed batch: ['85de31a6', '0baff78d', '480e', '0b33'] with model gpt2medium-355m in 4.8626 seconds
2024-09-10 11:44:52,298 Latency for request 85de31a6 with model gpt2medium-355m: 5.8102 seconds
2024-09-10 11:44:52,299 Latency for request 0baff78d with model gpt2medium-355m: 5.2225 seconds
2024-09-10 11:44:52,299 Latency for request 480e with model gpt2medium-355m: 4.9516 seconds
2024-09-10 11:44:52,299 Latency for request 0b33 with model gpt2medium-355m: 4.9516 seconds
2024-09-10 11:44:52,402 Time limit condition met for model distilgpt2-124m
2024-09-10 11:44:52,402 Updated batch size:8
2024-09-10 11:44:52,402 Loading model distilgpt2-124m
2024-09-10 11:44:53,430 Request with ID c9297e1a for model gpt2-124m received
2024-09-10 11:44:53,430 127.0.0.1 - - [10/Sep/2024 11:44:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:53,942 Processed batch: ['36ad03ea', '8b1ef93c', '71643a5c', 'f747aa2d', '4561cd7f', 'd702', '7706', '2b61'] with model distilgpt2-124m in 1.4794 seconds
2024-09-10 11:44:53,942 Latency for request 36ad03ea with model distilgpt2-124m: 7.5437 seconds
2024-09-10 11:44:53,943 Latency for request 8b1ef93c with model distilgpt2-124m: 7.2921 seconds
2024-09-10 11:44:53,943 Latency for request 71643a5c with model distilgpt2-124m: 6.5584 seconds
2024-09-10 11:44:53,944 Latency for request f747aa2d with model distilgpt2-124m: 4.8789 seconds
2024-09-10 11:44:53,944 Latency for request 4561cd7f with model distilgpt2-124m: 2.6241 seconds
2024-09-10 11:44:53,944 Latency for request d702 with model distilgpt2-124m: 1.5401 seconds
2024-09-10 11:44:53,944 Latency for request 7706 with model distilgpt2-124m: 1.5401 seconds
2024-09-10 11:44:53,945 Latency for request 2b61 with model distilgpt2-124m: 1.5401 seconds
2024-09-10 11:44:53,945 Time limit condition met for model gpt2-124m
2024-09-10 11:44:53,945 Updated batch size:8
2024-09-10 11:44:53,945 Loading model gpt2-124m
2024-09-10 11:44:54,363 Request with ID f6060cf3 for model gpt2medium-355m received
2024-09-10 11:44:54,363 Adjusted time limit for model gpt2medium-355m: 0.0000 seconds
2024-09-10 11:44:54,363 127.0.0.1 - - [10/Sep/2024 11:44:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:55,068 Request with ID dbaca4dd for model gpt2medium-355m received
2024-09-10 11:44:55,068 127.0.0.1 - - [10/Sep/2024 11:44:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:55,167 Processed batch: ['5d4179a9', '8752d81b', 'b0ee23a8', '0bbcc4fe', '56857111', '8cfb6de0', 'c9297e1a', '9117'] with model gpt2-124m in 1.1584 seconds
2024-09-10 11:44:55,167 Latency for request 5d4179a9 with model gpt2-124m: 8.6409 seconds
2024-09-10 11:44:55,168 Latency for request 8752d81b with model gpt2-124m: 8.1417 seconds
2024-09-10 11:44:55,168 Latency for request b0ee23a8 with model gpt2-124m: 7.0874 seconds
2024-09-10 11:44:55,168 Latency for request 0bbcc4fe with model gpt2-124m: 6.3561 seconds
2024-09-10 11:44:55,168 Latency for request 56857111 with model gpt2-124m: 5.2989 seconds
2024-09-10 11:44:55,169 Latency for request 8cfb6de0 with model gpt2-124m: 4.3993 seconds
2024-09-10 11:44:55,169 Latency for request c9297e1a with model gpt2-124m: 1.7370 seconds
2024-09-10 11:44:55,169 Latency for request 9117 with model gpt2-124m: 1.2216 seconds
2024-09-10 11:44:55,274 Time limit condition met for model gpt2medium-355m
2024-09-10 11:44:55,274 Updated batch size:4
2024-09-10 11:44:55,274 Loading model gpt2medium-355m
2024-09-10 11:44:55,544 Request with ID d86a3470 for model gpt2medium-355m received
2024-09-10 11:44:55,544 127.0.0.1 - - [10/Sep/2024 11:44:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:56,413 Request with ID a111e4fb for model gpt2medium-355m received
2024-09-10 11:44:56,413 127.0.0.1 - - [10/Sep/2024 11:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:56,944 Request with ID fd4900c5 for model gpt2-124m received
2024-09-10 11:44:56,944 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 11:44:56,945 127.0.0.1 - - [10/Sep/2024 11:44:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:57,249 Request with ID cd9609fb for model distilgpt2-124m received
2024-09-10 11:44:57,250 Adjusted time limit for model distilgpt2-124m: 1.9511 seconds
2024-09-10 11:44:57,250 127.0.0.1 - - [10/Sep/2024 11:44:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:57,994 Processed batch: ['eac9204f', 'b7aeb8a5', 'f6060cf3', 'dbaca4dd'] with model gpt2medium-355m in 2.6097 seconds
2024-09-10 11:44:57,994 Latency for request eac9204f with model gpt2medium-355m: 10.2822 seconds
2024-09-10 11:44:57,995 Latency for request b7aeb8a5 with model gpt2medium-355m: 9.4563 seconds
2024-09-10 11:44:57,996 Latency for request f6060cf3 with model gpt2medium-355m: 3.6310 seconds
2024-09-10 11:44:57,996 Latency for request dbaca4dd with model gpt2medium-355m: 2.9262 seconds
2024-09-10 11:44:58,045 Request with ID d1f4d7e9 for model distilgpt2-124m received
2024-09-10 11:44:58,045 127.0.0.1 - - [10/Sep/2024 11:44:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:58,101 Time limit condition met for model gpt2-124m
2024-09-10 11:44:58,101 Updated batch size:4
2024-09-10 11:44:58,101 Loading model gpt2-124m
2024-09-10 11:44:58,723 Request with ID 6a465a70 for model distilgpt2-124m received
2024-09-10 11:44:58,724 127.0.0.1 - - [10/Sep/2024 11:44:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:58,819 Request with ID c26c834c for model gpt2-124m received
2024-09-10 11:44:58,819 127.0.0.1 - - [10/Sep/2024 11:44:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:59,109 Processed batch: ['fd4900c5', '67f6', '49cf', 'adf5'] with model gpt2-124m in 0.9019 seconds
2024-09-10 11:44:59,109 Latency for request fd4900c5 with model gpt2-124m: 2.1647 seconds
2024-09-10 11:44:59,110 Latency for request 67f6 with model gpt2-124m: 1.0078 seconds
2024-09-10 11:44:59,110 Latency for request 49cf with model gpt2-124m: 1.0078 seconds
2024-09-10 11:44:59,110 Latency for request adf5 with model gpt2-124m: 1.0078 seconds
2024-09-10 11:44:59,215 Time limit condition met for model distilgpt2-124m
2024-09-10 11:44:59,216 Updated batch size:4
2024-09-10 11:44:59,216 Loading model distilgpt2-124m
2024-09-10 11:44:59,702 Request with ID 3ebf3c50 for model gpt2medium-355m received
2024-09-10 11:44:59,703 Adjusted time limit for model gpt2medium-355m: 0.0000 seconds
2024-09-10 11:44:59,703 127.0.0.1 - - [10/Sep/2024 11:44:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:44:59,946 Processed batch: ['cd9609fb', 'd1f4d7e9', '6a465a70', '4ea2'] with model distilgpt2-124m in 0.6730 seconds
2024-09-10 11:44:59,946 Latency for request cd9609fb with model distilgpt2-124m: 2.6969 seconds
2024-09-10 11:44:59,947 Latency for request d1f4d7e9 with model distilgpt2-124m: 1.9011 seconds
2024-09-10 11:44:59,947 Latency for request 6a465a70 with model distilgpt2-124m: 1.2230 seconds
2024-09-10 11:44:59,948 Latency for request 4ea2 with model distilgpt2-124m: 0.7308 seconds
2024-09-10 11:45:00,049 Time limit condition met for model gpt2medium-355m
2024-09-10 11:45:00,049 Updated batch size:4
2024-09-10 11:45:00,049 Loading model gpt2medium-355m
2024-09-10 11:45:00,287 Request with ID 0e3a4696 for model gpt2medium-355m received
2024-09-10 11:45:00,287 127.0.0.1 - - [10/Sep/2024 11:45:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:00,363 Request with ID b6f84437 for model gpt2medium-355m received
2024-09-10 11:45:00,363 127.0.0.1 - - [10/Sep/2024 11:45:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:01,474 Request with ID 4f8c34d9 for model gpt2medium-355m received
2024-09-10 11:45:01,474 127.0.0.1 - - [10/Sep/2024 11:45:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:02,012 Request with ID a83d5d4d for model gpt2-124m received
2024-09-10 11:45:02,012 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 11:45:02,012 127.0.0.1 - - [10/Sep/2024 11:45:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:02,459 Request with ID c9ebd968 for model gpt2medium-355m received
2024-09-10 11:45:02,459 127.0.0.1 - - [10/Sep/2024 11:45:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:02,788 Request with ID e9dada83 for model gpt2medium-355m received
2024-09-10 11:45:02,788 127.0.0.1 - - [10/Sep/2024 11:45:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:02,943 Processed batch: ['d86a3470', 'a111e4fb', '3ebf3c50', '1a6a'] with model gpt2medium-355m in 2.7873 seconds
2024-09-10 11:45:02,943 Latency for request d86a3470 with model gpt2medium-355m: 7.3990 seconds
2024-09-10 11:45:02,944 Latency for request a111e4fb with model gpt2medium-355m: 6.5304 seconds
2024-09-10 11:45:02,944 Latency for request 3ebf3c50 with model gpt2medium-355m: 3.2404 seconds
2024-09-10 11:45:02,945 Latency for request 1a6a with model gpt2medium-355m: 2.8935 seconds
2024-09-10 11:45:02,998 Request with ID a3eb8206 for model gpt2-124m received
2024-09-10 11:45:02,998 127.0.0.1 - - [10/Sep/2024 11:45:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:03,048 Time limit condition met for model gpt2-124m
2024-09-10 11:45:03,048 Updated batch size:4
2024-09-10 11:45:03,048 Loading model gpt2-124m
2024-09-10 11:45:03,706 Request with ID 1926f25c for model gpt2medium-355m received
2024-09-10 11:45:03,706 Adjusted time limit for model gpt2medium-355m: 0.0000 seconds
2024-09-10 11:45:03,707 127.0.0.1 - - [10/Sep/2024 11:45:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:04,095 Processed batch: ['c26c834c', 'a83d5d4d', 'a3eb8206', '7725'] with model gpt2-124m in 0.9768 seconds
2024-09-10 11:45:04,095 Latency for request c26c834c with model gpt2-124m: 5.2762 seconds
2024-09-10 11:45:04,097 Latency for request a83d5d4d with model gpt2-124m: 2.0836 seconds
2024-09-10 11:45:04,097 Latency for request a3eb8206 with model gpt2-124m: 1.0975 seconds
2024-09-10 11:45:04,097 Latency for request 7725 with model gpt2-124m: 1.0476 seconds
2024-09-10 11:45:04,203 Time limit condition met for model gpt2medium-355m
2024-09-10 11:45:04,203 Updated batch size:8
2024-09-10 11:45:04,203 Loading model gpt2medium-355m
2024-09-10 11:45:04,494 Request with ID 27326993 for model distilgpt2-124m received
2024-09-10 11:45:04,494 Adjusted time limit for model distilgpt2-124m: 1.9511 seconds
2024-09-10 11:45:04,494 127.0.0.1 - - [10/Sep/2024 11:45:04] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:05,027 Request with ID db5a9988 for model gpt2-124m received
2024-09-10 11:45:05,027 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 11:45:05,027 127.0.0.1 - - [10/Sep/2024 11:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:05,242 Request with ID 9f33f141 for model gpt2medium-355m received
2024-09-10 11:45:05,242 127.0.0.1 - - [10/Sep/2024 11:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:05,555 Request with ID cbaf16c6 for model gpt2-124m received
2024-09-10 11:45:05,556 127.0.0.1 - - [10/Sep/2024 11:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:05,569 Request with ID ad24d830 for model gpt2-124m received
2024-09-10 11:45:05,569 127.0.0.1 - - [10/Sep/2024 11:45:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:06,109 Request with ID ce8b308d for model gpt2-124m received
2024-09-10 11:45:06,109 127.0.0.1 - - [10/Sep/2024 11:45:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:06,389 Request with ID c5ca2db8 for model distilgpt2-124m received
2024-09-10 11:45:06,390 127.0.0.1 - - [10/Sep/2024 11:45:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:06,649 Request with ID 52bb626c for model distilgpt2-124m received
2024-09-10 11:45:06,649 127.0.0.1 - - [10/Sep/2024 11:45:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:07,391 Request with ID 0933af00 for model distilgpt2-124m received
2024-09-10 11:45:07,391 127.0.0.1 - - [10/Sep/2024 11:45:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:07,553 Request with ID ba28dcd4 for model distilgpt2-124m received
2024-09-10 11:45:07,553 127.0.0.1 - - [10/Sep/2024 11:45:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:07,992 Request with ID b4301646 for model distilgpt2-124m received
2024-09-10 11:45:07,992 127.0.0.1 - - [10/Sep/2024 11:45:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:08,249 Request with ID b2a86941 for model distilgpt2-124m received
2024-09-10 11:45:08,249 127.0.0.1 - - [10/Sep/2024 11:45:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:08,388 Processed batch: ['0e3a4696', 'b6f84437', '4f8c34d9', 'c9ebd968', 'e9dada83', '1926f25c', '7fd4', '5ac0'] with model gpt2medium-355m in 4.0669 seconds
2024-09-10 11:45:08,388 Latency for request 0e3a4696 with model gpt2medium-355m: 8.1015 seconds
2024-09-10 11:45:08,390 Latency for request b6f84437 with model gpt2medium-355m: 8.0257 seconds
2024-09-10 11:45:08,390 Latency for request 4f8c34d9 with model gpt2medium-355m: 6.9142 seconds
2024-09-10 11:45:08,390 Latency for request c9ebd968 with model gpt2medium-355m: 5.9298 seconds
2024-09-10 11:45:08,391 Latency for request e9dada83 with model gpt2medium-355m: 5.6009 seconds
2024-09-10 11:45:08,391 Latency for request 1926f25c with model gpt2medium-355m: 4.6821 seconds
2024-09-10 11:45:08,391 Latency for request 7fd4 with model gpt2medium-355m: 4.1851 seconds
2024-09-10 11:45:08,391 Latency for request 5ac0 with model gpt2medium-355m: 4.1851 seconds
2024-09-10 11:45:08,497 Time limit condition met for model distilgpt2-124m
2024-09-10 11:45:08,497 Updated batch size:8
2024-09-10 11:45:08,497 Loading model distilgpt2-124m
2024-09-10 11:45:08,550 Request with ID 687e941f for model distilgpt2-124m received
2024-09-10 11:45:08,552 127.0.0.1 - - [10/Sep/2024 11:45:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:08,898 Request with ID 79f64cf8 for model distilgpt2-124m received
2024-09-10 11:45:08,898 127.0.0.1 - - [10/Sep/2024 11:45:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:09,132 Request with ID 2b29cd79 for model distilgpt2-124m received
2024-09-10 11:45:09,132 127.0.0.1 - - [10/Sep/2024 11:45:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:09,392 Processed batch: ['27326993', 'c5ca2db8', '52bb626c', '0933af00', 'ba28dcd4', 'b4301646', 'b2a86941', '015a'] with model distilgpt2-124m in 0.8265 seconds
2024-09-10 11:45:09,392 Latency for request 27326993 with model distilgpt2-124m: 4.8980 seconds
2024-09-10 11:45:09,393 Latency for request c5ca2db8 with model distilgpt2-124m: 3.0027 seconds
2024-09-10 11:45:09,393 Latency for request 52bb626c with model distilgpt2-124m: 2.7428 seconds
2024-09-10 11:45:09,394 Latency for request 0933af00 with model distilgpt2-124m: 2.0011 seconds
2024-09-10 11:45:09,394 Latency for request ba28dcd4 with model distilgpt2-124m: 1.8390 seconds
2024-09-10 11:45:09,394 Latency for request b4301646 with model distilgpt2-124m: 1.4000 seconds
2024-09-10 11:45:09,394 Latency for request b2a86941 with model distilgpt2-124m: 1.1429 seconds
2024-09-10 11:45:09,395 Latency for request 015a with model distilgpt2-124m: 0.8954 seconds
2024-09-10 11:45:09,395 Time limit condition met for model gpt2-124m
2024-09-10 11:45:09,395 Updated batch size:4
2024-09-10 11:45:09,395 Loading model gpt2-124m
2024-09-10 11:45:10,080 Request with ID 31b6ca0e for model gpt2medium-355m received
2024-09-10 11:45:10,080 Adjusted time limit for model gpt2medium-355m: 0.0000 seconds
2024-09-10 11:45:10,080 127.0.0.1 - - [10/Sep/2024 11:45:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:10,384 Request with ID 2492bdc9 for model gpt2-124m received
2024-09-10 11:45:10,385 127.0.0.1 - - [10/Sep/2024 11:45:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:10,430 Processed batch: ['db5a9988', 'cbaf16c6', 'ad24d830', 'ce8b308d'] with model gpt2-124m in 0.9679 seconds
2024-09-10 11:45:10,430 Latency for request db5a9988 with model gpt2-124m: 5.4031 seconds
2024-09-10 11:45:10,431 Latency for request cbaf16c6 with model gpt2-124m: 4.8750 seconds
2024-09-10 11:45:10,432 Latency for request ad24d830 with model gpt2-124m: 4.8616 seconds
2024-09-10 11:45:10,432 Latency for request ce8b308d with model gpt2-124m: 4.3218 seconds
2024-09-10 11:45:10,537 Time limit condition met for model gpt2medium-355m
2024-09-10 11:45:10,537 Updated batch size:4
2024-09-10 11:45:10,537 Loading model gpt2medium-355m
2024-09-10 11:45:11,631 Request with ID 9238f784 for model gpt2-124m received
2024-09-10 11:45:11,631 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 11:45:11,631 127.0.0.1 - - [10/Sep/2024 11:45:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:12,399 Request with ID cb8ee169 for model distilgpt2-124m received
2024-09-10 11:45:12,399 Adjusted time limit for model distilgpt2-124m: 1.9511 seconds
2024-09-10 11:45:12,399 127.0.0.1 - - [10/Sep/2024 11:45:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:13,015 Request with ID 01c02efb for model distilgpt2-124m received
2024-09-10 11:45:13,015 127.0.0.1 - - [10/Sep/2024 11:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:13,202 Request with ID ff1a845b for model gpt2-124m received
2024-09-10 11:45:13,202 127.0.0.1 - - [10/Sep/2024 11:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:13,203 Processed batch: ['9f33f141', '31b6ca0e', 'd61c', '1c75'] with model gpt2medium-355m in 2.5503 seconds
2024-09-10 11:45:13,203 Latency for request 9f33f141 with model gpt2medium-355m: 7.9614 seconds
2024-09-10 11:45:13,204 Latency for request 31b6ca0e with model gpt2medium-355m: 3.1236 seconds
2024-09-10 11:45:13,204 Latency for request d61c with model gpt2medium-355m: 2.6663 seconds
2024-09-10 11:45:13,205 Latency for request 1c75 with model gpt2medium-355m: 2.6663 seconds
2024-09-10 11:45:13,308 Time limit condition met for model gpt2-124m
2024-09-10 11:45:13,308 Updated batch size:4
2024-09-10 11:45:13,308 Loading model gpt2-124m
2024-09-10 11:45:13,942 Request with ID 9f061dbd for model gpt2-124m received
2024-09-10 11:45:13,942 127.0.0.1 - - [10/Sep/2024 11:45:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:14,075 Request with ID 75673275 for model gpt2-124m received
2024-09-10 11:45:14,076 127.0.0.1 - - [10/Sep/2024 11:45:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:14,203 Processed batch: ['2492bdc9', '9238f784', 'ff1a845b', '895e'] with model gpt2-124m in 0.8241 seconds
2024-09-10 11:45:14,204 Latency for request 2492bdc9 with model gpt2-124m: 3.8191 seconds
2024-09-10 11:45:14,205 Latency for request 9238f784 with model gpt2-124m: 2.5728 seconds
2024-09-10 11:45:14,205 Latency for request ff1a845b with model gpt2-124m: 1.0011 seconds
2024-09-10 11:45:14,205 Latency for request 895e with model gpt2-124m: 0.8957 seconds
2024-09-10 11:45:14,397 Request with ID 57097e9b for model gpt2-124m received
2024-09-10 11:45:14,397 Adjusted time limit for model gpt2-124m: 0.0000 seconds
2024-09-10 11:45:14,397 127.0.0.1 - - [10/Sep/2024 11:45:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 11:45:14,413 Time limit condition met for model distilgpt2-124m
2024-09-10 11:45:14,413 Updated batch size:8
2024-09-10 11:45:14,413 Loading model distilgpt2-124m
2024-09-10 11:45:15,262 Processed batch: ['687e941f', '79f64cf8', '2b29cd79', 'cb8ee169', '01c02efb', '1e10', '6e7c', '74ca'] with model distilgpt2-124m in 0.7983 seconds
2024-09-10 11:45:15,262 Latency for request 687e941f with model distilgpt2-124m: 6.7114 seconds
2024-09-10 11:45:15,263 Latency for request 79f64cf8 with model distilgpt2-124m: 6.3637 seconds
2024-09-10 11:45:15,263 Latency for request 2b29cd79 with model distilgpt2-124m: 6.1302 seconds
2024-09-10 11:45:15,264 Latency for request cb8ee169 with model distilgpt2-124m: 2.8630 seconds
2024-09-10 11:45:15,264 Latency for request 01c02efb with model distilgpt2-124m: 2.2467 seconds
2024-09-10 11:45:15,264 Latency for request 1e10 with model distilgpt2-124m: 0.8490 seconds
2024-09-10 11:45:15,264 Latency for request 6e7c with model distilgpt2-124m: 0.8490 seconds
2024-09-10 11:45:15,265 Latency for request 74ca with model distilgpt2-124m: 0.8490 seconds
2024-09-10 11:45:15,265 Time limit condition met for model gpt2-124m
2024-09-10 11:45:15,265 Updated batch size:4
2024-09-10 11:45:15,265 Loading model gpt2-124m
2024-09-10 11:45:16,220 Processed batch: ['9f061dbd', '75673275', '57097e9b', '184a'] with model gpt2-124m in 0.8897 seconds
2024-09-10 11:45:16,220 Latency for request 9f061dbd with model gpt2-124m: 2.2784 seconds
2024-09-10 11:45:16,222 Latency for request 75673275 with model gpt2-124m: 2.1449 seconds
2024-09-10 11:45:16,222 Latency for request 57097e9b with model gpt2-124m: 1.8234 seconds
2024-09-10 11:45:16,222 Latency for request 184a with model gpt2-124m: 0.9555 seconds
