2024-09-10 15:56:07,846 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.11.77:5000
2024-09-10 15:56:07,846 [33mPress CTRL+C to quit[0m
2024-09-10 15:56:07,865 Request with ID c2ae642f for model gpt2-124m received
2024-09-10 15:56:07,865 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 15:56:07,866 Adjusted time limit for model gpt2-124m: 13.6926 seconds
2024-09-10 15:56:07,866 127.0.0.1 - - [10/Sep/2024 15:56:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:08,161 Request with ID bab74da1 for model gpt2-124m received
2024-09-10 15:56:08,162 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:56:08,162 127.0.0.1 - - [10/Sep/2024 15:56:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:08,360 Request with ID 8c5ba17e for model gpt2medium-355m received
2024-09-10 15:56:08,361 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:56:08,361 Adjusted time limit for model gpt2medium-355m: 11.8866 seconds
2024-09-10 15:56:08,361 127.0.0.1 - - [10/Sep/2024 15:56:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:08,398 Request with ID 9ad898a8 for model gpt2-124m received
2024-09-10 15:56:08,398 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:56:08,398 127.0.0.1 - - [10/Sep/2024 15:56:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:08,623 Request with ID cbc7a9df for model gpt2-124m received
2024-09-10 15:56:08,623 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:56:08,624 127.0.0.1 - - [10/Sep/2024 15:56:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:09,023 Request with ID 77a463c2 for model distilgpt2-124m received
2024-09-10 15:56:09,023 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:56:09,023 Adjusted time limit for model distilgpt2-124m: 14.1882 seconds
2024-09-10 15:56:09,024 127.0.0.1 - - [10/Sep/2024 15:56:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:09,390 Request with ID 775fdcc4 for model distilgpt2-124m received
2024-09-10 15:56:09,391 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:56:09,391 127.0.0.1 - - [10/Sep/2024 15:56:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:09,731 Request with ID 604b0c67 for model gpt2medium-355m received
2024-09-10 15:56:09,731 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:56:09,732 127.0.0.1 - - [10/Sep/2024 15:56:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:09,967 Request with ID 95df6a0e for model distilgpt2-124m received
2024-09-10 15:56:09,968 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:56:09,968 127.0.0.1 - - [10/Sep/2024 15:56:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:10,241 Request with ID dfda808d for model gpt2medium-355m received
2024-09-10 15:56:10,242 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:56:10,242 127.0.0.1 - - [10/Sep/2024 15:56:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:10,318 Time limit condition met for model gpt2medium-355m
2024-09-10 15:56:10,319 Updated batch size:4
2024-09-10 15:56:10,319 Loading model gpt2medium-355m
2024-09-10 15:56:10,533 Request with ID e3242b82 for model gpt2-124m received
2024-09-10 15:56:10,533 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:56:10,533 127.0.0.1 - - [10/Sep/2024 15:56:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:10,900 Request with ID e849ca3a for model gpt2medium-355m received
2024-09-10 15:56:10,900 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:56:10,900 127.0.0.1 - - [10/Sep/2024 15:56:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:11,119 Request with ID d6f3cb1f for model gpt2-124m received
2024-09-10 15:56:11,119 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:56:11,119 127.0.0.1 - - [10/Sep/2024 15:56:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:11,321 Request with ID f5b33f10 for model distilgpt2-124m received
2024-09-10 15:56:11,321 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:56:11,321 127.0.0.1 - - [10/Sep/2024 15:56:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:11,965 Request with ID d5168097 for model gpt2-124m received
2024-09-10 15:56:11,965 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:56:11,965 127.0.0.1 - - [10/Sep/2024 15:56:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:12,685 Request with ID 8decd868 for model gpt2-124m received
2024-09-10 15:56:12,685 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:56:12,685 Batch size condition met for model gpt2-124m
2024-09-10 15:56:12,942 Processed batch: ['8c5ba17e', '604b0c67', 'dfda808d', '9d14'] with model gpt2medium-355m in 2.4912 seconds
2024-09-10 15:56:12,942 Latency for request 8c5ba17e with model gpt2medium-355m: 4.5816 seconds
2024-09-10 15:56:12,944 Latency for request 604b0c67 with model gpt2medium-355m: 3.2112 seconds
2024-09-10 15:56:12,945 Latency for request dfda808d with model gpt2medium-355m: 2.7006 seconds
2024-09-10 15:56:12,945 Latency for request 9d14 with model gpt2medium-355m: 2.6234 seconds
2024-09-10 15:56:12,945 Updated batch size:8
2024-09-10 15:56:12,945 Loading model gpt2-124m
2024-09-10 15:56:13,126 Request with ID 7548e9e2 for model distilgpt2-124m received
2024-09-10 15:56:13,126 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:56:13,126 127.0.0.1 - - [10/Sep/2024 15:56:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:14,549 Processed batch: ['c2ae642f', 'bab74da1', '9ad898a8', 'cbc7a9df', 'e3242b82', 'd6f3cb1f', 'd5168097', '8decd868'] with model gpt2-124m in 1.5331 seconds
2024-09-10 15:56:14,549 Latency for request c2ae642f with model gpt2-124m: 6.6842 seconds
2024-09-10 15:56:14,550 Latency for request bab74da1 with model gpt2-124m: 6.3879 seconds
2024-09-10 15:56:14,551 Latency for request 9ad898a8 with model gpt2-124m: 6.1515 seconds
2024-09-10 15:56:14,551 Latency for request cbc7a9df with model gpt2-124m: 5.9265 seconds
2024-09-10 15:56:14,551 Latency for request e3242b82 with model gpt2-124m: 4.0165 seconds
2024-09-10 15:56:14,551 Latency for request d6f3cb1f with model gpt2-124m: 3.4307 seconds
2024-09-10 15:56:14,552 Latency for request d5168097 with model gpt2-124m: 2.5844 seconds
2024-09-10 15:56:14,552 Latency for request 8decd868 with model gpt2-124m: 1.8644 seconds
2024-09-10 15:56:14,552 127.0.0.1 - - [10/Sep/2024 15:56:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:14,816 Request with ID c93b708a for model gpt2-124m received
2024-09-10 15:56:14,816 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:56:14,816 Adjusted time limit for model gpt2-124m: 13.6858 seconds
2024-09-10 15:56:14,816 127.0.0.1 - - [10/Sep/2024 15:56:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:15,565 Request with ID 71c4e75c for model gpt2medium-355m received
2024-09-10 15:56:15,565 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:56:15,565 Adjusted time limit for model gpt2medium-355m: 11.8798 seconds
2024-09-10 15:56:15,565 127.0.0.1 - - [10/Sep/2024 15:56:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:16,129 Request with ID d854452f for model gpt2medium-355m received
2024-09-10 15:56:16,129 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:56:16,130 127.0.0.1 - - [10/Sep/2024 15:56:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:16,174 Time limit condition met for model gpt2medium-355m
2024-09-10 15:56:16,175 Updated batch size:4
2024-09-10 15:56:16,175 Loading model gpt2medium-355m
2024-09-10 15:56:16,509 Request with ID 8412efa5 for model gpt2medium-355m received
2024-09-10 15:56:16,509 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:56:16,509 127.0.0.1 - - [10/Sep/2024 15:56:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:17,204 Request with ID ec756103 for model gpt2medium-355m received
2024-09-10 15:56:17,204 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:56:17,204 127.0.0.1 - - [10/Sep/2024 15:56:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:17,629 Request with ID 06fd2468 for model gpt2-124m received
2024-09-10 15:56:17,629 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:56:17,630 127.0.0.1 - - [10/Sep/2024 15:56:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:17,875 Request with ID 54d8bc3e for model distilgpt2-124m received
2024-09-10 15:56:17,875 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:56:17,875 127.0.0.1 - - [10/Sep/2024 15:56:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:18,511 Request with ID 2d583f92 for model distilgpt2-124m received
2024-09-10 15:56:18,511 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:56:18,512 127.0.0.1 - - [10/Sep/2024 15:56:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:18,835 Processed batch: ['e849ca3a', '71c4e75c', 'd854452f', '8e22'] with model gpt2medium-355m in 2.5020 seconds
2024-09-10 15:56:18,835 Latency for request e849ca3a with model gpt2medium-355m: 7.9347 seconds
2024-09-10 15:56:18,836 Latency for request 71c4e75c with model gpt2medium-355m: 3.2702 seconds
2024-09-10 15:56:18,836 Latency for request d854452f with model gpt2medium-355m: 2.7055 seconds
2024-09-10 15:56:18,836 Latency for request 8e22 with model gpt2medium-355m: 2.6601 seconds
2024-09-10 15:56:19,055 Request with ID 2c06081c for model distilgpt2-124m received
2024-09-10 15:56:19,055 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:56:19,055 Batch size condition met for model distilgpt2-124m
2024-09-10 15:56:19,055 Updated batch size:8
2024-09-10 15:56:19,055 Loading model distilgpt2-124m
2024-09-10 15:56:19,130 Request with ID 1fd75590 for model gpt2-124m received
2024-09-10 15:56:19,131 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:56:19,131 127.0.0.1 - - [10/Sep/2024 15:56:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:19,837 Request with ID d3faea3a for model gpt2medium-355m received
2024-09-10 15:56:19,837 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:56:19,837 Adjusted time limit for model gpt2medium-355m: 11.8803 seconds
2024-09-10 15:56:19,837 127.0.0.1 - - [10/Sep/2024 15:56:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:20,065 Processed batch: ['77a463c2', '775fdcc4', '95df6a0e', 'f5b33f10', '7548e9e2', '54d8bc3e', '2d583f92', '2c06081c'] with model distilgpt2-124m in 0.9531 seconds
2024-09-10 15:56:20,065 Latency for request 77a463c2 with model distilgpt2-124m: 11.0423 seconds
2024-09-10 15:56:20,066 Latency for request 775fdcc4 with model distilgpt2-124m: 10.6749 seconds
2024-09-10 15:56:20,066 Latency for request 95df6a0e with model distilgpt2-124m: 10.0975 seconds
2024-09-10 15:56:20,066 Latency for request f5b33f10 with model distilgpt2-124m: 8.7440 seconds
2024-09-10 15:56:20,066 Latency for request 7548e9e2 with model distilgpt2-124m: 6.9390 seconds
2024-09-10 15:56:20,067 Latency for request 54d8bc3e with model distilgpt2-124m: 2.1902 seconds
2024-09-10 15:56:20,067 Latency for request 2d583f92 with model distilgpt2-124m: 1.5535 seconds
2024-09-10 15:56:20,067 Latency for request 2c06081c with model distilgpt2-124m: 1.0102 seconds
2024-09-10 15:56:20,067 127.0.0.1 - - [10/Sep/2024 15:56:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:20,304 Request with ID 904a31b5 for model gpt2medium-355m received
2024-09-10 15:56:20,304 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:56:20,304 127.0.0.1 - - [10/Sep/2024 15:56:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:20,366 Request with ID 12b67e9f for model gpt2medium-355m received
2024-09-10 15:56:20,366 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:56:20,366 127.0.0.1 - - [10/Sep/2024 15:56:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:20,377 Time limit condition met for model gpt2medium-355m
2024-09-10 15:56:20,377 Updated batch size:8
2024-09-10 15:56:20,377 Loading model gpt2medium-355m
2024-09-10 15:56:21,255 Request with ID c97004ba for model gpt2medium-355m received
2024-09-10 15:56:21,255 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:56:21,255 127.0.0.1 - - [10/Sep/2024 15:56:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:21,685 Request with ID 725bf040 for model gpt2-124m received
2024-09-10 15:56:21,685 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:56:21,685 127.0.0.1 - - [10/Sep/2024 15:56:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:22,042 Request with ID 070cf906 for model gpt2medium-355m received
2024-09-10 15:56:22,042 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:56:22,043 127.0.0.1 - - [10/Sep/2024 15:56:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:22,306 Request with ID f730b16b for model gpt2medium-355m received
2024-09-10 15:56:22,306 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:56:22,306 127.0.0.1 - - [10/Sep/2024 15:56:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:22,475 Request with ID 9075de37 for model gpt2-124m received
2024-09-10 15:56:22,475 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:56:22,476 127.0.0.1 - - [10/Sep/2024 15:56:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:23,041 Request with ID 145084f6 for model gpt2medium-355m received
2024-09-10 15:56:23,041 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:56:23,041 127.0.0.1 - - [10/Sep/2024 15:56:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:23,672 Request with ID dd8a422f for model distilgpt2-124m received
2024-09-10 15:56:23,673 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:56:23,673 Adjusted time limit for model distilgpt2-124m: 14.1775 seconds
2024-09-10 15:56:23,673 127.0.0.1 - - [10/Sep/2024 15:56:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:23,950 Processed batch: ['8412efa5', 'ec756103', 'd3faea3a', '904a31b5', '12b67e9f', 'bd37', '9f01', '8184'] with model gpt2medium-355m in 3.4682 seconds
2024-09-10 15:56:23,950 Latency for request 8412efa5 with model gpt2medium-355m: 7.4409 seconds
2024-09-10 15:56:23,951 Latency for request ec756103 with model gpt2medium-355m: 6.7462 seconds
2024-09-10 15:56:23,951 Latency for request d3faea3a with model gpt2medium-355m: 4.1128 seconds
2024-09-10 15:56:23,951 Latency for request 904a31b5 with model gpt2medium-355m: 3.6458 seconds
2024-09-10 15:56:23,952 Latency for request 12b67e9f with model gpt2medium-355m: 3.5840 seconds
2024-09-10 15:56:23,952 Latency for request bd37 with model gpt2medium-355m: 3.5725 seconds
2024-09-10 15:56:23,952 Latency for request 9f01 with model gpt2medium-355m: 3.5725 seconds
2024-09-10 15:56:23,952 Latency for request 8184 with model gpt2medium-355m: 3.5725 seconds
2024-09-10 15:56:24,100 Request with ID e5e78b5d for model gpt2-124m received
2024-09-10 15:56:24,100 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:56:24,100 127.0.0.1 - - [10/Sep/2024 15:56:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:24,272 Request with ID e3f52f94 for model gpt2medium-355m received
2024-09-10 15:56:24,272 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:56:24,272 Adjusted time limit for model gpt2medium-355m: 11.8759 seconds
2024-09-10 15:56:24,273 127.0.0.1 - - [10/Sep/2024 15:56:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:24,525 Request with ID 933768f1 for model gpt2-124m received
2024-09-10 15:56:24,525 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:56:24,526 127.0.0.1 - - [10/Sep/2024 15:56:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:24,536 Request with ID 5333f0ef for model gpt2-124m received
2024-09-10 15:56:24,537 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:56:24,537 Batch size condition met for model gpt2-124m
2024-09-10 15:56:24,537 Updated batch size:8
2024-09-10 15:56:24,537 Loading model gpt2-124m
2024-09-10 15:56:24,967 Request with ID f9da4aeb for model gpt2-124m received
2024-09-10 15:56:24,967 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:56:24,967 127.0.0.1 - - [10/Sep/2024 15:56:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:25,013 Time limit condition met for model gpt2-124m
2024-09-10 15:56:25,192 Request with ID fb816804 for model distilgpt2-124m received
2024-09-10 15:56:25,192 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:56:25,192 127.0.0.1 - - [10/Sep/2024 15:56:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:25,400 Request with ID 80940509 for model distilgpt2-124m received
2024-09-10 15:56:25,400 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:56:25,400 127.0.0.1 - - [10/Sep/2024 15:56:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:25,878 Processed batch: ['c93b708a', '06fd2468', '1fd75590', '725bf040', '9075de37', 'e5e78b5d', '933768f1', '5333f0ef'] with model gpt2-124m in 1.2439 seconds
2024-09-10 15:56:25,878 Latency for request c93b708a with model gpt2-124m: 11.0626 seconds
2024-09-10 15:56:25,879 Latency for request 06fd2468 with model gpt2-124m: 8.2488 seconds
2024-09-10 15:56:25,879 Latency for request 1fd75590 with model gpt2-124m: 6.7479 seconds
2024-09-10 15:56:25,879 Latency for request 725bf040 with model gpt2-124m: 4.1936 seconds
2024-09-10 15:56:25,880 Latency for request 9075de37 with model gpt2-124m: 3.4029 seconds
2024-09-10 15:56:25,880 Latency for request e5e78b5d with model gpt2-124m: 1.7780 seconds
2024-09-10 15:56:25,880 Latency for request 933768f1 with model gpt2-124m: 1.3533 seconds
2024-09-10 15:56:25,880 Latency for request 5333f0ef with model gpt2-124m: 1.3418 seconds
2024-09-10 15:56:25,881 127.0.0.1 - - [10/Sep/2024 15:56:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:25,881 Updated batch size:1
2024-09-10 15:56:25,881 Loading model gpt2-124m
2024-09-10 15:56:25,994 Request with ID 4027cde0 for model distilgpt2-124m received
2024-09-10 15:56:25,994 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:56:25,994 127.0.0.1 - - [10/Sep/2024 15:56:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:26,124 Request with ID 1357d72f for model distilgpt2-124m received
2024-09-10 15:56:26,124 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:56:26,124 127.0.0.1 - - [10/Sep/2024 15:56:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:26,339 Processed batch: ['f9da4aeb'] with model gpt2-124m in 0.4582 seconds
2024-09-10 15:56:26,339 Latency for request f9da4aeb with model gpt2-124m: 1.3725 seconds
2024-09-10 15:56:26,474 Request with ID 65acea06 for model distilgpt2-124m received
2024-09-10 15:56:26,474 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:56:26,474 127.0.0.1 - - [10/Sep/2024 15:56:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:26,682 Request with ID ece665dc for model distilgpt2-124m received
2024-09-10 15:56:26,682 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:56:26,682 127.0.0.1 - - [10/Sep/2024 15:56:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:26,921 Request with ID 4c5a5741 for model distilgpt2-124m received
2024-09-10 15:56:26,921 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:56:26,921 Batch size condition met for model distilgpt2-124m
2024-09-10 15:56:26,921 Updated batch size:8
2024-09-10 15:56:26,922 Loading model distilgpt2-124m
2024-09-10 15:56:27,202 Request with ID 19fd7fc0 for model distilgpt2-124m received
2024-09-10 15:56:27,202 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:56:27,202 127.0.0.1 - - [10/Sep/2024 15:56:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:27,388 Request with ID 9bc4b930 for model distilgpt2-124m received
2024-09-10 15:56:27,388 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:56:27,388 127.0.0.1 - - [10/Sep/2024 15:56:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:27,734 Processed batch: ['dd8a422f', 'fb816804', '80940509', '4027cde0', '1357d72f', '65acea06', 'ece665dc', '4c5a5741'] with model distilgpt2-124m in 0.7272 seconds
2024-09-10 15:56:27,734 Latency for request dd8a422f with model distilgpt2-124m: 4.0618 seconds
2024-09-10 15:56:27,735 Latency for request fb816804 with model distilgpt2-124m: 2.5425 seconds
2024-09-10 15:56:27,735 Latency for request 80940509 with model distilgpt2-124m: 2.3342 seconds
2024-09-10 15:56:27,736 Latency for request 4027cde0 with model distilgpt2-124m: 1.7402 seconds
2024-09-10 15:56:27,736 Latency for request 1357d72f with model distilgpt2-124m: 1.6107 seconds
2024-09-10 15:56:27,736 Latency for request 65acea06 with model distilgpt2-124m: 1.2606 seconds
2024-09-10 15:56:27,736 Latency for request ece665dc with model distilgpt2-124m: 1.0526 seconds
2024-09-10 15:56:27,736 Latency for request 4c5a5741 with model distilgpt2-124m: 0.8134 seconds
2024-09-10 15:56:27,737 127.0.0.1 - - [10/Sep/2024 15:56:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:56:28,652 Time limit condition met for model gpt2medium-355m
2024-09-10 15:56:28,652 Updated batch size:8
2024-09-10 15:56:28,652 Loading model gpt2medium-355m
2024-09-10 15:56:32,739 Processed batch: ['c97004ba', '070cf906', 'f730b16b', '145084f6', 'e3f52f94', '66b9', '3b61', 'b87b'] with model gpt2medium-355m in 3.9418 seconds
2024-09-10 15:56:32,739 Latency for request c97004ba with model gpt2medium-355m: 11.4841 seconds
2024-09-10 15:56:32,740 Latency for request 070cf906 with model gpt2medium-355m: 10.6964 seconds
2024-09-10 15:56:32,740 Latency for request f730b16b with model gpt2medium-355m: 10.4329 seconds
2024-09-10 15:56:32,740 Latency for request 145084f6 with model gpt2medium-355m: 9.6978 seconds
2024-09-10 15:56:32,741 Latency for request e3f52f94 with model gpt2medium-355m: 8.4664 seconds
2024-09-10 15:56:32,741 Latency for request 66b9 with model gpt2medium-355m: 4.0865 seconds
2024-09-10 15:56:32,741 Latency for request 3b61 with model gpt2medium-355m: 4.0864 seconds
2024-09-10 15:56:32,741 Latency for request b87b with model gpt2medium-355m: 4.0864 seconds
