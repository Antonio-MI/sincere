2024-09-10 15:22:38,234 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.11.77:5000
2024-09-10 15:22:38,235 [33mPress CTRL+C to quit[0m
2024-09-10 15:22:38,258 Request with ID 2db1fa91 for model distilgpt2-124m received
2024-09-10 15:22:38,259 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 15:22:38,259 Adjusted time limit for model distilgpt2-124m: 14.2150 seconds
2024-09-10 15:22:38,260 127.0.0.1 - - [10/Sep/2024 15:22:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:38,264 Request with ID de7082fd for model gpt2-124m received
2024-09-10 15:22:38,264 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:22:38,264 Adjusted time limit for model gpt2-124m: 13.3502 seconds
2024-09-10 15:22:38,265 127.0.0.1 - - [10/Sep/2024 15:22:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:38,300 Request with ID e2c8ab97 for model gpt2medium-355m received
2024-09-10 15:22:38,300 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:22:38,300 Adjusted time limit for model gpt2medium-355m: 9.9550 seconds
2024-09-10 15:22:38,301 127.0.0.1 - - [10/Sep/2024 15:22:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:38,340 Request with ID 40dcbad0 for model gpt2-124m received
2024-09-10 15:22:38,340 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:22:38,341 127.0.0.1 - - [10/Sep/2024 15:22:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:38,502 Request with ID 938f9e0f for model gpt2-124m received
2024-09-10 15:22:38,503 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:22:38,503 127.0.0.1 - - [10/Sep/2024 15:22:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:38,624 Request with ID 29230bda for model distilgpt2-124m received
2024-09-10 15:22:38,625 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:22:38,625 127.0.0.1 - - [10/Sep/2024 15:22:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:38,807 Request with ID 2d69a89b for model gpt2-124m received
2024-09-10 15:22:38,808 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:22:38,808 127.0.0.1 - - [10/Sep/2024 15:22:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:38,966 Request with ID 5520b469 for model gpt2medium-355m received
2024-09-10 15:22:38,967 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:22:38,967 127.0.0.1 - - [10/Sep/2024 15:22:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:39,203 Request with ID 4f54c95f for model distilgpt2-124m received
2024-09-10 15:22:39,203 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:22:39,203 127.0.0.1 - - [10/Sep/2024 15:22:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:39,478 Request with ID b13b7fdf for model gpt2medium-355m received
2024-09-10 15:22:39,478 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:22:39,479 127.0.0.1 - - [10/Sep/2024 15:22:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:39,772 Request with ID 39c64f7f for model gpt2-124m received
2024-09-10 15:22:39,773 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:22:39,773 127.0.0.1 - - [10/Sep/2024 15:22:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:40,140 Request with ID 53d5e1da for model gpt2medium-355m received
2024-09-10 15:22:40,141 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:22:40,141 127.0.0.1 - - [10/Sep/2024 15:22:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:40,360 Request with ID b28f3f78 for model gpt2-124m received
2024-09-10 15:22:40,361 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:22:40,361 127.0.0.1 - - [10/Sep/2024 15:22:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:40,561 Request with ID 28774b4c for model distilgpt2-124m received
2024-09-10 15:22:40,561 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:22:40,561 127.0.0.1 - - [10/Sep/2024 15:22:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:41,207 Request with ID 33400eb2 for model gpt2-124m received
2024-09-10 15:22:41,207 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:22:41,208 127.0.0.1 - - [10/Sep/2024 15:22:41] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:41,928 Request with ID 61d3501b for model gpt2-124m received
2024-09-10 15:22:41,928 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:22:41,929 Batch size condition met for model gpt2-124m
2024-09-10 15:22:41,929 Updated batch size:8
2024-09-10 15:22:41,929 Loading model gpt2-124m
2024-09-10 15:22:42,366 Request with ID c265f044 for model distilgpt2-124m received
2024-09-10 15:22:42,366 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:22:42,366 127.0.0.1 - - [10/Sep/2024 15:22:42] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:43,202 Processed batch: ['de7082fd', '40dcbad0', '938f9e0f', '2d69a89b', '39c64f7f', 'b28f3f78', '33400eb2', '61d3501b'] with model gpt2-124m in 1.1596 seconds
2024-09-10 15:22:43,202 Latency for request de7082fd with model gpt2-124m: 4.9377 seconds
2024-09-10 15:22:43,204 Latency for request 40dcbad0 with model gpt2-124m: 4.8614 seconds
2024-09-10 15:22:43,204 Latency for request 938f9e0f with model gpt2-124m: 4.6994 seconds
2024-09-10 15:22:43,204 Latency for request 2d69a89b with model gpt2-124m: 4.3943 seconds
2024-09-10 15:22:43,204 Latency for request 39c64f7f with model gpt2-124m: 3.4292 seconds
2024-09-10 15:22:43,205 Latency for request b28f3f78 with model gpt2-124m: 2.8413 seconds
2024-09-10 15:22:43,205 Latency for request 33400eb2 with model gpt2-124m: 1.9945 seconds
2024-09-10 15:22:43,205 Latency for request 61d3501b with model gpt2-124m: 1.2737 seconds
2024-09-10 15:22:43,205 127.0.0.1 - - [10/Sep/2024 15:22:43] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:44,058 Request with ID c52070ff for model gpt2-124m received
2024-09-10 15:22:44,059 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:22:44,059 Adjusted time limit for model gpt2-124m: 13.3434 seconds
2024-09-10 15:22:44,059 127.0.0.1 - - [10/Sep/2024 15:22:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:44,806 Request with ID 5a070d26 for model gpt2medium-355m received
2024-09-10 15:22:44,807 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:22:44,807 127.0.0.1 - - [10/Sep/2024 15:22:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:44,896 Time limit condition met for model gpt2medium-355m
2024-09-10 15:22:44,896 Updated batch size:8
2024-09-10 15:22:44,896 Loading model gpt2medium-355m
2024-09-10 15:22:45,369 Request with ID 9216d805 for model gpt2medium-355m received
2024-09-10 15:22:45,369 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:22:45,369 127.0.0.1 - - [10/Sep/2024 15:22:45] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:45,749 Request with ID a9fdb99c for model gpt2medium-355m received
2024-09-10 15:22:45,750 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:22:45,750 127.0.0.1 - - [10/Sep/2024 15:22:45] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:46,444 Request with ID 446bbc6d for model gpt2medium-355m received
2024-09-10 15:22:46,444 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:22:46,444 127.0.0.1 - - [10/Sep/2024 15:22:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:46,870 Request with ID 3a1e83f2 for model gpt2-124m received
2024-09-10 15:22:46,870 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:22:46,870 127.0.0.1 - - [10/Sep/2024 15:22:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:47,114 Request with ID 7aa254d8 for model distilgpt2-124m received
2024-09-10 15:22:47,114 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:22:47,115 127.0.0.1 - - [10/Sep/2024 15:22:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:47,752 Request with ID 7a095a9a for model distilgpt2-124m received
2024-09-10 15:22:47,752 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:22:47,752 127.0.0.1 - - [10/Sep/2024 15:22:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:48,294 Request with ID 093005ff for model distilgpt2-124m received
2024-09-10 15:22:48,294 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:22:48,294 Batch size condition met for model distilgpt2-124m
2024-09-10 15:22:48,371 Request with ID c7e64cdd for model gpt2-124m received
2024-09-10 15:22:48,371 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:22:48,371 127.0.0.1 - - [10/Sep/2024 15:22:48] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:49,078 Request with ID fcba7bfe for model gpt2medium-355m received
2024-09-10 15:22:49,079 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:22:49,079 127.0.0.1 - - [10/Sep/2024 15:22:49] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:49,546 Request with ID aa7c219b for model gpt2medium-355m received
2024-09-10 15:22:49,547 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:22:49,547 127.0.0.1 - - [10/Sep/2024 15:22:49] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:49,607 Request with ID 53b229a0 for model gpt2medium-355m received
2024-09-10 15:22:49,607 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:22:49,607 127.0.0.1 - - [10/Sep/2024 15:22:49] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:49,665 Processed batch: ['e2c8ab97', '5520b469', 'b13b7fdf', '53d5e1da', '5a070d26', '13c6', '7ff5', '1d21'] with model gpt2medium-355m in 4.6396 seconds
2024-09-10 15:22:49,665 Latency for request e2c8ab97 with model gpt2medium-355m: 11.3649 seconds
2024-09-10 15:22:49,666 Latency for request 5520b469 with model gpt2medium-355m: 10.6989 seconds
2024-09-10 15:22:49,667 Latency for request b13b7fdf with model gpt2medium-355m: 10.1875 seconds
2024-09-10 15:22:49,667 Latency for request 53d5e1da with model gpt2medium-355m: 9.5247 seconds
2024-09-10 15:22:49,667 Latency for request 5a070d26 with model gpt2medium-355m: 4.8589 seconds
2024-09-10 15:22:49,667 Latency for request 13c6 with model gpt2medium-355m: 4.7689 seconds
2024-09-10 15:22:49,667 Latency for request 7ff5 with model gpt2medium-355m: 4.7689 seconds
2024-09-10 15:22:49,668 Latency for request 1d21 with model gpt2medium-355m: 4.7688 seconds
2024-09-10 15:22:49,668 Updated batch size:8
2024-09-10 15:22:49,668 Loading model distilgpt2-124m
2024-09-10 15:22:50,496 Request with ID 3515424e for model gpt2medium-355m received
2024-09-10 15:22:50,496 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:22:50,496 Adjusted time limit for model gpt2medium-355m: 9.9487 seconds
2024-09-10 15:22:50,496 127.0.0.1 - - [10/Sep/2024 15:22:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:50,674 Processed batch: ['2db1fa91', '29230bda', '4f54c95f', '28774b4c', 'c265f044', '7aa254d8', '7a095a9a', '093005ff'] with model distilgpt2-124m in 0.9478 seconds
2024-09-10 15:22:50,674 Latency for request 2db1fa91 with model distilgpt2-124m: 12.4157 seconds
2024-09-10 15:22:50,675 Latency for request 29230bda with model distilgpt2-124m: 12.0498 seconds
2024-09-10 15:22:50,675 Latency for request 4f54c95f with model distilgpt2-124m: 11.4716 seconds
2024-09-10 15:22:50,676 Latency for request 28774b4c with model distilgpt2-124m: 10.1134 seconds
2024-09-10 15:22:50,676 Latency for request c265f044 with model distilgpt2-124m: 8.3081 seconds
2024-09-10 15:22:50,676 Latency for request 7aa254d8 with model distilgpt2-124m: 3.5599 seconds
2024-09-10 15:22:50,676 Latency for request 7a095a9a with model distilgpt2-124m: 2.9222 seconds
2024-09-10 15:22:50,677 Latency for request 093005ff with model distilgpt2-124m: 2.3804 seconds
2024-09-10 15:22:50,677 127.0.0.1 - - [10/Sep/2024 15:22:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:50,926 Request with ID 07bb6b39 for model gpt2-124m received
2024-09-10 15:22:50,926 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:22:50,926 127.0.0.1 - - [10/Sep/2024 15:22:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:51,286 Request with ID 17a74f9c for model gpt2medium-355m received
2024-09-10 15:22:51,287 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:22:51,287 Batch size condition met for model gpt2medium-355m
2024-09-10 15:22:51,287 Updated batch size:8
2024-09-10 15:22:51,287 Loading model gpt2medium-355m
2024-09-10 15:22:51,549 Request with ID f5fc21d6 for model gpt2medium-355m received
2024-09-10 15:22:51,550 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:22:51,550 127.0.0.1 - - [10/Sep/2024 15:22:51] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:51,559 Time limit condition met for model gpt2medium-355m
2024-09-10 15:22:51,718 Request with ID 6f8ee41c for model gpt2-124m received
2024-09-10 15:22:51,718 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:22:51,718 127.0.0.1 - - [10/Sep/2024 15:22:51] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:52,283 Request with ID bf586ece for model gpt2medium-355m received
2024-09-10 15:22:52,284 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:22:52,284 127.0.0.1 - - [10/Sep/2024 15:22:52] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:52,915 Request with ID d64ee433 for model distilgpt2-124m received
2024-09-10 15:22:52,915 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:22:52,915 Adjusted time limit for model distilgpt2-124m: 14.2043 seconds
2024-09-10 15:22:52,915 127.0.0.1 - - [10/Sep/2024 15:22:52] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:53,342 Request with ID b6ad4a2d for model gpt2-124m received
2024-09-10 15:22:53,342 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:22:53,342 127.0.0.1 - - [10/Sep/2024 15:22:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:53,514 Request with ID b49e826c for model gpt2medium-355m received
2024-09-10 15:22:53,514 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:22:53,514 127.0.0.1 - - [10/Sep/2024 15:22:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:53,764 Request with ID bbbf51dd for model gpt2-124m received
2024-09-10 15:22:53,764 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:22:53,764 127.0.0.1 - - [10/Sep/2024 15:22:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:53,776 Request with ID dad083dd for model gpt2-124m received
2024-09-10 15:22:53,776 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:22:53,776 Batch size condition met for model gpt2-124m
2024-09-10 15:22:54,208 Request with ID f4cfafc6 for model gpt2-124m received
2024-09-10 15:22:54,208 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:22:54,208 127.0.0.1 - - [10/Sep/2024 15:22:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:54,433 Request with ID 408dc9a6 for model distilgpt2-124m received
2024-09-10 15:22:54,433 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:22:54,433 127.0.0.1 - - [10/Sep/2024 15:22:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:54,640 Request with ID c82a573e for model distilgpt2-124m received
2024-09-10 15:22:54,640 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:22:54,641 127.0.0.1 - - [10/Sep/2024 15:22:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:54,871 Processed batch: ['9216d805', 'a9fdb99c', '446bbc6d', 'fcba7bfe', 'aa7c219b', '53b229a0', '3515424e', '17a74f9c'] with model gpt2medium-355m in 3.3867 seconds
2024-09-10 15:22:54,871 Latency for request 9216d805 with model gpt2medium-355m: 9.5025 seconds
2024-09-10 15:22:54,872 Latency for request a9fdb99c with model gpt2medium-355m: 9.1217 seconds
2024-09-10 15:22:54,873 Latency for request 446bbc6d with model gpt2medium-355m: 8.4270 seconds
2024-09-10 15:22:54,873 Latency for request fcba7bfe with model gpt2medium-355m: 5.7926 seconds
2024-09-10 15:22:54,873 Latency for request aa7c219b with model gpt2medium-355m: 5.3248 seconds
2024-09-10 15:22:54,873 Latency for request 53b229a0 with model gpt2medium-355m: 5.2641 seconds
2024-09-10 15:22:54,874 Latency for request 3515424e with model gpt2medium-355m: 4.3750 seconds
2024-09-10 15:22:54,874 Latency for request 17a74f9c with model gpt2medium-355m: 3.5849 seconds
2024-09-10 15:22:54,874 127.0.0.1 - - [10/Sep/2024 15:22:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:54,874 Updated batch size:4
2024-09-10 15:22:54,874 Loading model gpt2medium-355m
2024-09-10 15:22:55,234 Request with ID 0e8bb3c2 for model distilgpt2-124m received
2024-09-10 15:22:55,234 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:22:55,234 127.0.0.1 - - [10/Sep/2024 15:22:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:55,364 Request with ID a2ed821a for model distilgpt2-124m received
2024-09-10 15:22:55,364 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:22:55,364 127.0.0.1 - - [10/Sep/2024 15:22:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:55,714 Request with ID 4dad0a3d for model distilgpt2-124m received
2024-09-10 15:22:55,714 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:22:55,714 127.0.0.1 - - [10/Sep/2024 15:22:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:55,921 Request with ID 64d35195 for model distilgpt2-124m received
2024-09-10 15:22:55,921 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:22:55,921 127.0.0.1 - - [10/Sep/2024 15:22:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:56,158 Request with ID 3c3f3088 for model distilgpt2-124m received
2024-09-10 15:22:56,158 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:22:56,158 Batch size condition met for model distilgpt2-124m
2024-09-10 15:22:56,440 Request with ID 0e2bebeb for model distilgpt2-124m received
2024-09-10 15:22:56,440 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:22:56,441 127.0.0.1 - - [10/Sep/2024 15:22:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:56,627 Request with ID 097366b1 for model distilgpt2-124m received
2024-09-10 15:22:56,627 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:22:56,628 127.0.0.1 - - [10/Sep/2024 15:22:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:57,385 Request with ID 78fadb95 for model gpt2medium-355m received
2024-09-10 15:22:57,386 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:22:57,386 Adjusted time limit for model gpt2medium-355m: 9.9443 seconds
2024-09-10 15:22:57,386 127.0.0.1 - - [10/Sep/2024 15:22:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:57,398 Processed batch: ['f5fc21d6', 'c3cf', 'de2c', 'a972'] with model gpt2medium-355m in 2.5232 seconds
2024-09-10 15:22:57,398 Latency for request f5fc21d6 with model gpt2medium-355m: 5.8483 seconds
2024-09-10 15:22:57,398 Latency for request c3cf with model gpt2medium-355m: 2.5234 seconds
2024-09-10 15:22:57,399 Latency for request de2c with model gpt2medium-355m: 2.5234 seconds
2024-09-10 15:22:57,399 Latency for request a972 with model gpt2medium-355m: 2.5234 seconds
2024-09-10 15:22:57,399 Updated batch size:8
2024-09-10 15:22:57,399 Loading model gpt2-124m
2024-09-10 15:22:57,501 Time limit condition met for model gpt2-124m
2024-09-10 15:22:57,630 Request with ID 996c107c for model gpt2-124m received
2024-09-10 15:22:57,630 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:22:57,630 127.0.0.1 - - [10/Sep/2024 15:22:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:58,628 Request with ID 80ed99de for model gpt2-124m received
2024-09-10 15:22:58,628 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:22:58,628 127.0.0.1 - - [10/Sep/2024 15:22:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:58,708 Processed batch: ['c52070ff', '3a1e83f2', 'c7e64cdd', '07bb6b39', '6f8ee41c', 'b6ad4a2d', 'bbbf51dd', 'dad083dd'] with model gpt2-124m in 1.2310 seconds
2024-09-10 15:22:58,708 Latency for request c52070ff with model gpt2-124m: 14.6500 seconds
2024-09-10 15:22:58,710 Latency for request 3a1e83f2 with model gpt2-124m: 11.8385 seconds
2024-09-10 15:22:58,710 Latency for request c7e64cdd with model gpt2-124m: 10.3372 seconds
2024-09-10 15:22:58,710 Latency for request 07bb6b39 with model gpt2-124m: 7.7821 seconds
2024-09-10 15:22:58,710 Latency for request 6f8ee41c with model gpt2-124m: 6.9904 seconds
2024-09-10 15:22:58,711 Latency for request b6ad4a2d with model gpt2-124m: 5.3668 seconds
2024-09-10 15:22:58,711 Latency for request bbbf51dd with model gpt2-124m: 4.9443 seconds
2024-09-10 15:22:58,711 Latency for request dad083dd with model gpt2-124m: 4.9328 seconds
2024-09-10 15:22:58,711 127.0.0.1 - - [10/Sep/2024 15:22:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:58,711 Updated batch size:8
2024-09-10 15:22:58,711 Loading model distilgpt2-124m
2024-09-10 15:22:59,242 Request with ID 0e01fd15 for model distilgpt2-124m received
2024-09-10 15:22:59,242 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:22:59,242 127.0.0.1 - - [10/Sep/2024 15:22:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:59,535 Processed batch: ['d64ee433', '408dc9a6', 'c82a573e', '0e8bb3c2', 'a2ed821a', '4dad0a3d', '64d35195', '3c3f3088'] with model distilgpt2-124m in 0.7613 seconds
2024-09-10 15:22:59,535 Latency for request d64ee433 with model distilgpt2-124m: 6.6204 seconds
2024-09-10 15:22:59,536 Latency for request 408dc9a6 with model distilgpt2-124m: 5.1019 seconds
2024-09-10 15:22:59,536 Latency for request c82a573e with model distilgpt2-124m: 4.8949 seconds
2024-09-10 15:22:59,537 Latency for request 0e8bb3c2 with model distilgpt2-124m: 4.3012 seconds
2024-09-10 15:22:59,537 Latency for request a2ed821a with model distilgpt2-124m: 4.1714 seconds
2024-09-10 15:22:59,537 Latency for request 4dad0a3d with model distilgpt2-124m: 3.8209 seconds
2024-09-10 15:22:59,537 Latency for request 64d35195 with model distilgpt2-124m: 3.6143 seconds
2024-09-10 15:22:59,538 Latency for request 3c3f3088 with model distilgpt2-124m: 3.3771 seconds
2024-09-10 15:22:59,538 127.0.0.1 - - [10/Sep/2024 15:22:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:59,538 Updated batch size:4
2024-09-10 15:22:59,538 Loading model gpt2-124m
2024-09-10 15:22:59,736 Request with ID 5c46d02c for model distilgpt2-124m received
2024-09-10 15:22:59,736 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:22:59,736 Adjusted time limit for model distilgpt2-124m: 14.2082 seconds
2024-09-10 15:22:59,736 127.0.0.1 - - [10/Sep/2024 15:22:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:22:59,886 Request with ID 3e152dbe for model gpt2-124m received
2024-09-10 15:22:59,886 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:22:59,886 Adjusted time limit for model gpt2-124m: 13.3434 seconds
2024-09-10 15:22:59,886 127.0.0.1 - - [10/Sep/2024 15:22:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:00,477 Request with ID 00e09628 for model gpt2-124m received
2024-09-10 15:23:00,477 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:23:00,477 127.0.0.1 - - [10/Sep/2024 15:23:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:00,541 Processed batch: ['f4cfafc6', '1aa8', '9428', '8e0d'] with model gpt2-124m in 0.9145 seconds
2024-09-10 15:23:00,541 Latency for request f4cfafc6 with model gpt2-124m: 6.3328 seconds
2024-09-10 15:23:00,542 Latency for request 1aa8 with model gpt2-124m: 1.0027 seconds
2024-09-10 15:23:00,543 Latency for request 9428 with model gpt2-124m: 1.0026 seconds
2024-09-10 15:23:00,544 Latency for request 8e0d with model gpt2-124m: 1.0026 seconds
2024-09-10 15:23:00,584 Request with ID 4024f7c4 for model gpt2-124m received
2024-09-10 15:23:00,584 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:23:00,584 Adjusted time limit for model gpt2-124m: 13.3434 seconds
2024-09-10 15:23:00,584 127.0.0.1 - - [10/Sep/2024 15:23:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:00,842 Request with ID d1beea07 for model gpt2-124m received
2024-09-10 15:23:00,843 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:23:00,843 127.0.0.1 - - [10/Sep/2024 15:23:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:01,126 Request with ID bfcc3014 for model gpt2medium-355m received
2024-09-10 15:23:01,126 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:23:01,126 Adjusted time limit for model gpt2medium-355m: 9.9482 seconds
2024-09-10 15:23:01,127 127.0.0.1 - - [10/Sep/2024 15:23:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:01,781 Request with ID de1233d5 for model gpt2medium-355m received
2024-09-10 15:23:01,781 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:23:01,782 127.0.0.1 - - [10/Sep/2024 15:23:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:01,909 Request with ID b0e4c28a for model gpt2-124m received
2024-09-10 15:23:01,910 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:23:01,910 127.0.0.1 - - [10/Sep/2024 15:23:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:02,099 Request with ID 3590bd8b for model gpt2-124m received
2024-09-10 15:23:02,099 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 15:23:02,099 Batch size condition met for model gpt2-124m
2024-09-10 15:23:02,100 Updated batch size:8
2024-09-10 15:23:02,100 Loading model gpt2-124m
2024-09-10 15:23:02,496 Request with ID db159252 for model distilgpt2-124m received
2024-09-10 15:23:02,496 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:23:02,496 127.0.0.1 - - [10/Sep/2024 15:23:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:02,877 Request with ID bf592b17 for model gpt2-124m received
2024-09-10 15:23:02,877 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:23:02,877 127.0.0.1 - - [10/Sep/2024 15:23:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:02,985 Request with ID 48fea814 for model gpt2medium-355m received
2024-09-10 15:23:02,986 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:23:02,986 127.0.0.1 - - [10/Sep/2024 15:23:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:03,041 Time limit condition met for model gpt2medium-355m
2024-09-10 15:23:03,117 Processed batch: ['996c107c', '80ed99de', '3e152dbe', '00e09628', '4024f7c4', 'd1beea07', 'b0e4c28a', '3590bd8b'] with model gpt2-124m in 1.0173 seconds
2024-09-10 15:23:03,117 Latency for request 996c107c with model gpt2-124m: 5.4874 seconds
2024-09-10 15:23:03,118 Latency for request 80ed99de with model gpt2-124m: 4.4898 seconds
2024-09-10 15:23:03,119 Latency for request 3e152dbe with model gpt2-124m: 3.2314 seconds
2024-09-10 15:23:03,119 Latency for request 00e09628 with model gpt2-124m: 2.6402 seconds
2024-09-10 15:23:03,119 Latency for request 4024f7c4 with model gpt2-124m: 2.5335 seconds
2024-09-10 15:23:03,119 Latency for request d1beea07 with model gpt2-124m: 2.2750 seconds
2024-09-10 15:23:03,120 Latency for request b0e4c28a with model gpt2-124m: 1.2081 seconds
2024-09-10 15:23:03,120 Latency for request 3590bd8b with model gpt2-124m: 1.0187 seconds
2024-09-10 15:23:03,120 127.0.0.1 - - [10/Sep/2024 15:23:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:03,120 Updated batch size:8
2024-09-10 15:23:03,120 Loading model gpt2medium-355m
2024-09-10 15:23:03,319 Request with ID 9a0fc4bc for model distilgpt2-124m received
2024-09-10 15:23:03,319 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:23:03,320 127.0.0.1 - - [10/Sep/2024 15:23:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:03,563 Request with ID 33aa0ed9 for model gpt2-124m received
2024-09-10 15:23:03,563 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:23:03,563 Adjusted time limit for model gpt2-124m: 13.3395 seconds
2024-09-10 15:23:03,564 127.0.0.1 - - [10/Sep/2024 15:23:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:03,707 Request with ID b1a51f4f for model gpt2medium-355m received
2024-09-10 15:23:03,707 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:23:03,707 127.0.0.1 - - [10/Sep/2024 15:23:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:04,417 Request with ID f127a04d for model gpt2-124m received
2024-09-10 15:23:04,417 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:23:04,417 127.0.0.1 - - [10/Sep/2024 15:23:04] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:05,033 Request with ID df52aec2 for model gpt2-124m received
2024-09-10 15:23:05,033 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:23:05,033 127.0.0.1 - - [10/Sep/2024 15:23:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:05,309 Request with ID b7bf3b63 for model gpt2medium-355m received
2024-09-10 15:23:05,310 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:23:05,310 127.0.0.1 - - [10/Sep/2024 15:23:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:05,557 Request with ID 1738b7da for model gpt2medium-355m received
2024-09-10 15:23:05,557 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:23:05,557 127.0.0.1 - - [10/Sep/2024 15:23:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:06,039 Request with ID 17e3552a for model distilgpt2-124m received
2024-09-10 15:23:06,039 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:23:06,039 127.0.0.1 - - [10/Sep/2024 15:23:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:06,371 Request with ID 3a07e9c7 for model gpt2medium-355m received
2024-09-10 15:23:06,371 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:23:06,371 127.0.0.1 - - [10/Sep/2024 15:23:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:06,757 Request with ID 36edb661 for model distilgpt2-124m received
2024-09-10 15:23:06,757 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:23:06,757 Batch size condition met for model distilgpt2-124m
2024-09-10 15:23:07,061 Request with ID 940a454e for model distilgpt2-124m received
2024-09-10 15:23:07,061 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:23:07,061 127.0.0.1 - - [10/Sep/2024 15:23:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:07,163 Processed batch: ['bf586ece', 'b49e826c', '78fadb95', 'bfcc3014', 'de1233d5', '48fea814', 'fe9c', '0ccb'] with model gpt2medium-355m in 3.9303 seconds
2024-09-10 15:23:07,163 Latency for request bf586ece with model gpt2medium-355m: 14.8791 seconds
2024-09-10 15:23:07,164 Latency for request b49e826c with model gpt2medium-355m: 13.6489 seconds
2024-09-10 15:23:07,164 Latency for request 78fadb95 with model gpt2medium-355m: 9.7773 seconds
2024-09-10 15:23:07,164 Latency for request bfcc3014 with model gpt2medium-355m: 6.0363 seconds
2024-09-10 15:23:07,164 Latency for request de1233d5 with model gpt2medium-355m: 5.3818 seconds
2024-09-10 15:23:07,165 Latency for request 48fea814 with model gpt2medium-355m: 4.1772 seconds
2024-09-10 15:23:07,165 Latency for request fe9c with model gpt2medium-355m: 4.0424 seconds
2024-09-10 15:23:07,165 Latency for request 0ccb with model gpt2medium-355m: 4.0424 seconds
2024-09-10 15:23:07,165 Updated batch size:8
2024-09-10 15:23:07,165 Loading model distilgpt2-124m
2024-09-10 15:23:07,625 Request with ID ae02368b for model gpt2-124m received
2024-09-10 15:23:07,626 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:23:07,626 127.0.0.1 - - [10/Sep/2024 15:23:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:07,770 Request with ID f55f58a0 for model distilgpt2-124m received
2024-09-10 15:23:07,770 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:23:07,771 127.0.0.1 - - [10/Sep/2024 15:23:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:07,974 Request with ID 43e11972 for model distilgpt2-124m received
2024-09-10 15:23:07,974 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:23:07,974 127.0.0.1 - - [10/Sep/2024 15:23:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:08,010 Processed batch: ['0e2bebeb', '097366b1', '0e01fd15', '5c46d02c', 'db159252', '9a0fc4bc', '17e3552a', '36edb661'] with model distilgpt2-124m in 0.7865 seconds
2024-09-10 15:23:08,010 Latency for request 0e2bebeb with model distilgpt2-124m: 11.5698 seconds
2024-09-10 15:23:08,011 Latency for request 097366b1 with model distilgpt2-124m: 11.3828 seconds
2024-09-10 15:23:08,011 Latency for request 0e01fd15 with model distilgpt2-124m: 8.7680 seconds
2024-09-10 15:23:08,012 Latency for request 5c46d02c with model distilgpt2-124m: 8.2744 seconds
2024-09-10 15:23:08,012 Latency for request db159252 with model distilgpt2-124m: 5.5142 seconds
2024-09-10 15:23:08,012 Latency for request 9a0fc4bc with model distilgpt2-124m: 4.6910 seconds
2024-09-10 15:23:08,012 Latency for request 17e3552a with model distilgpt2-124m: 1.9710 seconds
2024-09-10 15:23:08,012 Latency for request 36edb661 with model distilgpt2-124m: 1.2529 seconds
2024-09-10 15:23:08,013 127.0.0.1 - - [10/Sep/2024 15:23:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:08,091 Request with ID c0db6be6 for model distilgpt2-124m received
2024-09-10 15:23:08,091 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:23:08,091 Adjusted time limit for model distilgpt2-124m: 14.2087 seconds
2024-09-10 15:23:08,091 127.0.0.1 - - [10/Sep/2024 15:23:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:08,931 Request with ID 4044b817 for model distilgpt2-124m received
2024-09-10 15:23:08,932 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:23:08,932 127.0.0.1 - - [10/Sep/2024 15:23:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:09,023 Request with ID ed5bb5fd for model distilgpt2-124m received
2024-09-10 15:23:09,023 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:23:09,024 127.0.0.1 - - [10/Sep/2024 15:23:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:09,170 Request with ID a51b3045 for model gpt2medium-355m received
2024-09-10 15:23:09,170 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:23:09,170 Adjusted time limit for model gpt2medium-355m: 9.9487 seconds
2024-09-10 15:23:09,171 127.0.0.1 - - [10/Sep/2024 15:23:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:09,283 Request with ID 004bf72e for model gpt2-124m received
2024-09-10 15:23:09,284 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 15:23:09,284 127.0.0.1 - - [10/Sep/2024 15:23:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:09,764 Request with ID 9812647a for model gpt2-124m received
2024-09-10 15:23:09,764 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 15:23:09,765 127.0.0.1 - - [10/Sep/2024 15:23:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:09,882 Request with ID 5efe3ac9 for model gpt2-124m received
2024-09-10 15:23:09,882 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 15:23:09,882 Batch size condition met for model gpt2-124m
2024-09-10 15:23:09,882 Updated batch size:8
2024-09-10 15:23:09,882 Loading model gpt2-124m
2024-09-10 15:23:09,961 Request with ID 10897b45 for model gpt2medium-355m received
2024-09-10 15:23:09,962 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:23:09,963 127.0.0.1 - - [10/Sep/2024 15:23:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:10,066 Time limit condition met for model gpt2medium-355m
2024-09-10 15:23:10,197 Request with ID d151176f for model gpt2-124m received
2024-09-10 15:23:10,197 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:23:10,197 127.0.0.1 - - [10/Sep/2024 15:23:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:10,710 Request with ID bc8c5c39 for model distilgpt2-124m received
2024-09-10 15:23:10,710 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:23:10,711 127.0.0.1 - - [10/Sep/2024 15:23:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:11,208 Request with ID 9e73a49c for model gpt2-124m received
2024-09-10 15:23:11,208 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:23:11,208 127.0.0.1 - - [10/Sep/2024 15:23:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:11,310 Request with ID 40203c6b for model gpt2medium-355m received
2024-09-10 15:23:11,310 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:23:11,311 127.0.0.1 - - [10/Sep/2024 15:23:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:11,484 Request with ID f00875bb for model distilgpt2-124m received
2024-09-10 15:23:11,484 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:23:11,484 Batch size condition met for model distilgpt2-124m
2024-09-10 15:23:11,664 Processed batch: ['bf592b17', '33aa0ed9', 'f127a04d', 'df52aec2', 'ae02368b', '004bf72e', '9812647a', '5efe3ac9'] with model gpt2-124m in 1.6830 seconds
2024-09-10 15:23:11,664 Latency for request bf592b17 with model gpt2-124m: 8.7870 seconds
2024-09-10 15:23:11,665 Latency for request 33aa0ed9 with model gpt2-124m: 8.1006 seconds
2024-09-10 15:23:11,666 Latency for request f127a04d with model gpt2-124m: 7.2474 seconds
2024-09-10 15:23:11,666 Latency for request df52aec2 with model gpt2-124m: 6.6310 seconds
2024-09-10 15:23:11,666 Latency for request ae02368b with model gpt2-124m: 4.0386 seconds
2024-09-10 15:23:11,666 Latency for request 004bf72e with model gpt2-124m: 2.3806 seconds
2024-09-10 15:23:11,666 Latency for request 9812647a with model gpt2-124m: 1.9003 seconds
2024-09-10 15:23:11,667 Latency for request 5efe3ac9 with model gpt2-124m: 1.7824 seconds
2024-09-10 15:23:11,667 127.0.0.1 - - [10/Sep/2024 15:23:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:11,667 Updated batch size:8
2024-09-10 15:23:11,667 Loading model gpt2medium-355m
2024-09-10 15:23:11,940 Request with ID a9d8eac1 for model distilgpt2-124m received
2024-09-10 15:23:11,940 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:23:11,940 127.0.0.1 - - [10/Sep/2024 15:23:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:12,248 Request with ID 7153f91e for model distilgpt2-124m received
2024-09-10 15:23:12,248 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:23:12,249 127.0.0.1 - - [10/Sep/2024 15:23:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:12,472 Request with ID 464831c6 for model gpt2medium-355m received
2024-09-10 15:23:12,472 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:23:12,472 127.0.0.1 - - [10/Sep/2024 15:23:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:13,510 Request with ID 51b279bd for model distilgpt2-124m received
2024-09-10 15:23:13,510 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:23:13,510 127.0.0.1 - - [10/Sep/2024 15:23:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:13,698 Request with ID 01ba3709 for model gpt2medium-355m received
2024-09-10 15:23:13,698 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:23:13,698 127.0.0.1 - - [10/Sep/2024 15:23:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:14,728 Request with ID adf88220 for model distilgpt2-124m received
2024-09-10 15:23:14,728 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:23:14,728 127.0.0.1 - - [10/Sep/2024 15:23:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:15,178 Request with ID 6bb3eb30 for model distilgpt2-124m received
2024-09-10 15:23:15,178 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:23:15,179 127.0.0.1 - - [10/Sep/2024 15:23:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:15,717 Processed batch: ['b1a51f4f', 'b7bf3b63', '1738b7da', '3a07e9c7', 'a51b3045', '10897b45', '28fe', 'f1fb'] with model gpt2medium-355m in 3.9300 seconds
2024-09-10 15:23:15,717 Latency for request b1a51f4f with model gpt2medium-355m: 12.0098 seconds
2024-09-10 15:23:15,718 Latency for request b7bf3b63 with model gpt2medium-355m: 10.4076 seconds
2024-09-10 15:23:15,719 Latency for request 1738b7da with model gpt2medium-355m: 10.1602 seconds
2024-09-10 15:23:15,719 Latency for request 3a07e9c7 with model gpt2medium-355m: 9.3461 seconds
2024-09-10 15:23:15,719 Latency for request a51b3045 with model gpt2medium-355m: 6.5474 seconds
2024-09-10 15:23:15,719 Latency for request 10897b45 with model gpt2medium-355m: 5.7562 seconds
2024-09-10 15:23:15,720 Latency for request 28fe with model gpt2medium-355m: 4.0500 seconds
2024-09-10 15:23:15,720 Latency for request f1fb with model gpt2medium-355m: 4.0500 seconds
2024-09-10 15:23:15,720 Updated batch size:8
2024-09-10 15:23:15,720 Loading model distilgpt2-124m
2024-09-10 15:23:16,416 Request with ID 03023e31 for model gpt2medium-355m received
2024-09-10 15:23:16,416 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:23:16,416 Adjusted time limit for model gpt2medium-355m: 9.9487 seconds
2024-09-10 15:23:16,416 127.0.0.1 - - [10/Sep/2024 15:23:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:16,635 Processed batch: ['940a454e', 'f55f58a0', '43e11972', 'c0db6be6', '4044b817', 'ed5bb5fd', 'bc8c5c39', 'f00875bb'] with model distilgpt2-124m in 0.8539 seconds
2024-09-10 15:23:16,635 Latency for request 940a454e with model distilgpt2-124m: 9.5742 seconds
2024-09-10 15:23:16,636 Latency for request f55f58a0 with model distilgpt2-124m: 8.8646 seconds
2024-09-10 15:23:16,636 Latency for request 43e11972 with model distilgpt2-124m: 8.6610 seconds
2024-09-10 15:23:16,636 Latency for request c0db6be6 with model distilgpt2-124m: 8.5444 seconds
2024-09-10 15:23:16,637 Latency for request 4044b817 with model distilgpt2-124m: 7.7038 seconds
2024-09-10 15:23:16,637 Latency for request ed5bb5fd with model distilgpt2-124m: 7.6121 seconds
2024-09-10 15:23:16,637 Latency for request bc8c5c39 with model distilgpt2-124m: 5.9246 seconds
2024-09-10 15:23:16,637 Latency for request f00875bb with model distilgpt2-124m: 5.1511 seconds
2024-09-10 15:23:16,638 127.0.0.1 - - [10/Sep/2024 15:23:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:17,098 Request with ID 8c6bf854 for model gpt2-124m received
2024-09-10 15:23:17,098 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:23:17,098 Adjusted time limit for model gpt2-124m: 13.3439 seconds
2024-09-10 15:23:17,099 127.0.0.1 - - [10/Sep/2024 15:23:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:17,353 Request with ID 10501b93 for model gpt2-124m received
2024-09-10 15:23:17,354 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:23:17,354 127.0.0.1 - - [10/Sep/2024 15:23:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:17,518 Request with ID dab42ce6 for model distilgpt2-124m received
2024-09-10 15:23:17,519 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:23:17,519 Adjusted time limit for model distilgpt2-124m: 14.2087 seconds
2024-09-10 15:23:17,519 127.0.0.1 - - [10/Sep/2024 15:23:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:17,797 Request with ID eaf78f2e for model gpt2medium-355m received
2024-09-10 15:23:17,797 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:23:17,798 127.0.0.1 - - [10/Sep/2024 15:23:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:18,887 Request with ID 24e8b7d4 for model distilgpt2-124m received
2024-09-10 15:23:18,887 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:23:18,887 127.0.0.1 - - [10/Sep/2024 15:23:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:19,125 Request with ID 94bee909 for model gpt2medium-355m received
2024-09-10 15:23:19,125 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 15:23:19,126 127.0.0.1 - - [10/Sep/2024 15:23:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:19,148 Time limit condition met for model gpt2medium-355m
2024-09-10 15:23:19,149 Updated batch size:8
2024-09-10 15:23:19,149 Loading model gpt2medium-355m
2024-09-10 15:23:19,495 Request with ID ea962edf for model distilgpt2-124m received
2024-09-10 15:23:19,495 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:23:19,495 Batch size condition met for model distilgpt2-124m
2024-09-10 15:23:20,149 Request with ID ef83987e for model gpt2medium-355m received
2024-09-10 15:23:20,149 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:23:20,149 127.0.0.1 - - [10/Sep/2024 15:23:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:21,063 Request with ID a3e2e792 for model distilgpt2-124m received
2024-09-10 15:23:21,063 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:23:21,063 127.0.0.1 - - [10/Sep/2024 15:23:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:21,108 Request with ID 8a6e5660 for model gpt2-124m received
2024-09-10 15:23:21,109 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:23:21,109 127.0.0.1 - - [10/Sep/2024 15:23:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:21,895 Request with ID 2b23e132 for model distilgpt2-124m received
2024-09-10 15:23:21,896 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:23:21,896 127.0.0.1 - - [10/Sep/2024 15:23:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:22,618 Request with ID 405b30ff for model gpt2medium-355m received
2024-09-10 15:23:22,618 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:23:22,618 127.0.0.1 - - [10/Sep/2024 15:23:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:23,082 Request with ID 9740a134 for model distilgpt2-124m received
2024-09-10 15:23:23,082 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:23:23,082 127.0.0.1 - - [10/Sep/2024 15:23:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:23,182 Processed batch: ['40203c6b', '464831c6', '01ba3709', '03023e31', 'eaf78f2e', '94bee909', '977a', 'c842'] with model gpt2medium-355m in 3.8975 seconds
2024-09-10 15:23:23,182 Latency for request 40203c6b with model gpt2medium-355m: 11.8712 seconds
2024-09-10 15:23:23,182 Latency for request 464831c6 with model gpt2medium-355m: 10.7096 seconds
2024-09-10 15:23:23,183 Latency for request 01ba3709 with model gpt2medium-355m: 9.4834 seconds
2024-09-10 15:23:23,183 Latency for request 03023e31 with model gpt2medium-355m: 6.7653 seconds
2024-09-10 15:23:23,183 Latency for request eaf78f2e with model gpt2medium-355m: 5.3846 seconds
2024-09-10 15:23:23,183 Latency for request 94bee909 with model gpt2medium-355m: 4.0567 seconds
2024-09-10 15:23:23,184 Latency for request 977a with model gpt2medium-355m: 4.0330 seconds
2024-09-10 15:23:23,184 Latency for request c842 with model gpt2medium-355m: 4.0330 seconds
2024-09-10 15:23:23,184 Updated batch size:8
2024-09-10 15:23:23,184 Loading model distilgpt2-124m
2024-09-10 15:23:23,495 Request with ID 44cd9991 for model distilgpt2-124m received
2024-09-10 15:23:23,495 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:23:23,495 127.0.0.1 - - [10/Sep/2024 15:23:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:23,694 Request with ID 53b11b5a for model gpt2medium-355m received
2024-09-10 15:23:23,694 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:23:23,694 Adjusted time limit for model gpt2medium-355m: 9.9487 seconds
2024-09-10 15:23:23,694 127.0.0.1 - - [10/Sep/2024 15:23:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:23,799 Request with ID 0d8818fc for model distilgpt2-124m received
2024-09-10 15:23:23,799 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:23:23,799 127.0.0.1 - - [10/Sep/2024 15:23:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:23,963 Request with ID bd0a6830 for model gpt2medium-355m received
2024-09-10 15:23:23,963 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:23:23,963 127.0.0.1 - - [10/Sep/2024 15:23:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:24,043 Processed batch: ['a9d8eac1', '7153f91e', '51b279bd', 'adf88220', '6bb3eb30', 'dab42ce6', '24e8b7d4', 'ea962edf'] with model distilgpt2-124m in 0.7993 seconds
2024-09-10 15:23:24,043 Latency for request a9d8eac1 with model distilgpt2-124m: 12.1031 seconds
2024-09-10 15:23:24,044 Latency for request 7153f91e with model distilgpt2-124m: 11.7945 seconds
2024-09-10 15:23:24,044 Latency for request 51b279bd with model distilgpt2-124m: 10.5333 seconds
2024-09-10 15:23:24,045 Latency for request adf88220 with model distilgpt2-124m: 9.3149 seconds
2024-09-10 15:23:24,045 Latency for request 6bb3eb30 with model distilgpt2-124m: 8.8645 seconds
2024-09-10 15:23:24,045 Latency for request dab42ce6 with model distilgpt2-124m: 6.5245 seconds
2024-09-10 15:23:24,045 Latency for request 24e8b7d4 with model distilgpt2-124m: 5.1564 seconds
2024-09-10 15:23:24,046 Latency for request ea962edf with model distilgpt2-124m: 4.5478 seconds
2024-09-10 15:23:24,046 127.0.0.1 - - [10/Sep/2024 15:23:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:24,429 Request with ID a4ca56b2 for model gpt2-124m received
2024-09-10 15:23:24,429 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:23:24,430 127.0.0.1 - - [10/Sep/2024 15:23:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:24,746 Request with ID 147a4eb6 for model gpt2-124m received
2024-09-10 15:23:24,746 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:23:24,747 127.0.0.1 - - [10/Sep/2024 15:23:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:24,800 Request with ID 03fa6276 for model gpt2medium-355m received
2024-09-10 15:23:24,801 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 15:23:24,801 127.0.0.1 - - [10/Sep/2024 15:23:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:24,909 Request with ID 78f52b38 for model gpt2-124m received
2024-09-10 15:23:24,909 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 15:23:24,910 Batch size condition met for model gpt2-124m
2024-09-10 15:23:24,910 Updated batch size:8
2024-09-10 15:23:24,910 Loading model gpt2-124m
2024-09-10 15:23:25,480 Request with ID de0abf22 for model gpt2medium-355m received
2024-09-10 15:23:25,480 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:23:25,480 127.0.0.1 - - [10/Sep/2024 15:23:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:25,488 Time limit condition met for model gpt2medium-355m
2024-09-10 15:23:25,603 Request with ID 02d43d27 for model gpt2-124m received
2024-09-10 15:23:25,603 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:23:25,603 127.0.0.1 - - [10/Sep/2024 15:23:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:25,621 Request with ID 474635aa for model distilgpt2-124m received
2024-09-10 15:23:25,621 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:23:25,621 Adjusted time limit for model distilgpt2-124m: 14.2082 seconds
2024-09-10 15:23:25,621 127.0.0.1 - - [10/Sep/2024 15:23:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:25,936 Request with ID 732a8126 for model gpt2medium-355m received
2024-09-10 15:23:25,936 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:23:25,936 127.0.0.1 - - [10/Sep/2024 15:23:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:26,383 Request with ID 021dc75b for model distilgpt2-124m received
2024-09-10 15:23:26,383 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:23:26,383 127.0.0.1 - - [10/Sep/2024 15:23:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:26,685 Request with ID edbdd4a9 for model distilgpt2-124m received
2024-09-10 15:23:26,685 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:23:26,685 Batch size condition met for model distilgpt2-124m
2024-09-10 15:23:26,733 Processed batch: ['d151176f', '9e73a49c', '8c6bf854', '10501b93', '8a6e5660', 'a4ca56b2', '147a4eb6', '78f52b38'] with model gpt2-124m in 1.7301 seconds
2024-09-10 15:23:26,733 Latency for request d151176f with model gpt2-124m: 16.5362 seconds
2024-09-10 15:23:26,734 Latency for request 9e73a49c with model gpt2-124m: 15.5251 seconds
2024-09-10 15:23:26,735 Latency for request 8c6bf854 with model gpt2-124m: 9.6354 seconds
2024-09-10 15:23:26,735 Latency for request 10501b93 with model gpt2-124m: 9.3798 seconds
2024-09-10 15:23:26,735 Latency for request 8a6e5660 with model gpt2-124m: 5.6247 seconds
2024-09-10 15:23:26,735 Latency for request a4ca56b2 with model gpt2-124m: 2.3041 seconds
2024-09-10 15:23:26,736 Latency for request 147a4eb6 with model gpt2-124m: 1.9875 seconds
2024-09-10 15:23:26,736 Latency for request 78f52b38 with model gpt2-124m: 1.8242 seconds
2024-09-10 15:23:26,736 127.0.0.1 - - [10/Sep/2024 15:23:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:26,736 Updated batch size:8
2024-09-10 15:23:26,736 Loading model gpt2medium-355m
2024-09-10 15:23:26,738 Request with ID b6f83604 for model gpt2-124m received
2024-09-10 15:23:26,738 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:23:26,738 Adjusted time limit for model gpt2-124m: 13.3502 seconds
2024-09-10 15:23:26,738 127.0.0.1 - - [10/Sep/2024 15:23:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:26,970 Request with ID c4011208 for model gpt2-124m received
2024-09-10 15:23:26,970 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:23:26,970 127.0.0.1 - - [10/Sep/2024 15:23:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:27,155 Request with ID c9de063a for model gpt2-124m received
2024-09-10 15:23:27,155 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:23:27,155 127.0.0.1 - - [10/Sep/2024 15:23:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:27,487 Request with ID 8b78fd60 for model gpt2-124m received
2024-09-10 15:23:27,487 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:23:27,487 127.0.0.1 - - [10/Sep/2024 15:23:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:27,652 Request with ID 4d64107e for model gpt2medium-355m received
2024-09-10 15:23:27,652 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:23:27,652 127.0.0.1 - - [10/Sep/2024 15:23:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:27,909 Request with ID a2c40116 for model gpt2medium-355m received
2024-09-10 15:23:27,909 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:23:27,910 127.0.0.1 - - [10/Sep/2024 15:23:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:27,994 Request with ID fc471845 for model gpt2-124m received
2024-09-10 15:23:27,994 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:23:27,995 127.0.0.1 - - [10/Sep/2024 15:23:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:28,239 Request with ID a747083b for model gpt2-124m received
2024-09-10 15:23:28,239 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:23:28,239 127.0.0.1 - - [10/Sep/2024 15:23:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:28,970 Request with ID 06af7a58 for model gpt2-124m received
2024-09-10 15:23:28,970 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:23:28,970 Batch size condition met for model gpt2-124m
2024-09-10 15:23:29,195 Request with ID d32bbf70 for model gpt2medium-355m received
2024-09-10 15:23:29,195 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:23:29,195 127.0.0.1 - - [10/Sep/2024 15:23:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:29,377 Request with ID 4fe376e8 for model gpt2medium-355m received
2024-09-10 15:23:29,377 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:23:29,378 127.0.0.1 - - [10/Sep/2024 15:23:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:29,659 Request with ID 17f1ba7a for model gpt2-124m received
2024-09-10 15:23:29,659 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:23:29,659 127.0.0.1 - - [10/Sep/2024 15:23:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:29,921 Request with ID d210457b for model distilgpt2-124m received
2024-09-10 15:23:29,922 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:23:29,922 127.0.0.1 - - [10/Sep/2024 15:23:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:30,255 Request with ID 6aca476e for model gpt2medium-355m received
2024-09-10 15:23:30,255 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:23:30,255 127.0.0.1 - - [10/Sep/2024 15:23:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:30,681 Request with ID 011e3c17 for model gpt2-124m received
2024-09-10 15:23:30,681 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:23:30,681 127.0.0.1 - - [10/Sep/2024 15:23:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:30,778 Processed batch: ['ef83987e', '405b30ff', '53b11b5a', 'bd0a6830', '03fa6276', 'de0abf22', '5b6f', '2edd'] with model gpt2medium-355m in 3.9206 seconds
2024-09-10 15:23:30,778 Latency for request ef83987e with model gpt2medium-355m: 10.6291 seconds
2024-09-10 15:23:30,779 Latency for request 405b30ff with model gpt2medium-355m: 8.1602 seconds
2024-09-10 15:23:30,780 Latency for request 53b11b5a with model gpt2medium-355m: 7.0845 seconds
2024-09-10 15:23:30,780 Latency for request bd0a6830 with model gpt2medium-355m: 6.8154 seconds
2024-09-10 15:23:30,780 Latency for request 03fa6276 with model gpt2medium-355m: 5.9784 seconds
2024-09-10 15:23:30,780 Latency for request de0abf22 with model gpt2medium-355m: 5.2982 seconds
2024-09-10 15:23:30,781 Latency for request 5b6f with model gpt2medium-355m: 4.0421 seconds
2024-09-10 15:23:30,781 Latency for request 2edd with model gpt2medium-355m: 4.0421 seconds
2024-09-10 15:23:30,781 Updated batch size:8
2024-09-10 15:23:30,781 Loading model distilgpt2-124m
2024-09-10 15:23:30,843 Request with ID c9419493 for model distilgpt2-124m received
2024-09-10 15:23:30,844 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:23:30,844 127.0.0.1 - - [10/Sep/2024 15:23:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:30,927 Request with ID cf7d35ff for model distilgpt2-124m received
2024-09-10 15:23:30,927 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:23:30,928 127.0.0.1 - - [10/Sep/2024 15:23:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:31,088 Request with ID 9ec4b7e0 for model gpt2-124m received
2024-09-10 15:23:31,088 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:23:31,088 127.0.0.1 - - [10/Sep/2024 15:23:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:31,484 Request with ID 9fa9efc8 for model distilgpt2-124m received
2024-09-10 15:23:31,485 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:23:31,485 127.0.0.1 - - [10/Sep/2024 15:23:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:31,635 Processed batch: ['a3e2e792', '2b23e132', '9740a134', '44cd9991', '0d8818fc', '474635aa', '021dc75b', 'edbdd4a9'] with model distilgpt2-124m in 0.7874 seconds
2024-09-10 15:23:31,636 Latency for request a3e2e792 with model distilgpt2-124m: 10.5723 seconds
2024-09-10 15:23:31,637 Latency for request 2b23e132 with model distilgpt2-124m: 9.7399 seconds
2024-09-10 15:23:31,637 Latency for request 9740a134 with model distilgpt2-124m: 8.5535 seconds
2024-09-10 15:23:31,637 Latency for request 44cd9991 with model distilgpt2-124m: 8.1407 seconds
2024-09-10 15:23:31,638 Latency for request 0d8818fc with model distilgpt2-124m: 7.8362 seconds
2024-09-10 15:23:31,638 Latency for request 474635aa with model distilgpt2-124m: 6.0149 seconds
2024-09-10 15:23:31,638 Latency for request 021dc75b with model distilgpt2-124m: 5.2524 seconds
2024-09-10 15:23:31,638 Latency for request edbdd4a9 with model distilgpt2-124m: 4.9501 seconds
2024-09-10 15:23:31,639 127.0.0.1 - - [10/Sep/2024 15:23:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:31,639 Updated batch size:8
2024-09-10 15:23:31,639 Loading model gpt2-124m
2024-09-10 15:23:31,822 Request with ID 9d67aea2 for model gpt2-124m received
2024-09-10 15:23:31,822 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:23:31,822 127.0.0.1 - - [10/Sep/2024 15:23:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:32,689 Request with ID fb4c457e for model gpt2-124m received
2024-09-10 15:23:32,689 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:23:32,690 127.0.0.1 - - [10/Sep/2024 15:23:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:33,139 Processed batch: ['02d43d27', 'b6f83604', 'c4011208', 'c9de063a', '8b78fd60', 'fc471845', 'a747083b', '06af7a58'] with model gpt2-124m in 1.4295 seconds
2024-09-10 15:23:33,139 Latency for request 02d43d27 with model gpt2-124m: 7.5359 seconds
2024-09-10 15:23:33,140 Latency for request b6f83604 with model gpt2-124m: 6.4008 seconds
2024-09-10 15:23:33,140 Latency for request c4011208 with model gpt2-124m: 6.1688 seconds
2024-09-10 15:23:33,141 Latency for request c9de063a with model gpt2-124m: 5.9841 seconds
2024-09-10 15:23:33,141 Latency for request 8b78fd60 with model gpt2-124m: 5.6519 seconds
2024-09-10 15:23:33,141 Latency for request fc471845 with model gpt2-124m: 5.1446 seconds
2024-09-10 15:23:33,141 Latency for request a747083b with model gpt2-124m: 4.8997 seconds
2024-09-10 15:23:33,142 Latency for request 06af7a58 with model gpt2-124m: 4.1693 seconds
2024-09-10 15:23:33,142 127.0.0.1 - - [10/Sep/2024 15:23:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:33,338 Request with ID f16dca07 for model gpt2medium-355m received
2024-09-10 15:23:33,338 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:23:33,338 Adjusted time limit for model gpt2medium-355m: 9.9482 seconds
2024-09-10 15:23:33,338 127.0.0.1 - - [10/Sep/2024 15:23:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:34,621 Request with ID fd1b379f for model distilgpt2-124m received
2024-09-10 15:23:34,621 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 15:23:34,621 Adjusted time limit for model distilgpt2-124m: 14.2082 seconds
2024-09-10 15:23:34,622 127.0.0.1 - - [10/Sep/2024 15:23:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:34,788 Request with ID 82078125 for model distilgpt2-124m received
2024-09-10 15:23:34,789 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 15:23:34,790 127.0.0.1 - - [10/Sep/2024 15:23:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:34,833 Request with ID 3a312c17 for model distilgpt2-124m received
2024-09-10 15:23:34,833 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 15:23:34,834 127.0.0.1 - - [10/Sep/2024 15:23:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:35,271 Request with ID 9e387e72 for model gpt2-124m received
2024-09-10 15:23:35,272 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 15:23:35,272 Adjusted time limit for model gpt2-124m: 13.3434 seconds
2024-09-10 15:23:35,272 127.0.0.1 - - [10/Sep/2024 15:23:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:35,369 Request with ID 08a5856c for model gpt2-124m received
2024-09-10 15:23:35,369 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 15:23:35,370 127.0.0.1 - - [10/Sep/2024 15:23:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:36,432 Request with ID 1d2d7bcd for model gpt2-124m received
2024-09-10 15:23:36,432 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 15:23:36,432 Batch size condition met for model gpt2-124m
2024-09-10 15:23:36,432 Updated batch size:8
2024-09-10 15:23:36,432 Loading model gpt2-124m
2024-09-10 15:23:37,743 Time limit condition met for model gpt2medium-355m
2024-09-10 15:23:38,062 Processed batch: ['17f1ba7a', '011e3c17', '9ec4b7e0', '9d67aea2', 'fb4c457e', '9e387e72', '08a5856c', '1d2d7bcd'] with model gpt2-124m in 1.6291 seconds
2024-09-10 15:23:38,062 Latency for request 17f1ba7a with model gpt2-124m: 8.4026 seconds
2024-09-10 15:23:38,062 Latency for request 011e3c17 with model gpt2-124m: 7.3810 seconds
2024-09-10 15:23:38,063 Latency for request 9ec4b7e0 with model gpt2-124m: 6.9736 seconds
2024-09-10 15:23:38,063 Latency for request 9d67aea2 with model gpt2-124m: 6.2397 seconds
2024-09-10 15:23:38,063 Latency for request fb4c457e with model gpt2-124m: 5.3722 seconds
2024-09-10 15:23:38,063 Latency for request 9e387e72 with model gpt2-124m: 2.7902 seconds
2024-09-10 15:23:38,064 Latency for request 08a5856c with model gpt2-124m: 2.6927 seconds
2024-09-10 15:23:38,064 Latency for request 1d2d7bcd with model gpt2-124m: 1.6295 seconds
2024-09-10 15:23:38,064 127.0.0.1 - - [10/Sep/2024 15:23:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:23:38,064 Updated batch size:8
2024-09-10 15:23:38,064 Loading model gpt2medium-355m
2024-09-10 15:23:41,919 Processed batch: ['732a8126', '4d64107e', 'a2c40116', 'd32bbf70', '4fe376e8', '6aca476e', 'f16dca07', 'bb18'] with model gpt2medium-355m in 3.7422 seconds
2024-09-10 15:23:41,919 Latency for request 732a8126 with model gpt2medium-355m: 15.9834 seconds
2024-09-10 15:23:41,920 Latency for request 4d64107e with model gpt2medium-355m: 14.2672 seconds
2024-09-10 15:23:41,921 Latency for request a2c40116 with model gpt2medium-355m: 14.0096 seconds
2024-09-10 15:23:41,921 Latency for request d32bbf70 with model gpt2medium-355m: 12.7241 seconds
2024-09-10 15:23:41,921 Latency for request 4fe376e8 with model gpt2medium-355m: 12.5417 seconds
2024-09-10 15:23:41,922 Latency for request 6aca476e with model gpt2medium-355m: 11.6640 seconds
2024-09-10 15:23:41,922 Latency for request f16dca07 with model gpt2medium-355m: 8.5809 seconds
2024-09-10 15:23:41,924 Latency for request bb18 with model gpt2medium-355m: 3.8548 seconds
2024-09-10 15:23:47,738 Time limit condition met for model distilgpt2-124m
2024-09-10 15:23:47,738 Updated batch size:8
2024-09-10 15:23:47,739 Loading model distilgpt2-124m
2024-09-10 15:23:48,548 Processed batch: ['d210457b', 'c9419493', 'cf7d35ff', '9fa9efc8', 'fd1b379f', '82078125', '3a312c17', 'bfea'] with model distilgpt2-124m in 0.7236 seconds
2024-09-10 15:23:48,549 Latency for request d210457b with model distilgpt2-124m: 18.6269 seconds
2024-09-10 15:23:48,550 Latency for request c9419493 with model distilgpt2-124m: 17.7049 seconds
2024-09-10 15:23:48,550 Latency for request cf7d35ff with model distilgpt2-124m: 17.6210 seconds
2024-09-10 15:23:48,550 Latency for request 9fa9efc8 with model distilgpt2-124m: 17.0639 seconds
2024-09-10 15:23:48,550 Latency for request fd1b379f with model distilgpt2-124m: 13.9278 seconds
2024-09-10 15:23:48,551 Latency for request 82078125 with model distilgpt2-124m: 13.7599 seconds
2024-09-10 15:23:48,551 Latency for request 3a312c17 with model distilgpt2-124m: 13.7155 seconds
2024-09-10 15:23:48,551 Latency for request bfea with model distilgpt2-124m: 0.8100 seconds
2024-09-10 15:23:48,551 Total time: 70.2927 seconds
2024-09-10 15:23:48,551 Total inference time: 46.4239 seconds
2024-09-10 15:23:48,551 Inference time as percentage of total time: 66.04%
