2024-09-09 19:14:57,877 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.212:5000
2024-09-09 19:14:57,877 [33mPress CTRL+C to quit[0m
2024-09-09 19:15:01,444 Adjusted time limit: 3.3502 seconds
2024-09-09 19:15:01,444 127.0.0.1 - - [09/Sep/2024 19:15:01] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:03,921 Adjusted time limit: 3.3502 seconds
2024-09-09 19:15:03,922 127.0.0.1 - - [09/Sep/2024 19:15:03] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:04,848 Time limit reached for model gpt2-124m at 1725923704.8486
2024-09-09 19:15:04,849 Time limit condition met for model gpt2-124m
2024-09-09 19:15:04,849 Loading model gpt2-124m
2024-09-09 19:15:04,914 Adjusted time limit: 0.0000 seconds
2024-09-09 19:15:04,914 127.0.0.1 - - [09/Sep/2024 19:15:04] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:05,098 Adjusted time limit: 3.3434 seconds
2024-09-09 19:15:05,098 127.0.0.1 - - [09/Sep/2024 19:15:05] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:05,606 Processed batch: ['f8355ae8', 'f0a912cf', '2236', 'a3d1'] with model gpt2-124m in 0.6401 seconds
2024-09-09 19:15:05,606 Latency for request f8355ae8 with model gpt2-124m: 4.1617 seconds
2024-09-09 19:15:05,608 Latency for request f0a912cf with model gpt2-124m: 1.6846 seconds
2024-09-09 19:15:05,608 Latency for request 2236 with model gpt2-124m: 0.7566 seconds
2024-09-09 19:15:05,608 Latency for request a3d1 with model gpt2-124m: 0.7566 seconds
2024-09-09 19:15:05,710 Time limit reached for model gpt2medium-355m at 1725923705.7100
2024-09-09 19:15:05,710 Time limit condition met for model gpt2medium-355m
2024-09-09 19:15:05,710 Loading model gpt2medium-355m
2024-09-09 19:15:06,208 Adjusted time limit: 3.3395 seconds
2024-09-09 19:15:06,208 127.0.0.1 - - [09/Sep/2024 19:15:06] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:08,195 Adjusted time limit: 4.2043 seconds
2024-09-09 19:15:08,195 127.0.0.1 - - [09/Sep/2024 19:15:08] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:08,807 Processed batch: ['5e82f019', 'fd1f', '3695', '6b9b'] with model gpt2medium-355m in 2.9840 seconds
2024-09-09 19:15:08,807 Latency for request 5e82f019 with model gpt2medium-355m: 3.8938 seconds
2024-09-09 19:15:08,808 Latency for request fd1f with model gpt2medium-355m: 3.0976 seconds
2024-09-09 19:15:08,808 Latency for request 3695 with model gpt2medium-355m: 3.0976 seconds
2024-09-09 19:15:08,808 Latency for request 6b9b with model gpt2medium-355m: 3.0976 seconds
2024-09-09 19:15:09,646 Time limit reached for model gpt2-124m at 1725923709.6463
2024-09-09 19:15:09,647 Time limit condition met for model gpt2-124m
2024-09-09 19:15:09,647 Loading model gpt2-124m
2024-09-09 19:15:10,021 Adjusted time limit: 4.2082 seconds
2024-09-09 19:15:10,021 127.0.0.1 - - [09/Sep/2024 19:15:10] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:10,491 Processed batch: ['21f0e959', 'dfdf38b6', 'bd72', '81b7'] with model gpt2-124m in 0.7514 seconds
2024-09-09 19:15:10,491 Latency for request 21f0e959 with model gpt2-124m: 5.3926 seconds
2024-09-09 19:15:10,492 Latency for request dfdf38b6 with model gpt2-124m: 4.2832 seconds
2024-09-09 19:15:10,492 Latency for request bd72 with model gpt2-124m: 0.8436 seconds
2024-09-09 19:15:10,492 Latency for request 81b7 with model gpt2-124m: 0.8435 seconds
2024-09-09 19:15:11,718 Adjusted time limit: 0.0000 seconds
2024-09-09 19:15:11,718 127.0.0.1 - - [09/Sep/2024 19:15:11] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:11,738 Time limit reached for model gpt2medium-355m at 1725923711.7379
2024-09-09 19:15:11,738 Time limit condition met for model gpt2medium-355m
2024-09-09 19:15:11,738 Loading model gpt2medium-355m
2024-09-09 19:15:12,892 Adjusted time limit: 4.2043 seconds
2024-09-09 19:15:12,893 127.0.0.1 - - [09/Sep/2024 19:15:12] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:14,095 Processed batch: ['1cdd032a', 'f2b0', '5220', '23f9'] with model gpt2medium-355m in 2.1920 seconds
2024-09-09 19:15:14,095 Latency for request 1cdd032a with model gpt2medium-355m: 2.3777 seconds
2024-09-09 19:15:14,096 Latency for request f2b0 with model gpt2medium-355m: 2.3576 seconds
2024-09-09 19:15:14,096 Latency for request 5220 with model gpt2medium-355m: 2.3576 seconds
2024-09-09 19:15:14,097 Latency for request 23f9 with model gpt2medium-355m: 2.3576 seconds
2024-09-09 19:15:14,202 Time limit reached for model distilgpt2-124m at 1725923714.2020
2024-09-09 19:15:14,202 Time limit condition met for model distilgpt2-124m
2024-09-09 19:15:14,202 Loading model distilgpt2-124m
2024-09-09 19:15:14,257 Adjusted time limit: 0.0000 seconds
2024-09-09 19:15:14,257 127.0.0.1 - - [09/Sep/2024 19:15:14] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:15,399 Processed batch: ['c3ac7746', 'c52f0386', '601c4799', '8b71'] with model distilgpt2-124m in 1.1401 seconds
2024-09-09 19:15:15,399 Latency for request c3ac7746 with model distilgpt2-124m: 7.2037 seconds
2024-09-09 19:15:15,399 Latency for request c52f0386 with model distilgpt2-124m: 5.3778 seconds
2024-09-09 19:15:15,400 Latency for request 601c4799 with model distilgpt2-124m: 2.5063 seconds
2024-09-09 19:15:15,400 Latency for request 8b71 with model distilgpt2-124m: 1.1969 seconds
2024-09-09 19:15:15,505 Time limit reached for model gpt2medium-355m at 1725923715.5057
2024-09-09 19:15:15,505 Time limit condition met for model gpt2medium-355m
2024-09-09 19:15:15,505 Loading model gpt2medium-355m
2024-09-09 19:15:15,722 Adjusted time limit: 3.3395 seconds
2024-09-09 19:15:15,722 127.0.0.1 - - [09/Sep/2024 19:15:15] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:17,553 Adjusted time limit: 0.0000 seconds
2024-09-09 19:15:17,553 127.0.0.1 - - [09/Sep/2024 19:15:17] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:17,945 Processed batch: ['3387e778', '847d', 'fa87', 'cf2e'] with model gpt2medium-355m in 2.3315 seconds
2024-09-09 19:15:17,946 Latency for request 3387e778 with model gpt2medium-355m: 3.6884 seconds
2024-09-09 19:15:17,947 Latency for request 847d with model gpt2medium-355m: 2.4400 seconds
2024-09-09 19:15:17,947 Latency for request fa87 with model gpt2medium-355m: 2.4400 seconds
2024-09-09 19:15:17,947 Latency for request cf2e with model gpt2medium-355m: 2.4400 seconds
2024-09-09 19:15:18,644 Adjusted time limit: 3.3395 seconds
2024-09-09 19:15:18,645 127.0.0.1 - - [09/Sep/2024 19:15:18] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:19,088 Time limit reached for model gpt2-124m at 1725923719.0881
2024-09-09 19:15:19,088 Time limit condition met for model gpt2-124m
2024-09-09 19:15:19,088 Loading model gpt2-124m
2024-09-09 19:15:19,647 Adjusted time limit: 4.2082 seconds
2024-09-09 19:15:19,648 127.0.0.1 - - [09/Sep/2024 19:15:19] "POST /inference HTTP/1.1" 200 -
2024-09-09 19:15:20,014 Processed batch: ['b0d4af6e', '309f4b00', 'cffe', '7ea5'] with model gpt2-124m in 0.8227 seconds
2024-09-09 19:15:20,014 Latency for request b0d4af6e with model gpt2-124m: 4.2919 seconds
2024-09-09 19:15:20,015 Latency for request 309f4b00 with model gpt2-124m: 1.3694 seconds
2024-09-09 19:15:20,015 Latency for request cffe with model gpt2-124m: 0.9254 seconds
2024-09-09 19:15:20,015 Latency for request 7ea5 with model gpt2-124m: 0.9254 seconds
2024-09-09 19:15:23,870 Time limit reached for model distilgpt2-124m at 1725923723.8704
2024-09-09 19:15:23,870 Time limit condition met for model distilgpt2-124m
2024-09-09 19:15:23,871 Loading model distilgpt2-124m
2024-09-09 19:15:24,501 Processed batch: ['41bb7803', '3ace', '0d3c', '8a43'] with model distilgpt2-124m in 0.5503 seconds
2024-09-09 19:15:24,501 Latency for request 41bb7803 with model distilgpt2-124m: 4.8532 seconds
2024-09-09 19:15:24,501 Latency for request 3ace with model distilgpt2-124m: 0.6299 seconds
2024-09-09 19:15:24,502 Latency for request 0d3c with model distilgpt2-124m: 0.6299 seconds
2024-09-09 19:15:24,502 Latency for request 8a43 with model distilgpt2-124m: 0.6299 seconds
