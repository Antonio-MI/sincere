2024-09-20 12:45:18,642 Using device: cuda
2024-09-20 12:45:18,642 Scheduling mode set as BestBatch+SLA
2024-09-20 12:45:18,646 Monitoring status set to True
2024-09-20 12:45:33,715 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.122.143:5000
2024-09-20 12:45:33,715 [33mPress CTRL+C to quit[0m
2024-09-20 12:45:33,859 Request with ID e170df14 for model llama3-8b received
2024-09-20 12:45:33,860 Adjusted batch time limit for llama3-8b: 5.0000 seconds
2024-09-20 12:45:33,860 127.0.0.1 - - [20/Sep/2024 12:45:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:33,878 Request with ID 323732f9 for model llama3-8b received
2024-09-20 12:45:33,879 127.0.0.1 - - [20/Sep/2024 12:45:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:34,046 Request with ID 8d9eb73c for model gemma-7b received
2024-09-20 12:45:34,046 Adjusted batch time limit for gemma-7b: 5.0000 seconds
2024-09-20 12:45:34,047 127.0.0.1 - - [20/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:34,060 Request with ID 94056911 for model llama3-8b received
2024-09-20 12:45:34,060 127.0.0.1 - - [20/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:34,061 Request with ID f865aa67 for model llama3-8b received
2024-09-20 12:45:34,061 127.0.0.1 - - [20/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:34,062 Request with ID 70f79507 for model llama3-8b received
2024-09-20 12:45:34,063 127.0.0.1 - - [20/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:34,129 Request with ID 353551fb for model gemma-7b received
2024-09-20 12:45:34,130 127.0.0.1 - - [20/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:34,417 Request with ID 0fef163e for model llama3-8b received
2024-09-20 12:45:34,418 127.0.0.1 - - [20/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:34,469 Request with ID 5e2fe931 for model llama3-8b received
2024-09-20 12:45:34,470 127.0.0.1 - - [20/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:34,800 Request with ID be532646 for model gemma-7b received
2024-09-20 12:45:34,801 127.0.0.1 - - [20/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:34,804 Request with ID e7eac449 for model llama3-8b received
2024-09-20 12:45:34,805 127.0.0.1 - - [20/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:34,859 Request with ID dbe4e13a for model gemma-7b received
2024-09-20 12:45:34,860 127.0.0.1 - - [20/Sep/2024 12:45:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:35,101 Request with ID a78b0267 for model gemma-7b received
2024-09-20 12:45:35,102 127.0.0.1 - - [20/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:35,170 Request with ID e1e49ad7 for model llama3-8b received
2024-09-20 12:45:35,170 127.0.0.1 - - [20/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:35,262 Request with ID 5113ce43 for model gemma-7b received
2024-09-20 12:45:35,263 127.0.0.1 - - [20/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:35,290 Request with ID 50bfdcb0 for model gemma-7b received
2024-09-20 12:45:35,291 127.0.0.1 - - [20/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:35,393 Request with ID e5bf1373 for model gemma-7b received
2024-09-20 12:45:35,393 127.0.0.1 - - [20/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:35,564 Request with ID 2dbfa549 for model gemma-7b received
2024-09-20 12:45:35,564 127.0.0.1 - - [20/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:35,637 Request with ID e0419ed5 for model llama3-8b received
2024-09-20 12:45:35,637 127.0.0.1 - - [20/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:35,751 Request with ID 96e9b264 for model llama3-8b received
2024-09-20 12:45:35,752 127.0.0.1 - - [20/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:35,778 Request with ID 84fd0d1f for model gemma-7b received
2024-09-20 12:45:35,779 127.0.0.1 - - [20/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:35,898 Request with ID 2c7e74b0 for model llama3-8b received
2024-09-20 12:45:35,898 127.0.0.1 - - [20/Sep/2024 12:45:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:36,082 Request with ID 108f12e1 for model gemma-7b received
2024-09-20 12:45:36,082 127.0.0.1 - - [20/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:36,095 Request with ID 67ddb485 for model llama3-8b received
2024-09-20 12:45:36,096 127.0.0.1 - - [20/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:36,127 Request with ID c743cfc9 for model gemma-7b received
2024-09-20 12:45:36,128 127.0.0.1 - - [20/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:36,533 Request with ID 4677547e for model gemma-7b received
2024-09-20 12:45:36,533 127.0.0.1 - - [20/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:36,542 Request with ID 7facdb2c for model llama3-8b received
2024-09-20 12:45:36,542 127.0.0.1 - - [20/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:36,644 Request with ID 8bb1ba8f for model gemma-7b received
2024-09-20 12:45:36,645 127.0.0.1 - - [20/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:36,766 Request with ID d91fafff for model llama3-8b received
2024-09-20 12:45:36,767 127.0.0.1 - - [20/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:36,820 Request with ID 551f7ffe for model llama3-8b received
2024-09-20 12:45:36,820 127.0.0.1 - - [20/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:36,829 Request with ID b230e7f4 for model llama3-8b received
2024-09-20 12:45:36,829 127.0.0.1 - - [20/Sep/2024 12:45:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:38,954 Processing batch for llama3-8b due to time limit with batch size 17
2024-09-20 12:45:38,954 Time limit condition met for model llama3-8b
2024-09-20 12:45:38,954 Next: call load_model for llama3-8b
