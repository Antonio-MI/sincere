2024-09-10 14:54:35,516 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.11.77:5000
2024-09-10 14:54:35,516 [33mPress CTRL+C to quit[0m
2024-09-10 14:54:35,606 Request with ID ef9b346d for model gpt2medium-355m received
2024-09-10 14:54:35,606 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 14:54:35,606 Adjusted time limit for model gpt2medium-355m: 9.9550 seconds
2024-09-10 14:54:35,606 127.0.0.1 - - [10/Sep/2024 14:54:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:35,608 Request with ID f7b634c9 for model gpt2-124m received
2024-09-10 14:54:35,608 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 14:54:35,608 Adjusted time limit for model gpt2-124m: 13.3502 seconds
2024-09-10 14:54:35,609 127.0.0.1 - - [10/Sep/2024 14:54:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:35,616 Request with ID 94d37fbc for model gpt2-124m received
2024-09-10 14:54:35,616 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 14:54:35,616 127.0.0.1 - - [10/Sep/2024 14:54:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:35,643 Request with ID 8daee823 for model gpt2-124m received
2024-09-10 14:54:35,643 Adjusted time limit based on total queue size 4: 11.2500 seconds
2024-09-10 14:54:35,643 127.0.0.1 - - [10/Sep/2024 14:54:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:35,868 Request with ID 4cdcc263 for model gpt2-124m received
2024-09-10 14:54:35,869 Adjusted time limit based on total queue size 5: 11.2500 seconds
2024-09-10 14:54:35,869 127.0.0.1 - - [10/Sep/2024 14:54:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:36,268 Request with ID 549ac0d2 for model distilgpt2-124m received
2024-09-10 14:54:36,268 Adjusted time limit based on total queue size 6: 11.2500 seconds
2024-09-10 14:54:36,269 Adjusted time limit for model distilgpt2-124m: 14.2150 seconds
2024-09-10 14:54:36,269 127.0.0.1 - - [10/Sep/2024 14:54:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:36,635 Request with ID 689661df for model distilgpt2-124m received
2024-09-10 14:54:36,635 Adjusted time limit based on total queue size 7: 11.2500 seconds
2024-09-10 14:54:36,636 127.0.0.1 - - [10/Sep/2024 14:54:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:36,976 Request with ID 17af34b5 for model gpt2medium-355m received
2024-09-10 14:54:36,976 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 14:54:36,976 127.0.0.1 - - [10/Sep/2024 14:54:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:37,212 Request with ID 15fff6e3 for model distilgpt2-124m received
2024-09-10 14:54:37,213 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 14:54:37,213 127.0.0.1 - - [10/Sep/2024 14:54:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:37,487 Request with ID a8303457 for model gpt2medium-355m received
2024-09-10 14:54:37,487 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 14:54:37,488 127.0.0.1 - - [10/Sep/2024 14:54:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:37,783 Request with ID 05423c0d for model gpt2-124m received
2024-09-10 14:54:37,783 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:54:37,784 127.0.0.1 - - [10/Sep/2024 14:54:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:38,151 Request with ID e5570501 for model gpt2medium-355m received
2024-09-10 14:54:38,151 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:54:38,152 127.0.0.1 - - [10/Sep/2024 14:54:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:38,370 Request with ID 61605df8 for model gpt2-124m received
2024-09-10 14:54:38,370 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:54:38,371 127.0.0.1 - - [10/Sep/2024 14:54:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:38,573 Request with ID dc8ffead for model distilgpt2-124m received
2024-09-10 14:54:38,573 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:54:38,574 127.0.0.1 - - [10/Sep/2024 14:54:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:39,215 Request with ID 889fda9b for model gpt2-124m received
2024-09-10 14:54:39,215 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:54:39,215 127.0.0.1 - - [10/Sep/2024 14:54:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:39,938 Request with ID 92a8eae6 for model gpt2-124m received
2024-09-10 14:54:39,938 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:54:39,939 127.0.0.1 - - [10/Sep/2024 14:54:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:40,380 Request with ID 3f364b30 for model distilgpt2-124m received
2024-09-10 14:54:40,380 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:54:40,380 127.0.0.1 - - [10/Sep/2024 14:54:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:42,070 Request with ID b0002936 for model gpt2-124m received
2024-09-10 14:54:42,071 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:54:42,071 127.0.0.1 - - [10/Sep/2024 14:54:42] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:42,819 Request with ID ae768431 for model gpt2medium-355m received
2024-09-10 14:54:42,819 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:54:42,819 127.0.0.1 - - [10/Sep/2024 14:54:42] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:42,868 Time limit condition met for model gpt2medium-355m
2024-09-10 14:54:42,868 Updated batch size:8
2024-09-10 14:54:42,869 Loading model gpt2medium-355m
2024-09-10 14:54:43,381 Request with ID fbc55b0e for model gpt2medium-355m received
2024-09-10 14:54:43,381 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:54:43,381 127.0.0.1 - - [10/Sep/2024 14:54:43] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:43,762 Request with ID 5b57ce8f for model gpt2medium-355m received
2024-09-10 14:54:43,762 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:54:43,762 127.0.0.1 - - [10/Sep/2024 14:54:43] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:44,456 Request with ID 3d77d20f for model gpt2medium-355m received
2024-09-10 14:54:44,456 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:54:44,457 127.0.0.1 - - [10/Sep/2024 14:54:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:44,881 Request with ID 5530bb2b for model gpt2-124m received
2024-09-10 14:54:44,881 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:54:44,881 127.0.0.1 - - [10/Sep/2024 14:54:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:45,127 Request with ID 59d689ee for model distilgpt2-124m received
2024-09-10 14:54:45,127 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:54:45,127 127.0.0.1 - - [10/Sep/2024 14:54:45] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:45,764 Request with ID 463b3dc3 for model distilgpt2-124m received
2024-09-10 14:54:45,764 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:54:45,764 127.0.0.1 - - [10/Sep/2024 14:54:45] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:46,193 Processed batch: ['ef9b346d', '17af34b5', 'a8303457', 'e5570501', 'ae768431', '36a8', '2d3f', '8f77'] with model gpt2medium-355m in 3.1752 seconds
2024-09-10 14:54:46,193 Latency for request ef9b346d with model gpt2medium-355m: 10.5875 seconds
2024-09-10 14:54:46,195 Latency for request 17af34b5 with model gpt2medium-355m: 9.2175 seconds
2024-09-10 14:54:46,195 Latency for request a8303457 with model gpt2medium-355m: 8.7061 seconds
2024-09-10 14:54:46,196 Latency for request e5570501 with model gpt2medium-355m: 8.0424 seconds
2024-09-10 14:54:46,196 Latency for request ae768431 with model gpt2medium-355m: 3.3745 seconds
2024-09-10 14:54:46,196 Latency for request 36a8 with model gpt2medium-355m: 3.3247 seconds
2024-09-10 14:54:46,196 Latency for request 2d3f with model gpt2medium-355m: 3.3247 seconds
2024-09-10 14:54:46,197 Latency for request 8f77 with model gpt2medium-355m: 3.3246 seconds
2024-09-10 14:54:46,306 Request with ID a57db08c for model distilgpt2-124m received
2024-09-10 14:54:46,306 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 14:54:46,306 127.0.0.1 - - [10/Sep/2024 14:54:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:46,383 Request with ID da163f48 for model gpt2-124m received
2024-09-10 14:54:46,383 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 14:54:46,383 127.0.0.1 - - [10/Sep/2024 14:54:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:46,613 Time limit condition met for model gpt2-124m
2024-09-10 14:54:46,614 Updated batch size:16
2024-09-10 14:54:46,614 Loading model gpt2-124m
2024-09-10 14:54:47,090 Request with ID 656fea24 for model gpt2medium-355m received
2024-09-10 14:54:47,090 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:54:47,090 Adjusted time limit for model gpt2medium-355m: 9.9482 seconds
2024-09-10 14:54:47,091 127.0.0.1 - - [10/Sep/2024 14:54:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:47,557 Request with ID 8ad9c9a3 for model gpt2medium-355m received
2024-09-10 14:54:47,557 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:54:47,557 127.0.0.1 - - [10/Sep/2024 14:54:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:47,619 Request with ID 71ded8ea for model gpt2medium-355m received
2024-09-10 14:54:47,619 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:54:47,619 127.0.0.1 - - [10/Sep/2024 14:54:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:48,508 Request with ID 4527fba0 for model gpt2medium-355m received
2024-09-10 14:54:48,508 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:54:48,508 127.0.0.1 - - [10/Sep/2024 14:54:48] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:48,691 Processed batch: ['f7b634c9', '94d37fbc', '8daee823', '4cdcc263', '05423c0d', '61605df8', '889fda9b', '92a8eae6', 'b0002936', '5530bb2b', 'da163f48', 'bdc2', 'b4bf', '7942', '31c2', 'ca5f'] with model gpt2-124m in 1.9907 seconds
2024-09-10 14:54:48,691 Latency for request f7b634c9 with model gpt2-124m: 13.0832 seconds
2024-09-10 14:54:48,692 Latency for request 94d37fbc with model gpt2-124m: 13.0755 seconds
2024-09-10 14:54:48,692 Latency for request 8daee823 with model gpt2-124m: 13.0483 seconds
2024-09-10 14:54:48,693 Latency for request 4cdcc263 with model gpt2-124m: 12.8229 seconds
2024-09-10 14:54:48,693 Latency for request 05423c0d with model gpt2-124m: 10.9088 seconds
2024-09-10 14:54:48,693 Latency for request 61605df8 with model gpt2-124m: 10.3217 seconds
2024-09-10 14:54:48,693 Latency for request 889fda9b with model gpt2-124m: 9.4761 seconds
2024-09-10 14:54:48,694 Latency for request 92a8eae6 with model gpt2-124m: 8.7536 seconds
2024-09-10 14:54:48,694 Latency for request b0002936 with model gpt2-124m: 6.6211 seconds
2024-09-10 14:54:48,694 Latency for request 5530bb2b with model gpt2-124m: 3.8102 seconds
2024-09-10 14:54:48,694 Latency for request da163f48 with model gpt2-124m: 2.3081 seconds
2024-09-10 14:54:48,694 Latency for request bdc2 with model gpt2-124m: 2.0777 seconds
2024-09-10 14:54:48,695 Latency for request b4bf with model gpt2-124m: 2.0777 seconds
2024-09-10 14:54:48,695 Latency for request 7942 with model gpt2-124m: 2.0777 seconds
2024-09-10 14:54:48,695 Latency for request 31c2 with model gpt2-124m: 2.0777 seconds
2024-09-10 14:54:48,695 Latency for request ca5f with model gpt2-124m: 2.0777 seconds
2024-09-10 14:54:48,797 Time limit condition met for model gpt2medium-355m
2024-09-10 14:54:48,797 Updated batch size:8
2024-09-10 14:54:48,797 Loading model gpt2medium-355m
2024-09-10 14:54:48,937 Request with ID 60b485bd for model gpt2-124m received
2024-09-10 14:54:48,937 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 14:54:48,937 Adjusted time limit for model gpt2-124m: 13.3502 seconds
2024-09-10 14:54:48,938 127.0.0.1 - - [10/Sep/2024 14:54:48] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:49,295 Request with ID d333fa6c for model gpt2medium-355m received
2024-09-10 14:54:49,295 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 14:54:49,295 127.0.0.1 - - [10/Sep/2024 14:54:49] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:49,559 Request with ID c7324a8d for model gpt2medium-355m received
2024-09-10 14:54:49,559 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:54:49,559 127.0.0.1 - - [10/Sep/2024 14:54:49] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:49,728 Request with ID 69acb991 for model gpt2-124m received
2024-09-10 14:54:49,728 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:54:49,729 127.0.0.1 - - [10/Sep/2024 14:54:49] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:50,294 Request with ID 6128fd9e for model gpt2medium-355m received
2024-09-10 14:54:50,294 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:54:50,294 127.0.0.1 - - [10/Sep/2024 14:54:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:50,925 Request with ID e3a4700c for model distilgpt2-124m received
2024-09-10 14:54:50,925 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:54:50,926 127.0.0.1 - - [10/Sep/2024 14:54:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:51,352 Request with ID 43ffd39c for model gpt2-124m received
2024-09-10 14:54:51,352 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:54:51,353 127.0.0.1 - - [10/Sep/2024 14:54:51] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:51,525 Request with ID 7b68d9de for model gpt2medium-355m received
2024-09-10 14:54:51,525 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:54:51,525 127.0.0.1 - - [10/Sep/2024 14:54:51] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:51,775 Request with ID dc771ae4 for model gpt2-124m received
2024-09-10 14:54:51,775 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:54:51,775 127.0.0.1 - - [10/Sep/2024 14:54:51] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:51,787 Request with ID 8f724cbb for model gpt2-124m received
2024-09-10 14:54:51,787 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:54:51,787 127.0.0.1 - - [10/Sep/2024 14:54:51] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:52,219 Request with ID bd7be69d for model gpt2-124m received
2024-09-10 14:54:52,219 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:54:52,219 127.0.0.1 - - [10/Sep/2024 14:54:52] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:52,408 Processed batch: ['fbc55b0e', '5b57ce8f', '3d77d20f', '656fea24', '8ad9c9a3', '71ded8ea', '4527fba0', 'c5e2'] with model gpt2medium-355m in 3.4533 seconds
2024-09-10 14:54:52,408 Latency for request fbc55b0e with model gpt2medium-355m: 9.0271 seconds
2024-09-10 14:54:52,409 Latency for request 5b57ce8f with model gpt2medium-355m: 8.6464 seconds
2024-09-10 14:54:52,409 Latency for request 3d77d20f with model gpt2medium-355m: 7.9516 seconds
2024-09-10 14:54:52,410 Latency for request 656fea24 with model gpt2medium-355m: 5.3176 seconds
2024-09-10 14:54:52,410 Latency for request 8ad9c9a3 with model gpt2medium-355m: 4.8509 seconds
2024-09-10 14:54:52,410 Latency for request 71ded8ea with model gpt2medium-355m: 4.7894 seconds
2024-09-10 14:54:52,410 Latency for request 4527fba0 with model gpt2medium-355m: 3.9003 seconds
2024-09-10 14:54:52,411 Latency for request c5e2 with model gpt2medium-355m: 3.6105 seconds
2024-09-10 14:54:52,443 Request with ID 12022dc3 for model distilgpt2-124m received
2024-09-10 14:54:52,444 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:54:52,444 127.0.0.1 - - [10/Sep/2024 14:54:52] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:52,513 Time limit condition met for model distilgpt2-124m
2024-09-10 14:54:52,513 Updated batch size:16
2024-09-10 14:54:52,513 Loading model distilgpt2-124m
2024-09-10 14:54:52,651 Request with ID e405edb4 for model distilgpt2-124m received
2024-09-10 14:54:52,651 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:54:52,651 127.0.0.1 - - [10/Sep/2024 14:54:52] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:53,245 Request with ID b707d81e for model distilgpt2-124m received
2024-09-10 14:54:53,245 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:54:53,245 127.0.0.1 - - [10/Sep/2024 14:54:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:53,375 Request with ID 47570840 for model distilgpt2-124m received
2024-09-10 14:54:53,375 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:54:53,375 127.0.0.1 - - [10/Sep/2024 14:54:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:53,725 Request with ID d5b72682 for model distilgpt2-124m received
2024-09-10 14:54:53,726 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:54:53,726 127.0.0.1 - - [10/Sep/2024 14:54:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:53,932 Request with ID 22cb3785 for model distilgpt2-124m received
2024-09-10 14:54:53,932 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:54:53,932 127.0.0.1 - - [10/Sep/2024 14:54:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:54,170 Request with ID 24bc38e7 for model distilgpt2-124m received
2024-09-10 14:54:54,170 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:54:54,170 127.0.0.1 - - [10/Sep/2024 14:54:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:54,452 Request with ID 42ee7d52 for model distilgpt2-124m received
2024-09-10 14:54:54,452 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:54:54,453 127.0.0.1 - - [10/Sep/2024 14:54:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:54,639 Request with ID 82cac4fc for model distilgpt2-124m received
2024-09-10 14:54:54,639 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:54:54,639 127.0.0.1 - - [10/Sep/2024 14:54:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:54,722 Processed batch: ['549ac0d2', '689661df', '15fff6e3', 'dc8ffead', '3f364b30', '59d689ee', '463b3dc3', 'a57db08c', 'e3a4700c', '12022dc3', 'a376', '1531', 'e3c6', 'f709', 'bbc3', '0ba9'] with model distilgpt2-124m in 2.1506 seconds
2024-09-10 14:54:54,722 Latency for request 549ac0d2 with model distilgpt2-124m: 18.4541 seconds
2024-09-10 14:54:54,723 Latency for request 689661df with model distilgpt2-124m: 18.0871 seconds
2024-09-10 14:54:54,724 Latency for request 15fff6e3 with model distilgpt2-124m: 17.5096 seconds
2024-09-10 14:54:54,724 Latency for request dc8ffead with model distilgpt2-124m: 16.1494 seconds
2024-09-10 14:54:54,724 Latency for request 3f364b30 with model distilgpt2-124m: 14.3426 seconds
2024-09-10 14:54:54,724 Latency for request 59d689ee with model distilgpt2-124m: 9.5951 seconds
2024-09-10 14:54:54,724 Latency for request 463b3dc3 with model distilgpt2-124m: 8.9582 seconds
2024-09-10 14:54:54,725 Latency for request a57db08c with model distilgpt2-124m: 8.4161 seconds
2024-09-10 14:54:54,725 Latency for request e3a4700c with model distilgpt2-124m: 3.7967 seconds
2024-09-10 14:54:54,725 Latency for request 12022dc3 with model distilgpt2-124m: 2.2786 seconds
2024-09-10 14:54:54,725 Latency for request a376 with model distilgpt2-124m: 2.2091 seconds
2024-09-10 14:54:54,726 Latency for request 1531 with model distilgpt2-124m: 2.2091 seconds
2024-09-10 14:54:54,726 Latency for request e3c6 with model distilgpt2-124m: 2.2091 seconds
2024-09-10 14:54:54,726 Latency for request f709 with model distilgpt2-124m: 2.2091 seconds
2024-09-10 14:54:54,726 Latency for request bbc3 with model distilgpt2-124m: 2.2091 seconds
2024-09-10 14:54:54,726 Latency for request 0ba9 with model distilgpt2-124m: 2.2091 seconds
2024-09-10 14:54:55,400 Request with ID ea50d12c for model gpt2medium-355m received
2024-09-10 14:54:55,400 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:54:55,400 Adjusted time limit for model gpt2medium-355m: 9.9487 seconds
2024-09-10 14:54:55,401 127.0.0.1 - - [10/Sep/2024 14:54:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:55,644 Request with ID 91fcf1b0 for model gpt2-124m received
2024-09-10 14:54:55,645 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:54:55,645 127.0.0.1 - - [10/Sep/2024 14:54:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:56,643 Request with ID 62b643fe for model gpt2-124m received
2024-09-10 14:54:56,644 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 14:54:56,644 127.0.0.1 - - [10/Sep/2024 14:54:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:57,259 Request with ID 4433cf74 for model distilgpt2-124m received
2024-09-10 14:54:57,259 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 14:54:57,259 Adjusted time limit for model distilgpt2-124m: 14.2087 seconds
2024-09-10 14:54:57,260 127.0.0.1 - - [10/Sep/2024 14:54:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:57,754 Request with ID b2a42e87 for model distilgpt2-124m received
2024-09-10 14:54:57,754 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 14:54:57,755 127.0.0.1 - - [10/Sep/2024 14:54:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:57,901 Request with ID 436fef91 for model gpt2-124m received
2024-09-10 14:54:57,901 Adjusted time limit based on total queue size 24: 3.7500 seconds
2024-09-10 14:54:57,902 127.0.0.1 - - [10/Sep/2024 14:54:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:58,496 Request with ID 866c7ea6 for model gpt2-124m received
2024-09-10 14:54:58,497 Adjusted time limit based on total queue size 25: 3.7500 seconds
2024-09-10 14:54:58,497 127.0.0.1 - - [10/Sep/2024 14:54:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:58,604 Request with ID ce216df0 for model gpt2-124m received
2024-09-10 14:54:58,605 Adjusted time limit based on total queue size 26: 3.7500 seconds
2024-09-10 14:54:58,605 127.0.0.1 - - [10/Sep/2024 14:54:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:58,863 Request with ID c9fcabb7 for model gpt2-124m received
2024-09-10 14:54:58,864 Adjusted time limit based on total queue size 27: 3.7500 seconds
2024-09-10 14:54:58,864 127.0.0.1 - - [10/Sep/2024 14:54:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:59,146 Request with ID 4d90d55c for model gpt2medium-355m received
2024-09-10 14:54:59,146 Adjusted time limit based on total queue size 28: 3.7500 seconds
2024-09-10 14:54:59,146 127.0.0.1 - - [10/Sep/2024 14:54:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:59,194 Time limit condition met for model gpt2medium-355m
2024-09-10 14:54:59,194 Updated batch size:8
2024-09-10 14:54:59,194 Loading model gpt2medium-355m
2024-09-10 14:54:59,796 Request with ID 3b4bd9eb for model gpt2medium-355m received
2024-09-10 14:54:59,796 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 14:54:59,796 127.0.0.1 - - [10/Sep/2024 14:54:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:54:59,925 Request with ID 98dedf77 for model gpt2-124m received
2024-09-10 14:54:59,925 Adjusted time limit based on total queue size 24: 3.7500 seconds
2024-09-10 14:54:59,925 127.0.0.1 - - [10/Sep/2024 14:54:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:00,113 Request with ID 64057711 for model gpt2-124m received
2024-09-10 14:55:00,113 Adjusted time limit based on total queue size 25: 3.7500 seconds
2024-09-10 14:55:00,113 127.0.0.1 - - [10/Sep/2024 14:55:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:00,511 Request with ID bbd61fd1 for model distilgpt2-124m received
2024-09-10 14:55:00,511 Adjusted time limit based on total queue size 26: 3.7500 seconds
2024-09-10 14:55:00,511 127.0.0.1 - - [10/Sep/2024 14:55:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:00,893 Request with ID eb4666ac for model gpt2-124m received
2024-09-10 14:55:00,893 Adjusted time limit based on total queue size 27: 3.7500 seconds
2024-09-10 14:55:00,893 127.0.0.1 - - [10/Sep/2024 14:55:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:01,002 Request with ID 6cc216a8 for model gpt2medium-355m received
2024-09-10 14:55:01,002 Adjusted time limit based on total queue size 28: 3.7500 seconds
2024-09-10 14:55:01,002 127.0.0.1 - - [10/Sep/2024 14:55:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:01,336 Request with ID c69c7059 for model distilgpt2-124m received
2024-09-10 14:55:01,336 Adjusted time limit based on total queue size 29: 3.7500 seconds
2024-09-10 14:55:01,336 127.0.0.1 - - [10/Sep/2024 14:55:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:01,581 Request with ID 9d4767f8 for model gpt2-124m received
2024-09-10 14:55:01,581 Adjusted time limit based on total queue size 30: 3.7500 seconds
2024-09-10 14:55:01,581 Batch size condition met for model gpt2-124m
2024-09-10 14:55:01,724 Request with ID e3a7ecb9 for model gpt2medium-355m received
2024-09-10 14:55:01,724 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:55:01,724 127.0.0.1 - - [10/Sep/2024 14:55:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:02,433 Request with ID 41e4c9ba for model gpt2-124m received
2024-09-10 14:55:02,433 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:55:02,433 127.0.0.1 - - [10/Sep/2024 14:55:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:03,051 Request with ID 55d7bd45 for model gpt2-124m received
2024-09-10 14:55:03,051 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:55:03,051 127.0.0.1 - - [10/Sep/2024 14:55:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:03,102 Processed batch: ['d333fa6c', 'c7324a8d', '6128fd9e', '7b68d9de', 'ea50d12c', '4d90d55c', '064f', '640a'] with model gpt2medium-355m in 3.8056 seconds
2024-09-10 14:55:03,102 Latency for request d333fa6c with model gpt2medium-355m: 13.8073 seconds
2024-09-10 14:55:03,104 Latency for request c7324a8d with model gpt2medium-355m: 13.5435 seconds
2024-09-10 14:55:03,104 Latency for request 6128fd9e with model gpt2medium-355m: 12.8082 seconds
2024-09-10 14:55:03,104 Latency for request 7b68d9de with model gpt2medium-355m: 11.5775 seconds
2024-09-10 14:55:03,104 Latency for request ea50d12c with model gpt2medium-355m: 7.7028 seconds
2024-09-10 14:55:03,105 Latency for request 4d90d55c with model gpt2medium-355m: 3.9567 seconds
2024-09-10 14:55:03,105 Latency for request 064f with model gpt2medium-355m: 3.9080 seconds
2024-09-10 14:55:03,105 Latency for request 640a with model gpt2medium-355m: 3.9080 seconds
2024-09-10 14:55:03,106 Updated batch size:16
2024-09-10 14:55:03,106 Loading model gpt2-124m
2024-09-10 14:55:03,211 Time limit condition met for model gpt2-124m
2024-09-10 14:55:03,327 Request with ID 7f681e86 for model gpt2medium-355m received
2024-09-10 14:55:03,327 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:55:03,327 Adjusted time limit for model gpt2medium-355m: 9.9482 seconds
2024-09-10 14:55:03,328 127.0.0.1 - - [10/Sep/2024 14:55:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:03,574 Request with ID 00ed2f73 for model gpt2medium-355m received
2024-09-10 14:55:03,574 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:55:03,574 127.0.0.1 - - [10/Sep/2024 14:55:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:04,056 Request with ID 11ecd89e for model distilgpt2-124m received
2024-09-10 14:55:04,056 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:55:04,056 127.0.0.1 - - [10/Sep/2024 14:55:04] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:04,388 Request with ID e9c40c1d for model gpt2medium-355m received
2024-09-10 14:55:04,388 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:55:04,388 127.0.0.1 - - [10/Sep/2024 14:55:04] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:04,775 Request with ID 5c8f38bd for model distilgpt2-124m received
2024-09-10 14:55:04,776 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:55:04,776 127.0.0.1 - - [10/Sep/2024 14:55:04] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:05,078 Request with ID 34bee4f0 for model distilgpt2-124m received
2024-09-10 14:55:05,079 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 14:55:05,079 127.0.0.1 - - [10/Sep/2024 14:55:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:05,253 Processed batch: ['60b485bd', '69acb991', '43ffd39c', 'dc771ae4', '8f724cbb', 'bd7be69d', '91fcf1b0', '62b643fe', '436fef91', '866c7ea6', 'ce216df0', 'c9fcabb7', '98dedf77', '64057711', 'eb4666ac', '9d4767f8'] with model gpt2-124m in 2.0763 seconds
2024-09-10 14:55:05,253 Latency for request 60b485bd with model gpt2-124m: 16.3153 seconds
2024-09-10 14:55:05,253 Latency for request 69acb991 with model gpt2-124m: 15.5243 seconds
2024-09-10 14:55:05,254 Latency for request 43ffd39c with model gpt2-124m: 13.9002 seconds
2024-09-10 14:55:05,254 Latency for request dc771ae4 with model gpt2-124m: 13.4780 seconds
2024-09-10 14:55:05,254 Latency for request 8f724cbb with model gpt2-124m: 13.4655 seconds
2024-09-10 14:55:05,255 Latency for request bd7be69d with model gpt2-124m: 13.0340 seconds
2024-09-10 14:55:05,255 Latency for request 91fcf1b0 with model gpt2-124m: 9.6083 seconds
2024-09-10 14:55:05,255 Latency for request 62b643fe with model gpt2-124m: 8.6094 seconds
2024-09-10 14:55:05,255 Latency for request 436fef91 with model gpt2-124m: 7.3514 seconds
2024-09-10 14:55:05,255 Latency for request 866c7ea6 with model gpt2-124m: 6.7564 seconds
2024-09-10 14:55:05,256 Latency for request ce216df0 with model gpt2-124m: 6.6483 seconds
2024-09-10 14:55:05,256 Latency for request c9fcabb7 with model gpt2-124m: 6.3895 seconds
2024-09-10 14:55:05,256 Latency for request 98dedf77 with model gpt2-124m: 5.3278 seconds
2024-09-10 14:55:05,256 Latency for request 64057711 with model gpt2-124m: 5.1398 seconds
2024-09-10 14:55:05,256 Latency for request eb4666ac with model gpt2-124m: 4.3595 seconds
2024-09-10 14:55:05,257 Latency for request 9d4767f8 with model gpt2-124m: 3.6719 seconds
2024-09-10 14:55:05,257 127.0.0.1 - - [10/Sep/2024 14:55:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:05,257 Updated batch size:4
2024-09-10 14:55:05,257 Loading model gpt2-124m
2024-09-10 14:55:05,643 Request with ID 4d303e13 for model gpt2-124m received
2024-09-10 14:55:05,643 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 14:55:05,643 Adjusted time limit for model gpt2-124m: 13.3434 seconds
2024-09-10 14:55:05,644 127.0.0.1 - - [10/Sep/2024 14:55:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:05,788 Request with ID 56ca2855 for model distilgpt2-124m received
2024-09-10 14:55:05,788 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 14:55:05,788 Batch size condition met for model distilgpt2-124m
2024-09-10 14:55:05,992 Request with ID a81645f7 for model distilgpt2-124m received
2024-09-10 14:55:05,992 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 14:55:05,992 127.0.0.1 - - [10/Sep/2024 14:55:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:06,108 Request with ID 56c813a7 for model distilgpt2-124m received
2024-09-10 14:55:06,109 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 14:55:06,109 127.0.0.1 - - [10/Sep/2024 14:55:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:06,225 Processed batch: ['41e4c9ba', '55d7bd45', 'a6d9', '9f29'] with model gpt2-124m in 0.9680 seconds
2024-09-10 14:55:06,225 Latency for request 41e4c9ba with model gpt2-124m: 3.7923 seconds
2024-09-10 14:55:06,226 Latency for request 55d7bd45 with model gpt2-124m: 3.1742 seconds
2024-09-10 14:55:06,226 Latency for request a6d9 with model gpt2-124m: 0.9682 seconds
2024-09-10 14:55:06,227 Latency for request 9f29 with model gpt2-124m: 0.9682 seconds
2024-09-10 14:55:06,227 Updated batch size:16
2024-09-10 14:55:06,227 Loading model distilgpt2-124m
2024-09-10 14:55:06,332 Time limit condition met for model gpt2medium-355m
2024-09-10 14:55:06,947 Request with ID e1ef8adc for model distilgpt2-124m received
2024-09-10 14:55:06,947 Adjusted time limit based on total queue size 4: 11.2500 seconds
2024-09-10 14:55:06,947 127.0.0.1 - - [10/Sep/2024 14:55:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:07,037 Request with ID 042156b7 for model distilgpt2-124m received
2024-09-10 14:55:07,037 Adjusted time limit based on total queue size 5: 11.2500 seconds
2024-09-10 14:55:07,037 127.0.0.1 - - [10/Sep/2024 14:55:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:07,183 Request with ID 6e7d0a5e for model gpt2medium-355m received
2024-09-10 14:55:07,183 Adjusted time limit based on total queue size 6: 11.2500 seconds
2024-09-10 14:55:07,183 127.0.0.1 - - [10/Sep/2024 14:55:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:07,296 Request with ID e4a0e770 for model gpt2-124m received
2024-09-10 14:55:07,296 Adjusted time limit based on total queue size 7: 11.2500 seconds
2024-09-10 14:55:07,296 Adjusted time limit for model gpt2-124m: 13.3439 seconds
2024-09-10 14:55:07,296 127.0.0.1 - - [10/Sep/2024 14:55:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:07,470 Processed batch: ['e405edb4', 'b707d81e', '47570840', 'd5b72682', '22cb3785', '24bc38e7', '42ee7d52', '82cac4fc', '4433cf74', 'b2a42e87', 'bbd61fd1', 'c69c7059', '11ecd89e', '5c8f38bd', '34bee4f0', '56ca2855'] with model distilgpt2-124m in 1.1893 seconds
2024-09-10 14:55:07,470 Latency for request e405edb4 with model distilgpt2-124m: 14.8189 seconds
2024-09-10 14:55:07,471 Latency for request b707d81e with model distilgpt2-124m: 14.2252 seconds
2024-09-10 14:55:07,472 Latency for request 47570840 with model distilgpt2-124m: 14.0956 seconds
2024-09-10 14:55:07,472 Latency for request d5b72682 with model distilgpt2-124m: 13.7448 seconds
2024-09-10 14:55:07,472 Latency for request 22cb3785 with model distilgpt2-124m: 13.5378 seconds
2024-09-10 14:55:07,472 Latency for request 24bc38e7 with model distilgpt2-124m: 13.3002 seconds
2024-09-10 14:55:07,473 Latency for request 42ee7d52 with model distilgpt2-124m: 13.0179 seconds
2024-09-10 14:55:07,473 Latency for request 82cac4fc with model distilgpt2-124m: 12.8315 seconds
2024-09-10 14:55:07,473 Latency for request 4433cf74 with model distilgpt2-124m: 10.2113 seconds
2024-09-10 14:55:07,473 Latency for request b2a42e87 with model distilgpt2-124m: 9.7166 seconds
2024-09-10 14:55:07,473 Latency for request bbd61fd1 with model distilgpt2-124m: 6.9590 seconds
2024-09-10 14:55:07,474 Latency for request c69c7059 with model distilgpt2-124m: 6.1346 seconds
2024-09-10 14:55:07,474 Latency for request 11ecd89e with model distilgpt2-124m: 3.4141 seconds
2024-09-10 14:55:07,474 Latency for request 5c8f38bd with model distilgpt2-124m: 2.6947 seconds
2024-09-10 14:55:07,474 Latency for request 34bee4f0 with model distilgpt2-124m: 2.3917 seconds
2024-09-10 14:55:07,474 Latency for request 56ca2855 with model distilgpt2-124m: 1.6824 seconds
2024-09-10 14:55:07,475 127.0.0.1 - - [10/Sep/2024 14:55:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:07,475 Updated batch size:8
2024-09-10 14:55:07,475 Loading model gpt2medium-355m
2024-09-10 14:55:07,776 Request with ID 3b3b0bca for model gpt2-124m received
2024-09-10 14:55:07,776 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 14:55:07,776 127.0.0.1 - - [10/Sep/2024 14:55:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:07,892 Request with ID 24a7e666 for model gpt2-124m received
2024-09-10 14:55:07,892 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 14:55:07,892 127.0.0.1 - - [10/Sep/2024 14:55:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:07,970 Request with ID f11b7acf for model gpt2medium-355m received
2024-09-10 14:55:07,970 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 14:55:07,970 127.0.0.1 - - [10/Sep/2024 14:55:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:08,210 Request with ID 2a28272c for model gpt2-124m received
2024-09-10 14:55:08,210 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 14:55:08,210 127.0.0.1 - - [10/Sep/2024 14:55:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:08,724 Request with ID 7355c648 for model distilgpt2-124m received
2024-09-10 14:55:08,724 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 14:55:08,724 Adjusted time limit for model distilgpt2-124m: 14.2043 seconds
2024-09-10 14:55:08,724 127.0.0.1 - - [10/Sep/2024 14:55:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:09,220 Request with ID d09ea269 for model gpt2-124m received
2024-09-10 14:55:09,220 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 14:55:09,221 127.0.0.1 - - [10/Sep/2024 14:55:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:09,323 Request with ID 2093b32a for model gpt2medium-355m received
2024-09-10 14:55:09,323 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 14:55:09,323 127.0.0.1 - - [10/Sep/2024 14:55:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:09,497 Request with ID 0f525716 for model distilgpt2-124m received
2024-09-10 14:55:09,497 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 14:55:09,497 127.0.0.1 - - [10/Sep/2024 14:55:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:09,952 Request with ID b8cea095 for model distilgpt2-124m received
2024-09-10 14:55:09,952 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 14:55:09,953 127.0.0.1 - - [10/Sep/2024 14:55:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:10,260 Request with ID 5e557b8c for model distilgpt2-124m received
2024-09-10 14:55:10,260 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 14:55:10,261 127.0.0.1 - - [10/Sep/2024 14:55:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:10,485 Request with ID 12a15bd8 for model gpt2medium-355m received
2024-09-10 14:55:10,485 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 14:55:10,485 127.0.0.1 - - [10/Sep/2024 14:55:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:11,523 Request with ID 89fdcadc for model distilgpt2-124m received
2024-09-10 14:55:11,523 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 14:55:11,524 127.0.0.1 - - [10/Sep/2024 14:55:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:11,530 Processed batch: ['3b4bd9eb', '6cc216a8', 'e3a7ecb9', '7f681e86', '00ed2f73', 'e9c40c1d', '92c1', '7f60'] with model gpt2medium-355m in 3.9385 seconds
2024-09-10 14:55:11,530 Latency for request 3b4bd9eb with model gpt2medium-355m: 11.7343 seconds
2024-09-10 14:55:11,531 Latency for request 6cc216a8 with model gpt2medium-355m: 10.5282 seconds
2024-09-10 14:55:11,532 Latency for request e3a7ecb9 with model gpt2medium-355m: 9.8064 seconds
2024-09-10 14:55:11,532 Latency for request 7f681e86 with model gpt2medium-355m: 8.2030 seconds
2024-09-10 14:55:11,532 Latency for request 00ed2f73 with model gpt2medium-355m: 7.9565 seconds
2024-09-10 14:55:11,532 Latency for request e9c40c1d with model gpt2medium-355m: 7.1421 seconds
2024-09-10 14:55:11,533 Latency for request 92c1 with model gpt2medium-355m: 4.0554 seconds
2024-09-10 14:55:11,533 Latency for request 7f60 with model gpt2medium-355m: 4.0554 seconds
2024-09-10 14:55:11,713 Request with ID 31f6c185 for model gpt2medium-355m received
2024-09-10 14:55:11,713 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 14:55:11,713 Adjusted time limit for model gpt2medium-355m: 9.9443 seconds
2024-09-10 14:55:11,713 127.0.0.1 - - [10/Sep/2024 14:55:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:12,744 Request with ID c311698b for model distilgpt2-124m received
2024-09-10 14:55:12,744 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 14:55:12,745 127.0.0.1 - - [10/Sep/2024 14:55:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:13,194 Request with ID 9a5d5fe7 for model distilgpt2-124m received
2024-09-10 14:55:13,195 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 14:55:13,195 127.0.0.1 - - [10/Sep/2024 14:55:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:14,431 Request with ID 5d2bdcce for model gpt2medium-355m received
2024-09-10 14:55:14,431 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 14:55:14,431 127.0.0.1 - - [10/Sep/2024 14:55:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 14:55:14,451 Time limit condition met for model gpt2medium-355m
2024-09-10 14:55:14,451 Updated batch size:8
2024-09-10 14:55:14,451 Loading model gpt2medium-355m
2024-09-10 14:55:17,665 Processed batch: ['6e7d0a5e', 'f11b7acf', '2093b32a', '12a15bd8', '31f6c185', '5d2bdcce', 'ac40', '3cd6'] with model gpt2medium-355m in 3.2145 seconds
2024-09-10 14:55:17,665 Latency for request 6e7d0a5e with model gpt2medium-355m: 10.4825 seconds
2024-09-10 14:55:17,666 Latency for request f11b7acf with model gpt2medium-355m: 9.6951 seconds
2024-09-10 14:55:17,667 Latency for request 2093b32a with model gpt2medium-355m: 8.3428 seconds
2024-09-10 14:55:17,667 Latency for request 12a15bd8 with model gpt2medium-355m: 7.1806 seconds
2024-09-10 14:55:17,667 Latency for request 31f6c185 with model gpt2medium-355m: 5.9528 seconds
2024-09-10 14:55:17,667 Latency for request 5d2bdcce with model gpt2medium-355m: 3.2346 seconds
2024-09-10 14:55:17,668 Latency for request ac40 with model gpt2medium-355m: 3.2147 seconds
2024-09-10 14:55:17,668 Latency for request 3cd6 with model gpt2medium-355m: 3.2147 seconds
2024-09-10 14:55:20,053 Time limit condition met for model gpt2-124m
2024-09-10 14:55:20,054 Updated batch size:8
2024-09-10 14:55:20,054 Loading model gpt2-124m
2024-09-10 14:55:21,933 Processed batch: ['4d303e13', 'e4a0e770', '3b3b0bca', '24a7e666', '2a28272c', 'd09ea269', '7bd2', '7468'] with model gpt2-124m in 1.7988 seconds
2024-09-10 14:55:21,933 Latency for request 4d303e13 with model gpt2-124m: 16.2900 seconds
2024-09-10 14:55:21,935 Latency for request e4a0e770 with model gpt2-124m: 14.6373 seconds
2024-09-10 14:55:21,935 Latency for request 3b3b0bca with model gpt2-124m: 14.1572 seconds
2024-09-10 14:55:21,935 Latency for request 24a7e666 with model gpt2-124m: 14.0410 seconds
2024-09-10 14:55:21,936 Latency for request 2a28272c with model gpt2-124m: 13.7235 seconds
2024-09-10 14:55:21,936 Latency for request d09ea269 with model gpt2-124m: 12.7129 seconds
2024-09-10 14:55:21,936 Latency for request 7bd2 with model gpt2-124m: 1.8796 seconds
2024-09-10 14:55:21,936 Latency for request 7468 with model gpt2-124m: 1.8795 seconds
2024-09-10 14:55:22,042 Time limit condition met for model distilgpt2-124m
2024-09-10 14:55:22,042 Updated batch size:16
2024-09-10 14:55:22,042 Loading model distilgpt2-124m
2024-09-10 14:55:23,279 Processed batch: ['a81645f7', '56c813a7', 'e1ef8adc', '042156b7', '7355c648', '0f525716', 'b8cea095', '5e557b8c', '89fdcadc', 'c311698b', '9a5d5fe7', '813f', '06a9', '6b45', 'cde9', 'd730'] with model distilgpt2-124m in 1.1790 seconds
2024-09-10 14:55:23,279 Latency for request a81645f7 with model distilgpt2-124m: 17.2869 seconds
2024-09-10 14:55:23,280 Latency for request 56c813a7 with model distilgpt2-124m: 17.1701 seconds
2024-09-10 14:55:23,280 Latency for request e1ef8adc with model distilgpt2-124m: 16.3319 seconds
2024-09-10 14:55:23,280 Latency for request 042156b7 with model distilgpt2-124m: 16.2416 seconds
2024-09-10 14:55:23,281 Latency for request 7355c648 with model distilgpt2-124m: 14.5545 seconds
2024-09-10 14:55:23,281 Latency for request 0f525716 with model distilgpt2-124m: 13.7820 seconds
2024-09-10 14:55:23,281 Latency for request b8cea095 with model distilgpt2-124m: 13.3262 seconds
2024-09-10 14:55:23,281 Latency for request 5e557b8c with model distilgpt2-124m: 13.0183 seconds
2024-09-10 14:55:23,282 Latency for request 89fdcadc with model distilgpt2-124m: 11.7552 seconds
2024-09-10 14:55:23,282 Latency for request c311698b with model distilgpt2-124m: 10.5348 seconds
2024-09-10 14:55:23,282 Latency for request 9a5d5fe7 with model distilgpt2-124m: 10.0843 seconds
2024-09-10 14:55:23,282 Latency for request 813f with model distilgpt2-124m: 1.2370 seconds
2024-09-10 14:55:23,283 Latency for request 06a9 with model distilgpt2-124m: 1.2370 seconds
2024-09-10 14:55:23,283 Latency for request 6b45 with model distilgpt2-124m: 1.2370 seconds
2024-09-10 14:55:23,283 Latency for request cde9 with model distilgpt2-124m: 1.2370 seconds
2024-09-10 14:55:23,283 Latency for request d730 with model distilgpt2-124m: 1.2369 seconds
2024-09-10 14:55:23,283 Total time: 47.6780 seconds
2024-09-10 14:55:23,284 Total inference time: 28.9397 seconds
2024-09-10 14:55:23,284 Inference time as percentage of total time: 60.70%
