2024-09-19 10:10:42,036 Using device: cuda
2024-09-19 10:10:42,036 Monitoring status set to True
2024-09-19 10:10:57,112 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.122.143:5000
2024-09-19 10:10:57,112 [33mPress CTRL+C to quit[0m
2024-09-19 10:10:58,307 127.0.0.1 - - [19/Sep/2024 10:10:58] "GET /health HTTP/1.1" 200 -
2024-09-19 10:11:09,678 Saving sys info
2024-09-19 10:11:09,719 Latency for request 8c5911b6 with model granite-7b: 11.1690 seconds
2024-09-19 10:11:09,719 Saving results with gpu monitoring
2024-09-19 10:11:09,724 127.0.0.1 - - [19/Sep/2024 10:11:09] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:11,593 Saving sys info
2024-09-19 10:11:11,626 Latency for request 3fe0bd67 with model granite-7b: 0.8620 seconds
2024-09-19 10:11:11,626 Saving results with gpu monitoring
2024-09-19 10:11:11,633 127.0.0.1 - - [19/Sep/2024 10:11:11] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:13,522 Saving sys info
2024-09-19 10:11:13,552 Latency for request 6817edf2 with model granite-7b: 0.8830 seconds
2024-09-19 10:11:13,553 Saving results with gpu monitoring
2024-09-19 10:11:13,560 127.0.0.1 - - [19/Sep/2024 10:11:13] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:15,426 Saving sys info
2024-09-19 10:11:15,458 Latency for request 7934c4bb with model granite-7b: 0.8590 seconds
2024-09-19 10:11:15,459 Saving results with gpu monitoring
2024-09-19 10:11:15,463 127.0.0.1 - - [19/Sep/2024 10:11:15] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:17,306 Saving sys info
2024-09-19 10:11:17,338 Latency for request 2ed1c514 with model granite-7b: 0.8370 seconds
2024-09-19 10:11:17,338 Saving results with gpu monitoring
2024-09-19 10:11:17,342 127.0.0.1 - - [19/Sep/2024 10:11:17] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:19,189 Saving sys info
2024-09-19 10:11:19,224 Latency for request 0276202f with model granite-7b: 0.8410 seconds
2024-09-19 10:11:19,224 Saving results with gpu monitoring
2024-09-19 10:11:19,231 127.0.0.1 - - [19/Sep/2024 10:11:19] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:21,096 Saving sys info
2024-09-19 10:11:21,127 Latency for request e2fa6993 with model granite-7b: 0.8590 seconds
2024-09-19 10:11:21,127 Saving results with gpu monitoring
2024-09-19 10:11:21,134 127.0.0.1 - - [19/Sep/2024 10:11:21] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:22,994 Saving sys info
2024-09-19 10:11:23,025 Latency for request d088edf4 with model granite-7b: 0.8540 seconds
2024-09-19 10:11:23,026 Saving results with gpu monitoring
2024-09-19 10:11:23,030 127.0.0.1 - - [19/Sep/2024 10:11:23] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:24,881 Saving sys info
2024-09-19 10:11:24,912 Latency for request eb04dbc6 with model granite-7b: 0.8450 seconds
2024-09-19 10:11:24,912 Saving results with gpu monitoring
2024-09-19 10:11:24,916 127.0.0.1 - - [19/Sep/2024 10:11:24] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:26,779 Saving sys info
2024-09-19 10:11:26,809 Latency for request e17561b2 with model granite-7b: 0.8560 seconds
2024-09-19 10:11:26,810 Saving results with gpu monitoring
2024-09-19 10:11:26,814 127.0.0.1 - - [19/Sep/2024 10:11:26] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:27,821 127.0.0.1 - - [19/Sep/2024 10:11:27] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:28,686 Saving sys info
2024-09-19 10:11:28,720 Latency for request 4e5677d9 with model granite-7b: 0.8660 seconds
2024-09-19 10:11:28,720 Saving results with gpu monitoring
2024-09-19 10:11:28,722 Latency for request f1501697 with model granite-7b: 0.8640 seconds
2024-09-19 10:11:28,723 Saving results with gpu monitoring
2024-09-19 10:11:28,729 127.0.0.1 - - [19/Sep/2024 10:11:28] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:29,736 127.0.0.1 - - [19/Sep/2024 10:11:29] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:30,616 Saving sys info
2024-09-19 10:11:30,647 Latency for request 6e674f7e with model granite-7b: 0.8810 seconds
2024-09-19 10:11:30,647 Saving results with gpu monitoring
2024-09-19 10:11:30,650 Latency for request 730fffe4 with model granite-7b: 0.8790 seconds
2024-09-19 10:11:30,650 Saving results with gpu monitoring
2024-09-19 10:11:30,654 127.0.0.1 - - [19/Sep/2024 10:11:30] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:31,661 127.0.0.1 - - [19/Sep/2024 10:11:31] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:32,514 Saving sys info
2024-09-19 10:11:32,545 Latency for request e07deef8 with model granite-7b: 0.8530 seconds
2024-09-19 10:11:32,545 Saving results with gpu monitoring
2024-09-19 10:11:32,548 Latency for request f4adcf9d with model granite-7b: 0.8520 seconds
2024-09-19 10:11:32,548 Saving results with gpu monitoring
2024-09-19 10:11:32,555 127.0.0.1 - - [19/Sep/2024 10:11:32] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:33,562 127.0.0.1 - - [19/Sep/2024 10:11:33] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:34,443 Saving sys info
2024-09-19 10:11:34,474 Latency for request 26a38af1 with model granite-7b: 0.8820 seconds
2024-09-19 10:11:34,474 Saving results with gpu monitoring
2024-09-19 10:11:34,476 Latency for request 5d0ed811 with model granite-7b: 0.8800 seconds
2024-09-19 10:11:34,477 Saving results with gpu monitoring
2024-09-19 10:11:34,480 127.0.0.1 - - [19/Sep/2024 10:11:34] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:35,487 127.0.0.1 - - [19/Sep/2024 10:11:35] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:36,372 Saving sys info
2024-09-19 10:11:36,406 Latency for request b8530103 with model granite-7b: 0.8860 seconds
2024-09-19 10:11:36,406 Saving results with gpu monitoring
2024-09-19 10:11:36,409 Latency for request 39020e3a with model granite-7b: 0.8830 seconds
2024-09-19 10:11:36,409 Saving results with gpu monitoring
2024-09-19 10:11:36,415 127.0.0.1 - - [19/Sep/2024 10:11:36] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:37,422 127.0.0.1 - - [19/Sep/2024 10:11:37] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:38,271 Saving sys info
2024-09-19 10:11:38,305 Latency for request 36fc2027 with model granite-7b: 0.8490 seconds
2024-09-19 10:11:38,305 Saving results with gpu monitoring
2024-09-19 10:11:38,308 Latency for request 8b0d40b2 with model granite-7b: 0.8470 seconds
2024-09-19 10:11:38,308 Saving results with gpu monitoring
2024-09-19 10:11:38,312 127.0.0.1 - - [19/Sep/2024 10:11:38] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:39,320 127.0.0.1 - - [19/Sep/2024 10:11:39] "POST /inference HTTP/1.1" 200 -
2024-09-19 10:11:40,168 Saving sys info
2024-09-19 10:11:40,204 Latency for request 5c33134f with model granite-7b: 0.8490 seconds
2024-09-19 10:11:40,204 Saving results with gpu monitoring
2024-09-19 10:11:40,207 Latency for request 5c9bfd17 with model granite-7b: 0.8480 seconds
2024-09-19 10:11:40,207 Saving results with gpu monitoring
2024-09-19 10:11:40,212 127.0.0.1 - - [19/Sep/2024 10:11:40] "POST /inference HTTP/1.1" 200 -
