2024-09-20 12:45:42,825 Using device: cuda
2024-09-20 12:45:42,825 Scheduling mode set as BestBatch+SLA
2024-09-20 12:45:42,828 Monitoring status set to True
2024-09-20 12:45:57,897 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.122.143:5000
2024-09-20 12:45:57,897 [33mPress CTRL+C to quit[0m
2024-09-20 12:45:58,984 Request with ID 69e5de4a for model gemma-7b received
2024-09-20 12:45:58,984 Adjusted batch time limit for gemma-7b: 5.0000 seconds
2024-09-20 12:45:58,984 127.0.0.1 - - [20/Sep/2024 12:45:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:59,136 Request with ID 21ccce27 for model llama3-8b received
2024-09-20 12:45:59,136 Adjusted batch time limit for llama3-8b: 5.0000 seconds
2024-09-20 12:45:59,137 127.0.0.1 - - [20/Sep/2024 12:45:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:59,148 Request with ID bf8650ea for model llama3-8b received
2024-09-20 12:45:59,148 127.0.0.1 - - [20/Sep/2024 12:45:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:59,242 Request with ID 1cb1f818 for model granite-7b received
2024-09-20 12:45:59,243 Adjusted batch time limit for granite-7b: 5.0000 seconds
2024-09-20 12:45:59,243 127.0.0.1 - - [20/Sep/2024 12:45:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:59,596 Request with ID 2159422d for model llama3-8b received
2024-09-20 12:45:59,597 127.0.0.1 - - [20/Sep/2024 12:45:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:59,598 Request with ID a81ee0d0 for model gemma-7b received
2024-09-20 12:45:59,599 127.0.0.1 - - [20/Sep/2024 12:45:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:59,634 Request with ID 9b913c18 for model granite-7b received
2024-09-20 12:45:59,635 127.0.0.1 - - [20/Sep/2024 12:45:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:59,638 Request with ID e5854eab for model llama3-8b received
2024-09-20 12:45:59,638 127.0.0.1 - - [20/Sep/2024 12:45:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:59,656 Request with ID c86c272c for model gemma-7b received
2024-09-20 12:45:59,656 127.0.0.1 - - [20/Sep/2024 12:45:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:45:59,666 Request with ID a4d66b13 for model gemma-7b received
2024-09-20 12:45:59,666 127.0.0.1 - - [20/Sep/2024 12:45:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:00,078 Request with ID a4a8bd8e for model granite-7b received
2024-09-20 12:46:00,078 127.0.0.1 - - [20/Sep/2024 12:46:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:00,173 Request with ID a40e5599 for model llama3-8b received
2024-09-20 12:46:00,173 127.0.0.1 - - [20/Sep/2024 12:46:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:00,175 Request with ID e5c43137 for model llama3-8b received
2024-09-20 12:46:00,175 127.0.0.1 - - [20/Sep/2024 12:46:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:00,342 Request with ID f601e473 for model gemma-7b received
2024-09-20 12:46:00,342 127.0.0.1 - - [20/Sep/2024 12:46:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:00,459 Request with ID 42dc530b for model granite-7b received
2024-09-20 12:46:00,459 127.0.0.1 - - [20/Sep/2024 12:46:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:00,701 Request with ID 7686dd87 for model gemma-7b received
2024-09-20 12:46:00,702 127.0.0.1 - - [20/Sep/2024 12:46:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:00,844 Request with ID 9222ce8c for model llama3-8b received
2024-09-20 12:46:00,845 127.0.0.1 - - [20/Sep/2024 12:46:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:00,925 Request with ID a4446bda for model llama3-8b received
2024-09-20 12:46:00,926 127.0.0.1 - - [20/Sep/2024 12:46:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:01,076 Request with ID a415a370 for model gemma-7b received
2024-09-20 12:46:01,076 127.0.0.1 - - [20/Sep/2024 12:46:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:01,339 Request with ID f5774f0d for model gemma-7b received
2024-09-20 12:46:01,339 127.0.0.1 - - [20/Sep/2024 12:46:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:01,425 Request with ID 11579f33 for model granite-7b received
2024-09-20 12:46:01,425 127.0.0.1 - - [20/Sep/2024 12:46:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:01,467 Request with ID 06f21d00 for model llama3-8b received
2024-09-20 12:46:01,468 127.0.0.1 - - [20/Sep/2024 12:46:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:01,557 Request with ID c70a1602 for model llama3-8b received
2024-09-20 12:46:01,558 127.0.0.1 - - [20/Sep/2024 12:46:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:01,590 Request with ID 4b20458a for model llama3-8b received
2024-09-20 12:46:01,591 127.0.0.1 - - [20/Sep/2024 12:46:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:01,599 Request with ID e8279a7e for model gemma-7b received
2024-09-20 12:46:01,599 127.0.0.1 - - [20/Sep/2024 12:46:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:01,636 Request with ID 427691f0 for model gemma-7b received
2024-09-20 12:46:01,636 127.0.0.1 - - [20/Sep/2024 12:46:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:01,762 Request with ID 9a94871b for model llama3-8b received
2024-09-20 12:46:01,763 127.0.0.1 - - [20/Sep/2024 12:46:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:01,769 Request with ID 0af95e52 for model llama3-8b received
2024-09-20 12:46:01,770 127.0.0.1 - - [20/Sep/2024 12:46:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:01,962 Request with ID 17a80fd6 for model gemma-7b received
2024-09-20 12:46:01,963 127.0.0.1 - - [20/Sep/2024 12:46:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:01,968 Request with ID 056ac3ac for model llama3-8b received
2024-09-20 12:46:01,969 127.0.0.1 - - [20/Sep/2024 12:46:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:02,061 Request with ID bcd34b59 for model llama3-8b received
2024-09-20 12:46:02,062 127.0.0.1 - - [20/Sep/2024 12:46:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:02,075 Request with ID 9992b408 for model llama3-8b received
2024-09-20 12:46:02,075 127.0.0.1 - - [20/Sep/2024 12:46:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:02,205 Request with ID 8114773d for model llama3-8b received
2024-09-20 12:46:02,206 127.0.0.1 - - [20/Sep/2024 12:46:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:02,275 Request with ID 04f3d4e9 for model llama3-8b received
2024-09-20 12:46:02,276 127.0.0.1 - - [20/Sep/2024 12:46:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:02,289 Request with ID 7306a43a for model gemma-7b received
2024-09-20 12:46:02,290 127.0.0.1 - - [20/Sep/2024 12:46:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:02,517 Request with ID 600e83a3 for model llama3-8b received
2024-09-20 12:46:02,517 127.0.0.1 - - [20/Sep/2024 12:46:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:02,638 Request with ID 74374eab for model llama3-8b received
2024-09-20 12:46:02,638 127.0.0.1 - - [20/Sep/2024 12:46:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:02,665 Request with ID caffafa8 for model llama3-8b received
2024-09-20 12:46:02,666 127.0.0.1 - - [20/Sep/2024 12:46:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:02,786 Request with ID 65961a15 for model llama3-8b received
2024-09-20 12:46:02,787 127.0.0.1 - - [20/Sep/2024 12:46:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:02,953 Request with ID 1ab43ba6 for model llama3-8b received
2024-09-20 12:46:02,954 127.0.0.1 - - [20/Sep/2024 12:46:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:02,974 Request with ID 96f1040a for model llama3-8b received
2024-09-20 12:46:02,975 127.0.0.1 - - [20/Sep/2024 12:46:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:03,141 Request with ID 4bbfc5d4 for model gemma-7b received
2024-09-20 12:46:03,142 127.0.0.1 - - [20/Sep/2024 12:46:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:03,154 Request with ID 37357b39 for model llama3-8b received
2024-09-20 12:46:03,155 Request with ID 17860dd8 for model llama3-8b received
2024-09-20 12:46:03,155 127.0.0.1 - - [20/Sep/2024 12:46:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:03,156 127.0.0.1 - - [20/Sep/2024 12:46:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:03,156 Request with ID 3db5b46e for model llama3-8b received
2024-09-20 12:46:03,157 127.0.0.1 - - [20/Sep/2024 12:46:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:03,224 Request with ID 1e6348b7 for model gemma-7b received
2024-09-20 12:46:03,224 127.0.0.1 - - [20/Sep/2024 12:46:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:03,512 Request with ID bd756482 for model llama3-8b received
2024-09-20 12:46:03,512 127.0.0.1 - - [20/Sep/2024 12:46:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:03,564 Request with ID 79e729c6 for model llama3-8b received
2024-09-20 12:46:03,564 127.0.0.1 - - [20/Sep/2024 12:46:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:03,894 Request with ID 8afb6a65 for model gemma-7b received
2024-09-20 12:46:03,895 127.0.0.1 - - [20/Sep/2024 12:46:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:03,897 Request with ID 63442d8f for model llama3-8b received
2024-09-20 12:46:03,897 127.0.0.1 - - [20/Sep/2024 12:46:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:03,952 Request with ID 822f1712 for model gemma-7b received
2024-09-20 12:46:03,953 127.0.0.1 - - [20/Sep/2024 12:46:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:04,044 Processing batch for gemma-7b due to time limit with batch size 16
2024-09-20 12:46:04,044 Time limit condition met for model gemma-7b
2024-09-20 12:46:04,045 Next: call load_model for gemma-7b
2024-09-20 12:46:04,559 Request with ID 6e748803 for model gemma-7b received
2024-09-20 12:46:04,561 127.0.0.1 - - [20/Sep/2024 12:46:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:04,564 Request with ID 012fe6cd for model llama3-8b received
2024-09-20 12:46:04,566 127.0.0.1 - - [20/Sep/2024 12:46:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:04,569 Request with ID a90645dc for model gemma-7b received
2024-09-20 12:46:04,570 127.0.0.1 - - [20/Sep/2024 12:46:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:04,572 Request with ID 2d62ebd9 for model gemma-7b received
2024-09-20 12:46:04,572 127.0.0.1 - - [20/Sep/2024 12:46:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:04,574 Request with ID 7819672e for model gemma-7b received
2024-09-20 12:46:04,574 127.0.0.1 - - [20/Sep/2024 12:46:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:04,718 Request with ID 8b2c98fa for model gemma-7b received
2024-09-20 12:46:04,719 127.0.0.1 - - [20/Sep/2024 12:46:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:04,793 Request with ID 0d1011fa for model llama3-8b received
2024-09-20 12:46:04,802 127.0.0.1 - - [20/Sep/2024 12:46:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:04,916 Request with ID b1b5e6be for model llama3-8b received
2024-09-20 12:46:04,916 127.0.0.1 - - [20/Sep/2024 12:46:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:04,929 Request with ID 2c84293b for model gemma-7b received
2024-09-20 12:46:04,932 127.0.0.1 - - [20/Sep/2024 12:46:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:04,993 Request with ID b51b18b6 for model llama3-8b received
2024-09-20 12:46:04,997 127.0.0.1 - - [20/Sep/2024 12:46:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:05,178 Request with ID a611a1b0 for model gemma-7b received
2024-09-20 12:46:05,182 127.0.0.1 - - [20/Sep/2024 12:46:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:05,191 Request with ID 5aa13db4 for model llama3-8b received
2024-09-20 12:46:05,192 127.0.0.1 - - [20/Sep/2024 12:46:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:05,220 Request with ID ddb9a9b0 for model gemma-7b received
2024-09-20 12:46:05,221 127.0.0.1 - - [20/Sep/2024 12:46:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:05,629 Request with ID 608b9c09 for model gemma-7b received
2024-09-20 12:46:05,630 127.0.0.1 - - [20/Sep/2024 12:46:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:05,636 Request with ID 8aa7194f for model llama3-8b received
2024-09-20 12:46:05,637 127.0.0.1 - - [20/Sep/2024 12:46:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:05,774 Request with ID 8c3c1f93 for model gemma-7b received
2024-09-20 12:46:05,774 127.0.0.1 - - [20/Sep/2024 12:46:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:05,862 Request with ID 6c242515 for model llama3-8b received
2024-09-20 12:46:05,862 127.0.0.1 - - [20/Sep/2024 12:46:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:05,908 Request with ID 6be48310 for model llama3-8b received
2024-09-20 12:46:05,909 127.0.0.1 - - [20/Sep/2024 12:46:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:05,918 Request with ID b3ff5b43 for model llama3-8b received
2024-09-20 12:46:05,918 127.0.0.1 - - [20/Sep/2024 12:46:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:06,015 Request with ID c166cdf6 for model gemma-7b received
2024-09-20 12:46:06,015 Request with ID 730a6242 for model llama3-8b received
2024-09-20 12:46:06,016 127.0.0.1 - - [20/Sep/2024 12:46:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:06,016 127.0.0.1 - - [20/Sep/2024 12:46:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:06,083 Request with ID 2c343b41 for model gemma-7b received
2024-09-20 12:46:06,083 127.0.0.1 - - [20/Sep/2024 12:46:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:06,209 Request with ID 257a369f for model gemma-7b received
2024-09-20 12:46:06,209 127.0.0.1 - - [20/Sep/2024 12:46:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:06,352 Request with ID 72e2ab60 for model llama3-8b received
2024-09-20 12:46:06,353 127.0.0.1 - - [20/Sep/2024 12:46:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:06,479 Request with ID 6f4565b4 for model llama3-8b received
2024-09-20 12:46:06,479 127.0.0.1 - - [20/Sep/2024 12:46:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:06,490 Request with ID a4dbc443 for model gemma-7b received
2024-09-20 12:46:06,492 127.0.0.1 - - [20/Sep/2024 12:46:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:06,519 Request with ID 340dc743 for model llama3-8b received
2024-09-20 12:46:06,520 127.0.0.1 - - [20/Sep/2024 12:46:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:06,587 Request with ID ad0d6651 for model llama3-8b received
2024-09-20 12:46:06,587 127.0.0.1 - - [20/Sep/2024 12:46:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:06,747 Request with ID 82784d7d for model llama3-8b received
2024-09-20 12:46:06,748 127.0.0.1 - - [20/Sep/2024 12:46:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:06,859 Request with ID c7c7004e for model gemma-7b received
2024-09-20 12:46:06,860 127.0.0.1 - - [20/Sep/2024 12:46:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:06,990 Request with ID 795e255b for model llama3-8b received
2024-09-20 12:46:06,991 127.0.0.1 - - [20/Sep/2024 12:46:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:07,139 Request with ID 846fa745 for model llama3-8b received
2024-09-20 12:46:07,139 127.0.0.1 - - [20/Sep/2024 12:46:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:07,204 Request with ID 9263d3f2 for model llama3-8b received
2024-09-20 12:46:07,204 127.0.0.1 - - [20/Sep/2024 12:46:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:07,252 Request with ID b612d9e1 for model llama3-8b received
2024-09-20 12:46:07,253 127.0.0.1 - - [20/Sep/2024 12:46:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:07,294 Request with ID 09ce5e3d for model llama3-8b received
2024-09-20 12:46:07,295 127.0.0.1 - - [20/Sep/2024 12:46:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:07,626 Request with ID 8776e8b3 for model granite-7b received
2024-09-20 12:46:07,626 127.0.0.1 - - [20/Sep/2024 12:46:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:07,664 Request with ID c51f4345 for model gemma-7b received
2024-09-20 12:46:07,664 127.0.0.1 - - [20/Sep/2024 12:46:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:07,731 Request with ID 5c1a5287 for model llama3-8b received
2024-09-20 12:46:07,732 127.0.0.1 - - [20/Sep/2024 12:46:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:08,008 Request with ID 6827f716 for model llama3-8b received
2024-09-20 12:46:08,009 127.0.0.1 - - [20/Sep/2024 12:46:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:08,016 Request with ID 2c641b79 for model llama3-8b received
2024-09-20 12:46:08,016 127.0.0.1 - - [20/Sep/2024 12:46:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:08,480 Request with ID ce20fff9 for model gemma-7b received
2024-09-20 12:46:08,481 127.0.0.1 - - [20/Sep/2024 12:46:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:08,520 Request with ID 0d5b46fa for model gemma-7b received
2024-09-20 12:46:08,521 127.0.0.1 - - [20/Sep/2024 12:46:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:08,557 Request with ID 060a6450 for model llama3-8b received
2024-09-20 12:46:08,558 127.0.0.1 - - [20/Sep/2024 12:46:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:08,762 Request with ID 004bafec for model llama3-8b received
2024-09-20 12:46:08,762 Request with ID e7f4a880 for model granite-7b received
2024-09-20 12:46:08,763 127.0.0.1 - - [20/Sep/2024 12:46:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:08,764 127.0.0.1 - - [20/Sep/2024 12:46:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:08,868 Request with ID fb1d39f3 for model granite-7b received
2024-09-20 12:46:08,869 127.0.0.1 - - [20/Sep/2024 12:46:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,087 Request with ID 721d874a for model gemma-7b received
2024-09-20 12:46:09,088 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,098 Request with ID 6d4783d5 for model granite-7b received
2024-09-20 12:46:09,099 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,164 Request with ID 622e1b86 for model llama3-8b received
2024-09-20 12:46:09,165 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,350 Request with ID 90d4046a for model granite-7b received
2024-09-20 12:46:09,350 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,386 Request with ID 92cc8ae0 for model gemma-7b received
2024-09-20 12:46:09,387 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,485 Request with ID 25e2be0b for model llama3-8b received
2024-09-20 12:46:09,486 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,509 Request with ID 7fd598c5 for model llama3-8b received
2024-09-20 12:46:09,510 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,523 Request with ID 1b8800af for model llama3-8b received
2024-09-20 12:46:09,524 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,651 Request with ID 2ca4dd1e for model llama3-8b received
2024-09-20 12:46:09,652 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,683 Request with ID 90690dbb for model granite-7b received
2024-09-20 12:46:09,684 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,686 Request with ID b17182f7 for model granite-7b received
2024-09-20 12:46:09,686 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,744 Request with ID 9a8736e1 for model llama3-8b received
2024-09-20 12:46:09,745 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,765 Request with ID 1e5c0677 for model llama3-8b received
2024-09-20 12:46:09,766 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,793 Request with ID d5830bf9 for model llama3-8b received
2024-09-20 12:46:09,794 127.0.0.1 - - [20/Sep/2024 12:46:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:09,905 Request with ID dd3e1891 for model llama3-8b received
2024-09-20 12:46:09,905 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:46:09,906 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:46:10,040 Request with ID 15ff5d83 for model llama3-8b received
2024-09-20 12:46:10,040 127.0.0.1 - - [20/Sep/2024 12:46:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:10,277 Request with ID 36150dc7 for model gemma-7b received
2024-09-20 12:46:10,278 127.0.0.1 - - [20/Sep/2024 12:46:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:10,314 Request with ID 73b4f8b5 for model granite-7b received
2024-09-20 12:46:10,315 127.0.0.1 - - [20/Sep/2024 12:46:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:10,319 Request with ID 54fef24f for model llama3-8b received
2024-09-20 12:46:10,319 127.0.0.1 - - [20/Sep/2024 12:46:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:10,340 Request with ID c9f8aca9 for model gemma-7b received
2024-09-20 12:46:10,340 127.0.0.1 - - [20/Sep/2024 12:46:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:10,405 Request with ID 7bb74316 for model gemma-7b received
2024-09-20 12:46:10,406 127.0.0.1 - - [20/Sep/2024 12:46:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:10,503 Request with ID 4f4c2131 for model llama3-8b received
2024-09-20 12:46:10,504 127.0.0.1 - - [20/Sep/2024 12:46:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:10,613 Request with ID 3347f64e for model llama3-8b received
2024-09-20 12:46:10,614 127.0.0.1 - - [20/Sep/2024 12:46:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:10,904 Request with ID beb9ae67 for model llama3-8b received
2024-09-20 12:46:10,904 127.0.0.1 - - [20/Sep/2024 12:46:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,006 Request with ID 6385c802 for model llama3-8b received
2024-09-20 12:46:11,006 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,057 Request with ID 53e2e26a for model llama3-8b received
2024-09-20 12:46:11,057 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,137 Request with ID c1cc4f66 for model llama3-8b received
2024-09-20 12:46:11,138 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,311 Request with ID 79e02c3c for model llama3-8b received
2024-09-20 12:46:11,312 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,334 Request with ID 06bf1265 for model gemma-7b received
2024-09-20 12:46:11,335 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,336 Request with ID 5d8eee18 for model llama3-8b received
2024-09-20 12:46:11,337 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,346 Request with ID 19e738c0 for model gemma-7b received
2024-09-20 12:46:11,346 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,462 Request with ID 074b2e33 for model gemma-7b received
2024-09-20 12:46:11,462 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,533 Request with ID 85eca884 for model llama3-8b received
2024-09-20 12:46:11,533 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,633 Request with ID 4efc169b for model granite-7b received
2024-09-20 12:46:11,633 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,688 Request with ID 05f05d47 for model gemma-7b received
2024-09-20 12:46:11,689 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,829 Request with ID 6148aa6a for model llama3-8b received
2024-09-20 12:46:11,830 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:11,877 Request with ID 98684439 for model gemma-7b received
2024-09-20 12:46:11,878 127.0.0.1 - - [20/Sep/2024 12:46:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:12,146 Request with ID a69e070e for model gemma-7b received
2024-09-20 12:46:12,147 127.0.0.1 - - [20/Sep/2024 12:46:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:12,262 Request with ID ac8a6af5 for model gemma-7b received
2024-09-20 12:46:12,262 127.0.0.1 - - [20/Sep/2024 12:46:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:12,341 Request with ID 27e8c1f4 for model llama3-8b received
2024-09-20 12:46:12,342 127.0.0.1 - - [20/Sep/2024 12:46:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:12,379 Request with ID e05200b5 for model granite-7b received
2024-09-20 12:46:12,380 127.0.0.1 - - [20/Sep/2024 12:46:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:12,386 Request with ID 8cde71a2 for model gemma-7b received
2024-09-20 12:46:12,386 127.0.0.1 - - [20/Sep/2024 12:46:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:12,703 Request with ID 8e6b1290 for model llama3-8b received
2024-09-20 12:46:12,703 127.0.0.1 - - [20/Sep/2024 12:46:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:12,711 Request with ID 3da04b21 for model gemma-7b received
2024-09-20 12:46:12,712 127.0.0.1 - - [20/Sep/2024 12:46:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:12,826 Request with ID 6e3e6e40 for model llama3-8b received
2024-09-20 12:46:12,827 127.0.0.1 - - [20/Sep/2024 12:46:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:12,835 Request with ID b74aebb4 for model llama3-8b received
2024-09-20 12:46:12,836 127.0.0.1 - - [20/Sep/2024 12:46:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:13,550 Request with ID e7281442 for model llama3-8b received
2024-09-20 12:46:13,551 127.0.0.1 - - [20/Sep/2024 12:46:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:13,610 Request with ID e95c801b for model llama3-8b received
2024-09-20 12:46:13,610 127.0.0.1 - - [20/Sep/2024 12:46:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:13,958 Request with ID c04a40b8 for model llama3-8b received
2024-09-20 12:46:13,959 127.0.0.1 - - [20/Sep/2024 12:46:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:13,968 Request with ID e3245979 for model llama3-8b received
2024-09-20 12:46:13,969 127.0.0.1 - - [20/Sep/2024 12:46:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:13,995 Request with ID ec729a92 for model llama3-8b received
2024-09-20 12:46:13,995 127.0.0.1 - - [20/Sep/2024 12:46:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:14,120 Request with ID c44682d5 for model llama3-8b received
2024-09-20 12:46:14,120 127.0.0.1 - - [20/Sep/2024 12:46:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:14,147 Request with ID b3521bba for model llama3-8b received
2024-09-20 12:46:14,148 127.0.0.1 - - [20/Sep/2024 12:46:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:14,361 Request with ID 9b57c974 for model llama3-8b received
2024-09-20 12:46:14,362 127.0.0.1 - - [20/Sep/2024 12:46:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:14,790 Request with ID 996e70d4 for model gemma-7b received
2024-09-20 12:46:14,790 127.0.0.1 - - [20/Sep/2024 12:46:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:14,915 Request with ID 5a3543ac for model llama3-8b received
2024-09-20 12:46:14,916 127.0.0.1 - - [20/Sep/2024 12:46:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:14,998 Request with ID f902306e for model gemma-7b received
2024-09-20 12:46:14,999 127.0.0.1 - - [20/Sep/2024 12:46:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:15,040 Request with ID f712be50 for model granite-7b received
2024-09-20 12:46:15,041 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:46:15,041 Dynamic batch size condition met for model granite-7b
2024-09-20 12:46:15,104 Request with ID 871e5fae for model llama3-8b received
2024-09-20 12:46:15,104 127.0.0.1 - - [20/Sep/2024 12:46:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:15,253 Request with ID d1344a89 for model llama3-8b received
2024-09-20 12:46:15,254 127.0.0.1 - - [20/Sep/2024 12:46:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:15,392 Request with ID fb7fc9eb for model gemma-7b received
2024-09-20 12:46:15,393 127.0.0.1 - - [20/Sep/2024 12:46:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:15,444 Request with ID 0f79f064 for model gemma-7b received
2024-09-20 12:46:15,444 127.0.0.1 - - [20/Sep/2024 12:46:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:15,649 Request with ID e240a508 for model llama3-8b received
2024-09-20 12:46:15,650 127.0.0.1 - - [20/Sep/2024 12:46:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:15,812 Request with ID 02d8603f for model llama3-8b received
2024-09-20 12:46:15,813 127.0.0.1 - - [20/Sep/2024 12:46:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:15,817 Request with ID b4ebc9f8 for model granite-7b received
2024-09-20 12:46:15,818 127.0.0.1 - - [20/Sep/2024 12:46:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:16,078 Request with ID b2737d3c for model gemma-7b received
2024-09-20 12:46:16,079 127.0.0.1 - - [20/Sep/2024 12:46:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:16,200 Request with ID 1035cef9 for model llama3-8b received
2024-09-20 12:46:16,201 127.0.0.1 - - [20/Sep/2024 12:46:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:16,321 Request with ID 8d87486d for model llama3-8b received
2024-09-20 12:46:16,321 127.0.0.1 - - [20/Sep/2024 12:46:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:16,369 Request with ID 5f2aec91 for model granite-7b received
2024-09-20 12:46:16,370 127.0.0.1 - - [20/Sep/2024 12:46:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:16,403 Request with ID 2c6244b3 for model gemma-7b received
2024-09-20 12:46:16,403 127.0.0.1 - - [20/Sep/2024 12:46:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:16,415 Request with ID f6eccea2 for model gemma-7b received
2024-09-20 12:46:16,416 127.0.0.1 - - [20/Sep/2024 12:46:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:16,440 Request with ID c281fbc0 for model gemma-7b received
2024-09-20 12:46:16,441 127.0.0.1 - - [20/Sep/2024 12:46:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:16,466 Request with ID 41c89de2 for model granite-7b received
2024-09-20 12:46:16,467 127.0.0.1 - - [20/Sep/2024 12:46:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:16,835 Request with ID 14ebb557 for model llama3-8b received
2024-09-20 12:46:16,836 127.0.0.1 - - [20/Sep/2024 12:46:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,009 Request with ID 4eb0f9de for model llama3-8b received
2024-09-20 12:46:17,010 Request with ID 43a23189 for model gemma-7b received
2024-09-20 12:46:17,011 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,012 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,014 Request with ID 1d512954 for model llama3-8b received
2024-09-20 12:46:17,015 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,146 Request with ID 1ea9e3c5 for model llama3-8b received
2024-09-20 12:46:17,147 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,155 Request with ID 88dad7e3 for model llama3-8b received
2024-09-20 12:46:17,156 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,162 Request with ID 8683c43e for model gemma-7b received
2024-09-20 12:46:17,162 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,330 Request with ID e56f3441 for model llama3-8b received
2024-09-20 12:46:17,331 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,379 Request with ID ad39065c for model gemma-7b received
2024-09-20 12:46:17,379 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,559 Request with ID d4e59939 for model llama3-8b received
2024-09-20 12:46:17,560 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,624 Request with ID a652e4bd for model gemma-7b received
2024-09-20 12:46:17,625 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,630 Request with ID dc7790ad for model llama3-8b received
2024-09-20 12:46:17,630 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,710 Request with ID e3cfd386 for model llama3-8b received
2024-09-20 12:46:17,711 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,793 Request with ID c27c2e44 for model llama3-8b received
2024-09-20 12:46:17,794 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,821 Request with ID f40bf953 for model gemma-7b received
2024-09-20 12:46:17,821 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,855 Request with ID cceaf44d for model llama3-8b received
2024-09-20 12:46:17,856 127.0.0.1 - - [20/Sep/2024 12:46:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:17,999 Request with ID 2864a1de for model gemma-7b received
2024-09-20 12:46:18,000 127.0.0.1 - - [20/Sep/2024 12:46:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:18,013 Request with ID b464b5e3 for model llama3-8b received
2024-09-20 12:46:18,013 127.0.0.1 - - [20/Sep/2024 12:46:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:18,163 Request with ID 8453a484 for model llama3-8b received
2024-09-20 12:46:18,164 127.0.0.1 - - [20/Sep/2024 12:46:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:18,510 Request with ID 04733fcc for model llama3-8b received
2024-09-20 12:46:18,511 127.0.0.1 - - [20/Sep/2024 12:46:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:18,525 Request with ID e6454a83 for model llama3-8b received
2024-09-20 12:46:18,526 127.0.0.1 - - [20/Sep/2024 12:46:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:18,649 Request with ID bb5513c4 for model llama3-8b received
2024-09-20 12:46:18,649 127.0.0.1 - - [20/Sep/2024 12:46:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:18,747 Request with ID 46a98592 for model llama3-8b received
2024-09-20 12:46:18,748 127.0.0.1 - - [20/Sep/2024 12:46:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:18,797 Request with ID 76a3a789 for model llama3-8b received
2024-09-20 12:46:18,797 127.0.0.1 - - [20/Sep/2024 12:46:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:18,877 Request with ID d225d061 for model gemma-7b received
2024-09-20 12:46:18,878 127.0.0.1 - - [20/Sep/2024 12:46:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:18,977 Request with ID 5811fc02 for model llama3-8b received
2024-09-20 12:46:18,978 127.0.0.1 - - [20/Sep/2024 12:46:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:18,993 Request with ID 728fa81a for model llama3-8b received
2024-09-20 12:46:18,994 127.0.0.1 - - [20/Sep/2024 12:46:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,001 Request with ID 6e080465 for model llama3-8b received
2024-09-20 12:46:19,001 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,072 Request with ID 336f55f1 for model gemma-7b received
2024-09-20 12:46:19,073 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,160 Request with ID 53bb7128 for model llama3-8b received
2024-09-20 12:46:19,160 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,224 Request with ID 15bad5ca for model llama3-8b received
2024-09-20 12:46:19,225 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,344 Request with ID 41080952 for model gemma-7b received
2024-09-20 12:46:19,345 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,387 Request with ID c2dd829c for model llama3-8b received
2024-09-20 12:46:19,388 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,500 Request with ID 34e333cd for model llama3-8b received
2024-09-20 12:46:19,501 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,526 Request with ID 27bb9e98 for model gemma-7b received
2024-09-20 12:46:19,527 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,571 Request with ID e6297bfe for model llama3-8b received
2024-09-20 12:46:19,572 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,649 Request with ID c4d0a86f for model gemma-7b received
2024-09-20 12:46:19,650 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,696 Request with ID 8859cab2 for model gemma-7b received
2024-09-20 12:46:19,696 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,735 Request with ID e968918d for model llama3-8b received
2024-09-20 12:46:19,736 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,744 Request with ID 5fa0a921 for model llama3-8b received
2024-09-20 12:46:19,744 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,751 Request with ID f771ac59 for model llama3-8b received
2024-09-20 12:46:19,752 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,761 Request with ID 888c12d2 for model gemma-7b received
2024-09-20 12:46:19,761 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,786 Request with ID 911f6be6 for model llama3-8b received
2024-09-20 12:46:19,787 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,814 Request with ID fa442cd5 for model gemma-7b received
2024-09-20 12:46:19,814 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,879 Request with ID 4a030a49 for model granite-7b received
2024-09-20 12:46:19,880 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:19,895 Request with ID 73039c12 for model llama3-8b received
2024-09-20 12:46:19,896 127.0.0.1 - - [20/Sep/2024 12:46:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:20,124 Request with ID 9dc06746 for model granite-7b received
2024-09-20 12:46:20,124 127.0.0.1 - - [20/Sep/2024 12:46:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:20,327 Request with ID ea808128 for model gemma-7b received
2024-09-20 12:46:20,328 127.0.0.1 - - [20/Sep/2024 12:46:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:20,359 Request with ID 0fcc6a33 for model gemma-7b received
2024-09-20 12:46:20,360 127.0.0.1 - - [20/Sep/2024 12:46:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:20,444 Request with ID 749b225f for model gemma-7b received
2024-09-20 12:46:20,445 127.0.0.1 - - [20/Sep/2024 12:46:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:20,484 Request with ID 2a084aae for model llama3-8b received
2024-09-20 12:46:20,485 127.0.0.1 - - [20/Sep/2024 12:46:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:20,578 Request with ID 2a9a69c5 for model gemma-7b received
2024-09-20 12:46:20,578 127.0.0.1 - - [20/Sep/2024 12:46:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:20,683 Request with ID ff864cd0 for model granite-7b received
2024-09-20 12:46:20,684 127.0.0.1 - - [20/Sep/2024 12:46:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:20,762 Request with ID dcb56ca8 for model llama3-8b received
2024-09-20 12:46:20,762 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:46:20,762 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:46:20,853 Request with ID 75a636d7 for model llama3-8b received
2024-09-20 12:46:20,853 127.0.0.1 - - [20/Sep/2024 12:46:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:20,948 Request with ID 17fcf92e for model llama3-8b received
2024-09-20 12:46:20,949 127.0.0.1 - - [20/Sep/2024 12:46:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:21,171 Request with ID 6c5cb1b9 for model granite-7b received
2024-09-20 12:46:21,172 127.0.0.1 - - [20/Sep/2024 12:46:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:21,174 Request with ID f95123a8 for model gemma-7b received
2024-09-20 12:46:21,175 127.0.0.1 - - [20/Sep/2024 12:46:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:21,176 Request with ID 7e911acb for model granite-7b received
2024-09-20 12:46:21,177 127.0.0.1 - - [20/Sep/2024 12:46:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:21,222 Request with ID b5cd9470 for model granite-7b received
2024-09-20 12:46:21,222 127.0.0.1 - - [20/Sep/2024 12:46:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:21,343 Request with ID 7c86e964 for model gemma-7b received
2024-09-20 12:46:21,343 127.0.0.1 - - [20/Sep/2024 12:46:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:21,395 Request with ID ab714917 for model llama3-8b received
2024-09-20 12:46:21,396 127.0.0.1 - - [20/Sep/2024 12:46:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:21,397 Request with ID ee43bb60 for model gemma-7b received
2024-09-20 12:46:21,397 127.0.0.1 - - [20/Sep/2024 12:46:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:21,416 Request with ID 1c4df185 for model llama3-8b received
2024-09-20 12:46:21,416 127.0.0.1 - - [20/Sep/2024 12:46:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:21,545 Request with ID ff811648 for model llama3-8b received
2024-09-20 12:46:21,545 127.0.0.1 - - [20/Sep/2024 12:46:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:21,729 Request with ID ebe209ba for model gemma-7b received
2024-09-20 12:46:21,730 127.0.0.1 - - [20/Sep/2024 12:46:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:21,769 Request with ID 25738126 for model gemma-7b received
2024-09-20 12:46:21,770 127.0.0.1 - - [20/Sep/2024 12:46:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:21,904 Request with ID f4d7e394 for model llama3-8b received
2024-09-20 12:46:21,905 127.0.0.1 - - [20/Sep/2024 12:46:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:22,052 Request with ID dba166d1 for model llama3-8b received
2024-09-20 12:46:22,053 127.0.0.1 - - [20/Sep/2024 12:46:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:22,070 Request with ID 03193550 for model llama3-8b received
2024-09-20 12:46:22,071 127.0.0.1 - - [20/Sep/2024 12:46:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:22,118 Request with ID 52af7b49 for model gemma-7b received
2024-09-20 12:46:22,118 Moving batch for gemma-7b from incoming to running due to dynamic batch size 64
2024-09-20 12:46:22,118 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:46:22,125 Request with ID 175a3bb3 for model llama3-8b received
2024-09-20 12:46:22,126 127.0.0.1 - - [20/Sep/2024 12:46:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:22,135 Request with ID 057f9592 for model llama3-8b received
2024-09-20 12:46:22,136 127.0.0.1 - - [20/Sep/2024 12:46:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:22,280 Request with ID 996e322d for model llama3-8b received
2024-09-20 12:46:22,281 127.0.0.1 - - [20/Sep/2024 12:46:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:22,375 Request with ID 1d3a4b09 for model llama3-8b received
2024-09-20 12:46:22,375 127.0.0.1 - - [20/Sep/2024 12:46:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:22,554 Request with ID 57bcc79e for model llama3-8b received
2024-09-20 12:46:22,555 127.0.0.1 - - [20/Sep/2024 12:46:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:22,827 Request with ID 87f7a975 for model gemma-7b received
2024-09-20 12:46:22,828 127.0.0.1 - - [20/Sep/2024 12:46:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:22,877 Request with ID 5a533503 for model llama3-8b received
2024-09-20 12:46:22,877 127.0.0.1 - - [20/Sep/2024 12:46:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:22,882 Request with ID b5cd4006 for model gemma-7b received
2024-09-20 12:46:22,883 127.0.0.1 - - [20/Sep/2024 12:46:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:23,043 Request with ID 28b92aae for model gemma-7b received
2024-09-20 12:46:23,044 127.0.0.1 - - [20/Sep/2024 12:46:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:23,062 Request with ID 582e1ad8 for model gemma-7b received
2024-09-20 12:46:23,062 127.0.0.1 - - [20/Sep/2024 12:46:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:23,164 Request with ID 25677502 for model gemma-7b received
2024-09-20 12:46:23,164 127.0.0.1 - - [20/Sep/2024 12:46:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:23,254 Request with ID 0521b7dc for model llama3-8b received
2024-09-20 12:46:23,254 127.0.0.1 - - [20/Sep/2024 12:46:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:23,302 Request with ID a65f96d4 for model llama3-8b received
2024-09-20 12:46:23,302 127.0.0.1 - - [20/Sep/2024 12:46:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:23,375 Request with ID 4f5f54fe for model gemma-7b received
2024-09-20 12:46:23,375 127.0.0.1 - - [20/Sep/2024 12:46:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:23,453 Request with ID 7bd928a4 for model llama3-8b received
2024-09-20 12:46:23,453 127.0.0.1 - - [20/Sep/2024 12:46:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:23,553 Request with ID cb4c5754 for model llama3-8b received
2024-09-20 12:46:23,553 127.0.0.1 - - [20/Sep/2024 12:46:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:23,594 Request with ID d7861f70 for model gemma-7b received
2024-09-20 12:46:23,594 127.0.0.1 - - [20/Sep/2024 12:46:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:23,609 Request with ID 2c5528ec for model llama3-8b received
2024-09-20 12:46:23,609 127.0.0.1 - - [20/Sep/2024 12:46:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:23,687 Request with ID c41bba7c for model llama3-8b received
2024-09-20 12:46:23,688 127.0.0.1 - - [20/Sep/2024 12:46:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:24,449 Request with ID 55416403 for model llama3-8b received
2024-09-20 12:46:24,449 127.0.0.1 - - [20/Sep/2024 12:46:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:24,451 Request with ID 033f1d5b for model gemma-7b received
2024-09-20 12:46:24,452 127.0.0.1 - - [20/Sep/2024 12:46:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:24,576 Request with ID be7e24b9 for model llama3-8b received
2024-09-20 12:46:24,576 127.0.0.1 - - [20/Sep/2024 12:46:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:24,618 Request with ID 110a05bd for model gemma-7b received
2024-09-20 12:46:24,619 127.0.0.1 - - [20/Sep/2024 12:46:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:24,808 Request with ID 99811dca for model llama3-8b received
2024-09-20 12:46:24,809 127.0.0.1 - - [20/Sep/2024 12:46:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:24,826 Request with ID 67bcab1d for model llama3-8b received
2024-09-20 12:46:24,826 127.0.0.1 - - [20/Sep/2024 12:46:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:24,976 Request with ID abcf5868 for model llama3-8b received
2024-09-20 12:46:24,977 127.0.0.1 - - [20/Sep/2024 12:46:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:25,061 Request with ID 2a6e879a for model gemma-7b received
2024-09-20 12:46:25,062 127.0.0.1 - - [20/Sep/2024 12:46:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:25,104 Request with ID a61a7342 for model llama3-8b received
2024-09-20 12:46:25,105 127.0.0.1 - - [20/Sep/2024 12:46:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:25,147 Request with ID c5d5fa84 for model llama3-8b received
2024-09-20 12:46:25,148 127.0.0.1 - - [20/Sep/2024 12:46:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:25,182 Request with ID 6ab08b98 for model gemma-7b received
2024-09-20 12:46:25,183 127.0.0.1 - - [20/Sep/2024 12:46:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:25,273 Request with ID 6dcbef3d for model gemma-7b received
2024-09-20 12:46:25,273 127.0.0.1 - - [20/Sep/2024 12:46:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:25,404 Request with ID c729d5c3 for model llama3-8b received
2024-09-20 12:46:25,404 127.0.0.1 - - [20/Sep/2024 12:46:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:25,562 Request with ID db009575 for model llama3-8b received
2024-09-20 12:46:25,563 127.0.0.1 - - [20/Sep/2024 12:46:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:25,713 Request with ID 6e966243 for model llama3-8b received
2024-09-20 12:46:25,713 127.0.0.1 - - [20/Sep/2024 12:46:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:25,847 Request with ID c1e42836 for model gemma-7b received
2024-09-20 12:46:25,847 127.0.0.1 - - [20/Sep/2024 12:46:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:25,875 Request with ID 7e38d17d for model gemma-7b received
2024-09-20 12:46:25,875 127.0.0.1 - - [20/Sep/2024 12:46:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:26,058 Request with ID 2cb799e4 for model gemma-7b received
2024-09-20 12:46:26,059 127.0.0.1 - - [20/Sep/2024 12:46:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:26,084 Request with ID c4799206 for model gemma-7b received
2024-09-20 12:46:26,084 127.0.0.1 - - [20/Sep/2024 12:46:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:26,091 Request with ID b9d4510a for model llama3-8b received
2024-09-20 12:46:26,092 Request with ID 0f8a21d1 for model gemma-7b received
2024-09-20 12:46:26,093 127.0.0.1 - - [20/Sep/2024 12:46:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:26,093 127.0.0.1 - - [20/Sep/2024 12:46:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:26,147 Request with ID 217ec69e for model llama3-8b received
2024-09-20 12:46:26,148 127.0.0.1 - - [20/Sep/2024 12:46:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:26,192 Request with ID b41b2259 for model llama3-8b received
2024-09-20 12:46:26,192 127.0.0.1 - - [20/Sep/2024 12:46:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:26,253 Request with ID 86916da2 for model granite-7b received
2024-09-20 12:46:26,254 127.0.0.1 - - [20/Sep/2024 12:46:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:26,499 Request with ID e1bcba98 for model gemma-7b received
2024-09-20 12:46:26,500 127.0.0.1 - - [20/Sep/2024 12:46:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:26,570 Request with ID a05fe2b2 for model granite-7b received
2024-09-20 12:46:26,570 127.0.0.1 - - [20/Sep/2024 12:46:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:26,609 Request with ID 18e62fff for model llama3-8b received
2024-09-20 12:46:26,609 127.0.0.1 - - [20/Sep/2024 12:46:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:26,710 Request with ID ddf9bbd7 for model llama3-8b received
2024-09-20 12:46:26,710 127.0.0.1 - - [20/Sep/2024 12:46:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:27,083 Request with ID b0db33ba for model llama3-8b received
2024-09-20 12:46:27,083 127.0.0.1 - - [20/Sep/2024 12:46:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:27,282 Request with ID cd716065 for model llama3-8b received
2024-09-20 12:46:27,282 127.0.0.1 - - [20/Sep/2024 12:46:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:27,353 Request with ID 39da499e for model gemma-7b received
2024-09-20 12:46:27,353 127.0.0.1 - - [20/Sep/2024 12:46:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:27,405 Request with ID c367ad6a for model llama3-8b received
2024-09-20 12:46:27,405 127.0.0.1 - - [20/Sep/2024 12:46:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:27,428 Request with ID 15c27468 for model gemma-7b received
2024-09-20 12:46:27,429 127.0.0.1 - - [20/Sep/2024 12:46:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:27,695 Request with ID 6cf30abc for model gemma-7b received
2024-09-20 12:46:27,695 127.0.0.1 - - [20/Sep/2024 12:46:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:27,739 Request with ID 6fab5da6 for model llama3-8b received
2024-09-20 12:46:27,739 127.0.0.1 - - [20/Sep/2024 12:46:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:27,806 Request with ID 84ccae2e for model llama3-8b received
2024-09-20 12:46:27,807 127.0.0.1 - - [20/Sep/2024 12:46:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:27,818 Request with ID f3e9b8a9 for model llama3-8b received
2024-09-20 12:46:27,819 127.0.0.1 - - [20/Sep/2024 12:46:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:27,866 Request with ID 05018b44 for model llama3-8b received
2024-09-20 12:46:27,867 127.0.0.1 - - [20/Sep/2024 12:46:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:27,944 Request with ID e67ee84a for model llama3-8b received
2024-09-20 12:46:27,945 127.0.0.1 - - [20/Sep/2024 12:46:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:28,129 Request with ID dfaec8ae for model llama3-8b received
2024-09-20 12:46:28,130 127.0.0.1 - - [20/Sep/2024 12:46:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:28,160 Request with ID 36b36628 for model llama3-8b received
2024-09-20 12:46:28,161 127.0.0.1 - - [20/Sep/2024 12:46:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:28,163 Request with ID f833796f for model granite-7b received
2024-09-20 12:46:28,164 127.0.0.1 - - [20/Sep/2024 12:46:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:28,192 Request with ID 9cb4f1fb for model llama3-8b received
2024-09-20 12:46:28,193 127.0.0.1 - - [20/Sep/2024 12:46:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:28,373 Request with ID 08bc1dc4 for model llama3-8b received
2024-09-20 12:46:28,374 127.0.0.1 - - [20/Sep/2024 12:46:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:28,388 Request with ID 02e1f756 for model gemma-7b received
2024-09-20 12:46:28,389 127.0.0.1 - - [20/Sep/2024 12:46:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:28,618 Request with ID 85821067 for model llama3-8b received
2024-09-20 12:46:28,619 127.0.0.1 - - [20/Sep/2024 12:46:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:28,753 Request with ID 453468a9 for model gemma-7b received
2024-09-20 12:46:28,754 127.0.0.1 - - [20/Sep/2024 12:46:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:28,965 Request with ID 15828d8a for model llama3-8b received
2024-09-20 12:46:28,966 127.0.0.1 - - [20/Sep/2024 12:46:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:29,191 Request with ID 191e38ad for model gemma-7b received
2024-09-20 12:46:29,191 127.0.0.1 - - [20/Sep/2024 12:46:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:29,369 Request with ID dcb678bf for model llama3-8b received
2024-09-20 12:46:29,369 127.0.0.1 - - [20/Sep/2024 12:46:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:29,400 Request with ID 8ef68a2c for model llama3-8b received
2024-09-20 12:46:29,401 127.0.0.1 - - [20/Sep/2024 12:46:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:29,482 Request with ID ddb38d60 for model gemma-7b received
2024-09-20 12:46:29,483 127.0.0.1 - - [20/Sep/2024 12:46:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:29,781 Request with ID 3535d6be for model gemma-7b received
2024-09-20 12:46:29,782 127.0.0.1 - - [20/Sep/2024 12:46:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:29,986 Request with ID 71e6b039 for model llama3-8b received
2024-09-20 12:46:29,987 127.0.0.1 - - [20/Sep/2024 12:46:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:30,149 Request with ID 548af47d for model llama3-8b received
2024-09-20 12:46:30,150 127.0.0.1 - - [20/Sep/2024 12:46:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:30,250 Request with ID 7df9e0e4 for model llama3-8b received
2024-09-20 12:46:30,251 127.0.0.1 - - [20/Sep/2024 12:46:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:30,307 Request with ID 312300d7 for model llama3-8b received
2024-09-20 12:46:30,308 127.0.0.1 - - [20/Sep/2024 12:46:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:30,426 Request with ID 9e3f5965 for model granite-7b received
2024-09-20 12:46:30,426 127.0.0.1 - - [20/Sep/2024 12:46:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:30,672 Request with ID ccb66624 for model llama3-8b received
2024-09-20 12:46:30,673 127.0.0.1 - - [20/Sep/2024 12:46:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:30,704 Request with ID 30a66381 for model llama3-8b received
2024-09-20 12:46:30,705 127.0.0.1 - - [20/Sep/2024 12:46:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:30,991 Request with ID 98d1c923 for model gemma-7b received
2024-09-20 12:46:30,992 Request with ID 14f38196 for model llama3-8b received
2024-09-20 12:46:30,993 127.0.0.1 - - [20/Sep/2024 12:46:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:30,993 127.0.0.1 - - [20/Sep/2024 12:46:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:31,110 Request with ID aba49b1f for model gemma-7b received
2024-09-20 12:46:31,110 127.0.0.1 - - [20/Sep/2024 12:46:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:31,212 Request with ID 6157b83b for model llama3-8b received
2024-09-20 12:46:31,213 127.0.0.1 - - [20/Sep/2024 12:46:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:31,321 Loaded model gemma-7b
2024-09-20 12:46:31,324 Batch processing started for model gemma-7b
2024-09-20 12:46:31,395 Request with ID 961af786 for model llama3-8b received
2024-09-20 12:46:31,396 127.0.0.1 - - [20/Sep/2024 12:46:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:31,399 Request with ID 47b559e1 for model llama3-8b received
2024-09-20 12:46:31,400 127.0.0.1 - - [20/Sep/2024 12:46:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:31,409 Request with ID 2faf5b77 for model gemma-7b received
2024-09-20 12:46:31,410 127.0.0.1 - - [20/Sep/2024 12:46:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:31,462 Request with ID 4a472bb2 for model llama3-8b received
2024-09-20 12:46:31,462 127.0.0.1 - - [20/Sep/2024 12:46:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:31,713 Request with ID d1887174 for model gemma-7b received
2024-09-20 12:46:31,713 127.0.0.1 - - [20/Sep/2024 12:46:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:31,796 Request with ID 362cdb02 for model gemma-7b received
2024-09-20 12:46:31,797 127.0.0.1 - - [20/Sep/2024 12:46:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:32,106 Request with ID 5177da10 for model llama3-8b received
2024-09-20 12:46:32,106 127.0.0.1 - - [20/Sep/2024 12:46:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:32,131 Request with ID a632d8a2 for model gemma-7b received
2024-09-20 12:46:32,131 127.0.0.1 - - [20/Sep/2024 12:46:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:32,224 Request with ID 7b11dee1 for model gemma-7b received
2024-09-20 12:46:32,224 127.0.0.1 - - [20/Sep/2024 12:46:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:32,323 Request with ID 3f2c4186 for model gemma-7b received
2024-09-20 12:46:32,323 127.0.0.1 - - [20/Sep/2024 12:46:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:32,367 Request with ID fab533e1 for model llama3-8b received
2024-09-20 12:46:32,367 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:46:32,368 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:46:32,486 Request with ID 2385f993 for model llama3-8b received
2024-09-20 12:46:32,487 127.0.0.1 - - [20/Sep/2024 12:46:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:32,494 Request with ID 90f86677 for model granite-7b received
2024-09-20 12:46:32,495 127.0.0.1 - - [20/Sep/2024 12:46:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:32,840 Request with ID e2ff160b for model llama3-8b received
2024-09-20 12:46:32,840 127.0.0.1 - - [20/Sep/2024 12:46:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:32,886 Request with ID 80342d33 for model llama3-8b received
2024-09-20 12:46:32,887 127.0.0.1 - - [20/Sep/2024 12:46:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:32,947 Request with ID b58ddd2b for model llama3-8b received
2024-09-20 12:46:32,948 127.0.0.1 - - [20/Sep/2024 12:46:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:33,155 Request with ID 1a323848 for model llama3-8b received
2024-09-20 12:46:33,156 127.0.0.1 - - [20/Sep/2024 12:46:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:33,299 Request with ID 68fdf022 for model llama3-8b received
2024-09-20 12:46:33,300 127.0.0.1 - - [20/Sep/2024 12:46:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:33,490 Request with ID 50314ae1 for model llama3-8b received
2024-09-20 12:46:33,490 127.0.0.1 - - [20/Sep/2024 12:46:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:33,610 Request with ID 4f7588f5 for model llama3-8b received
2024-09-20 12:46:33,610 127.0.0.1 - - [20/Sep/2024 12:46:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:33,614 Request with ID dbdec1ea for model llama3-8b received
2024-09-20 12:46:33,615 127.0.0.1 - - [20/Sep/2024 12:46:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:34,351 Request with ID c63ec68a for model llama3-8b received
2024-09-20 12:46:34,352 127.0.0.1 - - [20/Sep/2024 12:46:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:34,600 Request with ID 3ece685f for model llama3-8b received
2024-09-20 12:46:34,600 127.0.0.1 - - [20/Sep/2024 12:46:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:34,636 Request with ID 7387d949 for model llama3-8b received
2024-09-20 12:46:34,637 127.0.0.1 - - [20/Sep/2024 12:46:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:34,797 Request with ID e4b5bd42 for model granite-7b received
2024-09-20 12:46:34,798 127.0.0.1 - - [20/Sep/2024 12:46:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:34,859 Request with ID c948699e for model llama3-8b received
2024-09-20 12:46:34,860 127.0.0.1 - - [20/Sep/2024 12:46:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:34,863 Request with ID 3891124d for model gemma-7b received
2024-09-20 12:46:34,864 127.0.0.1 - - [20/Sep/2024 12:46:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:34,947 Request with ID ffb37381 for model llama3-8b received
2024-09-20 12:46:34,948 127.0.0.1 - - [20/Sep/2024 12:46:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:34,965 Processed batch: ['69e5de4a', 'a81ee0d0', 'c86c272c', 'a4d66b13', 'f601e473', '7686dd87', 'a415a370', 'f5774f0d', 'e8279a7e', '427691f0', '17a80fd6', '7306a43a', '4bbfc5d4', '1e6348b7', '8afb6a65', '822f1712'] with model gemma-7b in 3.6411 seconds
2024-09-20 12:46:34,965 Saving sys info
2024-09-20 12:46:35,013 Latency for request 69e5de4a with model gemma-7b: 35.9810 seconds
2024-09-20 12:46:35,013 Saving results with gpu monitoring
2024-09-20 12:46:35,023 Latency for request a81ee0d0 with model gemma-7b: 35.3670 seconds
2024-09-20 12:46:35,023 Saving results with gpu monitoring
2024-09-20 12:46:35,025 Latency for request c86c272c with model gemma-7b: 35.3090 seconds
2024-09-20 12:46:35,025 Saving results with gpu monitoring
2024-09-20 12:46:35,027 Latency for request a4d66b13 with model gemma-7b: 35.2990 seconds
2024-09-20 12:46:35,027 Saving results with gpu monitoring
2024-09-20 12:46:35,030 Latency for request f601e473 with model gemma-7b: 34.6230 seconds
2024-09-20 12:46:35,030 Saving results with gpu monitoring
2024-09-20 12:46:35,032 Latency for request 7686dd87 with model gemma-7b: 34.2630 seconds
2024-09-20 12:46:35,032 Saving results with gpu monitoring
2024-09-20 12:46:35,034 Latency for request a415a370 with model gemma-7b: 33.8890 seconds
2024-09-20 12:46:35,034 Saving results with gpu monitoring
2024-09-20 12:46:35,036 Latency for request f5774f0d with model gemma-7b: 33.6260 seconds
2024-09-20 12:46:35,036 Saving results with gpu monitoring
2024-09-20 12:46:35,038 Latency for request e8279a7e with model gemma-7b: 33.3660 seconds
2024-09-20 12:46:35,038 Saving results with gpu monitoring
2024-09-20 12:46:35,040 Latency for request 427691f0 with model gemma-7b: 33.3290 seconds
2024-09-20 12:46:35,040 Saving results with gpu monitoring
2024-09-20 12:46:35,043 Latency for request 17a80fd6 with model gemma-7b: 33.0020 seconds
2024-09-20 12:46:35,043 Saving results with gpu monitoring
2024-09-20 12:46:35,045 Latency for request 7306a43a with model gemma-7b: 32.6760 seconds
2024-09-20 12:46:35,045 Saving results with gpu monitoring
2024-09-20 12:46:35,047 Latency for request 4bbfc5d4 with model gemma-7b: 31.8240 seconds
2024-09-20 12:46:35,047 Saving results with gpu monitoring
2024-09-20 12:46:35,049 Latency for request 1e6348b7 with model gemma-7b: 31.7410 seconds
2024-09-20 12:46:35,049 Saving results with gpu monitoring
2024-09-20 12:46:35,051 Latency for request 8afb6a65 with model gemma-7b: 31.0710 seconds
2024-09-20 12:46:35,052 Saving results with gpu monitoring
2024-09-20 12:46:35,054 Request with ID adbdd4a8 for model llama3-8b received
2024-09-20 12:46:35,055 Latency for request 822f1712 with model gemma-7b: 31.0120 seconds
2024-09-20 12:46:35,056 127.0.0.1 - - [20/Sep/2024 12:46:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:35,056 Saving results with gpu monitoring
2024-09-20 12:46:35,059 Next: call load_model for llama3-8b
2024-09-20 12:46:35,170 Processing batch for llama3-8b due to time limit with batch size 15
2024-09-20 12:46:35,171 Time limit condition met for model llama3-8b
2024-09-20 12:46:35,172 Unloaded previous model
2024-09-20 12:46:35,174 Request with ID 1fc34d1b for model llama3-8b received
2024-09-20 12:46:35,175 127.0.0.1 - - [20/Sep/2024 12:46:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:35,395 Request with ID cca971f4 for model llama3-8b received
2024-09-20 12:46:35,395 127.0.0.1 - - [20/Sep/2024 12:46:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:35,462 Request with ID b95bcbee for model llama3-8b received
2024-09-20 12:46:35,464 127.0.0.1 - - [20/Sep/2024 12:46:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:35,975 Request with ID 7edc9ef2 for model llama3-8b received
2024-09-20 12:46:35,977 127.0.0.1 - - [20/Sep/2024 12:46:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:36,012 Request with ID c7a2d865 for model llama3-8b received
2024-09-20 12:46:36,018 127.0.0.1 - - [20/Sep/2024 12:46:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:36,623 Request with ID 790199d0 for model llama3-8b received
2024-09-20 12:46:36,623 127.0.0.1 - - [20/Sep/2024 12:46:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:36,674 Request with ID fcadaab6 for model llama3-8b received
2024-09-20 12:46:36,675 127.0.0.1 - - [20/Sep/2024 12:46:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:36,763 Request with ID 257bb30c for model llama3-8b received
2024-09-20 12:46:36,764 127.0.0.1 - - [20/Sep/2024 12:46:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:36,913 Request with ID 3af4b8b8 for model gemma-7b received
2024-09-20 12:46:36,913 Adjusted batch time limit for gemma-7b: 5.0000 seconds
2024-09-20 12:46:36,913 127.0.0.1 - - [20/Sep/2024 12:46:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:36,987 Request with ID faf4b072 for model llama3-8b received
2024-09-20 12:46:36,988 127.0.0.1 - - [20/Sep/2024 12:46:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:37,023 Request with ID 081736f1 for model gemma-7b received
2024-09-20 12:46:37,024 127.0.0.1 - - [20/Sep/2024 12:46:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:37,051 Request with ID 1129ba6f for model granite-7b received
2024-09-20 12:46:37,051 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:46:37,051 Dynamic batch size condition met for model granite-7b
2024-09-20 12:46:37,493 Request with ID 6282a7ae for model gemma-7b received
2024-09-20 12:46:37,494 127.0.0.1 - - [20/Sep/2024 12:46:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:37,608 Request with ID a5b90276 for model llama3-8b received
2024-09-20 12:46:37,609 127.0.0.1 - - [20/Sep/2024 12:46:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:37,640 Request with ID 6a457e4e for model llama3-8b received
2024-09-20 12:46:37,640 127.0.0.1 - - [20/Sep/2024 12:46:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:37,858 Request with ID 6473f838 for model llama3-8b received
2024-09-20 12:46:37,858 127.0.0.1 - - [20/Sep/2024 12:46:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:38,429 Request with ID cb89fd78 for model gemma-7b received
2024-09-20 12:46:38,429 127.0.0.1 - - [20/Sep/2024 12:46:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:38,600 Request with ID 4dd0bd4f for model llama3-8b received
2024-09-20 12:46:38,601 127.0.0.1 - - [20/Sep/2024 12:46:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:38,673 Request with ID 80c06a90 for model gemma-7b received
2024-09-20 12:46:38,673 127.0.0.1 - - [20/Sep/2024 12:46:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:38,677 Request with ID dabe058f for model gemma-7b received
2024-09-20 12:46:38,677 127.0.0.1 - - [20/Sep/2024 12:46:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:38,684 Request with ID f8c8cba4 for model llama3-8b received
2024-09-20 12:46:38,684 127.0.0.1 - - [20/Sep/2024 12:46:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:38,949 Request with ID 453d3133 for model llama3-8b received
2024-09-20 12:46:38,950 127.0.0.1 - - [20/Sep/2024 12:46:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:38,981 Request with ID 22c2633e for model llama3-8b received
2024-09-20 12:46:38,981 127.0.0.1 - - [20/Sep/2024 12:46:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:38,998 Request with ID 3b03ee47 for model llama3-8b received
2024-09-20 12:46:38,999 127.0.0.1 - - [20/Sep/2024 12:46:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:39,098 Request with ID a6adec0a for model llama3-8b received
2024-09-20 12:46:39,098 127.0.0.1 - - [20/Sep/2024 12:46:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:39,191 Request with ID 0af501bd for model llama3-8b received
2024-09-20 12:46:39,191 127.0.0.1 - - [20/Sep/2024 12:46:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:39,254 Request with ID 6b4dcb01 for model gemma-7b received
2024-09-20 12:46:39,254 127.0.0.1 - - [20/Sep/2024 12:46:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:39,268 Request with ID a4c8360a for model llama3-8b received
2024-09-20 12:46:39,269 127.0.0.1 - - [20/Sep/2024 12:46:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:39,468 Request with ID a56b9358 for model gemma-7b received
2024-09-20 12:46:39,469 127.0.0.1 - - [20/Sep/2024 12:46:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:39,739 Request with ID de8b6cec for model granite-7b received
2024-09-20 12:46:39,739 127.0.0.1 - - [20/Sep/2024 12:46:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:39,792 Request with ID 695c9e43 for model granite-7b received
2024-09-20 12:46:39,792 127.0.0.1 - - [20/Sep/2024 12:46:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:39,913 Request with ID f771ab20 for model llama3-8b received
2024-09-20 12:46:39,913 127.0.0.1 - - [20/Sep/2024 12:46:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:39,922 Request with ID a890d197 for model llama3-8b received
2024-09-20 12:46:39,922 127.0.0.1 - - [20/Sep/2024 12:46:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:39,930 Request with ID e9a1cfaf for model granite-7b received
2024-09-20 12:46:39,931 127.0.0.1 - - [20/Sep/2024 12:46:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:40,148 Request with ID 3daab79b for model llama3-8b received
2024-09-20 12:46:40,148 127.0.0.1 - - [20/Sep/2024 12:46:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:40,323 Request with ID ffc9057a for model llama3-8b received
2024-09-20 12:46:40,324 127.0.0.1 - - [20/Sep/2024 12:46:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:40,403 Request with ID a744e11b for model gemma-7b received
2024-09-20 12:46:40,404 127.0.0.1 - - [20/Sep/2024 12:46:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:40,617 Request with ID 3bfc0e79 for model llama3-8b received
2024-09-20 12:46:40,618 127.0.0.1 - - [20/Sep/2024 12:46:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:40,821 Request with ID ac5ed764 for model gemma-7b received
2024-09-20 12:46:40,822 127.0.0.1 - - [20/Sep/2024 12:46:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:40,849 Request with ID 986fdb95 for model llama3-8b received
2024-09-20 12:46:40,850 127.0.0.1 - - [20/Sep/2024 12:46:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:41,036 Request with ID dae9416e for model gemma-7b received
2024-09-20 12:46:41,037 127.0.0.1 - - [20/Sep/2024 12:46:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:41,164 Request with ID 102948ea for model llama3-8b received
2024-09-20 12:46:41,165 127.0.0.1 - - [20/Sep/2024 12:46:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:41,377 Request with ID dbe2cffc for model gemma-7b received
2024-09-20 12:46:41,378 127.0.0.1 - - [20/Sep/2024 12:46:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:41,419 Request with ID 71a3b787 for model gemma-7b received
2024-09-20 12:46:41,419 127.0.0.1 - - [20/Sep/2024 12:46:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:41,592 Request with ID 8908c39a for model llama3-8b received
2024-09-20 12:46:41,592 127.0.0.1 - - [20/Sep/2024 12:46:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:41,594 Request with ID 9d37645a for model granite-7b received
2024-09-20 12:46:41,594 127.0.0.1 - - [20/Sep/2024 12:46:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:41,633 Request with ID 026aa369 for model llama3-8b received
2024-09-20 12:46:41,634 127.0.0.1 - - [20/Sep/2024 12:46:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:41,664 Request with ID 223c2e42 for model granite-7b received
2024-09-20 12:46:41,665 127.0.0.1 - - [20/Sep/2024 12:46:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:41,838 Request with ID 6354bf23 for model gemma-7b received
2024-09-20 12:46:41,838 127.0.0.1 - - [20/Sep/2024 12:46:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:41,983 Request with ID 613ceebd for model llama3-8b received
2024-09-20 12:46:41,983 127.0.0.1 - - [20/Sep/2024 12:46:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:42,168 Request with ID 21e93ddf for model llama3-8b received
2024-09-20 12:46:42,169 127.0.0.1 - - [20/Sep/2024 12:46:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:42,438 Request with ID 11c33799 for model llama3-8b received
2024-09-20 12:46:42,439 127.0.0.1 - - [20/Sep/2024 12:46:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:42,458 Request with ID a9dd2d89 for model granite-7b received
2024-09-20 12:46:42,459 127.0.0.1 - - [20/Sep/2024 12:46:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:42,496 Request with ID 20f53611 for model llama3-8b received
2024-09-20 12:46:42,496 127.0.0.1 - - [20/Sep/2024 12:46:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:42,621 Request with ID 27e7eb3c for model gemma-7b received
2024-09-20 12:46:42,621 127.0.0.1 - - [20/Sep/2024 12:46:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:42,719 Request with ID ebed5126 for model llama3-8b received
2024-09-20 12:46:42,719 127.0.0.1 - - [20/Sep/2024 12:46:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:42,779 Request with ID ce051e57 for model gemma-7b received
2024-09-20 12:46:42,780 127.0.0.1 - - [20/Sep/2024 12:46:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:42,923 Request with ID 115da18c for model granite-7b received
2024-09-20 12:46:42,924 127.0.0.1 - - [20/Sep/2024 12:46:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,098 Request with ID 6928cad4 for model llama3-8b received
2024-09-20 12:46:43,098 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,127 Request with ID 8b5f739f for model llama3-8b received
2024-09-20 12:46:43,127 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,161 Request with ID 6f167c5c for model llama3-8b received
2024-09-20 12:46:43,161 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,222 Request with ID 4d711428 for model llama3-8b received
2024-09-20 12:46:43,223 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,399 Request with ID e7bb25ba for model gemma-7b received
2024-09-20 12:46:43,400 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-20 12:46:43,400 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:46:43,409 Request with ID d04fc58b for model gemma-7b received
2024-09-20 12:46:43,409 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,423 Request with ID 0bb2c0fc for model llama3-8b received
2024-09-20 12:46:43,423 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,480 Request with ID 47597463 for model gemma-7b received
2024-09-20 12:46:43,481 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,513 Request with ID 39d527fa for model gemma-7b received
2024-09-20 12:46:43,514 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,554 Request with ID e5182560 for model gemma-7b received
2024-09-20 12:46:43,555 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,579 Request with ID 68d76575 for model llama3-8b received
2024-09-20 12:46:43,580 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,708 Request with ID 0a3730c0 for model llama3-8b received
2024-09-20 12:46:43,708 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,915 Request with ID a36565eb for model gemma-7b received
2024-09-20 12:46:43,916 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,917 Request with ID d8409018 for model llama3-8b received
2024-09-20 12:46:43,918 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:43,985 Request with ID 366a5b88 for model granite-7b received
2024-09-20 12:46:43,986 127.0.0.1 - - [20/Sep/2024 12:46:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:44,146 Request with ID db722e9d for model granite-7b received
2024-09-20 12:46:44,147 127.0.0.1 - - [20/Sep/2024 12:46:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:44,402 Request with ID 1966470f for model llama3-8b received
2024-09-20 12:46:44,402 127.0.0.1 - - [20/Sep/2024 12:46:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:44,416 Request with ID 627e1fe2 for model gemma-7b received
2024-09-20 12:46:44,416 127.0.0.1 - - [20/Sep/2024 12:46:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:44,500 Request with ID f7472305 for model gemma-7b received
2024-09-20 12:46:44,500 127.0.0.1 - - [20/Sep/2024 12:46:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:44,607 Request with ID 5e5c578d for model llama3-8b received
2024-09-20 12:46:44,607 127.0.0.1 - - [20/Sep/2024 12:46:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:44,665 Request with ID 7740dbab for model llama3-8b received
2024-09-20 12:46:44,665 127.0.0.1 - - [20/Sep/2024 12:46:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:44,667 Request with ID e83c75ea for model llama3-8b received
2024-09-20 12:46:44,667 127.0.0.1 - - [20/Sep/2024 12:46:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:44,718 Request with ID db8f6578 for model llama3-8b received
2024-09-20 12:46:44,719 127.0.0.1 - - [20/Sep/2024 12:46:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:44,828 Request with ID 57378aee for model llama3-8b received
2024-09-20 12:46:44,829 127.0.0.1 - - [20/Sep/2024 12:46:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:44,981 Request with ID 43482b72 for model llama3-8b received
2024-09-20 12:46:44,982 127.0.0.1 - - [20/Sep/2024 12:46:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:45,122 Request with ID d47ff9d6 for model gemma-7b received
2024-09-20 12:46:45,122 127.0.0.1 - - [20/Sep/2024 12:46:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:45,555 Request with ID 2893a93f for model granite-7b received
2024-09-20 12:46:45,556 127.0.0.1 - - [20/Sep/2024 12:46:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:45,622 Request with ID eb13998e for model llama3-8b received
2024-09-20 12:46:45,622 127.0.0.1 - - [20/Sep/2024 12:46:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:45,706 Request with ID 923a5645 for model llama3-8b received
2024-09-20 12:46:45,707 127.0.0.1 - - [20/Sep/2024 12:46:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:45,714 Request with ID 43b1f5a8 for model gemma-7b received
2024-09-20 12:46:45,715 127.0.0.1 - - [20/Sep/2024 12:46:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:45,718 Request with ID 7fafe904 for model gemma-7b received
2024-09-20 12:46:45,718 127.0.0.1 - - [20/Sep/2024 12:46:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:45,759 Request with ID c134afd7 for model llama3-8b received
2024-09-20 12:46:45,759 127.0.0.1 - - [20/Sep/2024 12:46:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:45,922 Request with ID dec7ec06 for model gemma-7b received
2024-09-20 12:46:45,922 127.0.0.1 - - [20/Sep/2024 12:46:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:45,933 Request with ID 75e8813d for model gemma-7b received
2024-09-20 12:46:45,934 127.0.0.1 - - [20/Sep/2024 12:46:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:46,163 Request with ID 84eb8bea for model llama3-8b received
2024-09-20 12:46:46,164 127.0.0.1 - - [20/Sep/2024 12:46:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:46,169 Request with ID d8c8dac5 for model gemma-7b received
2024-09-20 12:46:46,170 127.0.0.1 - - [20/Sep/2024 12:46:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:46,445 Request with ID 8512b42a for model llama3-8b received
2024-09-20 12:46:46,446 127.0.0.1 - - [20/Sep/2024 12:46:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:46,709 Request with ID fc0b7999 for model llama3-8b received
2024-09-20 12:46:46,710 127.0.0.1 - - [20/Sep/2024 12:46:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:46,712 Request with ID e41cf8fd for model llama3-8b received
2024-09-20 12:46:46,713 127.0.0.1 - - [20/Sep/2024 12:46:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:46,714 Request with ID 5f91a387 for model llama3-8b received
2024-09-20 12:46:46,714 127.0.0.1 - - [20/Sep/2024 12:46:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:46,807 Request with ID 07a091d5 for model gemma-7b received
2024-09-20 12:46:46,808 127.0.0.1 - - [20/Sep/2024 12:46:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:46,866 Request with ID a74aabb7 for model llama3-8b received
2024-09-20 12:46:46,866 127.0.0.1 - - [20/Sep/2024 12:46:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:46,932 Request with ID f87ffd59 for model gemma-7b received
2024-09-20 12:46:46,933 127.0.0.1 - - [20/Sep/2024 12:46:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:47,307 Request with ID 12f90889 for model gemma-7b received
2024-09-20 12:46:47,307 127.0.0.1 - - [20/Sep/2024 12:46:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:47,464 Request with ID 15d14533 for model granite-7b received
2024-09-20 12:46:47,465 127.0.0.1 - - [20/Sep/2024 12:46:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:47,481 Request with ID 2efe9c8b for model llama3-8b received
2024-09-20 12:46:47,482 127.0.0.1 - - [20/Sep/2024 12:46:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:47,509 Request with ID 1ab920fc for model llama3-8b received
2024-09-20 12:46:47,510 127.0.0.1 - - [20/Sep/2024 12:46:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:47,618 Request with ID 97f55b16 for model llama3-8b received
2024-09-20 12:46:47,619 127.0.0.1 - - [20/Sep/2024 12:46:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:47,643 Request with ID d29ad7ef for model gemma-7b received
2024-09-20 12:46:47,643 127.0.0.1 - - [20/Sep/2024 12:46:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:47,829 Request with ID 4b6eb315 for model llama3-8b received
2024-09-20 12:46:47,830 127.0.0.1 - - [20/Sep/2024 12:46:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:47,966 Request with ID 60d4973a for model llama3-8b received
2024-09-20 12:46:47,967 127.0.0.1 - - [20/Sep/2024 12:46:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:48,100 Request with ID 9bd1d4d8 for model granite-7b received
2024-09-20 12:46:48,101 127.0.0.1 - - [20/Sep/2024 12:46:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:48,304 Request with ID d77b8b12 for model llama3-8b received
2024-09-20 12:46:48,304 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:46:48,304 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:46:48,307 Request with ID 836cc6e4 for model llama3-8b received
2024-09-20 12:46:48,307 127.0.0.1 - - [20/Sep/2024 12:46:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:48,400 Request with ID 436ea29e for model llama3-8b received
2024-09-20 12:46:48,401 127.0.0.1 - - [20/Sep/2024 12:46:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:48,887 Request with ID 434ef376 for model llama3-8b received
2024-09-20 12:46:48,887 127.0.0.1 - - [20/Sep/2024 12:46:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:48,911 Request with ID d5e9af3a for model llama3-8b received
2024-09-20 12:46:48,911 127.0.0.1 - - [20/Sep/2024 12:46:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:49,046 Request with ID ac20d28e for model llama3-8b received
2024-09-20 12:46:49,046 127.0.0.1 - - [20/Sep/2024 12:46:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:49,288 Request with ID b9df02cf for model llama3-8b received
2024-09-20 12:46:49,289 127.0.0.1 - - [20/Sep/2024 12:46:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:49,440 Request with ID 5c44158c for model gemma-7b received
2024-09-20 12:46:49,441 127.0.0.1 - - [20/Sep/2024 12:46:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:49,530 Request with ID 320cb067 for model gemma-7b received
2024-09-20 12:46:49,531 127.0.0.1 - - [20/Sep/2024 12:46:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:49,736 Request with ID 501925e7 for model llama3-8b received
2024-09-20 12:46:49,737 127.0.0.1 - - [20/Sep/2024 12:46:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:49,824 Request with ID 48daca95 for model granite-7b received
2024-09-20 12:46:49,825 127.0.0.1 - - [20/Sep/2024 12:46:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:49,932 Request with ID 42feb470 for model gemma-7b received
2024-09-20 12:46:49,932 127.0.0.1 - - [20/Sep/2024 12:46:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,129 Request with ID 89b0f374 for model gemma-7b received
2024-09-20 12:46:50,129 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,279 Request with ID 40187c84 for model gemma-7b received
2024-09-20 12:46:50,279 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,306 Request with ID 2a63ddfc for model gemma-7b received
2024-09-20 12:46:50,307 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,381 Request with ID 77653173 for model llama3-8b received
2024-09-20 12:46:50,382 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,396 Request with ID c1392665 for model llama3-8b received
2024-09-20 12:46:50,397 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,522 Request with ID 5233328e for model gemma-7b received
2024-09-20 12:46:50,523 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,571 Request with ID 59327b52 for model gemma-7b received
2024-09-20 12:46:50,571 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,648 Request with ID 89fafdb3 for model llama3-8b received
2024-09-20 12:46:50,649 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,738 Request with ID 021fc37f for model llama3-8b received
2024-09-20 12:46:50,739 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,817 Request with ID 99c0cf17 for model gemma-7b received
2024-09-20 12:46:50,818 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,823 Request with ID 9e0af8bf for model llama3-8b received
2024-09-20 12:46:50,823 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,828 Request with ID c9ed97ba for model gemma-7b received
2024-09-20 12:46:50,829 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,849 Request with ID a5210c9c for model gemma-7b received
2024-09-20 12:46:50,849 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,921 Request with ID 43ff3387 for model llama3-8b received
2024-09-20 12:46:50,922 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,973 Request with ID 134b2bde for model llama3-8b received
2024-09-20 12:46:50,974 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:50,976 Request with ID e744636b for model llama3-8b received
2024-09-20 12:46:50,976 127.0.0.1 - - [20/Sep/2024 12:46:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:51,180 Request with ID 6d873bd1 for model gemma-7b received
2024-09-20 12:46:51,180 127.0.0.1 - - [20/Sep/2024 12:46:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:51,255 Request with ID 100d068a for model llama3-8b received
2024-09-20 12:46:51,255 127.0.0.1 - - [20/Sep/2024 12:46:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:51,271 Request with ID e58739ae for model gemma-7b received
2024-09-20 12:46:51,271 127.0.0.1 - - [20/Sep/2024 12:46:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:51,396 Request with ID a1939810 for model llama3-8b received
2024-09-20 12:46:51,397 127.0.0.1 - - [20/Sep/2024 12:46:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:51,750 Request with ID c312bd86 for model llama3-8b received
2024-09-20 12:46:51,750 127.0.0.1 - - [20/Sep/2024 12:46:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:51,767 Request with ID 50a7e4be for model llama3-8b received
2024-09-20 12:46:51,767 127.0.0.1 - - [20/Sep/2024 12:46:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:51,787 Request with ID 8815b59a for model llama3-8b received
2024-09-20 12:46:51,788 127.0.0.1 - - [20/Sep/2024 12:46:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:51,905 Request with ID a4b4219d for model gemma-7b received
2024-09-20 12:46:51,906 127.0.0.1 - - [20/Sep/2024 12:46:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:52,237 Request with ID 37861a59 for model llama3-8b received
2024-09-20 12:46:52,238 127.0.0.1 - - [20/Sep/2024 12:46:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:52,240 Request with ID 5c25154e for model llama3-8b received
2024-09-20 12:46:52,240 127.0.0.1 - - [20/Sep/2024 12:46:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:52,342 Request with ID f755a567 for model llama3-8b received
2024-09-20 12:46:52,342 127.0.0.1 - - [20/Sep/2024 12:46:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:52,394 Request with ID 6f199d13 for model llama3-8b received
2024-09-20 12:46:52,394 127.0.0.1 - - [20/Sep/2024 12:46:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:52,438 Request with ID bbe9f024 for model llama3-8b received
2024-09-20 12:46:52,439 127.0.0.1 - - [20/Sep/2024 12:46:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:52,477 Request with ID 126f7e57 for model llama3-8b received
2024-09-20 12:46:52,478 127.0.0.1 - - [20/Sep/2024 12:46:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:52,632 Request with ID c3ad7ab1 for model gemma-7b received
2024-09-20 12:46:52,633 127.0.0.1 - - [20/Sep/2024 12:46:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:52,739 Request with ID a0618fcd for model llama3-8b received
2024-09-20 12:46:52,739 127.0.0.1 - - [20/Sep/2024 12:46:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:52,797 Request with ID eebadb31 for model gemma-7b received
2024-09-20 12:46:52,798 127.0.0.1 - - [20/Sep/2024 12:46:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,002 Request with ID bc9a03b1 for model gemma-7b received
2024-09-20 12:46:53,003 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,109 Request with ID 76ead994 for model llama3-8b received
2024-09-20 12:46:53,109 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,157 Request with ID e427a6d6 for model llama3-8b received
2024-09-20 12:46:53,157 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,238 Request with ID a443d163 for model granite-7b received
2024-09-20 12:46:53,238 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,328 Request with ID 1e06f85c for model llama3-8b received
2024-09-20 12:46:53,328 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,376 Request with ID b7cb0604 for model llama3-8b received
2024-09-20 12:46:53,377 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,380 Request with ID 85e136f1 for model gemma-7b received
2024-09-20 12:46:53,380 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,398 Request with ID f9081bd5 for model llama3-8b received
2024-09-20 12:46:53,398 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,477 Request with ID 06366875 for model llama3-8b received
2024-09-20 12:46:53,477 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,717 Loaded model llama3-8b
2024-09-20 12:46:53,718 Request with ID 4072b5ca for model llama3-8b received
2024-09-20 12:46:53,719 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,723 Batch processing started for model llama3-8b
2024-09-20 12:46:53,820 Request with ID 40bbb629 for model llama3-8b received
2024-09-20 12:46:53,821 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,828 Request with ID 36d1f5fd for model llama3-8b received
2024-09-20 12:46:53,828 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,835 Request with ID 92152432 for model llama3-8b received
2024-09-20 12:46:53,835 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,858 Request with ID fc76ecd8 for model llama3-8b received
2024-09-20 12:46:53,859 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,889 Request with ID b8979ad2 for model llama3-8b received
2024-09-20 12:46:53,890 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:53,969 Request with ID 074a92b5 for model llama3-8b received
2024-09-20 12:46:53,970 127.0.0.1 - - [20/Sep/2024 12:46:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:54,097 Request with ID dfa15a8d for model gemma-7b received
2024-09-20 12:46:54,097 127.0.0.1 - - [20/Sep/2024 12:46:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:54,117 Request with ID f8b9a30d for model llama3-8b received
2024-09-20 12:46:54,117 127.0.0.1 - - [20/Sep/2024 12:46:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:54,243 Request with ID 67a44bf4 for model gemma-7b received
2024-09-20 12:46:54,244 127.0.0.1 - - [20/Sep/2024 12:46:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:54,575 Request with ID 09d3b3bb for model granite-7b received
2024-09-20 12:46:54,575 127.0.0.1 - - [20/Sep/2024 12:46:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:54,746 Request with ID cece2f14 for model granite-7b received
2024-09-20 12:46:54,746 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:46:54,746 Dynamic batch size condition met for model granite-7b
2024-09-20 12:46:54,847 Request with ID 7bfa493d for model llama3-8b received
2024-09-20 12:46:54,848 127.0.0.1 - - [20/Sep/2024 12:46:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:54,874 Request with ID 4dce12ff for model llama3-8b received
2024-09-20 12:46:54,874 127.0.0.1 - - [20/Sep/2024 12:46:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:54,893 Request with ID 10a24e39 for model llama3-8b received
2024-09-20 12:46:54,894 127.0.0.1 - - [20/Sep/2024 12:46:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:55,127 Request with ID 1474555e for model llama3-8b received
2024-09-20 12:46:55,127 127.0.0.1 - - [20/Sep/2024 12:46:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:55,158 Request with ID ff233a05 for model gemma-7b received
2024-09-20 12:46:55,158 127.0.0.1 - - [20/Sep/2024 12:46:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:55,333 Request with ID 231ee75a for model llama3-8b received
2024-09-20 12:46:55,333 127.0.0.1 - - [20/Sep/2024 12:46:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:55,351 Request with ID d937c95a for model llama3-8b received
2024-09-20 12:46:55,352 127.0.0.1 - - [20/Sep/2024 12:46:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:55,371 Request with ID 76b0975b for model llama3-8b received
2024-09-20 12:46:55,371 127.0.0.1 - - [20/Sep/2024 12:46:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:55,438 Request with ID 54ad0187 for model granite-7b received
2024-09-20 12:46:55,438 127.0.0.1 - - [20/Sep/2024 12:46:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:55,542 Request with ID 10e0a0f5 for model gemma-7b received
2024-09-20 12:46:55,542 127.0.0.1 - - [20/Sep/2024 12:46:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:55,645 Request with ID 35e7f28b for model gemma-7b received
2024-09-20 12:46:55,645 127.0.0.1 - - [20/Sep/2024 12:46:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:55,738 Request with ID 058a997b for model llama3-8b received
2024-09-20 12:46:55,739 127.0.0.1 - - [20/Sep/2024 12:46:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:55,752 Request with ID 0f18d1f8 for model llama3-8b received
2024-09-20 12:46:55,753 127.0.0.1 - - [20/Sep/2024 12:46:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:55,881 Request with ID 5b32e1b5 for model gemma-7b received
2024-09-20 12:46:55,882 127.0.0.1 - - [20/Sep/2024 12:46:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,054 Request with ID 069a1c1c for model llama3-8b received
2024-09-20 12:46:56,054 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,142 Request with ID 841b0437 for model llama3-8b received
2024-09-20 12:46:56,143 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,173 Request with ID 17e944c0 for model llama3-8b received
2024-09-20 12:46:56,174 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,196 Request with ID 3b1fc465 for model gemma-7b received
2024-09-20 12:46:56,197 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,242 Request with ID fc7b93ae for model llama3-8b received
2024-09-20 12:46:56,242 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,423 Request with ID 93b3f747 for model llama3-8b received
2024-09-20 12:46:56,424 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,450 Request with ID 96cac7a1 for model llama3-8b received
2024-09-20 12:46:56,451 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,529 Request with ID d867c7a2 for model gemma-7b received
2024-09-20 12:46:56,530 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,641 Request with ID 0f83b3a9 for model llama3-8b received
2024-09-20 12:46:56,642 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,724 Request with ID 1dc82b5f for model llama3-8b received
2024-09-20 12:46:56,725 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,731 Request with ID 9add8bd5 for model llama3-8b received
2024-09-20 12:46:56,731 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,751 Request with ID 3bb71ad7 for model gemma-7b received
2024-09-20 12:46:56,752 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,806 Request with ID 6c77c61b for model llama3-8b received
2024-09-20 12:46:56,807 Request with ID 78c94f67 for model llama3-8b received
2024-09-20 12:46:56,807 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,808 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,968 Request with ID 6519ba1e for model gemma-7b received
2024-09-20 12:46:56,968 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:56,982 Request with ID 79b7f801 for model llama3-8b received
2024-09-20 12:46:56,983 127.0.0.1 - - [20/Sep/2024 12:46:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:57,247 Request with ID 31909ee9 for model gemma-7b received
2024-09-20 12:46:57,247 127.0.0.1 - - [20/Sep/2024 12:46:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:57,360 Request with ID d03297e2 for model llama3-8b received
2024-09-20 12:46:57,361 127.0.0.1 - - [20/Sep/2024 12:46:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:57,369 Request with ID cf15a054 for model llama3-8b received
2024-09-20 12:46:57,369 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:46:57,369 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:46:57,466 Request with ID 47e66e56 for model llama3-8b received
2024-09-20 12:46:57,466 127.0.0.1 - - [20/Sep/2024 12:46:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:57,470 Request with ID fa6974b5 for model gemma-7b received
2024-09-20 12:46:57,470 127.0.0.1 - - [20/Sep/2024 12:46:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:57,513 Request with ID 67cad9b4 for model gemma-7b received
2024-09-20 12:46:57,514 127.0.0.1 - - [20/Sep/2024 12:46:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:57,541 Request with ID f1b90c87 for model llama3-8b received
2024-09-20 12:46:57,542 127.0.0.1 - - [20/Sep/2024 12:46:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:57,576 Request with ID 99476e0a for model llama3-8b received
2024-09-20 12:46:57,576 127.0.0.1 - - [20/Sep/2024 12:46:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:57,650 Request with ID c4438f34 for model llama3-8b received
2024-09-20 12:46:57,651 127.0.0.1 - - [20/Sep/2024 12:46:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:57,738 Request with ID 4dc9d07e for model llama3-8b received
2024-09-20 12:46:57,738 127.0.0.1 - - [20/Sep/2024 12:46:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:57,762 Request with ID 4cbb3645 for model gemma-7b received
2024-09-20 12:46:57,763 127.0.0.1 - - [20/Sep/2024 12:46:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:57,934 Request with ID 2e6d35e0 for model llama3-8b received
2024-09-20 12:46:57,935 127.0.0.1 - - [20/Sep/2024 12:46:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:58,013 Request with ID 62d2840c for model gemma-7b received
2024-09-20 12:46:58,013 127.0.0.1 - - [20/Sep/2024 12:46:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:58,036 Request with ID 782ccf06 for model gemma-7b received
2024-09-20 12:46:58,037 127.0.0.1 - - [20/Sep/2024 12:46:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:58,039 Request with ID 5685d49c for model gemma-7b received
2024-09-20 12:46:58,040 127.0.0.1 - - [20/Sep/2024 12:46:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:58,359 Request with ID 75591edd for model llama3-8b received
2024-09-20 12:46:58,359 127.0.0.1 - - [20/Sep/2024 12:46:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:58,533 Request with ID 0699dd0b for model llama3-8b received
2024-09-20 12:46:58,534 127.0.0.1 - - [20/Sep/2024 12:46:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:58,572 Request with ID 3e7ae13b for model llama3-8b received
2024-09-20 12:46:58,572 127.0.0.1 - - [20/Sep/2024 12:46:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:58,667 Request with ID e20c47fb for model llama3-8b received
2024-09-20 12:46:58,668 127.0.0.1 - - [20/Sep/2024 12:46:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:58,706 Request with ID 229054da for model llama3-8b received
2024-09-20 12:46:58,707 127.0.0.1 - - [20/Sep/2024 12:46:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:58,819 Request with ID 7e755f5a for model gemma-7b received
2024-09-20 12:46:58,819 127.0.0.1 - - [20/Sep/2024 12:46:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:59,151 Request with ID 4813cc63 for model llama3-8b received
2024-09-20 12:46:59,151 127.0.0.1 - - [20/Sep/2024 12:46:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:59,165 Request with ID 8f3f2767 for model gemma-7b received
2024-09-20 12:46:59,165 127.0.0.1 - - [20/Sep/2024 12:46:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:59,238 Request with ID 50a9eed6 for model gemma-7b received
2024-09-20 12:46:59,238 127.0.0.1 - - [20/Sep/2024 12:46:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:59,430 Request with ID 6ee92f2d for model granite-7b received
2024-09-20 12:46:59,430 127.0.0.1 - - [20/Sep/2024 12:46:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:59,524 Request with ID d9e3da3e for model llama3-8b received
2024-09-20 12:46:59,525 127.0.0.1 - - [20/Sep/2024 12:46:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:59,587 Request with ID 5740e847 for model llama3-8b received
2024-09-20 12:46:59,588 127.0.0.1 - - [20/Sep/2024 12:46:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:46:59,730 Request with ID 96aa3717 for model llama3-8b received
2024-09-20 12:46:59,730 127.0.0.1 - - [20/Sep/2024 12:46:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,143 Request with ID 32c21542 for model gemma-7b received
2024-09-20 12:47:00,144 127.0.0.1 - - [20/Sep/2024 12:47:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,151 Request with ID 2a193ccc for model gemma-7b received
2024-09-20 12:47:00,151 127.0.0.1 - - [20/Sep/2024 12:47:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,164 Request with ID f5e7862e for model granite-7b received
2024-09-20 12:47:00,164 127.0.0.1 - - [20/Sep/2024 12:47:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,237 Request with ID 91ca63c3 for model gemma-7b received
2024-09-20 12:47:00,238 127.0.0.1 - - [20/Sep/2024 12:47:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,265 Request with ID f50310f2 for model gemma-7b received
2024-09-20 12:47:00,266 127.0.0.1 - - [20/Sep/2024 12:47:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,364 Request with ID 5fb02444 for model llama3-8b received
2024-09-20 12:47:00,365 127.0.0.1 - - [20/Sep/2024 12:47:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,495 Request with ID 4d185c94 for model llama3-8b received
2024-09-20 12:47:00,495 127.0.0.1 - - [20/Sep/2024 12:47:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,556 Request with ID b2496ae5 for model gemma-7b received
2024-09-20 12:47:00,556 127.0.0.1 - - [20/Sep/2024 12:47:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,633 Request with ID 9811193b for model gemma-7b received
2024-09-20 12:47:00,633 127.0.0.1 - - [20/Sep/2024 12:47:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,683 Request with ID dffbae4f for model gemma-7b received
2024-09-20 12:47:00,684 127.0.0.1 - - [20/Sep/2024 12:47:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,698 Request with ID cfeee21c for model gemma-7b received
2024-09-20 12:47:00,698 127.0.0.1 - - [20/Sep/2024 12:47:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,844 Request with ID 4c6ed301 for model llama3-8b received
2024-09-20 12:47:00,844 127.0.0.1 - - [20/Sep/2024 12:47:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:00,868 Request with ID 3b116f00 for model gemma-7b received
2024-09-20 12:47:00,869 Moving batch for gemma-7b from incoming to running due to dynamic batch size 64
2024-09-20 12:47:00,869 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:47:01,245 Request with ID 6deac7d5 for model llama3-8b received
2024-09-20 12:47:01,245 127.0.0.1 - - [20/Sep/2024 12:47:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:01,312 Request with ID dd390eb7 for model llama3-8b received
2024-09-20 12:47:01,313 127.0.0.1 - - [20/Sep/2024 12:47:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:01,374 Request with ID bac60af2 for model granite-7b received
2024-09-20 12:47:01,375 127.0.0.1 - - [20/Sep/2024 12:47:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:01,443 Request with ID 383d1247 for model llama3-8b received
2024-09-20 12:47:01,444 127.0.0.1 - - [20/Sep/2024 12:47:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:01,473 Request with ID c3ced8de for model llama3-8b received
2024-09-20 12:47:01,473 127.0.0.1 - - [20/Sep/2024 12:47:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:01,521 Request with ID 0afb0ea7 for model llama3-8b received
2024-09-20 12:47:01,522 127.0.0.1 - - [20/Sep/2024 12:47:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:01,572 Request with ID 7ea669f5 for model gemma-7b received
2024-09-20 12:47:01,573 127.0.0.1 - - [20/Sep/2024 12:47:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:01,682 Request with ID 5404d464 for model llama3-8b received
2024-09-20 12:47:01,683 127.0.0.1 - - [20/Sep/2024 12:47:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:01,741 Request with ID 00ea6d6d for model gemma-7b received
2024-09-20 12:47:01,742 127.0.0.1 - - [20/Sep/2024 12:47:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,009 Request with ID 4f998e49 for model llama3-8b received
2024-09-20 12:47:02,010 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,079 Request with ID 6baa745b for model llama3-8b received
2024-09-20 12:47:02,080 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,182 Request with ID ecbc05bd for model llama3-8b received
2024-09-20 12:47:02,183 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,243 Request with ID 85f8aa4e for model llama3-8b received
2024-09-20 12:47:02,244 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,303 Request with ID 5be152d0 for model granite-7b received
2024-09-20 12:47:02,303 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,313 Request with ID c48ff6d8 for model llama3-8b received
2024-09-20 12:47:02,313 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,394 Processed batch: ['75a636d7', '17fcf92e', 'ab714917', '1c4df185', 'ff811648', 'f4d7e394', 'dba166d1', '03193550', '175a3bb3', '057f9592', '996e322d', '1d3a4b09', '57bcc79e', '5a533503', '0521b7dc', 'a65f96d4', '7bd928a4', 'cb4c5754', '2c5528ec', 'c41bba7c', '55416403', 'be7e24b9', '99811dca', '67bcab1d', 'abcf5868', 'a61a7342', 'c5d5fa84', 'c729d5c3', 'db009575', '6e966243', 'b9d4510a', '217ec69e', 'b41b2259', '18e62fff', 'ddf9bbd7', 'b0db33ba', 'cd716065', 'c367ad6a', '6fab5da6', '84ccae2e', 'f3e9b8a9', '05018b44', 'e67ee84a', 'dfaec8ae', '36b36628', '9cb4f1fb', '08bc1dc4', '85821067', '15828d8a', 'dcb678bf', '8ef68a2c', '71e6b039', '548af47d', '7df9e0e4', '312300d7', 'ccb66624', '30a66381', '14f38196', '6157b83b', '961af786', '47b559e1', '4a472bb2', '5177da10', 'fab533e1'] with model llama3-8b in 8.6716 seconds
2024-09-20 12:47:02,394 Saving sys info
2024-09-20 12:47:02,455 Latency for request 75a636d7 with model llama3-8b: 41.5420 seconds
2024-09-20 12:47:02,455 Saving results with gpu monitoring
2024-09-20 12:47:02,458 Latency for request 17fcf92e with model llama3-8b: 41.4460 seconds
2024-09-20 12:47:02,458 Saving results with gpu monitoring
2024-09-20 12:47:02,460 Latency for request ab714917 with model llama3-8b: 40.9990 seconds
2024-09-20 12:47:02,460 Saving results with gpu monitoring
2024-09-20 12:47:02,462 Latency for request 1c4df185 with model llama3-8b: 40.9780 seconds
2024-09-20 12:47:02,462 Saving results with gpu monitoring
2024-09-20 12:47:02,464 Latency for request ff811648 with model llama3-8b: 40.8490 seconds
2024-09-20 12:47:02,464 Saving results with gpu monitoring
2024-09-20 12:47:02,466 Latency for request f4d7e394 with model llama3-8b: 40.4900 seconds
2024-09-20 12:47:02,466 Saving results with gpu monitoring
2024-09-20 12:47:02,468 Latency for request dba166d1 with model llama3-8b: 40.3420 seconds
2024-09-20 12:47:02,468 Saving results with gpu monitoring
2024-09-20 12:47:02,470 Latency for request 03193550 with model llama3-8b: 40.3240 seconds
2024-09-20 12:47:02,470 Saving results with gpu monitoring
2024-09-20 12:47:02,472 Latency for request 175a3bb3 with model llama3-8b: 40.2690 seconds
2024-09-20 12:47:02,472 Saving results with gpu monitoring
2024-09-20 12:47:02,474 Latency for request 057f9592 with model llama3-8b: 40.2590 seconds
2024-09-20 12:47:02,475 Saving results with gpu monitoring
2024-09-20 12:47:02,477 Latency for request 996e322d with model llama3-8b: 40.1140 seconds
2024-09-20 12:47:02,477 Saving results with gpu monitoring
2024-09-20 12:47:02,480 Latency for request 1d3a4b09 with model llama3-8b: 40.0190 seconds
2024-09-20 12:47:02,480 Saving results with gpu monitoring
2024-09-20 12:47:02,482 Request with ID 9e6bb139 for model llama3-8b received
2024-09-20 12:47:02,483 Latency for request 57bcc79e with model llama3-8b: 39.8400 seconds
2024-09-20 12:47:02,483 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,483 Saving results with gpu monitoring
2024-09-20 12:47:02,486 Latency for request 5a533503 with model llama3-8b: 39.5170 seconds
2024-09-20 12:47:02,486 Saving results with gpu monitoring
2024-09-20 12:47:02,488 Latency for request 0521b7dc with model llama3-8b: 39.1410 seconds
2024-09-20 12:47:02,488 Saving results with gpu monitoring
2024-09-20 12:47:02,490 Latency for request a65f96d4 with model llama3-8b: 39.0920 seconds
2024-09-20 12:47:02,490 Saving results with gpu monitoring
2024-09-20 12:47:02,492 Latency for request 7bd928a4 with model llama3-8b: 38.9420 seconds
2024-09-20 12:47:02,492 Saving results with gpu monitoring
2024-09-20 12:47:02,494 Latency for request cb4c5754 with model llama3-8b: 38.8420 seconds
2024-09-20 12:47:02,494 Saving results with gpu monitoring
2024-09-20 12:47:02,496 Latency for request 2c5528ec with model llama3-8b: 38.7850 seconds
2024-09-20 12:47:02,496 Saving results with gpu monitoring
2024-09-20 12:47:02,499 Latency for request c41bba7c with model llama3-8b: 38.7070 seconds
2024-09-20 12:47:02,499 Saving results with gpu monitoring
2024-09-20 12:47:02,501 Latency for request 55416403 with model llama3-8b: 37.9450 seconds
2024-09-20 12:47:02,501 Saving results with gpu monitoring
2024-09-20 12:47:02,503 Latency for request be7e24b9 with model llama3-8b: 37.8180 seconds
2024-09-20 12:47:02,503 Saving results with gpu monitoring
2024-09-20 12:47:02,505 Latency for request 99811dca with model llama3-8b: 37.5860 seconds
2024-09-20 12:47:02,505 Saving results with gpu monitoring
2024-09-20 12:47:02,507 Latency for request 67bcab1d with model llama3-8b: 37.5680 seconds
2024-09-20 12:47:02,507 Saving results with gpu monitoring
2024-09-20 12:47:02,509 Latency for request abcf5868 with model llama3-8b: 37.4180 seconds
2024-09-20 12:47:02,509 Saving results with gpu monitoring
2024-09-20 12:47:02,511 Latency for request a61a7342 with model llama3-8b: 37.2900 seconds
2024-09-20 12:47:02,511 Saving results with gpu monitoring
2024-09-20 12:47:02,513 Latency for request c5d5fa84 with model llama3-8b: 37.2470 seconds
2024-09-20 12:47:02,513 Saving results with gpu monitoring
2024-09-20 12:47:02,515 Latency for request c729d5c3 with model llama3-8b: 36.9900 seconds
2024-09-20 12:47:02,515 Saving results with gpu monitoring
2024-09-20 12:47:02,517 Latency for request db009575 with model llama3-8b: 36.8320 seconds
2024-09-20 12:47:02,517 Saving results with gpu monitoring
2024-09-20 12:47:02,519 Latency for request 6e966243 with model llama3-8b: 36.6820 seconds
2024-09-20 12:47:02,519 Saving results with gpu monitoring
2024-09-20 12:47:02,521 Latency for request b9d4510a with model llama3-8b: 36.3030 seconds
2024-09-20 12:47:02,521 Saving results with gpu monitoring
2024-09-20 12:47:02,523 Latency for request 217ec69e with model llama3-8b: 36.2470 seconds
2024-09-20 12:47:02,523 Saving results with gpu monitoring
2024-09-20 12:47:02,525 Latency for request b41b2259 with model llama3-8b: 36.2030 seconds
2024-09-20 12:47:02,525 Saving results with gpu monitoring
2024-09-20 12:47:02,527 Latency for request 18e62fff with model llama3-8b: 35.7860 seconds
2024-09-20 12:47:02,527 Saving results with gpu monitoring
2024-09-20 12:47:02,529 Latency for request ddf9bbd7 with model llama3-8b: 35.6850 seconds
2024-09-20 12:47:02,529 Saving results with gpu monitoring
2024-09-20 12:47:02,532 Latency for request b0db33ba with model llama3-8b: 35.3110 seconds
2024-09-20 12:47:02,532 Saving results with gpu monitoring
2024-09-20 12:47:02,534 Latency for request cd716065 with model llama3-8b: 35.1120 seconds
2024-09-20 12:47:02,534 Saving results with gpu monitoring
2024-09-20 12:47:02,536 Latency for request c367ad6a with model llama3-8b: 34.9890 seconds
2024-09-20 12:47:02,536 Saving results with gpu monitoring
2024-09-20 12:47:02,538 Latency for request 6fab5da6 with model llama3-8b: 34.6560 seconds
2024-09-20 12:47:02,538 Saving results with gpu monitoring
2024-09-20 12:47:02,541 Latency for request 84ccae2e with model llama3-8b: 34.5880 seconds
2024-09-20 12:47:02,541 Saving results with gpu monitoring
2024-09-20 12:47:02,543 Latency for request f3e9b8a9 with model llama3-8b: 34.5760 seconds
2024-09-20 12:47:02,543 Saving results with gpu monitoring
2024-09-20 12:47:02,546 Request with ID e1e8ac50 for model gemma-7b received
2024-09-20 12:47:02,546 Latency for request 05018b44 with model llama3-8b: 34.5280 seconds
2024-09-20 12:47:02,546 Saving results with gpu monitoring
2024-09-20 12:47:02,546 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,549 Latency for request e67ee84a with model llama3-8b: 34.4500 seconds
2024-09-20 12:47:02,549 Saving results with gpu monitoring
2024-09-20 12:47:02,551 Latency for request dfaec8ae with model llama3-8b: 34.2650 seconds
2024-09-20 12:47:02,551 Saving results with gpu monitoring
2024-09-20 12:47:02,553 Latency for request 36b36628 with model llama3-8b: 34.2340 seconds
2024-09-20 12:47:02,553 Saving results with gpu monitoring
2024-09-20 12:47:02,555 Latency for request 9cb4f1fb with model llama3-8b: 34.2020 seconds
2024-09-20 12:47:02,555 Saving results with gpu monitoring
2024-09-20 12:47:02,557 Latency for request 08bc1dc4 with model llama3-8b: 34.0210 seconds
2024-09-20 12:47:02,557 Saving results with gpu monitoring
2024-09-20 12:47:02,559 Latency for request 85821067 with model llama3-8b: 33.7760 seconds
2024-09-20 12:47:02,559 Saving results with gpu monitoring
2024-09-20 12:47:02,561 Latency for request 15828d8a with model llama3-8b: 33.4290 seconds
2024-09-20 12:47:02,561 Saving results with gpu monitoring
2024-09-20 12:47:02,564 Latency for request dcb678bf with model llama3-8b: 33.0260 seconds
2024-09-20 12:47:02,564 Saving results with gpu monitoring
2024-09-20 12:47:02,566 Latency for request 8ef68a2c with model llama3-8b: 32.9940 seconds
2024-09-20 12:47:02,566 Saving results with gpu monitoring
2024-09-20 12:47:02,568 Latency for request 71e6b039 with model llama3-8b: 32.4080 seconds
2024-09-20 12:47:02,568 Saving results with gpu monitoring
2024-09-20 12:47:02,570 Latency for request 548af47d with model llama3-8b: 32.2450 seconds
2024-09-20 12:47:02,570 Saving results with gpu monitoring
2024-09-20 12:47:02,573 Latency for request 7df9e0e4 with model llama3-8b: 32.1440 seconds
2024-09-20 12:47:02,573 Saving results with gpu monitoring
2024-09-20 12:47:02,576 Request with ID cef3a48a for model llama3-8b received
2024-09-20 12:47:02,576 Latency for request 312300d7 with model llama3-8b: 32.0870 seconds
2024-09-20 12:47:02,577 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,577 Saving results with gpu monitoring
2024-09-20 12:47:02,579 Latency for request ccb66624 with model llama3-8b: 31.7220 seconds
2024-09-20 12:47:02,579 Saving results with gpu monitoring
2024-09-20 12:47:02,581 Latency for request 30a66381 with model llama3-8b: 31.6900 seconds
2024-09-20 12:47:02,581 Saving results with gpu monitoring
2024-09-20 12:47:02,584 Latency for request 14f38196 with model llama3-8b: 31.4020 seconds
2024-09-20 12:47:02,584 Saving results with gpu monitoring
2024-09-20 12:47:02,586 Latency for request 6157b83b with model llama3-8b: 31.1820 seconds
2024-09-20 12:47:02,586 Saving results with gpu monitoring
2024-09-20 12:47:02,588 Latency for request 961af786 with model llama3-8b: 30.9990 seconds
2024-09-20 12:47:02,588 Saving results with gpu monitoring
2024-09-20 12:47:02,590 Latency for request 47b559e1 with model llama3-8b: 30.9950 seconds
2024-09-20 12:47:02,590 Saving results with gpu monitoring
2024-09-20 12:47:02,592 Latency for request 4a472bb2 with model llama3-8b: 30.9320 seconds
2024-09-20 12:47:02,592 Saving results with gpu monitoring
2024-09-20 12:47:02,594 Latency for request 5177da10 with model llama3-8b: 30.2890 seconds
2024-09-20 12:47:02,594 Saving results with gpu monitoring
2024-09-20 12:47:02,596 Latency for request fab533e1 with model llama3-8b: 30.0270 seconds
2024-09-20 12:47:02,596 Saving results with gpu monitoring
2024-09-20 12:47:02,599 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,599 Next: call load_model for granite-7b
2024-09-20 12:47:02,701 Unloaded previous model
2024-09-20 12:47:02,752 Request with ID e8f7878f for model gemma-7b received
2024-09-20 12:47:02,753 Request with ID 13acf2a9 for model llama3-8b received
2024-09-20 12:47:02,754 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,755 Adjusted batch time limit for llama3-8b: 5.0000 seconds
2024-09-20 12:47:02,757 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,771 Request with ID 12915b1a for model granite-7b received
2024-09-20 12:47:02,772 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,855 Request with ID 8d22b675 for model llama3-8b received
2024-09-20 12:47:02,857 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:02,885 Request with ID 3bc7f4cd for model gemma-7b received
2024-09-20 12:47:02,888 127.0.0.1 - - [20/Sep/2024 12:47:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:03,003 Request with ID 1b05ab67 for model granite-7b received
2024-09-20 12:47:03,004 127.0.0.1 - - [20/Sep/2024 12:47:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:03,315 Request with ID ee449835 for model granite-7b received
2024-09-20 12:47:03,316 127.0.0.1 - - [20/Sep/2024 12:47:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:03,650 Request with ID 4230b8bb for model llama3-8b received
2024-09-20 12:47:03,749 127.0.0.1 - - [20/Sep/2024 12:47:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:03,755 Request with ID d9a8c2ce for model llama3-8b received
2024-09-20 12:47:03,755 127.0.0.1 - - [20/Sep/2024 12:47:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:03,856 Request with ID 2b9a9eeb for model llama3-8b received
2024-09-20 12:47:03,856 127.0.0.1 - - [20/Sep/2024 12:47:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:03,858 Request with ID 267de8b1 for model gemma-7b received
2024-09-20 12:47:03,859 127.0.0.1 - - [20/Sep/2024 12:47:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:04,076 Request with ID 9fa45d7a for model gemma-7b received
2024-09-20 12:47:04,077 127.0.0.1 - - [20/Sep/2024 12:47:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:04,157 Request with ID eb5fc6a2 for model gemma-7b received
2024-09-20 12:47:04,158 127.0.0.1 - - [20/Sep/2024 12:47:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:04,181 Request with ID f5bbb490 for model granite-7b received
2024-09-20 12:47:04,181 127.0.0.1 - - [20/Sep/2024 12:47:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:04,671 Request with ID 02daa080 for model llama3-8b received
2024-09-20 12:47:04,672 127.0.0.1 - - [20/Sep/2024 12:47:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:04,871 Request with ID 02cfd630 for model llama3-8b received
2024-09-20 12:47:04,871 127.0.0.1 - - [20/Sep/2024 12:47:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:04,900 Request with ID 97f79a0e for model llama3-8b received
2024-09-20 12:47:04,900 127.0.0.1 - - [20/Sep/2024 12:47:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:04,984 Request with ID 653df721 for model llama3-8b received
2024-09-20 12:47:04,985 127.0.0.1 - - [20/Sep/2024 12:47:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:05,005 Request with ID 94f6fc13 for model llama3-8b received
2024-09-20 12:47:05,005 127.0.0.1 - - [20/Sep/2024 12:47:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:05,037 Request with ID 61eafbc2 for model gemma-7b received
2024-09-20 12:47:05,038 127.0.0.1 - - [20/Sep/2024 12:47:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:05,169 Request with ID f9a10fea for model llama3-8b received
2024-09-20 12:47:05,169 127.0.0.1 - - [20/Sep/2024 12:47:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:05,237 Request with ID 4fdc97f4 for model llama3-8b received
2024-09-20 12:47:05,237 127.0.0.1 - - [20/Sep/2024 12:47:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:05,371 Request with ID 55c112b6 for model llama3-8b received
2024-09-20 12:47:05,371 127.0.0.1 - - [20/Sep/2024 12:47:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:05,467 Request with ID 320a8f22 for model llama3-8b received
2024-09-20 12:47:05,468 127.0.0.1 - - [20/Sep/2024 12:47:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:05,586 Request with ID 4e141915 for model llama3-8b received
2024-09-20 12:47:05,586 127.0.0.1 - - [20/Sep/2024 12:47:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:05,798 Request with ID 71a54478 for model gemma-7b received
2024-09-20 12:47:05,799 127.0.0.1 - - [20/Sep/2024 12:47:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:05,881 Request with ID 7b32fd36 for model llama3-8b received
2024-09-20 12:47:05,882 127.0.0.1 - - [20/Sep/2024 12:47:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:06,365 Request with ID 33c0718a for model llama3-8b received
2024-09-20 12:47:06,365 127.0.0.1 - - [20/Sep/2024 12:47:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:06,604 Request with ID 0a16f383 for model llama3-8b received
2024-09-20 12:47:06,604 127.0.0.1 - - [20/Sep/2024 12:47:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:06,624 Request with ID 3af59e18 for model llama3-8b received
2024-09-20 12:47:06,625 127.0.0.1 - - [20/Sep/2024 12:47:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:06,673 Request with ID 514ce88a for model llama3-8b received
2024-09-20 12:47:06,674 127.0.0.1 - - [20/Sep/2024 12:47:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:06,675 Request with ID b0845003 for model granite-7b received
2024-09-20 12:47:06,675 127.0.0.1 - - [20/Sep/2024 12:47:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:06,813 Request with ID cf60ec86 for model llama3-8b received
2024-09-20 12:47:06,813 127.0.0.1 - - [20/Sep/2024 12:47:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:06,958 Request with ID ab08f3d2 for model llama3-8b received
2024-09-20 12:47:06,958 127.0.0.1 - - [20/Sep/2024 12:47:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:07,022 Request with ID be02205e for model gemma-7b received
2024-09-20 12:47:07,023 127.0.0.1 - - [20/Sep/2024 12:47:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:07,072 Request with ID b6f645cc for model llama3-8b received
2024-09-20 12:47:07,073 127.0.0.1 - - [20/Sep/2024 12:47:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:07,292 Request with ID b0c9e203 for model gemma-7b received
2024-09-20 12:47:07,292 127.0.0.1 - - [20/Sep/2024 12:47:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:07,402 Request with ID 1cc5876f for model llama3-8b received
2024-09-20 12:47:07,404 127.0.0.1 - - [20/Sep/2024 12:47:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:07,406 Request with ID c9db68c5 for model gemma-7b received
2024-09-20 12:47:07,406 127.0.0.1 - - [20/Sep/2024 12:47:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:07,424 Request with ID 5378f31c for model granite-7b received
2024-09-20 12:47:07,425 127.0.0.1 - - [20/Sep/2024 12:47:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:07,515 Request with ID a792b56c for model llama3-8b received
2024-09-20 12:47:07,516 127.0.0.1 - - [20/Sep/2024 12:47:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:07,528 Request with ID 6d340653 for model llama3-8b received
2024-09-20 12:47:07,528 127.0.0.1 - - [20/Sep/2024 12:47:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:07,533 Request with ID df4d73d6 for model llama3-8b received
2024-09-20 12:47:07,533 127.0.0.1 - - [20/Sep/2024 12:47:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:07,627 Request with ID 7b246cea for model gemma-7b received
2024-09-20 12:47:07,628 127.0.0.1 - - [20/Sep/2024 12:47:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:07,730 Request with ID 7e624062 for model llama3-8b received
2024-09-20 12:47:07,731 127.0.0.1 - - [20/Sep/2024 12:47:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:07,870 Request with ID 3d73ce6c for model llama3-8b received
2024-09-20 12:47:07,871 127.0.0.1 - - [20/Sep/2024 12:47:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:08,028 Request with ID 0b533008 for model llama3-8b received
2024-09-20 12:47:08,029 127.0.0.1 - - [20/Sep/2024 12:47:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:08,044 Request with ID 38355afe for model llama3-8b received
2024-09-20 12:47:08,045 127.0.0.1 - - [20/Sep/2024 12:47:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:08,073 Request with ID a127f5c8 for model gemma-7b received
2024-09-20 12:47:08,073 127.0.0.1 - - [20/Sep/2024 12:47:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:08,166 Request with ID 4ffd19e0 for model llama3-8b received
2024-09-20 12:47:08,167 127.0.0.1 - - [20/Sep/2024 12:47:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:08,439 Request with ID 2f35fd7b for model gemma-7b received
2024-09-20 12:47:08,440 127.0.0.1 - - [20/Sep/2024 12:47:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:08,543 Request with ID 94cff25a for model llama3-8b received
2024-09-20 12:47:08,543 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:47:08,544 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:47:08,557 Request with ID 4796a08d for model llama3-8b received
2024-09-20 12:47:08,557 127.0.0.1 - - [20/Sep/2024 12:47:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:08,697 Request with ID bc27d6d3 for model llama3-8b received
2024-09-20 12:47:08,698 127.0.0.1 - - [20/Sep/2024 12:47:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:08,718 Request with ID 4067f9ef for model llama3-8b received
2024-09-20 12:47:08,719 127.0.0.1 - - [20/Sep/2024 12:47:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:08,737 Request with ID 7bd76149 for model granite-7b received
2024-09-20 12:47:08,738 127.0.0.1 - - [20/Sep/2024 12:47:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:08,919 Request with ID 25820009 for model llama3-8b received
2024-09-20 12:47:08,920 127.0.0.1 - - [20/Sep/2024 12:47:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:09,214 Request with ID 62171d7c for model llama3-8b received
2024-09-20 12:47:09,215 127.0.0.1 - - [20/Sep/2024 12:47:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:09,216 Request with ID fedead94 for model llama3-8b received
2024-09-20 12:47:09,217 127.0.0.1 - - [20/Sep/2024 12:47:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:09,234 Request with ID e09812b2 for model llama3-8b received
2024-09-20 12:47:09,235 127.0.0.1 - - [20/Sep/2024 12:47:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:09,515 Request with ID 87d703b5 for model granite-7b received
2024-09-20 12:47:09,516 127.0.0.1 - - [20/Sep/2024 12:47:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:09,646 Request with ID 8865978a for model llama3-8b received
2024-09-20 12:47:09,647 127.0.0.1 - - [20/Sep/2024 12:47:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:09,799 Request with ID 46f2648e for model granite-7b received
2024-09-20 12:47:09,800 127.0.0.1 - - [20/Sep/2024 12:47:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:09,826 Request with ID a1c5eaeb for model gemma-7b received
2024-09-20 12:47:09,827 127.0.0.1 - - [20/Sep/2024 12:47:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:10,084 Request with ID 7526e2d7 for model llama3-8b received
2024-09-20 12:47:10,085 127.0.0.1 - - [20/Sep/2024 12:47:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:10,092 Request with ID 0d5d471a for model granite-7b received
2024-09-20 12:47:10,092 127.0.0.1 - - [20/Sep/2024 12:47:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:10,095 Request with ID 605beae8 for model gemma-7b received
2024-09-20 12:47:10,096 127.0.0.1 - - [20/Sep/2024 12:47:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:10,335 Request with ID 212d3485 for model llama3-8b received
2024-09-20 12:47:10,336 127.0.0.1 - - [20/Sep/2024 12:47:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:10,382 Request with ID 5b7f3dd5 for model llama3-8b received
2024-09-20 12:47:10,382 127.0.0.1 - - [20/Sep/2024 12:47:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:10,534 Request with ID 5428b655 for model gemma-7b received
2024-09-20 12:47:10,534 127.0.0.1 - - [20/Sep/2024 12:47:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:10,727 Request with ID 3bb6ec57 for model granite-7b received
2024-09-20 12:47:10,727 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:47:10,727 Dynamic batch size condition met for model granite-7b
2024-09-20 12:47:10,967 Request with ID 294422ad for model gemma-7b received
2024-09-20 12:47:10,968 127.0.0.1 - - [20/Sep/2024 12:47:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:11,006 Request with ID 3a71e551 for model gemma-7b received
2024-09-20 12:47:11,006 127.0.0.1 - - [20/Sep/2024 12:47:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:11,238 Request with ID 48d63299 for model llama3-8b received
2024-09-20 12:47:11,239 127.0.0.1 - - [20/Sep/2024 12:47:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:11,319 Request with ID 21612519 for model llama3-8b received
2024-09-20 12:47:11,320 127.0.0.1 - - [20/Sep/2024 12:47:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:11,597 Request with ID a0f4d62e for model llama3-8b received
2024-09-20 12:47:11,598 127.0.0.1 - - [20/Sep/2024 12:47:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:11,754 Request with ID b42250d1 for model llama3-8b received
2024-09-20 12:47:11,755 127.0.0.1 - - [20/Sep/2024 12:47:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:12,145 Request with ID 479dda91 for model gemma-7b received
2024-09-20 12:47:12,145 127.0.0.1 - - [20/Sep/2024 12:47:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:12,187 Request with ID ab907d1a for model llama3-8b received
2024-09-20 12:47:12,188 127.0.0.1 - - [20/Sep/2024 12:47:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:12,283 Request with ID b06e02e9 for model granite-7b received
2024-09-20 12:47:12,284 127.0.0.1 - - [20/Sep/2024 12:47:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:12,413 Request with ID 86dc8c21 for model gemma-7b received
2024-09-20 12:47:12,414 127.0.0.1 - - [20/Sep/2024 12:47:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:12,605 Request with ID 3f337dfc for model llama3-8b received
2024-09-20 12:47:12,605 127.0.0.1 - - [20/Sep/2024 12:47:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:12,630 Request with ID a2f311e1 for model llama3-8b received
2024-09-20 12:47:12,631 127.0.0.1 - - [20/Sep/2024 12:47:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:12,639 Request with ID f6c0d13a for model llama3-8b received
2024-09-20 12:47:12,640 127.0.0.1 - - [20/Sep/2024 12:47:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:12,648 Request with ID 6f16163a for model llama3-8b received
2024-09-20 12:47:12,649 127.0.0.1 - - [20/Sep/2024 12:47:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:12,707 Request with ID b940f674 for model llama3-8b received
2024-09-20 12:47:12,708 127.0.0.1 - - [20/Sep/2024 12:47:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:12,733 Request with ID efdfe3c9 for model llama3-8b received
2024-09-20 12:47:12,734 127.0.0.1 - - [20/Sep/2024 12:47:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:12,796 Request with ID 42fd2cd8 for model granite-7b received
2024-09-20 12:47:12,796 127.0.0.1 - - [20/Sep/2024 12:47:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:12,869 Request with ID 0d31fe23 for model gemma-7b received
2024-09-20 12:47:12,870 127.0.0.1 - - [20/Sep/2024 12:47:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:13,253 Request with ID efdab88d for model llama3-8b received
2024-09-20 12:47:13,254 127.0.0.1 - - [20/Sep/2024 12:47:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:13,298 Request with ID 1661958b for model llama3-8b received
2024-09-20 12:47:13,299 127.0.0.1 - - [20/Sep/2024 12:47:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:13,441 Request with ID 4f3170f9 for model llama3-8b received
2024-09-20 12:47:13,441 127.0.0.1 - - [20/Sep/2024 12:47:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:13,465 Request with ID 8d6972ba for model llama3-8b received
2024-09-20 12:47:13,466 127.0.0.1 - - [20/Sep/2024 12:47:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:13,671 Request with ID 06f85879 for model llama3-8b received
2024-09-20 12:47:13,672 127.0.0.1 - - [20/Sep/2024 12:47:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:13,755 Request with ID 1ce146bf for model granite-7b received
2024-09-20 12:47:13,755 127.0.0.1 - - [20/Sep/2024 12:47:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:13,819 Request with ID cc3e2f3a for model gemma-7b received
2024-09-20 12:47:13,819 127.0.0.1 - - [20/Sep/2024 12:47:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:13,869 Request with ID 22e9eec2 for model gemma-7b received
2024-09-20 12:47:13,869 127.0.0.1 - - [20/Sep/2024 12:47:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:13,931 Request with ID 58567354 for model granite-7b received
2024-09-20 12:47:13,931 127.0.0.1 - - [20/Sep/2024 12:47:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:13,991 Request with ID 350fb1c9 for model gemma-7b received
2024-09-20 12:47:13,992 127.0.0.1 - - [20/Sep/2024 12:47:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:14,066 Request with ID 94b8ea6f for model llama3-8b received
2024-09-20 12:47:14,067 127.0.0.1 - - [20/Sep/2024 12:47:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:14,100 Request with ID c73ce597 for model gemma-7b received
2024-09-20 12:47:14,100 127.0.0.1 - - [20/Sep/2024 12:47:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:14,349 Request with ID 50c038a2 for model llama3-8b received
2024-09-20 12:47:14,350 127.0.0.1 - - [20/Sep/2024 12:47:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:14,410 Request with ID 050ab216 for model llama3-8b received
2024-09-20 12:47:14,410 127.0.0.1 - - [20/Sep/2024 12:47:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:14,648 Request with ID 33dbfa44 for model gemma-7b received
2024-09-20 12:47:14,648 127.0.0.1 - - [20/Sep/2024 12:47:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:14,721 Request with ID cf999fad for model gemma-7b received
2024-09-20 12:47:14,721 127.0.0.1 - - [20/Sep/2024 12:47:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:14,947 Request with ID b9517a23 for model llama3-8b received
2024-09-20 12:47:14,948 127.0.0.1 - - [20/Sep/2024 12:47:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:14,987 Request with ID 68f7a9db for model llama3-8b received
2024-09-20 12:47:14,987 127.0.0.1 - - [20/Sep/2024 12:47:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:15,001 Request with ID ffbaa9eb for model llama3-8b received
2024-09-20 12:47:15,001 127.0.0.1 - - [20/Sep/2024 12:47:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:15,345 Request with ID 98edc882 for model llama3-8b received
2024-09-20 12:47:15,346 127.0.0.1 - - [20/Sep/2024 12:47:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:15,359 Request with ID bf73f7f7 for model llama3-8b received
2024-09-20 12:47:15,360 127.0.0.1 - - [20/Sep/2024 12:47:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:15,378 Request with ID 8f20bd6c for model llama3-8b received
2024-09-20 12:47:15,379 127.0.0.1 - - [20/Sep/2024 12:47:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:15,488 Request with ID 80518da5 for model granite-7b received
2024-09-20 12:47:15,489 127.0.0.1 - - [20/Sep/2024 12:47:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:15,492 Request with ID c9952ffd for model llama3-8b received
2024-09-20 12:47:15,493 127.0.0.1 - - [20/Sep/2024 12:47:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:15,500 Request with ID 6465e54e for model gemma-7b received
2024-09-20 12:47:15,501 127.0.0.1 - - [20/Sep/2024 12:47:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:15,699 Request with ID 5bb83328 for model llama3-8b received
2024-09-20 12:47:15,699 127.0.0.1 - - [20/Sep/2024 12:47:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:15,711 Request with ID 23690661 for model llama3-8b received
2024-09-20 12:47:15,711 127.0.0.1 - - [20/Sep/2024 12:47:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:15,820 Request with ID 3c5007b6 for model llama3-8b received
2024-09-20 12:47:15,821 127.0.0.1 - - [20/Sep/2024 12:47:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:16,035 Request with ID b358c378 for model gemma-7b received
2024-09-20 12:47:16,035 127.0.0.1 - - [20/Sep/2024 12:47:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:16,161 Request with ID 2012847f for model gemma-7b received
2024-09-20 12:47:16,162 127.0.0.1 - - [20/Sep/2024 12:47:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:16,191 Request with ID 243ddb27 for model llama3-8b received
2024-09-20 12:47:16,192 127.0.0.1 - - [20/Sep/2024 12:47:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:16,328 Request with ID 3625e437 for model llama3-8b received
2024-09-20 12:47:16,328 127.0.0.1 - - [20/Sep/2024 12:47:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:16,434 Request with ID 5189bd96 for model gemma-7b received
2024-09-20 12:47:16,435 127.0.0.1 - - [20/Sep/2024 12:47:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:16,619 Request with ID 23bf8cbe for model llama3-8b received
2024-09-20 12:47:16,619 127.0.0.1 - - [20/Sep/2024 12:47:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:16,648 Request with ID 6a5756f8 for model gemma-7b received
2024-09-20 12:47:16,649 127.0.0.1 - - [20/Sep/2024 12:47:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:16,764 Request with ID 32365d34 for model gemma-7b received
2024-09-20 12:47:16,766 Request with ID 4e9167e3 for model gemma-7b received
2024-09-20 12:47:16,766 127.0.0.1 - - [20/Sep/2024 12:47:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:16,767 127.0.0.1 - - [20/Sep/2024 12:47:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:16,961 Request with ID 5571e6dd for model llama3-8b received
2024-09-20 12:47:16,961 127.0.0.1 - - [20/Sep/2024 12:47:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:16,969 Request with ID 552f0199 for model llama3-8b received
2024-09-20 12:47:16,969 127.0.0.1 - - [20/Sep/2024 12:47:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,090 Request with ID 364b044a for model gemma-7b received
2024-09-20 12:47:17,090 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,136 Request with ID abaa69b6 for model granite-7b received
2024-09-20 12:47:17,137 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,172 Request with ID ec992b13 for model llama3-8b received
2024-09-20 12:47:17,173 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,322 Request with ID ef6f9389 for model llama3-8b received
2024-09-20 12:47:17,323 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,354 Request with ID f42c9cbc for model llama3-8b received
2024-09-20 12:47:17,355 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,436 Request with ID d56265ed for model llama3-8b received
2024-09-20 12:47:17,437 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,500 Request with ID cd86d278 for model llama3-8b received
2024-09-20 12:47:17,501 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,549 Request with ID f4b9ae86 for model llama3-8b received
2024-09-20 12:47:17,550 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,616 Request with ID c5c7b931 for model granite-7b received
2024-09-20 12:47:17,617 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,752 Request with ID aea7eafb for model llama3-8b received
2024-09-20 12:47:17,752 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,767 Request with ID bcc9358b for model llama3-8b received
2024-09-20 12:47:17,768 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,944 Request with ID af6ebb51 for model llama3-8b received
2024-09-20 12:47:17,944 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,948 Request with ID 24c252ed for model llama3-8b received
2024-09-20 12:47:17,950 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,981 Request with ID 5f53d5a1 for model gemma-7b received
2024-09-20 12:47:17,981 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:17,995 Request with ID c12d6dd7 for model granite-7b received
2024-09-20 12:47:17,995 127.0.0.1 - - [20/Sep/2024 12:47:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:18,082 Request with ID f3bea84b for model llama3-8b received
2024-09-20 12:47:18,083 127.0.0.1 - - [20/Sep/2024 12:47:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:18,088 Request with ID 1ccd9f69 for model granite-7b received
2024-09-20 12:47:18,089 127.0.0.1 - - [20/Sep/2024 12:47:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:18,325 Request with ID e798b266 for model llama3-8b received
2024-09-20 12:47:18,326 127.0.0.1 - - [20/Sep/2024 12:47:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:18,366 Request with ID 0329c4c6 for model llama3-8b received
2024-09-20 12:47:18,367 127.0.0.1 - - [20/Sep/2024 12:47:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:18,389 Request with ID 568a9531 for model llama3-8b received
2024-09-20 12:47:18,389 127.0.0.1 - - [20/Sep/2024 12:47:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:18,574 Request with ID efb9ea37 for model llama3-8b received
2024-09-20 12:47:18,575 127.0.0.1 - - [20/Sep/2024 12:47:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:18,606 Request with ID d5c347f3 for model llama3-8b received
2024-09-20 12:47:18,607 127.0.0.1 - - [20/Sep/2024 12:47:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:18,683 Request with ID ada688cb for model gemma-7b received
2024-09-20 12:47:18,683 127.0.0.1 - - [20/Sep/2024 12:47:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:18,709 Request with ID 1b01484c for model llama3-8b received
2024-09-20 12:47:18,709 127.0.0.1 - - [20/Sep/2024 12:47:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:18,713 Request with ID 826c7786 for model llama3-8b received
2024-09-20 12:47:18,714 127.0.0.1 - - [20/Sep/2024 12:47:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:18,928 Request with ID 8543be40 for model llama3-8b received
2024-09-20 12:47:18,929 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:47:18,929 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:47:18,984 Request with ID f1a8a195 for model llama3-8b received
2024-09-20 12:47:18,985 127.0.0.1 - - [20/Sep/2024 12:47:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:19,210 Request with ID 2c68025f for model llama3-8b received
2024-09-20 12:47:19,210 127.0.0.1 - - [20/Sep/2024 12:47:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:19,310 Request with ID cb220a5c for model llama3-8b received
2024-09-20 12:47:19,311 127.0.0.1 - - [20/Sep/2024 12:47:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:19,414 Request with ID 5e52d118 for model llama3-8b received
2024-09-20 12:47:19,415 127.0.0.1 - - [20/Sep/2024 12:47:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:19,425 Request with ID 907b529a for model llama3-8b received
2024-09-20 12:47:19,426 127.0.0.1 - - [20/Sep/2024 12:47:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:19,782 Request with ID 3b8f4d58 for model llama3-8b received
2024-09-20 12:47:19,783 127.0.0.1 - - [20/Sep/2024 12:47:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:19,876 Request with ID 1e3cfca1 for model llama3-8b received
2024-09-20 12:47:19,877 127.0.0.1 - - [20/Sep/2024 12:47:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:19,979 Request with ID d71171c2 for model granite-7b received
2024-09-20 12:47:19,980 127.0.0.1 - - [20/Sep/2024 12:47:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,072 Request with ID e1de93fd for model gemma-7b received
2024-09-20 12:47:20,073 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,106 Request with ID 67206bdf for model gemma-7b received
2024-09-20 12:47:20,106 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,173 Request with ID 3a49435b for model llama3-8b received
2024-09-20 12:47:20,174 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,234 Request with ID 1a52646f for model gemma-7b received
2024-09-20 12:47:20,235 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,309 Request with ID 4575e3b6 for model llama3-8b received
2024-09-20 12:47:20,309 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,315 Request with ID 3d7f01b9 for model granite-7b received
2024-09-20 12:47:20,315 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,328 Request with ID bad86cc5 for model llama3-8b received
2024-09-20 12:47:20,329 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,388 Request with ID a4bf6f55 for model llama3-8b received
2024-09-20 12:47:20,388 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,424 Request with ID ea14aadf for model llama3-8b received
2024-09-20 12:47:20,424 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,459 Request with ID 5abe6e2d for model llama3-8b received
2024-09-20 12:47:20,459 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,673 Request with ID 1318c9fb for model llama3-8b received
2024-09-20 12:47:20,673 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,743 Request with ID b9649e41 for model llama3-8b received
2024-09-20 12:47:20,743 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,758 Request with ID e5bb896d for model gemma-7b received
2024-09-20 12:47:20,758 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-20 12:47:20,758 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:47:20,890 Request with ID e0c65216 for model llama3-8b received
2024-09-20 12:47:20,891 127.0.0.1 - - [20/Sep/2024 12:47:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:20,972 Loaded model granite-7b
2024-09-20 12:47:20,975 Batch processing started for model granite-7b
2024-09-20 12:47:21,018 Request with ID 0b8ac91a for model llama3-8b received
2024-09-20 12:47:21,018 127.0.0.1 - - [20/Sep/2024 12:47:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:21,331 Request with ID c79fc487 for model granite-7b received
2024-09-20 12:47:21,331 Request with ID 43984ba9 for model llama3-8b received
2024-09-20 12:47:21,332 127.0.0.1 - - [20/Sep/2024 12:47:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:21,332 127.0.0.1 - - [20/Sep/2024 12:47:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:21,538 Request with ID f5c5a68e for model gemma-7b received
2024-09-20 12:47:21,539 127.0.0.1 - - [20/Sep/2024 12:47:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:21,588 Request with ID 3d075bb1 for model gemma-7b received
2024-09-20 12:47:21,588 127.0.0.1 - - [20/Sep/2024 12:47:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:21,601 Request with ID e155e800 for model llama3-8b received
2024-09-20 12:47:21,602 127.0.0.1 - - [20/Sep/2024 12:47:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:21,609 Request with ID 029dc630 for model llama3-8b received
2024-09-20 12:47:21,610 127.0.0.1 - - [20/Sep/2024 12:47:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:21,722 Request with ID 457bf2f1 for model llama3-8b received
2024-09-20 12:47:21,723 127.0.0.1 - - [20/Sep/2024 12:47:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:21,943 Request with ID a9fb51e8 for model granite-7b received
2024-09-20 12:47:21,943 127.0.0.1 - - [20/Sep/2024 12:47:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:22,046 Request with ID 1866d588 for model gemma-7b received
2024-09-20 12:47:22,047 127.0.0.1 - - [20/Sep/2024 12:47:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:22,150 Request with ID fe183078 for model llama3-8b received
2024-09-20 12:47:22,150 127.0.0.1 - - [20/Sep/2024 12:47:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:22,156 Request with ID c6e4e113 for model llama3-8b received
2024-09-20 12:47:22,156 127.0.0.1 - - [20/Sep/2024 12:47:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:22,330 Request with ID a9b8f51f for model gemma-7b received
2024-09-20 12:47:22,330 127.0.0.1 - - [20/Sep/2024 12:47:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:22,398 Request with ID 4cd6d918 for model granite-7b received
2024-09-20 12:47:22,398 127.0.0.1 - - [20/Sep/2024 12:47:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:22,411 Request with ID da56339a for model gemma-7b received
2024-09-20 12:47:22,412 127.0.0.1 - - [20/Sep/2024 12:47:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:22,477 Request with ID 8104a417 for model llama3-8b received
2024-09-20 12:47:22,477 127.0.0.1 - - [20/Sep/2024 12:47:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:22,666 Request with ID 3dc28813 for model llama3-8b received
2024-09-20 12:47:22,666 127.0.0.1 - - [20/Sep/2024 12:47:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:22,719 Request with ID ab707bf7 for model llama3-8b received
2024-09-20 12:47:22,719 127.0.0.1 - - [20/Sep/2024 12:47:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:22,919 Request with ID 5affc7c7 for model llama3-8b received
2024-09-20 12:47:22,920 127.0.0.1 - - [20/Sep/2024 12:47:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,082 Request with ID e73422f2 for model llama3-8b received
2024-09-20 12:47:23,082 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,169 Request with ID e6f9ce33 for model llama3-8b received
2024-09-20 12:47:23,170 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,208 Request with ID 4479cbbb for model gemma-7b received
2024-09-20 12:47:23,209 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,212 Request with ID 7092e011 for model llama3-8b received
2024-09-20 12:47:23,213 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,261 Request with ID 51f898aa for model gemma-7b received
2024-09-20 12:47:23,261 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,484 Request with ID 4b80ac08 for model granite-7b received
2024-09-20 12:47:23,484 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,515 Processed batch: ['de8b6cec', '695c9e43', 'e9a1cfaf', '9d37645a', '223c2e42', 'a9dd2d89', '115da18c', '366a5b88', 'db722e9d', '2893a93f', '15d14533', '9bd1d4d8', '48daca95', 'a443d163', '09d3b3bb', 'cece2f14'] with model granite-7b in 2.5403 seconds
2024-09-20 12:47:23,515 Saving sys info
2024-09-20 12:47:23,552 Latency for request de8b6cec with model granite-7b: 43.7760 seconds
2024-09-20 12:47:23,552 Saving results with gpu monitoring
2024-09-20 12:47:23,555 Latency for request 695c9e43 with model granite-7b: 43.7230 seconds
2024-09-20 12:47:23,555 Saving results with gpu monitoring
2024-09-20 12:47:23,557 Latency for request e9a1cfaf with model granite-7b: 43.5850 seconds
2024-09-20 12:47:23,557 Saving results with gpu monitoring
2024-09-20 12:47:23,559 Latency for request 9d37645a with model granite-7b: 41.9220 seconds
2024-09-20 12:47:23,559 Saving results with gpu monitoring
2024-09-20 12:47:23,561 Latency for request 223c2e42 with model granite-7b: 41.8510 seconds
2024-09-20 12:47:23,561 Saving results with gpu monitoring
2024-09-20 12:47:23,563 Latency for request a9dd2d89 with model granite-7b: 41.0570 seconds
2024-09-20 12:47:23,563 Saving results with gpu monitoring
2024-09-20 12:47:23,565 Latency for request 115da18c with model granite-7b: 40.5920 seconds
2024-09-20 12:47:23,565 Saving results with gpu monitoring
2024-09-20 12:47:23,567 Latency for request 366a5b88 with model granite-7b: 39.5300 seconds
2024-09-20 12:47:23,567 Saving results with gpu monitoring
2024-09-20 12:47:23,569 Latency for request db722e9d with model granite-7b: 39.3690 seconds
2024-09-20 12:47:23,569 Saving results with gpu monitoring
2024-09-20 12:47:23,571 Latency for request 2893a93f with model granite-7b: 37.9600 seconds
2024-09-20 12:47:23,571 Saving results with gpu monitoring
2024-09-20 12:47:23,573 Latency for request 15d14533 with model granite-7b: 36.0510 seconds
2024-09-20 12:47:23,573 Saving results with gpu monitoring
2024-09-20 12:47:23,575 Latency for request 9bd1d4d8 with model granite-7b: 35.4150 seconds
2024-09-20 12:47:23,575 Saving results with gpu monitoring
2024-09-20 12:47:23,577 Latency for request 48daca95 with model granite-7b: 33.6910 seconds
2024-09-20 12:47:23,577 Saving results with gpu monitoring
2024-09-20 12:47:23,579 Latency for request a443d163 with model granite-7b: 30.2770 seconds
2024-09-20 12:47:23,579 Saving results with gpu monitoring
2024-09-20 12:47:23,581 Latency for request 09d3b3bb with model granite-7b: 28.9410 seconds
2024-09-20 12:47:23,581 Saving results with gpu monitoring
2024-09-20 12:47:23,583 Latency for request cece2f14 with model granite-7b: 28.7690 seconds
2024-09-20 12:47:23,583 Saving results with gpu monitoring
2024-09-20 12:47:23,585 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,586 Next: call load_model for llama3-8b
2024-09-20 12:47:23,589 Request with ID a608de53 for model granite-7b received
2024-09-20 12:47:23,589 Adjusted batch time limit for granite-7b: 5.0000 seconds
2024-09-20 12:47:23,589 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:47:23,589 Dynamic batch size condition met for model granite-7b
2024-09-20 12:47:23,681 Unloaded previous model
2024-09-20 12:47:23,683 Request with ID 9bbd193d for model llama3-8b received
2024-09-20 12:47:23,684 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,901 Request with ID b3717367 for model llama3-8b received
2024-09-20 12:47:23,902 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,905 Request with ID d8327046 for model llama3-8b received
2024-09-20 12:47:23,906 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,909 Request with ID fd4cf0a3 for model gemma-7b received
2024-09-20 12:47:23,910 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,911 Request with ID 54b26827 for model llama3-8b received
2024-09-20 12:47:23,912 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,913 Request with ID b1c3d9bc for model gemma-7b received
2024-09-20 12:47:23,913 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,915 Request with ID 437c332b for model llama3-8b received
2024-09-20 12:47:23,916 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,967 Request with ID a7337cd2 for model gemma-7b received
2024-09-20 12:47:23,970 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:23,983 Request with ID 5d2f4780 for model gemma-7b received
2024-09-20 12:47:23,984 127.0.0.1 - - [20/Sep/2024 12:47:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:24,230 Request with ID ab0d613b for model llama3-8b received
2024-09-20 12:47:24,235 127.0.0.1 - - [20/Sep/2024 12:47:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:24,361 Request with ID bb106906 for model llama3-8b received
2024-09-20 12:47:24,370 127.0.0.1 - - [20/Sep/2024 12:47:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:24,371 Request with ID cf9286b7 for model gemma-7b received
2024-09-20 12:47:24,374 127.0.0.1 - - [20/Sep/2024 12:47:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:24,771 Request with ID 4451da35 for model granite-7b received
2024-09-20 12:47:24,773 127.0.0.1 - - [20/Sep/2024 12:47:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:25,016 Request with ID da79dfde for model llama3-8b received
2024-09-20 12:47:25,016 127.0.0.1 - - [20/Sep/2024 12:47:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:25,033 Request with ID fb31c48f for model llama3-8b received
2024-09-20 12:47:25,034 127.0.0.1 - - [20/Sep/2024 12:47:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:25,181 Request with ID 5e2de6b2 for model llama3-8b received
2024-09-20 12:47:25,181 127.0.0.1 - - [20/Sep/2024 12:47:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:25,225 Request with ID 48ffc046 for model gemma-7b received
2024-09-20 12:47:25,226 127.0.0.1 - - [20/Sep/2024 12:47:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:25,248 Request with ID b14642ea for model gemma-7b received
2024-09-20 12:47:25,248 127.0.0.1 - - [20/Sep/2024 12:47:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:25,280 Request with ID a4f364d6 for model llama3-8b received
2024-09-20 12:47:25,281 127.0.0.1 - - [20/Sep/2024 12:47:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:25,361 Request with ID 7469cc65 for model llama3-8b received
2024-09-20 12:47:25,362 127.0.0.1 - - [20/Sep/2024 12:47:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:26,180 Request with ID 06c0aafc for model llama3-8b received
2024-09-20 12:47:26,181 127.0.0.1 - - [20/Sep/2024 12:47:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:26,249 Request with ID 7bf44a4f for model gemma-7b received
2024-09-20 12:47:26,249 127.0.0.1 - - [20/Sep/2024 12:47:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:26,408 Request with ID ec81b81a for model llama3-8b received
2024-09-20 12:47:26,408 127.0.0.1 - - [20/Sep/2024 12:47:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:26,425 Request with ID e8c9663b for model llama3-8b received
2024-09-20 12:47:26,426 127.0.0.1 - - [20/Sep/2024 12:47:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:26,665 Request with ID da317fc5 for model llama3-8b received
2024-09-20 12:47:26,666 127.0.0.1 - - [20/Sep/2024 12:47:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:26,908 Request with ID ffd0699b for model gemma-7b received
2024-09-20 12:47:26,909 127.0.0.1 - - [20/Sep/2024 12:47:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:26,971 Request with ID b9fdc24f for model gemma-7b received
2024-09-20 12:47:26,972 127.0.0.1 - - [20/Sep/2024 12:47:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,131 Request with ID 292e8fca for model llama3-8b received
2024-09-20 12:47:27,132 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,134 Request with ID bd5cf57f for model gemma-7b received
2024-09-20 12:47:27,135 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,199 Request with ID 89a220b7 for model llama3-8b received
2024-09-20 12:47:27,199 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,268 Request with ID a210b003 for model gemma-7b received
2024-09-20 12:47:27,269 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,303 Request with ID 0eb155aa for model llama3-8b received
2024-09-20 12:47:27,304 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,399 Request with ID 8225a1f7 for model llama3-8b received
2024-09-20 12:47:27,400 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,487 Request with ID 8859e2fd for model llama3-8b received
2024-09-20 12:47:27,488 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,549 Request with ID 27bde919 for model llama3-8b received
2024-09-20 12:47:27,550 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,754 Request with ID e4341362 for model llama3-8b received
2024-09-20 12:47:27,755 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,756 Request with ID 2ddce967 for model llama3-8b received
2024-09-20 12:47:27,757 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,777 Request with ID deba1a6f for model gemma-7b received
2024-09-20 12:47:27,778 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,805 Request with ID bb949142 for model llama3-8b received
2024-09-20 12:47:27,806 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,879 Request with ID a2fb341f for model llama3-8b received
2024-09-20 12:47:27,879 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:27,881 Request with ID 8d4965a9 for model llama3-8b received
2024-09-20 12:47:27,882 127.0.0.1 - - [20/Sep/2024 12:47:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:28,012 Request with ID 88268731 for model llama3-8b received
2024-09-20 12:47:28,013 127.0.0.1 - - [20/Sep/2024 12:47:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:28,117 Request with ID 83c44840 for model llama3-8b received
2024-09-20 12:47:28,118 127.0.0.1 - - [20/Sep/2024 12:47:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:28,150 Request with ID 0277a353 for model llama3-8b received
2024-09-20 12:47:28,150 127.0.0.1 - - [20/Sep/2024 12:47:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:28,310 Request with ID 29bf5379 for model gemma-7b received
2024-09-20 12:47:28,310 127.0.0.1 - - [20/Sep/2024 12:47:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:28,835 Request with ID f4d89df9 for model granite-7b received
2024-09-20 12:47:28,836 127.0.0.1 - - [20/Sep/2024 12:47:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:28,971 Request with ID 2e370431 for model llama3-8b received
2024-09-20 12:47:28,972 127.0.0.1 - - [20/Sep/2024 12:47:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:28,978 Request with ID a4009115 for model llama3-8b received
2024-09-20 12:47:28,979 127.0.0.1 - - [20/Sep/2024 12:47:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:29,128 Request with ID aafa6242 for model llama3-8b received
2024-09-20 12:47:29,129 127.0.0.1 - - [20/Sep/2024 12:47:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:29,317 Request with ID e96c750b for model granite-7b received
2024-09-20 12:47:29,318 127.0.0.1 - - [20/Sep/2024 12:47:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:29,371 Request with ID e83a731b for model granite-7b received
2024-09-20 12:47:29,371 127.0.0.1 - - [20/Sep/2024 12:47:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:29,409 Request with ID b5fa90a8 for model llama3-8b received
2024-09-20 12:47:29,409 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:47:29,409 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:47:29,706 Request with ID b6e5eeac for model granite-7b received
2024-09-20 12:47:29,706 127.0.0.1 - - [20/Sep/2024 12:47:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:29,716 Request with ID 15256932 for model gemma-7b received
2024-09-20 12:47:29,716 127.0.0.1 - - [20/Sep/2024 12:47:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:29,726 Request with ID ea014fe9 for model llama3-8b received
2024-09-20 12:47:29,726 127.0.0.1 - - [20/Sep/2024 12:47:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:29,850 Request with ID e08eae89 for model llama3-8b received
2024-09-20 12:47:29,851 127.0.0.1 - - [20/Sep/2024 12:47:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:29,962 Request with ID e81cd126 for model gemma-7b received
2024-09-20 12:47:29,963 127.0.0.1 - - [20/Sep/2024 12:47:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:29,996 Request with ID df6b919b for model llama3-8b received
2024-09-20 12:47:29,997 127.0.0.1 - - [20/Sep/2024 12:47:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,182 Request with ID 36d59045 for model granite-7b received
2024-09-20 12:47:30,183 Request with ID f8c440f0 for model llama3-8b received
2024-09-20 12:47:30,183 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,184 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,234 Request with ID 96ed6e81 for model llama3-8b received
2024-09-20 12:47:30,235 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,379 Request with ID 067d0412 for model llama3-8b received
2024-09-20 12:47:30,380 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,452 Request with ID 86300d35 for model llama3-8b received
2024-09-20 12:47:30,452 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,626 Request with ID 8b74c9a3 for model granite-7b received
2024-09-20 12:47:30,626 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,742 Request with ID df1cfc0d for model gemma-7b received
2024-09-20 12:47:30,743 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,776 Request with ID ecb47b49 for model llama3-8b received
2024-09-20 12:47:30,777 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,793 Request with ID a044404e for model llama3-8b received
2024-09-20 12:47:30,794 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,846 Request with ID 0c20ea2b for model gemma-7b received
2024-09-20 12:47:30,847 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,862 Request with ID dac93e80 for model llama3-8b received
2024-09-20 12:47:30,862 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,895 Request with ID 758b414a for model granite-7b received
2024-09-20 12:47:30,896 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:30,969 Request with ID fd374856 for model gemma-7b received
2024-09-20 12:47:30,969 127.0.0.1 - - [20/Sep/2024 12:47:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:31,095 Request with ID ba5447ba for model llama3-8b received
2024-09-20 12:47:31,095 Request with ID 31287222 for model granite-7b received
2024-09-20 12:47:31,096 127.0.0.1 - - [20/Sep/2024 12:47:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:31,096 127.0.0.1 - - [20/Sep/2024 12:47:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:31,364 Request with ID 02a2e6cd for model gemma-7b received
2024-09-20 12:47:31,365 127.0.0.1 - - [20/Sep/2024 12:47:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:31,396 Request with ID 503bcf5f for model llama3-8b received
2024-09-20 12:47:31,396 127.0.0.1 - - [20/Sep/2024 12:47:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:31,484 Request with ID f92feca6 for model llama3-8b received
2024-09-20 12:47:31,484 127.0.0.1 - - [20/Sep/2024 12:47:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:31,727 Request with ID 886da9a4 for model llama3-8b received
2024-09-20 12:47:31,728 127.0.0.1 - - [20/Sep/2024 12:47:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:31,741 Request with ID f7595a72 for model llama3-8b received
2024-09-20 12:47:31,741 127.0.0.1 - - [20/Sep/2024 12:47:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:31,792 Request with ID c6aa7cf7 for model llama3-8b received
2024-09-20 12:47:31,792 127.0.0.1 - - [20/Sep/2024 12:47:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:31,906 Request with ID 907e81f4 for model gemma-7b received
2024-09-20 12:47:31,907 127.0.0.1 - - [20/Sep/2024 12:47:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:32,117 Request with ID 15a70939 for model llama3-8b received
2024-09-20 12:47:32,118 127.0.0.1 - - [20/Sep/2024 12:47:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:32,262 Request with ID 75fdd653 for model llama3-8b received
2024-09-20 12:47:32,262 127.0.0.1 - - [20/Sep/2024 12:47:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:32,553 Request with ID 6cfd8a98 for model gemma-7b received
2024-09-20 12:47:32,553 127.0.0.1 - - [20/Sep/2024 12:47:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:32,742 Request with ID 91681841 for model llama3-8b received
2024-09-20 12:47:32,743 Request with ID 74082f13 for model llama3-8b received
2024-09-20 12:47:32,743 127.0.0.1 - - [20/Sep/2024 12:47:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:32,744 127.0.0.1 - - [20/Sep/2024 12:47:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:32,789 Request with ID 16642d48 for model llama3-8b received
2024-09-20 12:47:32,789 127.0.0.1 - - [20/Sep/2024 12:47:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:32,803 Request with ID 9d9ad00c for model llama3-8b received
2024-09-20 12:47:32,804 127.0.0.1 - - [20/Sep/2024 12:47:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:32,805 Request with ID af59e80f for model llama3-8b received
2024-09-20 12:47:32,805 127.0.0.1 - - [20/Sep/2024 12:47:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:32,859 Request with ID 42c158e2 for model llama3-8b received
2024-09-20 12:47:32,860 127.0.0.1 - - [20/Sep/2024 12:47:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:32,988 Request with ID 74c3ecf5 for model llama3-8b received
2024-09-20 12:47:32,989 127.0.0.1 - - [20/Sep/2024 12:47:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,053 Request with ID 57a33c80 for model llama3-8b received
2024-09-20 12:47:33,054 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,214 Request with ID 94e4f68f for model llama3-8b received
2024-09-20 12:47:33,215 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,250 Request with ID 14d3c5d2 for model llama3-8b received
2024-09-20 12:47:33,251 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,265 Request with ID 5611bd3a for model llama3-8b received
2024-09-20 12:47:33,266 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,271 Request with ID a2e6c0d9 for model llama3-8b received
2024-09-20 12:47:33,272 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,295 Request with ID f5eeca41 for model granite-7b received
2024-09-20 12:47:33,295 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,300 Request with ID 150d79ae for model granite-7b received
2024-09-20 12:47:33,300 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,313 Request with ID 17b7d7a1 for model llama3-8b received
2024-09-20 12:47:33,313 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,326 Request with ID 3038e121 for model gemma-7b received
2024-09-20 12:47:33,326 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,571 Request with ID a456891e for model llama3-8b received
2024-09-20 12:47:33,571 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,870 Request with ID c8ee0371 for model llama3-8b received
2024-09-20 12:47:33,870 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,923 Request with ID 2687dc1d for model llama3-8b received
2024-09-20 12:47:33,923 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:33,954 Request with ID def8e957 for model llama3-8b received
2024-09-20 12:47:33,955 127.0.0.1 - - [20/Sep/2024 12:47:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:34,288 Request with ID 19e76e28 for model llama3-8b received
2024-09-20 12:47:34,289 127.0.0.1 - - [20/Sep/2024 12:47:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:34,438 Request with ID c5c217cf for model gemma-7b received
2024-09-20 12:47:34,438 127.0.0.1 - - [20/Sep/2024 12:47:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:34,634 Request with ID dc679a46 for model llama3-8b received
2024-09-20 12:47:34,635 127.0.0.1 - - [20/Sep/2024 12:47:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:34,800 Request with ID 0de8c3dc for model gemma-7b received
2024-09-20 12:47:34,801 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-20 12:47:34,801 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:47:34,859 Request with ID 93ce78e8 for model gemma-7b received
2024-09-20 12:47:34,859 127.0.0.1 - - [20/Sep/2024 12:47:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:35,008 Request with ID 50ee7773 for model granite-7b received
2024-09-20 12:47:35,009 127.0.0.1 - - [20/Sep/2024 12:47:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:35,045 Request with ID 5307b962 for model llama3-8b received
2024-09-20 12:47:35,046 127.0.0.1 - - [20/Sep/2024 12:47:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:35,259 Request with ID 85c504c9 for model granite-7b received
2024-09-20 12:47:35,259 127.0.0.1 - - [20/Sep/2024 12:47:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:35,490 Request with ID 22426927 for model llama3-8b received
2024-09-20 12:47:35,490 127.0.0.1 - - [20/Sep/2024 12:47:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:35,525 Request with ID 5f66e5c5 for model gemma-7b received
2024-09-20 12:47:35,525 127.0.0.1 - - [20/Sep/2024 12:47:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:35,533 Request with ID 6ca7c0d1 for model llama3-8b received
2024-09-20 12:47:35,534 127.0.0.1 - - [20/Sep/2024 12:47:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:35,628 Request with ID fb1e9b8e for model granite-7b received
2024-09-20 12:47:35,629 127.0.0.1 - - [20/Sep/2024 12:47:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:35,741 Request with ID fad06e3c for model llama3-8b received
2024-09-20 12:47:35,741 127.0.0.1 - - [20/Sep/2024 12:47:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,029 Request with ID fb84d874 for model llama3-8b received
2024-09-20 12:47:36,029 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,109 Request with ID dfbb0fad for model gemma-7b received
2024-09-20 12:47:36,110 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,135 Request with ID 8c2a0615 for model llama3-8b received
2024-09-20 12:47:36,135 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,176 Request with ID aebed035 for model llama3-8b received
2024-09-20 12:47:36,176 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,279 Request with ID cdefc2e9 for model gemma-7b received
2024-09-20 12:47:36,280 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,384 Request with ID b1975665 for model llama3-8b received
2024-09-20 12:47:36,385 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,426 Request with ID 2374414d for model llama3-8b received
2024-09-20 12:47:36,427 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,434 Request with ID bc0bb9ff for model granite-7b received
2024-09-20 12:47:36,435 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,451 Request with ID 6ced2308 for model llama3-8b received
2024-09-20 12:47:36,452 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,479 Request with ID 89bb6962 for model llama3-8b received
2024-09-20 12:47:36,480 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,516 Request with ID 62ea2e10 for model gemma-7b received
2024-09-20 12:47:36,517 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,816 Request with ID d9863372 for model granite-7b received
2024-09-20 12:47:36,816 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:47:36,817 Dynamic batch size condition met for model granite-7b
2024-09-20 12:47:36,850 Request with ID 1869f334 for model llama3-8b received
2024-09-20 12:47:36,850 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,934 Request with ID be6e3135 for model llama3-8b received
2024-09-20 12:47:36,934 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:36,957 Request with ID d67bcbd1 for model llama3-8b received
2024-09-20 12:47:36,958 127.0.0.1 - - [20/Sep/2024 12:47:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:37,357 Request with ID 249a5b7a for model llama3-8b received
2024-09-20 12:47:37,357 127.0.0.1 - - [20/Sep/2024 12:47:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:37,523 Request with ID aecb4507 for model gemma-7b received
2024-09-20 12:47:37,523 127.0.0.1 - - [20/Sep/2024 12:47:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:37,525 Request with ID d6fdc0ed for model llama3-8b received
2024-09-20 12:47:37,525 127.0.0.1 - - [20/Sep/2024 12:47:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:37,616 Request with ID 8da99835 for model gemma-7b received
2024-09-20 12:47:37,616 127.0.0.1 - - [20/Sep/2024 12:47:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:37,674 Request with ID aaa317ad for model granite-7b received
2024-09-20 12:47:37,675 127.0.0.1 - - [20/Sep/2024 12:47:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:37,773 Request with ID 47522244 for model gemma-7b received
2024-09-20 12:47:37,774 127.0.0.1 - - [20/Sep/2024 12:47:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:37,932 Request with ID b3345be0 for model llama3-8b received
2024-09-20 12:47:37,933 127.0.0.1 - - [20/Sep/2024 12:47:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,009 Request with ID 41d9887b for model llama3-8b received
2024-09-20 12:47:38,009 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,028 Request with ID 533f13e5 for model llama3-8b received
2024-09-20 12:47:38,029 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,066 Request with ID 91ce580c for model llama3-8b received
2024-09-20 12:47:38,067 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,178 Request with ID 56019ec4 for model llama3-8b received
2024-09-20 12:47:38,179 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,324 Request with ID 7808b846 for model llama3-8b received
2024-09-20 12:47:38,325 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,326 Request with ID 6be8e356 for model llama3-8b received
2024-09-20 12:47:38,327 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,375 Request with ID b579049f for model llama3-8b received
2024-09-20 12:47:38,375 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,395 Request with ID 154dbffd for model granite-7b received
2024-09-20 12:47:38,396 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,453 Request with ID 66fd3c44 for model llama3-8b received
2024-09-20 12:47:38,453 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,563 Request with ID 3bacc6c4 for model llama3-8b received
2024-09-20 12:47:38,564 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,581 Request with ID a5e043e3 for model llama3-8b received
2024-09-20 12:47:38,582 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:47:38,582 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:47:38,652 Request with ID 509ff701 for model llama3-8b received
2024-09-20 12:47:38,652 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,699 Request with ID 7cd66b64 for model granite-7b received
2024-09-20 12:47:38,699 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,703 Request with ID 35a5fa09 for model llama3-8b received
2024-09-20 12:47:38,704 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,753 Request with ID bb3d6c14 for model gemma-7b received
2024-09-20 12:47:38,754 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:38,863 Request with ID 50cb2948 for model llama3-8b received
2024-09-20 12:47:38,864 127.0.0.1 - - [20/Sep/2024 12:47:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:39,076 Request with ID e3a0a225 for model gemma-7b received
2024-09-20 12:47:39,076 127.0.0.1 - - [20/Sep/2024 12:47:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:39,148 Request with ID d349aa63 for model granite-7b received
2024-09-20 12:47:39,149 127.0.0.1 - - [20/Sep/2024 12:47:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:39,153 Request with ID 6aa84081 for model gemma-7b received
2024-09-20 12:47:39,154 127.0.0.1 - - [20/Sep/2024 12:47:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:39,269 Request with ID b1068f6f for model llama3-8b received
2024-09-20 12:47:39,269 127.0.0.1 - - [20/Sep/2024 12:47:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:39,358 Request with ID 5ee3c1d7 for model llama3-8b received
2024-09-20 12:47:39,358 127.0.0.1 - - [20/Sep/2024 12:47:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:39,415 Request with ID 6e074dcd for model gemma-7b received
2024-09-20 12:47:39,415 127.0.0.1 - - [20/Sep/2024 12:47:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:39,641 Request with ID ea97c7c3 for model llama3-8b received
2024-09-20 12:47:39,642 127.0.0.1 - - [20/Sep/2024 12:47:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:39,787 Request with ID ba663f5b for model llama3-8b received
2024-09-20 12:47:39,944 127.0.0.1 - - [20/Sep/2024 12:47:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:39,947 Request with ID fac5cd36 for model gemma-7b received
2024-09-20 12:47:39,948 Request with ID d70c8481 for model llama3-8b received
2024-09-20 12:47:39,948 127.0.0.1 - - [20/Sep/2024 12:47:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:39,949 127.0.0.1 - - [20/Sep/2024 12:47:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:39,951 Request with ID b845c3bb for model granite-7b received
2024-09-20 12:47:39,952 127.0.0.1 - - [20/Sep/2024 12:47:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,213 Request with ID d3e79a40 for model llama3-8b received
2024-09-20 12:47:40,214 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,381 Request with ID 26315abd for model granite-7b received
2024-09-20 12:47:40,382 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,513 Request with ID 5db65327 for model llama3-8b received
2024-09-20 12:47:40,513 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,622 Request with ID 0804398a for model llama3-8b received
2024-09-20 12:47:40,622 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,700 Request with ID 47f01a35 for model llama3-8b received
2024-09-20 12:47:40,701 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,752 Request with ID 41080650 for model llama3-8b received
2024-09-20 12:47:40,754 Request with ID 80fc2ce9 for model llama3-8b received
2024-09-20 12:47:40,754 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,755 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,759 Request with ID 4fb7b370 for model gemma-7b received
2024-09-20 12:47:40,760 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,784 Request with ID fe8bd1ca for model gemma-7b received
2024-09-20 12:47:40,785 Request with ID cb5329d3 for model gemma-7b received
2024-09-20 12:47:40,785 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,786 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,823 Request with ID 5cecb8c2 for model llama3-8b received
2024-09-20 12:47:40,823 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,878 Request with ID e53148db for model llama3-8b received
2024-09-20 12:47:40,879 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:40,915 Request with ID e1e2ffd7 for model llama3-8b received
2024-09-20 12:47:40,916 127.0.0.1 - - [20/Sep/2024 12:47:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:41,087 Request with ID 7c27b1bd for model gemma-7b received
2024-09-20 12:47:41,087 127.0.0.1 - - [20/Sep/2024 12:47:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:41,129 Request with ID 74f1ae53 for model llama3-8b received
2024-09-20 12:47:41,130 127.0.0.1 - - [20/Sep/2024 12:47:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:41,229 Loaded model llama3-8b
2024-09-20 12:47:41,231 Request with ID b86eda8f for model gemma-7b received
2024-09-20 12:47:41,232 127.0.0.1 - - [20/Sep/2024 12:47:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:41,235 Batch processing started for model llama3-8b
2024-09-20 12:47:41,246 Request with ID 6b90dfbf for model granite-7b received
2024-09-20 12:47:41,247 127.0.0.1 - - [20/Sep/2024 12:47:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:41,326 Request with ID 2876db33 for model gemma-7b received
2024-09-20 12:47:41,327 127.0.0.1 - - [20/Sep/2024 12:47:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:41,479 Request with ID 8baca678 for model gemma-7b received
2024-09-20 12:47:41,480 127.0.0.1 - - [20/Sep/2024 12:47:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:41,580 Request with ID 94e22d4e for model gemma-7b received
2024-09-20 12:47:41,581 127.0.0.1 - - [20/Sep/2024 12:47:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:41,707 Request with ID 1b0853ed for model llama3-8b received
2024-09-20 12:47:41,708 127.0.0.1 - - [20/Sep/2024 12:47:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:41,726 Request with ID 6bc3c9e5 for model llama3-8b received
2024-09-20 12:47:41,727 127.0.0.1 - - [20/Sep/2024 12:47:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:41,904 Request with ID 5ffe377f for model gemma-7b received
2024-09-20 12:47:41,905 127.0.0.1 - - [20/Sep/2024 12:47:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:41,915 Request with ID 76d8744a for model llama3-8b received
2024-09-20 12:47:41,915 127.0.0.1 - - [20/Sep/2024 12:47:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:42,048 Request with ID 55eda007 for model gemma-7b received
2024-09-20 12:47:42,049 127.0.0.1 - - [20/Sep/2024 12:47:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:42,052 Request with ID 6dea4394 for model gemma-7b received
2024-09-20 12:47:42,053 127.0.0.1 - - [20/Sep/2024 12:47:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:42,096 Request with ID 592a7cae for model llama3-8b received
2024-09-20 12:47:42,097 127.0.0.1 - - [20/Sep/2024 12:47:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:42,114 Request with ID 92369933 for model llama3-8b received
2024-09-20 12:47:42,115 127.0.0.1 - - [20/Sep/2024 12:47:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:42,199 Request with ID 244657f9 for model llama3-8b received
2024-09-20 12:47:42,200 127.0.0.1 - - [20/Sep/2024 12:47:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:42,247 Request with ID 737d49be for model gemma-7b received
2024-09-20 12:47:42,248 127.0.0.1 - - [20/Sep/2024 12:47:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:42,487 Request with ID 6de7596b for model granite-7b received
2024-09-20 12:47:42,487 127.0.0.1 - - [20/Sep/2024 12:47:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:42,671 Request with ID 8637637c for model llama3-8b received
2024-09-20 12:47:42,671 127.0.0.1 - - [20/Sep/2024 12:47:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:43,025 Request with ID 463ab308 for model granite-7b received
2024-09-20 12:47:43,026 127.0.0.1 - - [20/Sep/2024 12:47:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:43,108 Request with ID 29a9a42a for model llama3-8b received
2024-09-20 12:47:43,109 127.0.0.1 - - [20/Sep/2024 12:47:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:43,452 Request with ID e08ab24a for model llama3-8b received
2024-09-20 12:47:43,452 127.0.0.1 - - [20/Sep/2024 12:47:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:43,652 Request with ID 11c6f2d3 for model llama3-8b received
2024-09-20 12:47:43,653 127.0.0.1 - - [20/Sep/2024 12:47:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:43,779 Request with ID 8291989d for model gemma-7b received
2024-09-20 12:47:43,780 127.0.0.1 - - [20/Sep/2024 12:47:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:43,794 Request with ID bf94fedb for model llama3-8b received
2024-09-20 12:47:43,794 127.0.0.1 - - [20/Sep/2024 12:47:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:43,910 Request with ID f29f4176 for model llama3-8b received
2024-09-20 12:47:43,910 127.0.0.1 - - [20/Sep/2024 12:47:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:44,023 Request with ID c907ec7f for model gemma-7b received
2024-09-20 12:47:44,023 127.0.0.1 - - [20/Sep/2024 12:47:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:44,122 Request with ID 1d40c588 for model llama3-8b received
2024-09-20 12:47:44,123 127.0.0.1 - - [20/Sep/2024 12:47:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:44,526 Request with ID 57afd774 for model gemma-7b received
2024-09-20 12:47:44,526 127.0.0.1 - - [20/Sep/2024 12:47:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:44,544 Request with ID 1034178d for model granite-7b received
2024-09-20 12:47:44,545 127.0.0.1 - - [20/Sep/2024 12:47:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:44,595 Request with ID c1322626 for model gemma-7b received
2024-09-20 12:47:44,596 127.0.0.1 - - [20/Sep/2024 12:47:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:44,694 Request with ID e1b3d836 for model llama3-8b received
2024-09-20 12:47:44,695 127.0.0.1 - - [20/Sep/2024 12:47:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:44,748 Request with ID c40eedf7 for model gemma-7b received
2024-09-20 12:47:44,748 127.0.0.1 - - [20/Sep/2024 12:47:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:44,793 Request with ID 1d075fa7 for model llama3-8b received
2024-09-20 12:47:44,794 127.0.0.1 - - [20/Sep/2024 12:47:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:44,911 Request with ID e627cb4e for model gemma-7b received
2024-09-20 12:47:44,912 127.0.0.1 - - [20/Sep/2024 12:47:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:44,961 Request with ID b329718c for model llama3-8b received
2024-09-20 12:47:44,961 127.0.0.1 - - [20/Sep/2024 12:47:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:45,095 Request with ID 02e5cfd4 for model gemma-7b received
2024-09-20 12:47:45,095 127.0.0.1 - - [20/Sep/2024 12:47:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:45,150 Request with ID dc3979ce for model llama3-8b received
2024-09-20 12:47:45,151 127.0.0.1 - - [20/Sep/2024 12:47:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:45,617 Request with ID 718c781b for model gemma-7b received
2024-09-20 12:47:45,617 127.0.0.1 - - [20/Sep/2024 12:47:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:45,674 Request with ID 0eea745d for model granite-7b received
2024-09-20 12:47:45,675 127.0.0.1 - - [20/Sep/2024 12:47:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:45,736 Request with ID f983ad45 for model gemma-7b received
2024-09-20 12:47:45,736 127.0.0.1 - - [20/Sep/2024 12:47:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:46,092 Request with ID 96f897dc for model llama3-8b received
2024-09-20 12:47:46,093 127.0.0.1 - - [20/Sep/2024 12:47:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:46,174 Request with ID dc2de411 for model llama3-8b received
2024-09-20 12:47:46,175 127.0.0.1 - - [20/Sep/2024 12:47:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:46,218 Request with ID bd262628 for model llama3-8b received
2024-09-20 12:47:46,218 127.0.0.1 - - [20/Sep/2024 12:47:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:46,355 Request with ID 952ae328 for model gemma-7b received
2024-09-20 12:47:46,355 127.0.0.1 - - [20/Sep/2024 12:47:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:46,464 Request with ID d744d5d4 for model gemma-7b received
2024-09-20 12:47:46,464 127.0.0.1 - - [20/Sep/2024 12:47:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:46,557 Request with ID 2587a6af for model granite-7b received
2024-09-20 12:47:46,558 127.0.0.1 - - [20/Sep/2024 12:47:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:46,862 Request with ID f85a5611 for model llama3-8b received
2024-09-20 12:47:46,862 127.0.0.1 - - [20/Sep/2024 12:47:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:46,924 Request with ID c2bb5cfe for model llama3-8b received
2024-09-20 12:47:46,925 127.0.0.1 - - [20/Sep/2024 12:47:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:47,049 Request with ID b9f72f34 for model gemma-7b received
2024-09-20 12:47:47,050 127.0.0.1 - - [20/Sep/2024 12:47:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:47,163 Request with ID 944fba91 for model llama3-8b received
2024-09-20 12:47:47,164 127.0.0.1 - - [20/Sep/2024 12:47:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:47,253 Request with ID f441513a for model gemma-7b received
2024-09-20 12:47:47,253 127.0.0.1 - - [20/Sep/2024 12:47:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:47,346 Request with ID b8f8819a for model gemma-7b received
2024-09-20 12:47:47,346 127.0.0.1 - - [20/Sep/2024 12:47:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:47,360 Request with ID 71fa002d for model gemma-7b received
2024-09-20 12:47:47,360 127.0.0.1 - - [20/Sep/2024 12:47:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:47,653 Request with ID 7fa7a8e0 for model llama3-8b received
2024-09-20 12:47:47,655 Request with ID 4b7c2a6d for model llama3-8b received
2024-09-20 12:47:47,655 127.0.0.1 - - [20/Sep/2024 12:47:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:47,656 127.0.0.1 - - [20/Sep/2024 12:47:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:47,777 Request with ID 03c7f92f for model granite-7b received
2024-09-20 12:47:47,777 127.0.0.1 - - [20/Sep/2024 12:47:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:47,877 Request with ID d9395dfc for model llama3-8b received
2024-09-20 12:47:47,878 127.0.0.1 - - [20/Sep/2024 12:47:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:47,906 Request with ID 15fb4aae for model llama3-8b received
2024-09-20 12:47:47,907 127.0.0.1 - - [20/Sep/2024 12:47:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:47,959 Request with ID d2f1ddb5 for model gemma-7b received
2024-09-20 12:47:47,959 127.0.0.1 - - [20/Sep/2024 12:47:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:48,073 Request with ID 07847e03 for model llama3-8b received
2024-09-20 12:47:48,073 127.0.0.1 - - [20/Sep/2024 12:47:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:48,143 Request with ID 27fb2837 for model llama3-8b received
2024-09-20 12:47:48,143 127.0.0.1 - - [20/Sep/2024 12:47:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:48,153 Request with ID e8ea86ce for model llama3-8b received
2024-09-20 12:47:48,153 127.0.0.1 - - [20/Sep/2024 12:47:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:48,211 Request with ID e6e787c3 for model llama3-8b received
2024-09-20 12:47:48,212 127.0.0.1 - - [20/Sep/2024 12:47:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:48,342 Request with ID 8ff884e9 for model gemma-7b received
2024-09-20 12:47:48,342 127.0.0.1 - - [20/Sep/2024 12:47:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:48,422 Request with ID c832ed48 for model gemma-7b received
2024-09-20 12:47:48,422 127.0.0.1 - - [20/Sep/2024 12:47:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:48,549 Request with ID b58e0fe9 for model gemma-7b received
2024-09-20 12:47:48,550 127.0.0.1 - - [20/Sep/2024 12:47:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:48,761 Request with ID f9c7a3a3 for model llama3-8b received
2024-09-20 12:47:48,762 127.0.0.1 - - [20/Sep/2024 12:47:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:48,765 Request with ID 01f6625a for model granite-7b received
2024-09-20 12:47:48,765 127.0.0.1 - - [20/Sep/2024 12:47:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:48,774 Request with ID 59ff8230 for model granite-7b received
2024-09-20 12:47:48,774 127.0.0.1 - - [20/Sep/2024 12:47:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:48,838 Request with ID 931ddd80 for model llama3-8b received
2024-09-20 12:47:48,839 127.0.0.1 - - [20/Sep/2024 12:47:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:48,931 Request with ID d8a87b5b for model llama3-8b received
2024-09-20 12:47:48,932 127.0.0.1 - - [20/Sep/2024 12:47:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,115 Request with ID 8f65bad4 for model gemma-7b received
2024-09-20 12:47:49,116 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,185 Request with ID 94bc2925 for model llama3-8b received
2024-09-20 12:47:49,185 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,216 Request with ID bde74e22 for model llama3-8b received
2024-09-20 12:47:49,216 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,224 Request with ID e79fcee6 for model llama3-8b received
2024-09-20 12:47:49,224 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,249 Request with ID 347d0b87 for model gemma-7b received
2024-09-20 12:47:49,249 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,296 Request with ID 43762034 for model llama3-8b received
2024-09-20 12:47:49,296 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,300 Request with ID f8c516fe for model llama3-8b received
2024-09-20 12:47:49,301 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,405 Request with ID 44fae99e for model llama3-8b received
2024-09-20 12:47:49,405 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,464 Request with ID aa3b1a84 for model llama3-8b received
2024-09-20 12:47:49,465 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,471 Request with ID 5d1cf4fe for model gemma-7b received
2024-09-20 12:47:49,472 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,532 Request with ID 0cdbc072 for model gemma-7b received
2024-09-20 12:47:49,532 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,605 Request with ID d95d48ea for model llama3-8b received
2024-09-20 12:47:49,606 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,869 Request with ID c9c1f843 for model llama3-8b received
2024-09-20 12:47:49,869 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,871 Request with ID 63454ac1 for model gemma-7b received
2024-09-20 12:47:49,872 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:49,889 Request with ID 91545ed8 for model llama3-8b received
2024-09-20 12:47:49,889 127.0.0.1 - - [20/Sep/2024 12:47:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:50,064 Request with ID 3670e8c0 for model llama3-8b received
2024-09-20 12:47:50,075 127.0.0.1 - - [20/Sep/2024 12:47:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:50,084 Processed batch: ['4796a08d', 'bc27d6d3', '4067f9ef', '25820009', '62171d7c', 'fedead94', 'e09812b2', '8865978a', '7526e2d7', '212d3485', '5b7f3dd5', '48d63299', '21612519', 'a0f4d62e', 'b42250d1', 'ab907d1a', '3f337dfc', 'a2f311e1', 'f6c0d13a', '6f16163a', 'b940f674', 'efdfe3c9', 'efdab88d', '1661958b', '4f3170f9', '8d6972ba', '06f85879', '94b8ea6f', '50c038a2', '050ab216', 'b9517a23', '68f7a9db', 'ffbaa9eb', '98edc882', 'bf73f7f7', '8f20bd6c', 'c9952ffd', '5bb83328', '23690661', '3c5007b6', '243ddb27', '3625e437', '23bf8cbe', '5571e6dd', '552f0199', 'ec992b13', 'ef6f9389', 'f42c9cbc', 'd56265ed', 'cd86d278', 'f4b9ae86', 'aea7eafb', 'bcc9358b', 'af6ebb51', '24c252ed', 'f3bea84b', 'e798b266', '0329c4c6', '568a9531', 'efb9ea37', 'd5c347f3', '1b01484c', '826c7786', '8543be40'] with model llama3-8b in 8.8493 seconds
2024-09-20 12:47:50,084 Saving sys info
2024-09-20 12:47:50,133 Latency for request 4796a08d with model llama3-8b: 41.5270 seconds
2024-09-20 12:47:50,133 Saving results with gpu monitoring
2024-09-20 12:47:50,137 Latency for request bc27d6d3 with model llama3-8b: 41.3870 seconds
2024-09-20 12:47:50,137 Saving results with gpu monitoring
2024-09-20 12:47:50,139 Latency for request 4067f9ef with model llama3-8b: 41.3660 seconds
2024-09-20 12:47:50,139 Saving results with gpu monitoring
2024-09-20 12:47:50,141 Latency for request 25820009 with model llama3-8b: 41.1650 seconds
2024-09-20 12:47:50,141 Saving results with gpu monitoring
2024-09-20 12:47:50,143 Latency for request 62171d7c with model llama3-8b: 40.8700 seconds
2024-09-20 12:47:50,143 Saving results with gpu monitoring
2024-09-20 12:47:50,145 Latency for request fedead94 with model llama3-8b: 40.8680 seconds
2024-09-20 12:47:50,145 Saving results with gpu monitoring
2024-09-20 12:47:50,147 Latency for request e09812b2 with model llama3-8b: 40.8500 seconds
2024-09-20 12:47:50,147 Saving results with gpu monitoring
2024-09-20 12:47:50,149 Latency for request 8865978a with model llama3-8b: 40.4380 seconds
2024-09-20 12:47:50,149 Saving results with gpu monitoring
2024-09-20 12:47:50,151 Latency for request 7526e2d7 with model llama3-8b: 40.0000 seconds
2024-09-20 12:47:50,151 Saving results with gpu monitoring
2024-09-20 12:47:50,153 Latency for request 212d3485 with model llama3-8b: 39.7490 seconds
2024-09-20 12:47:50,153 Saving results with gpu monitoring
2024-09-20 12:47:50,155 Latency for request 5b7f3dd5 with model llama3-8b: 39.7020 seconds
2024-09-20 12:47:50,155 Saving results with gpu monitoring
2024-09-20 12:47:50,157 Latency for request 48d63299 with model llama3-8b: 38.8460 seconds
2024-09-20 12:47:50,157 Saving results with gpu monitoring
2024-09-20 12:47:50,159 Latency for request 21612519 with model llama3-8b: 38.7650 seconds
2024-09-20 12:47:50,159 Saving results with gpu monitoring
2024-09-20 12:47:50,161 Latency for request a0f4d62e with model llama3-8b: 38.4870 seconds
2024-09-20 12:47:50,161 Saving results with gpu monitoring
2024-09-20 12:47:50,163 Latency for request b42250d1 with model llama3-8b: 38.3300 seconds
2024-09-20 12:47:50,163 Saving results with gpu monitoring
2024-09-20 12:47:50,165 Latency for request ab907d1a with model llama3-8b: 37.8970 seconds
2024-09-20 12:47:50,165 Saving results with gpu monitoring
2024-09-20 12:47:50,167 Latency for request 3f337dfc with model llama3-8b: 37.4790 seconds
2024-09-20 12:47:50,167 Saving results with gpu monitoring
2024-09-20 12:47:50,169 Latency for request a2f311e1 with model llama3-8b: 37.4540 seconds
2024-09-20 12:47:50,169 Saving results with gpu monitoring
2024-09-20 12:47:50,171 Latency for request f6c0d13a with model llama3-8b: 37.4450 seconds
2024-09-20 12:47:50,171 Saving results with gpu monitoring
2024-09-20 12:47:50,173 Latency for request 6f16163a with model llama3-8b: 37.4360 seconds
2024-09-20 12:47:50,173 Saving results with gpu monitoring
2024-09-20 12:47:50,175 Latency for request b940f674 with model llama3-8b: 37.3770 seconds
2024-09-20 12:47:50,175 Saving results with gpu monitoring
2024-09-20 12:47:50,177 Latency for request efdfe3c9 with model llama3-8b: 37.3510 seconds
2024-09-20 12:47:50,178 Saving results with gpu monitoring
2024-09-20 12:47:50,180 Latency for request efdab88d with model llama3-8b: 36.8310 seconds
2024-09-20 12:47:50,180 Saving results with gpu monitoring
2024-09-20 12:47:50,182 Latency for request 1661958b with model llama3-8b: 36.7860 seconds
2024-09-20 12:47:50,182 Saving results with gpu monitoring
2024-09-20 12:47:50,184 Latency for request 4f3170f9 with model llama3-8b: 36.6430 seconds
2024-09-20 12:47:50,184 Saving results with gpu monitoring
2024-09-20 12:47:50,186 Latency for request 8d6972ba with model llama3-8b: 36.6190 seconds
2024-09-20 12:47:50,186 Saving results with gpu monitoring
2024-09-20 12:47:50,189 Request with ID 3143586c for model llama3-8b received
2024-09-20 12:47:50,190 Latency for request 06f85879 with model llama3-8b: 36.4130 seconds
2024-09-20 12:47:50,190 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:47:50,190 Saving results with gpu monitoring
2024-09-20 12:47:50,190 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:47:50,193 Latency for request 94b8ea6f with model llama3-8b: 36.0180 seconds
2024-09-20 12:47:50,193 Saving results with gpu monitoring
2024-09-20 12:47:50,195 Latency for request 50c038a2 with model llama3-8b: 35.7350 seconds
2024-09-20 12:47:50,195 Saving results with gpu monitoring
2024-09-20 12:47:50,197 Latency for request 050ab216 with model llama3-8b: 35.6740 seconds
2024-09-20 12:47:50,197 Saving results with gpu monitoring
2024-09-20 12:47:50,199 Latency for request b9517a23 with model llama3-8b: 35.1370 seconds
2024-09-20 12:47:50,199 Saving results with gpu monitoring
2024-09-20 12:47:50,201 Latency for request 68f7a9db with model llama3-8b: 35.0970 seconds
2024-09-20 12:47:50,201 Saving results with gpu monitoring
2024-09-20 12:47:50,203 Latency for request ffbaa9eb with model llama3-8b: 35.0830 seconds
2024-09-20 12:47:50,203 Saving results with gpu monitoring
2024-09-20 12:47:50,205 Latency for request 98edc882 with model llama3-8b: 34.7390 seconds
2024-09-20 12:47:50,205 Saving results with gpu monitoring
2024-09-20 12:47:50,207 Latency for request bf73f7f7 with model llama3-8b: 34.7250 seconds
2024-09-20 12:47:50,207 Saving results with gpu monitoring
2024-09-20 12:47:50,209 Latency for request 8f20bd6c with model llama3-8b: 34.7060 seconds
2024-09-20 12:47:50,209 Saving results with gpu monitoring
2024-09-20 12:47:50,211 Latency for request c9952ffd with model llama3-8b: 34.5920 seconds
2024-09-20 12:47:50,211 Saving results with gpu monitoring
2024-09-20 12:47:50,213 Latency for request 5bb83328 with model llama3-8b: 34.3850 seconds
2024-09-20 12:47:50,213 Saving results with gpu monitoring
2024-09-20 12:47:50,215 Latency for request 23690661 with model llama3-8b: 34.3730 seconds
2024-09-20 12:47:50,215 Saving results with gpu monitoring
2024-09-20 12:47:50,217 Latency for request 3c5007b6 with model llama3-8b: 34.2640 seconds
2024-09-20 12:47:50,217 Saving results with gpu monitoring
2024-09-20 12:47:50,219 Latency for request 243ddb27 with model llama3-8b: 33.8930 seconds
2024-09-20 12:47:50,219 Saving results with gpu monitoring
2024-09-20 12:47:50,221 Latency for request 3625e437 with model llama3-8b: 33.7560 seconds
2024-09-20 12:47:50,221 Saving results with gpu monitoring
2024-09-20 12:47:50,223 Latency for request 23bf8cbe with model llama3-8b: 33.4650 seconds
2024-09-20 12:47:50,223 Saving results with gpu monitoring
2024-09-20 12:47:50,225 Latency for request 5571e6dd with model llama3-8b: 33.1230 seconds
2024-09-20 12:47:50,225 Saving results with gpu monitoring
2024-09-20 12:47:50,227 Latency for request 552f0199 with model llama3-8b: 33.1160 seconds
2024-09-20 12:47:50,227 Saving results with gpu monitoring
2024-09-20 12:47:50,229 Latency for request ec992b13 with model llama3-8b: 32.9120 seconds
2024-09-20 12:47:50,229 Saving results with gpu monitoring
2024-09-20 12:47:50,231 Latency for request ef6f9389 with model llama3-8b: 32.7620 seconds
2024-09-20 12:47:50,231 Saving results with gpu monitoring
2024-09-20 12:47:50,233 Latency for request f42c9cbc with model llama3-8b: 32.7300 seconds
2024-09-20 12:47:50,233 Saving results with gpu monitoring
2024-09-20 12:47:50,235 Latency for request d56265ed with model llama3-8b: 32.6480 seconds
2024-09-20 12:47:50,236 Saving results with gpu monitoring
2024-09-20 12:47:50,237 Latency for request cd86d278 with model llama3-8b: 32.5840 seconds
2024-09-20 12:47:50,237 Saving results with gpu monitoring
2024-09-20 12:47:50,239 Latency for request f4b9ae86 with model llama3-8b: 32.5350 seconds
2024-09-20 12:47:50,240 Saving results with gpu monitoring
2024-09-20 12:47:50,241 Latency for request aea7eafb with model llama3-8b: 32.3320 seconds
2024-09-20 12:47:50,242 Saving results with gpu monitoring
2024-09-20 12:47:50,243 Latency for request bcc9358b with model llama3-8b: 32.3170 seconds
2024-09-20 12:47:50,244 Saving results with gpu monitoring
2024-09-20 12:47:50,245 Latency for request af6ebb51 with model llama3-8b: 32.1410 seconds
2024-09-20 12:47:50,246 Saving results with gpu monitoring
2024-09-20 12:47:50,247 Latency for request 24c252ed with model llama3-8b: 32.1360 seconds
2024-09-20 12:47:50,248 Saving results with gpu monitoring
2024-09-20 12:47:50,249 Latency for request f3bea84b with model llama3-8b: 32.0020 seconds
2024-09-20 12:47:50,250 Saving results with gpu monitoring
2024-09-20 12:47:50,251 Latency for request e798b266 with model llama3-8b: 31.7590 seconds
2024-09-20 12:47:50,252 Saving results with gpu monitoring
2024-09-20 12:47:50,254 Latency for request 0329c4c6 with model llama3-8b: 31.7180 seconds
2024-09-20 12:47:50,254 Saving results with gpu monitoring
2024-09-20 12:47:50,256 Latency for request 568a9531 with model llama3-8b: 31.6950 seconds
2024-09-20 12:47:50,256 Saving results with gpu monitoring
2024-09-20 12:47:50,257 Latency for request efb9ea37 with model llama3-8b: 31.5100 seconds
2024-09-20 12:47:50,258 Saving results with gpu monitoring
2024-09-20 12:47:50,259 Latency for request d5c347f3 with model llama3-8b: 31.4780 seconds
2024-09-20 12:47:50,260 Saving results with gpu monitoring
2024-09-20 12:47:50,262 Latency for request 1b01484c with model llama3-8b: 31.3750 seconds
2024-09-20 12:47:50,262 Saving results with gpu monitoring
2024-09-20 12:47:50,264 Latency for request 826c7786 with model llama3-8b: 31.3710 seconds
2024-09-20 12:47:50,264 Saving results with gpu monitoring
2024-09-20 12:47:50,266 Latency for request 8543be40 with model llama3-8b: 31.1560 seconds
2024-09-20 12:47:50,266 Saving results with gpu monitoring
2024-09-20 12:47:50,268 127.0.0.1 - - [20/Sep/2024 12:47:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:50,268 Next: call load_model for gemma-7b
2024-09-20 12:47:50,374 Unloaded previous model
2024-09-20 12:47:50,376 Request with ID 1c81f59b for model gemma-7b received
2024-09-20 12:47:50,377 127.0.0.1 - - [20/Sep/2024 12:47:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:50,380 Request with ID c51b6f30 for model llama3-8b received
2024-09-20 12:47:50,881 Adjusted batch time limit for llama3-8b: 5.0000 seconds
2024-09-20 12:47:50,885 127.0.0.1 - - [20/Sep/2024 12:47:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:50,890 Request with ID 9e73ef1d for model llama3-8b received
2024-09-20 12:47:50,891 127.0.0.1 - - [20/Sep/2024 12:47:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:50,892 Request with ID 653a47c0 for model gemma-7b received
2024-09-20 12:47:50,893 127.0.0.1 - - [20/Sep/2024 12:47:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:50,895 Request with ID 1afb0b72 for model llama3-8b received
2024-09-20 12:47:50,895 127.0.0.1 - - [20/Sep/2024 12:47:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:50,898 Request with ID f1e1b3cb for model llama3-8b received
2024-09-20 12:47:50,899 127.0.0.1 - - [20/Sep/2024 12:47:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:51,069 Request with ID 9cf61615 for model llama3-8b received
2024-09-20 12:47:51,073 127.0.0.1 - - [20/Sep/2024 12:47:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:51,093 Request with ID c191ab5e for model llama3-8b received
2024-09-20 12:47:51,094 Request with ID 576b9d1a for model llama3-8b received
2024-09-20 12:47:51,100 127.0.0.1 - - [20/Sep/2024 12:47:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:51,112 127.0.0.1 - - [20/Sep/2024 12:47:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:51,266 Request with ID 49d2dfa3 for model llama3-8b received
2024-09-20 12:47:51,282 127.0.0.1 - - [20/Sep/2024 12:47:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:51,292 Request with ID 552d3aff for model llama3-8b received
2024-09-20 12:47:51,295 127.0.0.1 - - [20/Sep/2024 12:47:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:51,358 Request with ID 8947d34c for model llama3-8b received
2024-09-20 12:47:51,362 127.0.0.1 - - [20/Sep/2024 12:47:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:51,478 Request with ID 3931311c for model gemma-7b received
2024-09-20 12:47:51,479 127.0.0.1 - - [20/Sep/2024 12:47:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:51,503 Request with ID fbf2433d for model llama3-8b received
2024-09-20 12:47:51,507 127.0.0.1 - - [20/Sep/2024 12:47:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:51,685 Request with ID d341dbd3 for model gemma-7b received
2024-09-20 12:47:51,686 127.0.0.1 - - [20/Sep/2024 12:47:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:51,719 Request with ID 733df681 for model gemma-7b received
2024-09-20 12:47:51,720 127.0.0.1 - - [20/Sep/2024 12:47:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:51,758 Request with ID d12cb24f for model gemma-7b received
2024-09-20 12:47:51,762 127.0.0.1 - - [20/Sep/2024 12:47:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:51,883 Request with ID b1de3aa2 for model llama3-8b received
2024-09-20 12:47:51,884 127.0.0.1 - - [20/Sep/2024 12:47:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:52,061 Request with ID e35c2a97 for model llama3-8b received
2024-09-20 12:47:52,063 127.0.0.1 - - [20/Sep/2024 12:47:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:52,077 Request with ID b3d3a363 for model gemma-7b received
2024-09-20 12:47:52,078 127.0.0.1 - - [20/Sep/2024 12:47:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:52,092 Request with ID 6dc9604f for model llama3-8b received
2024-09-20 12:47:52,097 127.0.0.1 - - [20/Sep/2024 12:47:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:52,300 Request with ID f5be52d4 for model llama3-8b received
2024-09-20 12:47:52,301 127.0.0.1 - - [20/Sep/2024 12:47:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:52,303 Request with ID 7800fec1 for model llama3-8b received
2024-09-20 12:47:52,303 127.0.0.1 - - [20/Sep/2024 12:47:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:52,460 Request with ID 977c160e for model gemma-7b received
2024-09-20 12:47:52,461 127.0.0.1 - - [20/Sep/2024 12:47:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:52,579 Request with ID 5c0a71b0 for model gemma-7b received
2024-09-20 12:47:52,580 127.0.0.1 - - [20/Sep/2024 12:47:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:52,726 Request with ID 23b7754b for model llama3-8b received
2024-09-20 12:47:52,727 127.0.0.1 - - [20/Sep/2024 12:47:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:53,030 Request with ID 0578d1f9 for model granite-7b received
2024-09-20 12:47:53,030 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:47:53,030 Dynamic batch size condition met for model granite-7b
2024-09-20 12:47:53,188 Request with ID fde20fcb for model llama3-8b received
2024-09-20 12:47:53,189 127.0.0.1 - - [20/Sep/2024 12:47:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:53,273 Request with ID c6e7eb19 for model llama3-8b received
2024-09-20 12:47:53,273 127.0.0.1 - - [20/Sep/2024 12:47:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:53,304 Request with ID be52e9dd for model llama3-8b received
2024-09-20 12:47:53,305 127.0.0.1 - - [20/Sep/2024 12:47:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:53,427 Request with ID 8b47b08c for model llama3-8b received
2024-09-20 12:47:53,428 127.0.0.1 - - [20/Sep/2024 12:47:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:53,600 Request with ID 73308ef8 for model gemma-7b received
2024-09-20 12:47:53,601 127.0.0.1 - - [20/Sep/2024 12:47:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:53,759 Request with ID e74980d1 for model llama3-8b received
2024-09-20 12:47:53,759 127.0.0.1 - - [20/Sep/2024 12:47:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:53,932 Request with ID cba9d667 for model llama3-8b received
2024-09-20 12:47:53,932 127.0.0.1 - - [20/Sep/2024 12:47:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:53,934 Request with ID f55ad40c for model llama3-8b received
2024-09-20 12:47:53,935 127.0.0.1 - - [20/Sep/2024 12:47:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:53,937 Request with ID 1af52b3b for model gemma-7b received
2024-09-20 12:47:53,937 127.0.0.1 - - [20/Sep/2024 12:47:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:53,944 Request with ID d92dfd3d for model llama3-8b received
2024-09-20 12:47:53,944 127.0.0.1 - - [20/Sep/2024 12:47:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:53,952 Request with ID 6a822398 for model llama3-8b received
2024-09-20 12:47:53,952 127.0.0.1 - - [20/Sep/2024 12:47:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,026 Request with ID 3089a07c for model llama3-8b received
2024-09-20 12:47:54,027 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,111 Request with ID 97f540e5 for model granite-7b received
2024-09-20 12:47:54,111 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,243 Request with ID e16489af for model granite-7b received
2024-09-20 12:47:54,244 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,290 Request with ID 800ecc70 for model gemma-7b received
2024-09-20 12:47:54,291 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,297 Request with ID ff03ee36 for model granite-7b received
2024-09-20 12:47:54,297 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,321 Request with ID e7ec53b3 for model llama3-8b received
2024-09-20 12:47:54,322 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,372 Request with ID 2979ba3d for model llama3-8b received
2024-09-20 12:47:54,372 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,522 Request with ID d80c0e7f for model granite-7b received
2024-09-20 12:47:54,523 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,612 Request with ID 689764b3 for model llama3-8b received
2024-09-20 12:47:54,612 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,687 Request with ID 4db1ac18 for model llama3-8b received
2024-09-20 12:47:54,687 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,761 Request with ID 4b3679bf for model llama3-8b received
2024-09-20 12:47:54,761 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,897 Request with ID 0df56b28 for model llama3-8b received
2024-09-20 12:47:54,898 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:54,943 Request with ID 249134dd for model llama3-8b received
2024-09-20 12:47:54,943 127.0.0.1 - - [20/Sep/2024 12:47:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:55,183 Request with ID f45e76c1 for model llama3-8b received
2024-09-20 12:47:55,183 127.0.0.1 - - [20/Sep/2024 12:47:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:55,290 Request with ID 69ad63e6 for model llama3-8b received
2024-09-20 12:47:55,290 127.0.0.1 - - [20/Sep/2024 12:47:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:55,452 Request with ID 183fb94d for model llama3-8b received
2024-09-20 12:47:55,453 127.0.0.1 - - [20/Sep/2024 12:47:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:55,495 Request with ID 9949dd87 for model gemma-7b received
2024-09-20 12:47:55,496 127.0.0.1 - - [20/Sep/2024 12:47:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:55,524 Request with ID 6ea51bb1 for model llama3-8b received
2024-09-20 12:47:55,524 127.0.0.1 - - [20/Sep/2024 12:47:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:55,729 Request with ID 3e069ff5 for model llama3-8b received
2024-09-20 12:47:55,729 127.0.0.1 - - [20/Sep/2024 12:47:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:55,750 Request with ID 10e04ed7 for model llama3-8b received
2024-09-20 12:47:55,751 127.0.0.1 - - [20/Sep/2024 12:47:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:55,861 Request with ID adca1d9b for model gemma-7b received
2024-09-20 12:47:55,861 127.0.0.1 - - [20/Sep/2024 12:47:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:55,980 Request with ID fe3c7a22 for model llama3-8b received
2024-09-20 12:47:55,980 127.0.0.1 - - [20/Sep/2024 12:47:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:56,120 Request with ID fac5b370 for model gemma-7b received
2024-09-20 12:47:56,120 Moving batch for gemma-7b from incoming to running due to dynamic batch size 64
2024-09-20 12:47:56,121 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:47:56,152 Request with ID 4d9c7986 for model llama3-8b received
2024-09-20 12:47:56,153 127.0.0.1 - - [20/Sep/2024 12:47:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:56,186 Request with ID 870ba09b for model llama3-8b received
2024-09-20 12:47:56,186 127.0.0.1 - - [20/Sep/2024 12:47:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:56,218 Request with ID 13968b07 for model llama3-8b received
2024-09-20 12:47:56,218 127.0.0.1 - - [20/Sep/2024 12:47:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:56,283 Request with ID b9733050 for model llama3-8b received
2024-09-20 12:47:56,283 127.0.0.1 - - [20/Sep/2024 12:47:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:56,433 Request with ID d44bf5ca for model gemma-7b received
2024-09-20 12:47:56,433 127.0.0.1 - - [20/Sep/2024 12:47:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:56,458 Request with ID 5988ef00 for model llama3-8b received
2024-09-20 12:47:56,459 127.0.0.1 - - [20/Sep/2024 12:47:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:56,680 Request with ID 5992847b for model llama3-8b received
2024-09-20 12:47:56,680 127.0.0.1 - - [20/Sep/2024 12:47:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:56,683 Request with ID e4c3448f for model llama3-8b received
2024-09-20 12:47:56,684 127.0.0.1 - - [20/Sep/2024 12:47:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:56,742 Request with ID c99ecf3a for model llama3-8b received
2024-09-20 12:47:56,742 127.0.0.1 - - [20/Sep/2024 12:47:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:56,783 Request with ID 4a8ce740 for model llama3-8b received
2024-09-20 12:47:56,783 127.0.0.1 - - [20/Sep/2024 12:47:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:56,960 Request with ID a70dd390 for model llama3-8b received
2024-09-20 12:47:56,960 127.0.0.1 - - [20/Sep/2024 12:47:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:57,304 Request with ID c2d18bb1 for model llama3-8b received
2024-09-20 12:47:57,305 127.0.0.1 - - [20/Sep/2024 12:47:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:57,345 Request with ID c2740c44 for model llama3-8b received
2024-09-20 12:47:57,346 127.0.0.1 - - [20/Sep/2024 12:47:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:57,544 Request with ID d626407d for model llama3-8b received
2024-09-20 12:47:57,544 127.0.0.1 - - [20/Sep/2024 12:47:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:57,630 Request with ID d73064bf for model llama3-8b received
2024-09-20 12:47:57,630 127.0.0.1 - - [20/Sep/2024 12:47:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:57,854 Request with ID f622f8ea for model llama3-8b received
2024-09-20 12:47:57,854 127.0.0.1 - - [20/Sep/2024 12:47:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:57,856 Request with ID d49588e1 for model llama3-8b received
2024-09-20 12:47:57,856 127.0.0.1 - - [20/Sep/2024 12:47:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:57,883 Request with ID 89d6b9bb for model granite-7b received
2024-09-20 12:47:57,883 127.0.0.1 - - [20/Sep/2024 12:47:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:58,135 Request with ID b46bd796 for model gemma-7b received
2024-09-20 12:47:58,135 127.0.0.1 - - [20/Sep/2024 12:47:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:58,149 Request with ID eadde75c for model granite-7b received
2024-09-20 12:47:58,150 127.0.0.1 - - [20/Sep/2024 12:47:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:58,432 Request with ID da17c00b for model llama3-8b received
2024-09-20 12:47:58,433 127.0.0.1 - - [20/Sep/2024 12:47:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:58,585 Request with ID c571a427 for model llama3-8b received
2024-09-20 12:47:58,585 127.0.0.1 - - [20/Sep/2024 12:47:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:58,664 Request with ID dcd4b2df for model gemma-7b received
2024-09-20 12:47:58,664 127.0.0.1 - - [20/Sep/2024 12:47:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:58,752 Request with ID cb5e8960 for model gemma-7b received
2024-09-20 12:47:58,752 127.0.0.1 - - [20/Sep/2024 12:47:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:58,799 Request with ID dba82251 for model llama3-8b received
2024-09-20 12:47:58,799 127.0.0.1 - - [20/Sep/2024 12:47:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:58,859 Request with ID a1814165 for model llama3-8b received
2024-09-20 12:47:58,859 127.0.0.1 - - [20/Sep/2024 12:47:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:47:58,988 Waiting for running processes to finish
2024-09-20 12:48:00,990 Waiting for running processes to finish
2024-09-20 12:48:02,993 Waiting for running processes to finish
2024-09-20 12:48:05,008 Waiting for running processes to finish
2024-09-20 12:48:07,011 Waiting for running processes to finish
2024-09-20 12:48:09,014 Waiting for running processes to finish
2024-09-20 12:48:11,017 Waiting for running processes to finish
2024-09-20 12:48:13,020 Waiting for running processes to finish
2024-09-20 12:48:14,345 Loaded model gemma-7b
2024-09-20 12:48:14,347 Batch processing started for model gemma-7b
2024-09-20 12:48:15,022 Waiting for running processes to finish
2024-09-20 12:48:17,025 Waiting for running processes to finish
2024-09-20 12:48:18,409 Processed batch: ['f5c5a68e', '3d075bb1', '1866d588', 'a9b8f51f', 'da56339a', '4479cbbb', '51f898aa', 'fd4cf0a3', 'b1c3d9bc', 'a7337cd2', '5d2f4780', 'cf9286b7', '48ffc046', 'b14642ea', '7bf44a4f', 'ffd0699b', 'b9fdc24f', 'bd5cf57f', 'a210b003', 'deba1a6f', '29bf5379', '15256932', 'e81cd126', 'df1cfc0d', '0c20ea2b', 'fd374856', '02a2e6cd', '907e81f4', '6cfd8a98', '3038e121', 'c5c217cf', '0de8c3dc'] with model gemma-7b in 4.0622 seconds
2024-09-20 12:48:18,410 Saving sys info
2024-09-20 12:48:18,463 Latency for request f5c5a68e with model gemma-7b: 56.8710 seconds
2024-09-20 12:48:18,463 Saving results with gpu monitoring
2024-09-20 12:48:18,468 Latency for request 3d075bb1 with model gemma-7b: 56.8220 seconds
2024-09-20 12:48:18,468 Saving results with gpu monitoring
2024-09-20 12:48:18,470 Latency for request 1866d588 with model gemma-7b: 56.3630 seconds
2024-09-20 12:48:18,470 Saving results with gpu monitoring
2024-09-20 12:48:18,472 Latency for request a9b8f51f with model gemma-7b: 56.0800 seconds
2024-09-20 12:48:18,472 Saving results with gpu monitoring
2024-09-20 12:48:18,474 Latency for request da56339a with model gemma-7b: 55.9980 seconds
2024-09-20 12:48:18,474 Saving results with gpu monitoring
2024-09-20 12:48:18,476 Latency for request 4479cbbb with model gemma-7b: 55.2010 seconds
2024-09-20 12:48:18,476 Saving results with gpu monitoring
2024-09-20 12:48:18,478 Latency for request 51f898aa with model gemma-7b: 55.1490 seconds
2024-09-20 12:48:18,478 Saving results with gpu monitoring
2024-09-20 12:48:18,480 Latency for request fd4cf0a3 with model gemma-7b: 54.5000 seconds
2024-09-20 12:48:18,480 Saving results with gpu monitoring
2024-09-20 12:48:18,482 Latency for request b1c3d9bc with model gemma-7b: 54.4960 seconds
2024-09-20 12:48:18,482 Saving results with gpu monitoring
2024-09-20 12:48:18,484 Latency for request a7337cd2 with model gemma-7b: 54.4430 seconds
2024-09-20 12:48:18,484 Saving results with gpu monitoring
2024-09-20 12:48:18,486 Latency for request 5d2f4780 with model gemma-7b: 54.4260 seconds
2024-09-20 12:48:18,486 Saving results with gpu monitoring
2024-09-20 12:48:18,488 Latency for request cf9286b7 with model gemma-7b: 54.0390 seconds
2024-09-20 12:48:18,488 Saving results with gpu monitoring
2024-09-20 12:48:18,490 Latency for request 48ffc046 with model gemma-7b: 53.1840 seconds
2024-09-20 12:48:18,490 Saving results with gpu monitoring
2024-09-20 12:48:18,492 Latency for request b14642ea with model gemma-7b: 53.1620 seconds
2024-09-20 12:48:18,492 Saving results with gpu monitoring
2024-09-20 12:48:18,494 Latency for request 7bf44a4f with model gemma-7b: 52.1610 seconds
2024-09-20 12:48:18,494 Saving results with gpu monitoring
2024-09-20 12:48:18,496 Latency for request ffd0699b with model gemma-7b: 51.5010 seconds
2024-09-20 12:48:18,496 Saving results with gpu monitoring
2024-09-20 12:48:18,498 Latency for request b9fdc24f with model gemma-7b: 51.4380 seconds
2024-09-20 12:48:18,498 Saving results with gpu monitoring
2024-09-20 12:48:18,500 Latency for request bd5cf57f with model gemma-7b: 51.2750 seconds
2024-09-20 12:48:18,500 Saving results with gpu monitoring
2024-09-20 12:48:18,502 Latency for request a210b003 with model gemma-7b: 51.1410 seconds
2024-09-20 12:48:18,502 Saving results with gpu monitoring
2024-09-20 12:48:18,504 Latency for request deba1a6f with model gemma-7b: 50.6320 seconds
2024-09-20 12:48:18,504 Saving results with gpu monitoring
2024-09-20 12:48:18,506 Latency for request 29bf5379 with model gemma-7b: 50.1000 seconds
2024-09-20 12:48:18,506 Saving results with gpu monitoring
2024-09-20 12:48:18,508 Latency for request 15256932 with model gemma-7b: 48.6930 seconds
2024-09-20 12:48:18,508 Saving results with gpu monitoring
2024-09-20 12:48:18,510 Latency for request e81cd126 with model gemma-7b: 48.4470 seconds
2024-09-20 12:48:18,510 Saving results with gpu monitoring
2024-09-20 12:48:18,512 Latency for request df1cfc0d with model gemma-7b: 47.6680 seconds
2024-09-20 12:48:18,512 Saving results with gpu monitoring
2024-09-20 12:48:18,514 Latency for request 0c20ea2b with model gemma-7b: 47.5630 seconds
2024-09-20 12:48:18,514 Saving results with gpu monitoring
2024-09-20 12:48:18,516 Latency for request fd374856 with model gemma-7b: 47.4410 seconds
2024-09-20 12:48:18,516 Saving results with gpu monitoring
2024-09-20 12:48:18,518 Latency for request 02a2e6cd with model gemma-7b: 47.0450 seconds
2024-09-20 12:48:18,518 Saving results with gpu monitoring
2024-09-20 12:48:18,520 Latency for request 907e81f4 with model gemma-7b: 46.5030 seconds
2024-09-20 12:48:18,520 Saving results with gpu monitoring
2024-09-20 12:48:18,522 Latency for request 6cfd8a98 with model gemma-7b: 45.8570 seconds
2024-09-20 12:48:18,522 Saving results with gpu monitoring
2024-09-20 12:48:18,524 Latency for request 3038e121 with model gemma-7b: 45.0840 seconds
2024-09-20 12:48:18,524 Saving results with gpu monitoring
2024-09-20 12:48:18,526 Latency for request c5c217cf with model gemma-7b: 43.9720 seconds
2024-09-20 12:48:18,526 Saving results with gpu monitoring
2024-09-20 12:48:18,528 Latency for request 0de8c3dc with model gemma-7b: 43.6090 seconds
2024-09-20 12:48:18,528 Saving results with gpu monitoring
2024-09-20 12:48:18,531 127.0.0.1 - - [20/Sep/2024 12:48:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:48:18,531 Next: call load_model for llama3-8b
2024-09-20 12:48:18,647 Unloaded previous model
2024-09-20 12:48:19,038 Waiting for running processes to finish
2024-09-20 12:48:21,041 Waiting for running processes to finish
2024-09-20 12:48:23,044 Waiting for running processes to finish
2024-09-20 12:48:25,046 Waiting for running processes to finish
2024-09-20 12:48:27,049 Waiting for running processes to finish
2024-09-20 12:48:29,068 Waiting for running processes to finish
2024-09-20 12:48:31,156 Waiting for running processes to finish
2024-09-20 12:48:33,192 Waiting for running processes to finish
2024-09-20 12:48:34,205 Loaded model llama3-8b
2024-09-20 12:48:34,208 Batch processing started for model llama3-8b
2024-09-20 12:48:35,195 Waiting for running processes to finish
2024-09-20 12:48:37,197 Waiting for running processes to finish
2024-09-20 12:48:39,200 Waiting for running processes to finish
2024-09-20 12:48:40,742 Processed batch: ['509ff701', '35a5fa09', '50cb2948', 'b1068f6f', '5ee3c1d7', 'ea97c7c3', 'ba663f5b', 'd70c8481', 'd3e79a40', '5db65327', '0804398a', '47f01a35', '41080650', '80fc2ce9', '5cecb8c2', 'e53148db', 'e1e2ffd7', '74f1ae53', '1b0853ed', '6bc3c9e5', '76d8744a', '592a7cae', '92369933', '244657f9', '8637637c', '29a9a42a', 'e08ab24a', '11c6f2d3', 'bf94fedb', 'f29f4176', '1d40c588', 'e1b3d836', '1d075fa7', 'b329718c', 'dc3979ce', '96f897dc', 'dc2de411', 'bd262628', 'f85a5611', 'c2bb5cfe', '944fba91', '7fa7a8e0', '4b7c2a6d', 'd9395dfc', '15fb4aae', '07847e03', '27fb2837', 'e8ea86ce', 'e6e787c3', 'f9c7a3a3', '931ddd80', 'd8a87b5b', '94bc2925', 'bde74e22', 'e79fcee6', '43762034', 'f8c516fe', '44fae99e', 'aa3b1a84', 'd95d48ea', 'c9c1f843', '91545ed8', '3670e8c0', '3143586c'] with model llama3-8b in 6.5337 seconds
2024-09-20 12:48:40,742 Saving sys info
2024-09-20 12:48:40,807 Latency for request 509ff701 with model llama3-8b: 62.0900 seconds
2024-09-20 12:48:40,807 Saving results with gpu monitoring
2024-09-20 12:48:40,810 Latency for request 35a5fa09 with model llama3-8b: 62.0390 seconds
2024-09-20 12:48:40,810 Saving results with gpu monitoring
2024-09-20 12:48:40,812 Latency for request 50cb2948 with model llama3-8b: 61.8790 seconds
2024-09-20 12:48:40,812 Saving results with gpu monitoring
2024-09-20 12:48:40,814 Latency for request b1068f6f with model llama3-8b: 61.4730 seconds
2024-09-20 12:48:40,814 Saving results with gpu monitoring
2024-09-20 12:48:40,816 Latency for request 5ee3c1d7 with model llama3-8b: 61.3840 seconds
2024-09-20 12:48:40,816 Saving results with gpu monitoring
2024-09-20 12:48:40,818 Latency for request ea97c7c3 with model llama3-8b: 61.1010 seconds
2024-09-20 12:48:40,819 Saving results with gpu monitoring
2024-09-20 12:48:40,820 Latency for request ba663f5b with model llama3-8b: 60.9550 seconds
2024-09-20 12:48:40,821 Saving results with gpu monitoring
2024-09-20 12:48:40,823 Latency for request d70c8481 with model llama3-8b: 60.7940 seconds
2024-09-20 12:48:40,823 Saving results with gpu monitoring
2024-09-20 12:48:40,825 Latency for request d3e79a40 with model llama3-8b: 60.5290 seconds
2024-09-20 12:48:40,825 Saving results with gpu monitoring
2024-09-20 12:48:40,827 Latency for request 5db65327 with model llama3-8b: 60.2290 seconds
2024-09-20 12:48:40,827 Saving results with gpu monitoring
2024-09-20 12:48:40,829 Latency for request 0804398a with model llama3-8b: 60.1200 seconds
2024-09-20 12:48:40,829 Saving results with gpu monitoring
2024-09-20 12:48:40,831 Latency for request 47f01a35 with model llama3-8b: 60.0420 seconds
2024-09-20 12:48:40,831 Saving results with gpu monitoring
2024-09-20 12:48:40,833 Latency for request 41080650 with model llama3-8b: 59.9900 seconds
2024-09-20 12:48:40,833 Saving results with gpu monitoring
2024-09-20 12:48:40,835 Latency for request 80fc2ce9 with model llama3-8b: 59.9880 seconds
2024-09-20 12:48:40,835 Saving results with gpu monitoring
2024-09-20 12:48:40,837 Latency for request 5cecb8c2 with model llama3-8b: 59.9190 seconds
2024-09-20 12:48:40,837 Saving results with gpu monitoring
2024-09-20 12:48:40,839 Latency for request e53148db with model llama3-8b: 59.8640 seconds
2024-09-20 12:48:40,839 Saving results with gpu monitoring
2024-09-20 12:48:40,841 Latency for request e1e2ffd7 with model llama3-8b: 59.8270 seconds
2024-09-20 12:48:40,841 Saving results with gpu monitoring
2024-09-20 12:48:40,843 Latency for request 74f1ae53 with model llama3-8b: 59.6130 seconds
2024-09-20 12:48:40,843 Saving results with gpu monitoring
2024-09-20 12:48:40,845 Latency for request 1b0853ed with model llama3-8b: 59.0350 seconds
2024-09-20 12:48:40,845 Saving results with gpu monitoring
2024-09-20 12:48:40,847 Latency for request 6bc3c9e5 with model llama3-8b: 59.0160 seconds
2024-09-20 12:48:40,847 Saving results with gpu monitoring
2024-09-20 12:48:40,849 Latency for request 76d8744a with model llama3-8b: 58.8270 seconds
2024-09-20 12:48:40,849 Saving results with gpu monitoring
2024-09-20 12:48:40,851 Latency for request 592a7cae with model llama3-8b: 58.6450 seconds
2024-09-20 12:48:40,851 Saving results with gpu monitoring
2024-09-20 12:48:40,853 Latency for request 92369933 with model llama3-8b: 58.6280 seconds
2024-09-20 12:48:40,853 Saving results with gpu monitoring
2024-09-20 12:48:40,855 Latency for request 244657f9 with model llama3-8b: 58.5430 seconds
2024-09-20 12:48:40,855 Saving results with gpu monitoring
2024-09-20 12:48:40,857 Latency for request 8637637c with model llama3-8b: 58.0710 seconds
2024-09-20 12:48:40,857 Saving results with gpu monitoring
2024-09-20 12:48:40,859 Latency for request 29a9a42a with model llama3-8b: 57.6340 seconds
2024-09-20 12:48:40,859 Saving results with gpu monitoring
2024-09-20 12:48:40,861 Latency for request e08ab24a with model llama3-8b: 57.2900 seconds
2024-09-20 12:48:40,861 Saving results with gpu monitoring
2024-09-20 12:48:40,863 Latency for request 11c6f2d3 with model llama3-8b: 57.0900 seconds
2024-09-20 12:48:40,863 Saving results with gpu monitoring
2024-09-20 12:48:40,865 Latency for request bf94fedb with model llama3-8b: 56.9480 seconds
2024-09-20 12:48:40,865 Saving results with gpu monitoring
2024-09-20 12:48:40,867 Latency for request f29f4176 with model llama3-8b: 56.8320 seconds
2024-09-20 12:48:40,867 Saving results with gpu monitoring
2024-09-20 12:48:40,869 Latency for request 1d40c588 with model llama3-8b: 56.6200 seconds
2024-09-20 12:48:40,869 Saving results with gpu monitoring
2024-09-20 12:48:40,871 Latency for request e1b3d836 with model llama3-8b: 56.0480 seconds
2024-09-20 12:48:40,871 Saving results with gpu monitoring
2024-09-20 12:48:40,873 Latency for request 1d075fa7 with model llama3-8b: 55.9490 seconds
2024-09-20 12:48:40,873 Saving results with gpu monitoring
2024-09-20 12:48:40,875 Latency for request b329718c with model llama3-8b: 55.7810 seconds
2024-09-20 12:48:40,875 Saving results with gpu monitoring
2024-09-20 12:48:40,877 Latency for request dc3979ce with model llama3-8b: 55.5920 seconds
2024-09-20 12:48:40,877 Saving results with gpu monitoring
2024-09-20 12:48:40,879 Latency for request 96f897dc with model llama3-8b: 54.6500 seconds
2024-09-20 12:48:40,879 Saving results with gpu monitoring
2024-09-20 12:48:40,881 Latency for request dc2de411 with model llama3-8b: 54.5680 seconds
2024-09-20 12:48:40,881 Saving results with gpu monitoring
2024-09-20 12:48:40,883 Latency for request bd262628 with model llama3-8b: 54.5240 seconds
2024-09-20 12:48:40,883 Saving results with gpu monitoring
2024-09-20 12:48:40,885 Latency for request f85a5611 with model llama3-8b: 53.8800 seconds
2024-09-20 12:48:40,885 Saving results with gpu monitoring
2024-09-20 12:48:40,887 Latency for request c2bb5cfe with model llama3-8b: 53.8180 seconds
2024-09-20 12:48:40,887 Saving results with gpu monitoring
2024-09-20 12:48:40,889 Latency for request 944fba91 with model llama3-8b: 53.5790 seconds
2024-09-20 12:48:40,889 Saving results with gpu monitoring
2024-09-20 12:48:40,891 Latency for request 7fa7a8e0 with model llama3-8b: 53.0890 seconds
2024-09-20 12:48:40,891 Saving results with gpu monitoring
2024-09-20 12:48:40,893 Latency for request 4b7c2a6d with model llama3-8b: 53.0870 seconds
2024-09-20 12:48:40,894 Saving results with gpu monitoring
2024-09-20 12:48:40,895 Latency for request d9395dfc with model llama3-8b: 52.8650 seconds
2024-09-20 12:48:40,896 Saving results with gpu monitoring
2024-09-20 12:48:40,898 Latency for request 15fb4aae with model llama3-8b: 52.8360 seconds
2024-09-20 12:48:40,898 Saving results with gpu monitoring
2024-09-20 12:48:40,900 Latency for request 07847e03 with model llama3-8b: 52.6690 seconds
2024-09-20 12:48:40,900 Saving results with gpu monitoring
2024-09-20 12:48:40,902 Latency for request 27fb2837 with model llama3-8b: 52.5990 seconds
2024-09-20 12:48:40,902 Saving results with gpu monitoring
2024-09-20 12:48:40,904 Latency for request e8ea86ce with model llama3-8b: 52.5890 seconds
2024-09-20 12:48:40,904 Saving results with gpu monitoring
2024-09-20 12:48:40,906 Latency for request e6e787c3 with model llama3-8b: 52.5300 seconds
2024-09-20 12:48:40,906 Saving results with gpu monitoring
2024-09-20 12:48:40,908 Latency for request f9c7a3a3 with model llama3-8b: 51.9800 seconds
2024-09-20 12:48:40,908 Saving results with gpu monitoring
2024-09-20 12:48:40,910 Latency for request 931ddd80 with model llama3-8b: 51.9040 seconds
2024-09-20 12:48:40,910 Saving results with gpu monitoring
2024-09-20 12:48:40,912 Latency for request d8a87b5b with model llama3-8b: 51.8110 seconds
2024-09-20 12:48:40,912 Saving results with gpu monitoring
2024-09-20 12:48:40,914 Latency for request 94bc2925 with model llama3-8b: 51.5570 seconds
2024-09-20 12:48:40,914 Saving results with gpu monitoring
2024-09-20 12:48:40,916 Latency for request bde74e22 with model llama3-8b: 51.5260 seconds
2024-09-20 12:48:40,916 Saving results with gpu monitoring
2024-09-20 12:48:40,918 Latency for request e79fcee6 with model llama3-8b: 51.5180 seconds
2024-09-20 12:48:40,918 Saving results with gpu monitoring
2024-09-20 12:48:40,920 Latency for request 43762034 with model llama3-8b: 51.4460 seconds
2024-09-20 12:48:40,920 Saving results with gpu monitoring
2024-09-20 12:48:40,922 Latency for request f8c516fe with model llama3-8b: 51.4420 seconds
2024-09-20 12:48:40,922 Saving results with gpu monitoring
2024-09-20 12:48:40,924 Latency for request 44fae99e with model llama3-8b: 51.3370 seconds
2024-09-20 12:48:40,924 Saving results with gpu monitoring
2024-09-20 12:48:40,926 Latency for request aa3b1a84 with model llama3-8b: 51.2780 seconds
2024-09-20 12:48:40,926 Saving results with gpu monitoring
2024-09-20 12:48:40,928 Latency for request d95d48ea with model llama3-8b: 51.1370 seconds
2024-09-20 12:48:40,928 Saving results with gpu monitoring
2024-09-20 12:48:40,930 Latency for request c9c1f843 with model llama3-8b: 50.8730 seconds
2024-09-20 12:48:40,930 Saving results with gpu monitoring
2024-09-20 12:48:40,932 Latency for request 91545ed8 with model llama3-8b: 50.8530 seconds
2024-09-20 12:48:40,932 Saving results with gpu monitoring
2024-09-20 12:48:40,934 Latency for request 3670e8c0 with model llama3-8b: 50.6780 seconds
2024-09-20 12:48:40,934 Saving results with gpu monitoring
2024-09-20 12:48:40,936 Latency for request 3143586c with model llama3-8b: 50.5530 seconds
2024-09-20 12:48:40,936 Saving results with gpu monitoring
2024-09-20 12:48:40,939 127.0.0.1 - - [20/Sep/2024 12:48:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:48:40,939 No batch to process for model llama3-8b
2024-09-20 12:48:40,939 Processing batch for granite-7b due to time limit with batch size 6
2024-09-20 12:48:40,939 Time limit condition met for model granite-7b
2024-09-20 12:48:40,940 Next: call load_model for granite-7b
2024-09-20 12:48:41,037 Unloaded previous model
2024-09-20 12:48:41,204 Waiting for running processes to finish
2024-09-20 12:48:43,209 Waiting for running processes to finish
2024-09-20 12:48:45,212 Waiting for running processes to finish
2024-09-20 12:48:47,215 Waiting for running processes to finish
2024-09-20 12:48:49,217 Waiting for running processes to finish
2024-09-20 12:48:51,220 Waiting for running processes to finish
2024-09-20 12:48:53,222 Waiting for running processes to finish
2024-09-20 12:48:55,225 Waiting for running processes to finish
2024-09-20 12:48:57,227 Waiting for running processes to finish
2024-09-20 12:48:59,230 Waiting for running processes to finish
2024-09-20 12:48:59,808 Loaded model granite-7b
2024-09-20 12:48:59,812 Batch processing started for model granite-7b
2024-09-20 12:49:01,232 Waiting for running processes to finish
2024-09-20 12:49:01,541 Processed batch: ['97f540e5', 'e16489af', 'ff03ee36', 'd80c0e7f', '89d6b9bb', 'eadde75c'] with model granite-7b in 1.7286 seconds
2024-09-20 12:49:01,541 Saving sys info
2024-09-20 12:49:01,574 Latency for request 97f540e5 with model granite-7b: 67.4300 seconds
2024-09-20 12:49:01,574 Saving results with gpu monitoring
2024-09-20 12:49:01,578 Latency for request e16489af with model granite-7b: 67.2980 seconds
2024-09-20 12:49:01,578 Saving results with gpu monitoring
2024-09-20 12:49:01,580 Latency for request ff03ee36 with model granite-7b: 67.2440 seconds
2024-09-20 12:49:01,580 Saving results with gpu monitoring
2024-09-20 12:49:01,582 Latency for request d80c0e7f with model granite-7b: 67.0190 seconds
2024-09-20 12:49:01,582 Saving results with gpu monitoring
2024-09-20 12:49:01,584 Latency for request 89d6b9bb with model granite-7b: 63.6580 seconds
2024-09-20 12:49:01,584 Saving results with gpu monitoring
2024-09-20 12:49:01,586 Latency for request eadde75c with model granite-7b: 63.3910 seconds
2024-09-20 12:49:01,586 Saving results with gpu monitoring
2024-09-20 12:49:01,588 127.0.0.1 - - [20/Sep/2024 12:49:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:01,589 Next: call load_model for gemma-7b
2024-09-20 12:49:01,666 Unloaded previous model
2024-09-20 12:49:03,266 Waiting for running processes to finish
2024-09-20 12:49:06,270 Total time: 182.6045 seconds
2024-09-20 12:49:06,270 Total inference time: 36.0270 seconds
2024-09-20 12:49:06,270 Inference time as percentage of total time: 19.73%
2024-09-20 12:49:06,271 END
2024-09-20 12:49:06,271 127.0.0.1 - - [20/Sep/2024 12:49:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:26,887 Loaded model gemma-7b
2024-09-20 12:49:26,889 Batch processing started for model gemma-7b
2024-09-20 12:49:36,545 Processed batch: ['93ce78e8', '5f66e5c5', 'dfbb0fad', 'cdefc2e9', '62ea2e10', 'aecb4507', '8da99835', '47522244', 'bb3d6c14', 'e3a0a225', '6aa84081', '6e074dcd', 'fac5cd36', '4fb7b370', 'fe8bd1ca', 'cb5329d3', '7c27b1bd', 'b86eda8f', '2876db33', '8baca678', '94e22d4e', '5ffe377f', '55eda007', '6dea4394', '737d49be', '8291989d', 'c907ec7f', '57afd774', 'c1322626', 'c40eedf7', 'e627cb4e', '02e5cfd4', '718c781b', 'f983ad45', '952ae328', 'd744d5d4', 'b9f72f34', 'f441513a', 'b8f8819a', '71fa002d', 'd2f1ddb5', '8ff884e9', 'c832ed48', 'b58e0fe9', '8f65bad4', '347d0b87', '5d1cf4fe', '0cdbc072', '63454ac1', '1c81f59b', '653a47c0', '3931311c', 'd341dbd3', '733df681', 'd12cb24f', 'b3d3a363', '977c160e', '5c0a71b0', '73308ef8', '1af52b3b', '800ecc70', '9949dd87', 'adca1d9b', 'fac5b370'] with model gemma-7b in 9.6560 seconds
2024-09-20 12:49:36,546 Saving sys info
2024-09-20 12:49:36,594 Latency for request 93ce78e8 with model gemma-7b: 121.6870 seconds
2024-09-20 12:49:36,594 Saving results with gpu monitoring
2024-09-20 12:49:36,597 Latency for request 5f66e5c5 with model gemma-7b: 121.0210 seconds
2024-09-20 12:49:36,597 Saving results with gpu monitoring
2024-09-20 12:49:36,599 Latency for request dfbb0fad with model gemma-7b: 120.4360 seconds
2024-09-20 12:49:36,599 Saving results with gpu monitoring
2024-09-20 12:49:36,601 Latency for request cdefc2e9 with model gemma-7b: 120.2660 seconds
2024-09-20 12:49:36,601 Saving results with gpu monitoring
2024-09-20 12:49:36,603 Latency for request 62ea2e10 with model gemma-7b: 120.0290 seconds
2024-09-20 12:49:36,603 Saving results with gpu monitoring
2024-09-20 12:49:36,605 Latency for request aecb4507 with model gemma-7b: 119.0230 seconds
2024-09-20 12:49:36,605 Saving results with gpu monitoring
2024-09-20 12:49:36,607 Latency for request 8da99835 with model gemma-7b: 118.9300 seconds
2024-09-20 12:49:36,607 Saving results with gpu monitoring
2024-09-20 12:49:36,609 Latency for request 47522244 with model gemma-7b: 118.7720 seconds
2024-09-20 12:49:36,609 Saving results with gpu monitoring
2024-09-20 12:49:36,611 Latency for request bb3d6c14 with model gemma-7b: 117.7920 seconds
2024-09-20 12:49:36,611 Saving results with gpu monitoring
2024-09-20 12:49:36,613 Latency for request e3a0a225 with model gemma-7b: 117.4690 seconds
2024-09-20 12:49:36,613 Saving results with gpu monitoring
2024-09-20 12:49:36,615 Latency for request 6aa84081 with model gemma-7b: 117.3920 seconds
2024-09-20 12:49:36,615 Saving results with gpu monitoring
2024-09-20 12:49:36,617 Latency for request 6e074dcd with model gemma-7b: 117.1310 seconds
2024-09-20 12:49:36,617 Saving results with gpu monitoring
2024-09-20 12:49:36,620 Latency for request fac5cd36 with model gemma-7b: 116.5990 seconds
2024-09-20 12:49:36,620 Saving results with gpu monitoring
2024-09-20 12:49:36,622 Latency for request 4fb7b370 with model gemma-7b: 115.7860 seconds
2024-09-20 12:49:36,622 Saving results with gpu monitoring
2024-09-20 12:49:36,624 Latency for request fe8bd1ca with model gemma-7b: 115.7620 seconds
2024-09-20 12:49:36,624 Saving results with gpu monitoring
2024-09-20 12:49:36,626 Latency for request cb5329d3 with model gemma-7b: 115.7610 seconds
2024-09-20 12:49:36,626 Saving results with gpu monitoring
2024-09-20 12:49:36,628 Latency for request 7c27b1bd with model gemma-7b: 115.4590 seconds
2024-09-20 12:49:36,628 Saving results with gpu monitoring
2024-09-20 12:49:36,630 Latency for request b86eda8f with model gemma-7b: 115.3140 seconds
2024-09-20 12:49:36,630 Saving results with gpu monitoring
2024-09-20 12:49:36,632 Latency for request 2876db33 with model gemma-7b: 115.2190 seconds
2024-09-20 12:49:36,632 Saving results with gpu monitoring
2024-09-20 12:49:36,634 Latency for request 8baca678 with model gemma-7b: 115.0660 seconds
2024-09-20 12:49:36,634 Saving results with gpu monitoring
2024-09-20 12:49:36,636 Latency for request 94e22d4e with model gemma-7b: 114.9650 seconds
2024-09-20 12:49:36,636 Saving results with gpu monitoring
2024-09-20 12:49:36,638 Latency for request 5ffe377f with model gemma-7b: 114.6410 seconds
2024-09-20 12:49:36,638 Saving results with gpu monitoring
2024-09-20 12:49:36,640 Latency for request 55eda007 with model gemma-7b: 114.4970 seconds
2024-09-20 12:49:36,640 Saving results with gpu monitoring
2024-09-20 12:49:36,642 Latency for request 6dea4394 with model gemma-7b: 114.4930 seconds
2024-09-20 12:49:36,642 Saving results with gpu monitoring
2024-09-20 12:49:36,644 Latency for request 737d49be with model gemma-7b: 114.2980 seconds
2024-09-20 12:49:36,644 Saving results with gpu monitoring
2024-09-20 12:49:36,646 Latency for request 8291989d with model gemma-7b: 112.7660 seconds
2024-09-20 12:49:36,646 Saving results with gpu monitoring
2024-09-20 12:49:36,648 Latency for request c907ec7f with model gemma-7b: 112.5230 seconds
2024-09-20 12:49:36,648 Saving results with gpu monitoring
2024-09-20 12:49:36,650 Latency for request 57afd774 with model gemma-7b: 112.0200 seconds
2024-09-20 12:49:36,650 Saving results with gpu monitoring
2024-09-20 12:49:36,652 Latency for request c1322626 with model gemma-7b: 111.9500 seconds
2024-09-20 12:49:36,652 Saving results with gpu monitoring
2024-09-20 12:49:36,654 Latency for request c40eedf7 with model gemma-7b: 111.7970 seconds
2024-09-20 12:49:36,654 Saving results with gpu monitoring
2024-09-20 12:49:36,656 Latency for request e627cb4e with model gemma-7b: 111.6340 seconds
2024-09-20 12:49:36,656 Saving results with gpu monitoring
2024-09-20 12:49:36,658 Latency for request 02e5cfd4 with model gemma-7b: 111.4510 seconds
2024-09-20 12:49:36,658 Saving results with gpu monitoring
2024-09-20 12:49:36,660 Latency for request 718c781b with model gemma-7b: 110.9290 seconds
2024-09-20 12:49:36,660 Saving results with gpu monitoring
2024-09-20 12:49:36,662 Latency for request f983ad45 with model gemma-7b: 110.8100 seconds
2024-09-20 12:49:36,662 Saving results with gpu monitoring
2024-09-20 12:49:36,664 Latency for request 952ae328 with model gemma-7b: 110.1910 seconds
2024-09-20 12:49:36,664 Saving results with gpu monitoring
2024-09-20 12:49:36,666 Latency for request d744d5d4 with model gemma-7b: 110.0820 seconds
2024-09-20 12:49:36,666 Saving results with gpu monitoring
2024-09-20 12:49:36,668 Latency for request b9f72f34 with model gemma-7b: 109.4960 seconds
2024-09-20 12:49:36,668 Saving results with gpu monitoring
2024-09-20 12:49:36,670 Latency for request f441513a with model gemma-7b: 109.2930 seconds
2024-09-20 12:49:36,670 Saving results with gpu monitoring
2024-09-20 12:49:36,672 Latency for request b8f8819a with model gemma-7b: 109.2000 seconds
2024-09-20 12:49:36,672 Saving results with gpu monitoring
2024-09-20 12:49:36,674 Latency for request 71fa002d with model gemma-7b: 109.1860 seconds
2024-09-20 12:49:36,674 Saving results with gpu monitoring
2024-09-20 12:49:36,676 Latency for request d2f1ddb5 with model gemma-7b: 108.5870 seconds
2024-09-20 12:49:36,676 Saving results with gpu monitoring
2024-09-20 12:49:36,678 Latency for request 8ff884e9 with model gemma-7b: 108.2040 seconds
2024-09-20 12:49:36,678 Saving results with gpu monitoring
2024-09-20 12:49:36,680 Latency for request c832ed48 with model gemma-7b: 108.1240 seconds
2024-09-20 12:49:36,680 Saving results with gpu monitoring
2024-09-20 12:49:36,682 Latency for request b58e0fe9 with model gemma-7b: 107.9960 seconds
2024-09-20 12:49:36,682 Saving results with gpu monitoring
2024-09-20 12:49:36,684 Latency for request 8f65bad4 with model gemma-7b: 107.4300 seconds
2024-09-20 12:49:36,684 Saving results with gpu monitoring
2024-09-20 12:49:36,686 Latency for request 347d0b87 with model gemma-7b: 107.2970 seconds
2024-09-20 12:49:36,686 Saving results with gpu monitoring
2024-09-20 12:49:36,688 Latency for request 5d1cf4fe with model gemma-7b: 107.0740 seconds
2024-09-20 12:49:36,688 Saving results with gpu monitoring
2024-09-20 12:49:36,690 Latency for request 0cdbc072 with model gemma-7b: 107.0140 seconds
2024-09-20 12:49:36,690 Saving results with gpu monitoring
2024-09-20 12:49:36,692 Latency for request 63454ac1 with model gemma-7b: 106.6750 seconds
2024-09-20 12:49:36,692 Saving results with gpu monitoring
2024-09-20 12:49:36,694 Latency for request 1c81f59b with model gemma-7b: 106.1690 seconds
2024-09-20 12:49:36,694 Saving results with gpu monitoring
2024-09-20 12:49:36,696 Latency for request 653a47c0 with model gemma-7b: 105.6540 seconds
2024-09-20 12:49:36,696 Saving results with gpu monitoring
2024-09-20 12:49:36,698 Latency for request 3931311c with model gemma-7b: 105.0670 seconds
2024-09-20 12:49:36,698 Saving results with gpu monitoring
2024-09-20 12:49:36,700 Latency for request d341dbd3 with model gemma-7b: 104.8610 seconds
2024-09-20 12:49:36,700 Saving results with gpu monitoring
2024-09-20 12:49:36,702 Latency for request 733df681 with model gemma-7b: 104.8260 seconds
2024-09-20 12:49:36,702 Saving results with gpu monitoring
2024-09-20 12:49:36,704 Latency for request d12cb24f with model gemma-7b: 104.7880 seconds
2024-09-20 12:49:36,704 Saving results with gpu monitoring
2024-09-20 12:49:36,706 Latency for request b3d3a363 with model gemma-7b: 104.4680 seconds
2024-09-20 12:49:36,706 Saving results with gpu monitoring
2024-09-20 12:49:36,708 Latency for request 977c160e with model gemma-7b: 104.0850 seconds
2024-09-20 12:49:36,708 Saving results with gpu monitoring
2024-09-20 12:49:36,710 Latency for request 5c0a71b0 with model gemma-7b: 103.9660 seconds
2024-09-20 12:49:36,710 Saving results with gpu monitoring
2024-09-20 12:49:36,712 Latency for request 73308ef8 with model gemma-7b: 102.9450 seconds
2024-09-20 12:49:36,712 Saving results with gpu monitoring
2024-09-20 12:49:36,714 Latency for request 1af52b3b with model gemma-7b: 102.6090 seconds
2024-09-20 12:49:36,715 Saving results with gpu monitoring
2024-09-20 12:49:36,716 Latency for request 800ecc70 with model gemma-7b: 102.2550 seconds
2024-09-20 12:49:36,717 Saving results with gpu monitoring
2024-09-20 12:49:36,719 Latency for request 9949dd87 with model gemma-7b: 101.0500 seconds
2024-09-20 12:49:36,719 Saving results with gpu monitoring
2024-09-20 12:49:36,721 Latency for request adca1d9b with model gemma-7b: 100.6850 seconds
2024-09-20 12:49:36,721 Saving results with gpu monitoring
2024-09-20 12:49:36,723 Latency for request fac5b370 with model gemma-7b: 100.4260 seconds
2024-09-20 12:49:36,723 Saving results with gpu monitoring
2024-09-20 12:49:36,725 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,725 No batch to process for model llama3-8b
2024-09-20 12:49:36,726 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,726 No batch to process for model granite-7b
2024-09-20 12:49:36,727 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,727 No batch to process for model llama3-8b
2024-09-20 12:49:36,728 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,728 No batch to process for model gemma-7b
2024-09-20 12:49:36,729 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,729 No batch to process for model llama3-8b
2024-09-20 12:49:36,730 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,732 No batch to process for model granite-7b
2024-09-20 12:49:36,732 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,732 No batch to process for model llama3-8b
2024-09-20 12:49:36,733 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,733 No batch to process for model gemma-7b
2024-09-20 12:49:36,735 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,735 No batch to process for model granite-7b
2024-09-20 12:49:36,735 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,736 No batch to process for model llama3-8b
2024-09-20 12:49:36,736 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,736 No batch to process for model gemma-7b
2024-09-20 12:49:36,737 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,737 No batch to process for model granite-7b
2024-09-20 12:49:36,738 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,739 No batch to process for model llama3-8b
2024-09-20 12:49:36,740 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,740 No batch to process for model llama3-8b
2024-09-20 12:49:36,740 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,741 No batch to process for model granite-7b
2024-09-20 12:49:36,741 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,741 No batch to process for model gemma-7b
2024-09-20 12:49:36,742 127.0.0.1 - - [20/Sep/2024 12:49:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:49:36,743 No batch to process for model granite-7b
