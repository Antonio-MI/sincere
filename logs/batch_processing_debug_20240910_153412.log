2024-09-10 15:34:17,760 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.11.77:5000
2024-09-10 15:34:17,760 [33mPress CTRL+C to quit[0m
2024-09-10 15:34:21,145 Request with ID 052e0e61 for model gpt2-124m received
2024-09-10 15:34:21,145 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 15:34:21,145 Adjusted time limit for model gpt2-124m: 13.6926 seconds
2024-09-10 15:34:21,145 127.0.0.1 - - [10/Sep/2024 15:34:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:21,644 Request with ID 72f828d1 for model gpt2-124m received
2024-09-10 15:34:21,645 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:34:21,645 127.0.0.1 - - [10/Sep/2024 15:34:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:21,842 Request with ID 723869ce for model gpt2medium-355m received
2024-09-10 15:34:21,842 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:21,842 Adjusted time limit for model gpt2medium-355m: 11.8866 seconds
2024-09-10 15:34:21,843 127.0.0.1 - - [10/Sep/2024 15:34:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:21,880 Request with ID f2c804ac for model gpt2-124m received
2024-09-10 15:34:21,880 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:21,881 127.0.0.1 - - [10/Sep/2024 15:34:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:22,106 Request with ID 2fd55c4d for model gpt2-124m received
2024-09-10 15:34:22,106 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:22,107 Batch size condition met for model gpt2-124m
2024-09-10 15:34:22,107 Updated batch size:4
2024-09-10 15:34:22,107 Loading model gpt2-124m
2024-09-10 15:34:22,502 Request with ID 9ddecb99 for model distilgpt2-124m received
2024-09-10 15:34:22,502 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:34:22,502 Adjusted time limit for model distilgpt2-124m: 14.1814 seconds
2024-09-10 15:34:22,502 127.0.0.1 - - [10/Sep/2024 15:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:22,868 Request with ID 674c5e73 for model distilgpt2-124m received
2024-09-10 15:34:22,868 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:22,868 127.0.0.1 - - [10/Sep/2024 15:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:22,920 Processed batch: ['052e0e61', '72f828d1', 'f2c804ac', '2fd55c4d'] with model gpt2-124m in 0.6796 seconds
2024-09-10 15:34:22,920 Latency for request 052e0e61 with model gpt2-124m: 1.7749 seconds
2024-09-10 15:34:22,921 Latency for request 72f828d1 with model gpt2-124m: 1.2754 seconds
2024-09-10 15:34:22,922 Latency for request f2c804ac with model gpt2-124m: 1.0394 seconds
2024-09-10 15:34:22,922 Latency for request 2fd55c4d with model gpt2-124m: 0.8136 seconds
2024-09-10 15:34:22,922 127.0.0.1 - - [10/Sep/2024 15:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:23,209 Request with ID 55c0067f for model gpt2medium-355m received
2024-09-10 15:34:23,209 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:23,209 127.0.0.1 - - [10/Sep/2024 15:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:23,448 Request with ID e4e744b3 for model distilgpt2-124m received
2024-09-10 15:34:23,448 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:23,449 127.0.0.1 - - [10/Sep/2024 15:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:23,722 Request with ID 71458982 for model gpt2medium-355m received
2024-09-10 15:34:23,723 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:23,723 127.0.0.1 - - [10/Sep/2024 15:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:23,759 Time limit condition met for model gpt2medium-355m
2024-09-10 15:34:23,760 Updated batch size:4
2024-09-10 15:34:23,760 Loading model gpt2medium-355m
2024-09-10 15:34:24,014 Request with ID 5f809c44 for model gpt2-124m received
2024-09-10 15:34:24,014 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:24,014 Adjusted time limit for model gpt2-124m: 13.6819 seconds
2024-09-10 15:34:24,014 127.0.0.1 - - [10/Sep/2024 15:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:24,381 Request with ID 428ffea0 for model gpt2medium-355m received
2024-09-10 15:34:24,381 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:24,382 127.0.0.1 - - [10/Sep/2024 15:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:24,600 Request with ID 9763775b for model gpt2-124m received
2024-09-10 15:34:24,600 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:24,600 127.0.0.1 - - [10/Sep/2024 15:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:24,802 Request with ID 68ddea6b for model distilgpt2-124m received
2024-09-10 15:34:24,802 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:34:24,802 Batch size condition met for model distilgpt2-124m
2024-09-10 15:34:25,446 Request with ID b8467c3c for model gpt2-124m received
2024-09-10 15:34:25,446 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:25,446 127.0.0.1 - - [10/Sep/2024 15:34:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:26,166 Request with ID 41f2bb00 for model gpt2-124m received
2024-09-10 15:34:26,166 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:26,166 Batch size condition met for model gpt2-124m
2024-09-10 15:34:26,570 Processed batch: ['723869ce', '55c0067f', '71458982', '35cc'] with model gpt2medium-355m in 2.6838 seconds
2024-09-10 15:34:26,570 Latency for request 723869ce with model gpt2medium-355m: 4.7280 seconds
2024-09-10 15:34:26,571 Latency for request 55c0067f with model gpt2medium-355m: 3.3611 seconds
2024-09-10 15:34:26,571 Latency for request 71458982 with model gpt2medium-355m: 2.8480 seconds
2024-09-10 15:34:26,571 Latency for request 35cc with model gpt2medium-355m: 2.8105 seconds
2024-09-10 15:34:26,572 Updated batch size:4
2024-09-10 15:34:26,572 Loading model distilgpt2-124m
2024-09-10 15:34:26,609 Request with ID 23e9a690 for model distilgpt2-124m received
2024-09-10 15:34:26,610 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:34:26,618 127.0.0.1 - - [10/Sep/2024 15:34:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:27,236 Processed batch: ['9ddecb99', '674c5e73', 'e4e744b3', '68ddea6b'] with model distilgpt2-124m in 0.6087 seconds
2024-09-10 15:34:27,237 Latency for request 9ddecb99 with model distilgpt2-124m: 4.7344 seconds
2024-09-10 15:34:27,238 Latency for request 674c5e73 with model distilgpt2-124m: 4.3681 seconds
2024-09-10 15:34:27,239 Latency for request e4e744b3 with model distilgpt2-124m: 3.7886 seconds
2024-09-10 15:34:27,239 Latency for request 68ddea6b with model distilgpt2-124m: 2.4343 seconds
2024-09-10 15:34:27,239 127.0.0.1 - - [10/Sep/2024 15:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:27,239 Updated batch size:4
2024-09-10 15:34:27,239 Loading model gpt2-124m
2024-09-10 15:34:28,100 Processed batch: ['5f809c44', '9763775b', 'b8467c3c', '41f2bb00'] with model gpt2-124m in 0.7961 seconds
2024-09-10 15:34:28,100 Latency for request 5f809c44 with model gpt2-124m: 4.0861 seconds
2024-09-10 15:34:28,101 Latency for request 9763775b with model gpt2-124m: 3.5006 seconds
2024-09-10 15:34:28,101 Latency for request b8467c3c with model gpt2-124m: 2.6541 seconds
2024-09-10 15:34:28,101 Latency for request 41f2bb00 with model gpt2-124m: 1.9342 seconds
2024-09-10 15:34:28,102 127.0.0.1 - - [10/Sep/2024 15:34:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:28,297 Request with ID 51d73e2b for model gpt2-124m received
2024-09-10 15:34:28,297 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:28,297 Adjusted time limit for model gpt2-124m: 13.6858 seconds
2024-09-10 15:34:28,297 127.0.0.1 - - [10/Sep/2024 15:34:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:29,046 Request with ID 291aa37b for model gpt2medium-355m received
2024-09-10 15:34:29,047 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:29,047 Adjusted time limit for model gpt2medium-355m: 11.8798 seconds
2024-09-10 15:34:29,047 127.0.0.1 - - [10/Sep/2024 15:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:29,611 Request with ID 26978ab3 for model gpt2medium-355m received
2024-09-10 15:34:29,612 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:29,612 127.0.0.1 - - [10/Sep/2024 15:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:29,693 Time limit condition met for model gpt2medium-355m
2024-09-10 15:34:29,694 Updated batch size:4
2024-09-10 15:34:29,694 Loading model gpt2medium-355m
2024-09-10 15:34:29,990 Request with ID c569366d for model gpt2medium-355m received
2024-09-10 15:34:29,990 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:29,991 127.0.0.1 - - [10/Sep/2024 15:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:30,685 Request with ID b0920f30 for model gpt2medium-355m received
2024-09-10 15:34:30,685 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:30,685 127.0.0.1 - - [10/Sep/2024 15:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:31,111 Request with ID ddca29cc for model gpt2-124m received
2024-09-10 15:34:31,111 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:31,111 127.0.0.1 - - [10/Sep/2024 15:34:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:31,356 Request with ID 647a5b15 for model distilgpt2-124m received
2024-09-10 15:34:31,356 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:31,356 Adjusted time limit for model distilgpt2-124m: 14.1775 seconds
2024-09-10 15:34:31,356 127.0.0.1 - - [10/Sep/2024 15:34:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:31,993 Request with ID d10eab02 for model distilgpt2-124m received
2024-09-10 15:34:31,993 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:34:31,993 127.0.0.1 - - [10/Sep/2024 15:34:31] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:32,415 Processed batch: ['428ffea0', '291aa37b', '26978ab3', '303d'] with model gpt2medium-355m in 2.5790 seconds
2024-09-10 15:34:32,415 Latency for request 428ffea0 with model gpt2medium-355m: 8.0333 seconds
2024-09-10 15:34:32,416 Latency for request 291aa37b with model gpt2medium-355m: 3.3685 seconds
2024-09-10 15:34:32,416 Latency for request 26978ab3 with model gpt2medium-355m: 2.8035 seconds
2024-09-10 15:34:32,417 Latency for request 303d with model gpt2medium-355m: 2.7212 seconds
2024-09-10 15:34:32,535 Request with ID 78fb82d6 for model distilgpt2-124m received
2024-09-10 15:34:32,535 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:34:32,535 Batch size condition met for model distilgpt2-124m
2024-09-10 15:34:32,535 Updated batch size:4
2024-09-10 15:34:32,535 Loading model distilgpt2-124m
2024-09-10 15:34:32,634 Request with ID 230b2aff for model gpt2-124m received
2024-09-10 15:34:32,634 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:32,634 127.0.0.1 - - [10/Sep/2024 15:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:33,280 Processed batch: ['23e9a690', '647a5b15', 'd10eab02', '78fb82d6'] with model distilgpt2-124m in 0.6408 seconds
2024-09-10 15:34:33,280 Latency for request 23e9a690 with model distilgpt2-124m: 6.6703 seconds
2024-09-10 15:34:33,281 Latency for request 647a5b15 with model distilgpt2-124m: 1.9241 seconds
2024-09-10 15:34:33,281 Latency for request d10eab02 with model distilgpt2-124m: 1.2870 seconds
2024-09-10 15:34:33,281 Latency for request 78fb82d6 with model distilgpt2-124m: 0.7452 seconds
2024-09-10 15:34:33,282 127.0.0.1 - - [10/Sep/2024 15:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:33,319 Request with ID 272dd88b for model gpt2medium-355m received
2024-09-10 15:34:33,319 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:33,319 Adjusted time limit for model gpt2medium-355m: 11.8803 seconds
2024-09-10 15:34:33,319 127.0.0.1 - - [10/Sep/2024 15:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:33,789 Request with ID 7eaa91c9 for model gpt2medium-355m received
2024-09-10 15:34:33,789 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:34:33,789 Batch size condition met for model gpt2medium-355m
2024-09-10 15:34:33,789 Updated batch size:4
2024-09-10 15:34:33,789 Loading model gpt2medium-355m
2024-09-10 15:34:33,856 Request with ID 2c58c5b5 for model gpt2medium-355m received
2024-09-10 15:34:33,856 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:33,856 127.0.0.1 - - [10/Sep/2024 15:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:33,913 Time limit condition met for model gpt2medium-355m
2024-09-10 15:34:34,737 Request with ID 9c45de3e for model gpt2medium-355m received
2024-09-10 15:34:34,737 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:34,738 127.0.0.1 - - [10/Sep/2024 15:34:34] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:35,167 Request with ID f528dd42 for model gpt2-124m received
2024-09-10 15:34:35,167 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:35,167 Batch size condition met for model gpt2-124m
2024-09-10 15:34:35,524 Request with ID 65f84bd9 for model gpt2medium-355m received
2024-09-10 15:34:35,525 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:34:35,525 127.0.0.1 - - [10/Sep/2024 15:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:35,788 Request with ID 477d25e5 for model gpt2medium-355m received
2024-09-10 15:34:35,788 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:35,789 127.0.0.1 - - [10/Sep/2024 15:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:35,957 Request with ID a7fbe854 for model gpt2-124m received
2024-09-10 15:34:35,957 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:35,957 127.0.0.1 - - [10/Sep/2024 15:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:36,524 Request with ID 093cb2b4 for model gpt2medium-355m received
2024-09-10 15:34:36,524 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:36,524 Batch size condition met for model gpt2medium-355m
2024-09-10 15:34:36,682 Processed batch: ['c569366d', 'b0920f30', '272dd88b', '7eaa91c9'] with model gpt2medium-355m in 2.7372 seconds
2024-09-10 15:34:36,682 Latency for request c569366d with model gpt2medium-355m: 6.6914 seconds
2024-09-10 15:34:36,683 Latency for request b0920f30 with model gpt2medium-355m: 5.9967 seconds
2024-09-10 15:34:36,683 Latency for request 272dd88b with model gpt2medium-355m: 3.3632 seconds
2024-09-10 15:34:36,683 Latency for request 7eaa91c9 with model gpt2medium-355m: 2.8931 seconds
2024-09-10 15:34:36,684 127.0.0.1 - - [10/Sep/2024 15:34:36] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:36,684 Updated batch size:4
2024-09-10 15:34:36,684 Loading model gpt2medium-355m
2024-09-10 15:34:37,154 Request with ID 3cf00d5a for model distilgpt2-124m received
2024-09-10 15:34:37,155 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:34:37,155 Adjusted time limit for model distilgpt2-124m: 14.1775 seconds
2024-09-10 15:34:37,155 127.0.0.1 - - [10/Sep/2024 15:34:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:37,581 Request with ID 72e8719b for model gpt2-124m received
2024-09-10 15:34:37,581 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:37,581 127.0.0.1 - - [10/Sep/2024 15:34:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:37,754 Request with ID 4a71d6d4 for model gpt2medium-355m received
2024-09-10 15:34:37,754 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:37,754 Adjusted time limit for model gpt2medium-355m: 11.8759 seconds
2024-09-10 15:34:37,754 127.0.0.1 - - [10/Sep/2024 15:34:37] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:38,004 Request with ID a4ebc7aa for model gpt2-124m received
2024-09-10 15:34:38,004 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:38,004 127.0.0.1 - - [10/Sep/2024 15:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:38,015 Request with ID 17873705 for model gpt2-124m received
2024-09-10 15:34:38,016 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:38,016 Batch size condition met for model gpt2-124m
2024-09-10 15:34:38,448 Request with ID 182e71bd for model gpt2-124m received
2024-09-10 15:34:38,448 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:38,448 127.0.0.1 - - [10/Sep/2024 15:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:38,673 Request with ID 541ec12e for model distilgpt2-124m received
2024-09-10 15:34:38,674 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:38,674 127.0.0.1 - - [10/Sep/2024 15:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:38,881 Request with ID c4847e68 for model distilgpt2-124m received
2024-09-10 15:34:38,881 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:38,881 127.0.0.1 - - [10/Sep/2024 15:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:39,474 Request with ID a7ead4d0 for model distilgpt2-124m received
2024-09-10 15:34:39,474 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:39,474 Batch size condition met for model distilgpt2-124m
2024-09-10 15:34:39,604 Processed batch: ['9c45de3e', '65f84bd9', '477d25e5', '093cb2b4'] with model gpt2medium-355m in 2.9202 seconds
2024-09-10 15:34:39,605 Latency for request 9c45de3e with model gpt2medium-355m: 4.8669 seconds
2024-09-10 15:34:39,605 Request with ID 01ec4e87 for model distilgpt2-124m received
2024-09-10 15:34:39,605 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:39,605 127.0.0.1 - - [10/Sep/2024 15:34:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:39,606 Latency for request 65f84bd9 with model gpt2medium-355m: 4.0798 seconds
2024-09-10 15:34:39,607 Latency for request 477d25e5 with model gpt2medium-355m: 3.8158 seconds
2024-09-10 15:34:39,607 Latency for request 093cb2b4 with model gpt2medium-355m: 3.0805 seconds
2024-09-10 15:34:39,607 Updated batch size:4
2024-09-10 15:34:39,607 Loading model gpt2-124m
2024-09-10 15:34:39,712 Time limit condition met for model gpt2-124m
2024-09-10 15:34:39,954 Request with ID 72e73d22 for model distilgpt2-124m received
2024-09-10 15:34:39,954 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:39,954 127.0.0.1 - - [10/Sep/2024 15:34:39] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:40,161 Request with ID ab7d2751 for model distilgpt2-124m received
2024-09-10 15:34:40,161 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:40,161 127.0.0.1 - - [10/Sep/2024 15:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:40,397 Request with ID 775788e6 for model distilgpt2-124m received
2024-09-10 15:34:40,398 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:40,398 Batch size condition met for model distilgpt2-124m
2024-09-10 15:34:40,554 Processed batch: ['a7fbe854', '72e8719b', 'a4ebc7aa', '17873705'] with model gpt2-124m in 0.8696 seconds
2024-09-10 15:34:40,554 Latency for request a7fbe854 with model gpt2-124m: 4.5971 seconds
2024-09-10 15:34:40,555 Latency for request 72e8719b with model gpt2-124m: 2.9731 seconds
2024-09-10 15:34:40,555 Latency for request a4ebc7aa with model gpt2-124m: 2.5505 seconds
2024-09-10 15:34:40,556 Latency for request 17873705 with model gpt2-124m: 2.5388 seconds
2024-09-10 15:34:40,556 127.0.0.1 - - [10/Sep/2024 15:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:40,556 No batch to process for model gpt2medium-355m
2024-09-10 15:34:40,556 127.0.0.1 - - [10/Sep/2024 15:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:40,556 Updated batch size:1
2024-09-10 15:34:40,556 Loading model gpt2-124m
2024-09-10 15:34:40,683 Request with ID 1f2bde86 for model distilgpt2-124m received
2024-09-10 15:34:40,683 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:34:40,684 127.0.0.1 - - [10/Sep/2024 15:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:40,866 Request with ID 39f0da8c for model distilgpt2-124m received
2024-09-10 15:34:40,866 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:40,867 127.0.0.1 - - [10/Sep/2024 15:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:41,041 Processed batch: ['182e71bd'] with model gpt2-124m in 0.4844 seconds
2024-09-10 15:34:41,041 Latency for request 182e71bd with model gpt2-124m: 2.5931 seconds
2024-09-10 15:34:41,042 127.0.0.1 - - [10/Sep/2024 15:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:41,042 Updated batch size:4
2024-09-10 15:34:41,042 Loading model distilgpt2-124m
2024-09-10 15:34:41,618 Processed batch: ['01ec4e87', '72e73d22', 'ab7d2751', '775788e6'] with model distilgpt2-124m in 0.5184 seconds
2024-09-10 15:34:41,618 Latency for request 01ec4e87 with model distilgpt2-124m: 2.0135 seconds
2024-09-10 15:34:41,619 Latency for request 72e73d22 with model distilgpt2-124m: 1.6644 seconds
2024-09-10 15:34:41,619 Latency for request ab7d2751 with model distilgpt2-124m: 1.4572 seconds
2024-09-10 15:34:41,620 Latency for request 775788e6 with model distilgpt2-124m: 1.2209 seconds
2024-09-10 15:34:41,620 127.0.0.1 - - [10/Sep/2024 15:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:41,620 No batch to process for model gpt2-124m
2024-09-10 15:34:41,620 No batch to process for model distilgpt2-124m
2024-09-10 15:34:41,620 127.0.0.1 - - [10/Sep/2024 15:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:41,623 Request with ID 19dbe6fe for model gpt2medium-355m received
2024-09-10 15:34:41,624 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:41,624 Adjusted time limit for model gpt2medium-355m: 11.8803 seconds
2024-09-10 15:34:41,624 127.0.0.1 - - [10/Sep/2024 15:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:41,868 Request with ID 1a4225ee for model gpt2-124m received
2024-09-10 15:34:41,868 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:41,868 Adjusted time limit for model gpt2-124m: 13.6863 seconds
2024-09-10 15:34:41,868 127.0.0.1 - - [10/Sep/2024 15:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:42,869 Request with ID 51e20261 for model gpt2-124m received
2024-09-10 15:34:42,869 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:42,870 127.0.0.1 - - [10/Sep/2024 15:34:42] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:43,484 Request with ID d01b8ceb for model distilgpt2-124m received
2024-09-10 15:34:43,484 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:34:43,485 Adjusted time limit for model distilgpt2-124m: 14.1819 seconds
2024-09-10 15:34:43,485 127.0.0.1 - - [10/Sep/2024 15:34:43] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:43,978 Request with ID b74f4820 for model distilgpt2-124m received
2024-09-10 15:34:43,978 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:34:43,979 Batch size condition met for model distilgpt2-124m
2024-09-10 15:34:43,979 Updated batch size:4
2024-09-10 15:34:43,979 Loading model distilgpt2-124m
2024-09-10 15:34:44,125 Request with ID 79423674 for model gpt2-124m received
2024-09-10 15:34:44,126 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:44,126 127.0.0.1 - - [10/Sep/2024 15:34:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:44,572 Processed batch: ['1f2bde86', '39f0da8c', 'd01b8ceb', 'b74f4820'] with model distilgpt2-124m in 0.5926 seconds
2024-09-10 15:34:44,572 Latency for request 1f2bde86 with model distilgpt2-124m: 3.8892 seconds
2024-09-10 15:34:44,573 Latency for request 39f0da8c with model distilgpt2-124m: 3.7056 seconds
2024-09-10 15:34:44,573 Latency for request d01b8ceb with model distilgpt2-124m: 1.0879 seconds
2024-09-10 15:34:44,573 Latency for request b74f4820 with model distilgpt2-124m: 0.5941 seconds
2024-09-10 15:34:44,574 127.0.0.1 - - [10/Sep/2024 15:34:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:44,717 Request with ID 6b8c6603 for model gpt2-124m received
2024-09-10 15:34:44,717 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:44,717 Batch size condition met for model gpt2-124m
2024-09-10 15:34:44,717 Updated batch size:4
2024-09-10 15:34:44,717 Loading model gpt2-124m
2024-09-10 15:34:44,824 Request with ID ef1a6925 for model gpt2-124m received
2024-09-10 15:34:44,825 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:44,825 127.0.0.1 - - [10/Sep/2024 15:34:44] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:45,082 Request with ID 536d6392 for model gpt2-124m received
2024-09-10 15:34:45,082 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:45,082 127.0.0.1 - - [10/Sep/2024 15:34:45] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:45,367 Request with ID 6f920b02 for model gpt2medium-355m received
2024-09-10 15:34:45,367 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:45,367 127.0.0.1 - - [10/Sep/2024 15:34:45] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:45,454 Processed batch: ['1a4225ee', '51e20261', '79423674', '6b8c6603'] with model gpt2-124m in 0.6716 seconds
2024-09-10 15:34:45,454 Latency for request 1a4225ee with model gpt2-124m: 3.5862 seconds
2024-09-10 15:34:45,454 Latency for request 51e20261 with model gpt2-124m: 2.5850 seconds
2024-09-10 15:34:45,455 Latency for request 79423674 with model gpt2-124m: 1.3283 seconds
2024-09-10 15:34:45,455 Latency for request 6b8c6603 with model gpt2-124m: 0.7368 seconds
2024-09-10 15:34:45,455 127.0.0.1 - - [10/Sep/2024 15:34:45] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:45,470 Time limit condition met for model gpt2medium-355m
2024-09-10 15:34:45,470 Updated batch size:4
2024-09-10 15:34:45,470 Loading model gpt2medium-355m
2024-09-10 15:34:46,018 Request with ID 8231eef3 for model gpt2medium-355m received
2024-09-10 15:34:46,018 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:46,019 127.0.0.1 - - [10/Sep/2024 15:34:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:46,146 Request with ID 38a0f145 for model gpt2-124m received
2024-09-10 15:34:46,146 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:46,146 Adjusted time limit for model gpt2-124m: 13.6819 seconds
2024-09-10 15:34:46,146 127.0.0.1 - - [10/Sep/2024 15:34:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:46,334 Request with ID 66ccaf96 for model gpt2-124m received
2024-09-10 15:34:46,334 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:46,334 Batch size condition met for model gpt2-124m
2024-09-10 15:34:46,733 Request with ID d386d5ed for model distilgpt2-124m received
2024-09-10 15:34:46,733 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:34:46,733 Adjusted time limit for model distilgpt2-124m: 14.1775 seconds
2024-09-10 15:34:46,734 127.0.0.1 - - [10/Sep/2024 15:34:46] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:47,114 Request with ID b98d7052 for model gpt2-124m received
2024-09-10 15:34:47,115 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:47,115 127.0.0.1 - - [10/Sep/2024 15:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:47,223 Request with ID 76393fe6 for model gpt2medium-355m received
2024-09-10 15:34:47,223 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:47,223 127.0.0.1 - - [10/Sep/2024 15:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:47,556 Request with ID b868214a for model distilgpt2-124m received
2024-09-10 15:34:47,556 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:47,557 127.0.0.1 - - [10/Sep/2024 15:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:47,803 Request with ID 7d7eeee1 for model gpt2-124m received
2024-09-10 15:34:47,803 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:47,803 127.0.0.1 - - [10/Sep/2024 15:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:47,945 Request with ID ce9692a4 for model gpt2medium-355m received
2024-09-10 15:34:47,945 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:34:47,946 127.0.0.1 - - [10/Sep/2024 15:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:48,443 Processed batch: ['4a71d6d4', '19dbe6fe', '6f920b02', '2914'] with model gpt2medium-355m in 2.8640 seconds
2024-09-10 15:34:48,443 Latency for request 4a71d6d4 with model gpt2medium-355m: 10.6889 seconds
2024-09-10 15:34:48,444 Latency for request 19dbe6fe with model gpt2medium-355m: 6.8194 seconds
2024-09-10 15:34:48,444 Latency for request 6f920b02 with model gpt2medium-355m: 3.0762 seconds
2024-09-10 15:34:48,445 Latency for request 2914 with model gpt2medium-355m: 2.9729 seconds
2024-09-10 15:34:48,445 Updated batch size:4
2024-09-10 15:34:48,445 Loading model gpt2-124m
2024-09-10 15:34:48,654 Request with ID b8664d0a for model gpt2-124m received
2024-09-10 15:34:48,654 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:34:48,654 127.0.0.1 - - [10/Sep/2024 15:34:48] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:49,271 Request with ID 3136d1f8 for model gpt2-124m received
2024-09-10 15:34:49,272 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:34:49,272 Batch size condition met for model gpt2-124m
2024-09-10 15:34:49,469 Processed batch: ['ef1a6925', '536d6392', '38a0f145', '66ccaf96'] with model gpt2-124m in 0.9522 seconds
2024-09-10 15:34:49,469 Latency for request ef1a6925 with model gpt2-124m: 4.6441 seconds
2024-09-10 15:34:49,469 Latency for request 536d6392 with model gpt2-124m: 4.3866 seconds
2024-09-10 15:34:49,470 Latency for request 38a0f145 with model gpt2-124m: 3.3227 seconds
2024-09-10 15:34:49,470 Latency for request 66ccaf96 with model gpt2-124m: 3.1344 seconds
2024-09-10 15:34:49,470 127.0.0.1 - - [10/Sep/2024 15:34:49] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:49,470 Updated batch size:4
2024-09-10 15:34:49,470 Loading model gpt2-124m
2024-09-10 15:34:49,548 Request with ID aa23bdfe for model gpt2medium-355m received
2024-09-10 15:34:49,548 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:49,548 Adjusted time limit for model gpt2medium-355m: 11.8798 seconds
2024-09-10 15:34:49,548 Batch size condition met for model gpt2medium-355m
2024-09-10 15:34:49,795 Request with ID 4bcbd8e6 for model gpt2medium-355m received
2024-09-10 15:34:49,795 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:49,795 127.0.0.1 - - [10/Sep/2024 15:34:49] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:50,277 Request with ID 76d5f3a3 for model distilgpt2-124m received
2024-09-10 15:34:50,277 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:50,277 127.0.0.1 - - [10/Sep/2024 15:34:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:50,426 Processed batch: ['b98d7052', '7d7eeee1', 'b8664d0a', '3136d1f8'] with model gpt2-124m in 0.9559 seconds
2024-09-10 15:34:50,426 Latency for request b98d7052 with model gpt2-124m: 3.3118 seconds
2024-09-10 15:34:50,427 Latency for request 7d7eeee1 with model gpt2-124m: 2.6235 seconds
2024-09-10 15:34:50,428 Latency for request b8664d0a with model gpt2-124m: 1.7723 seconds
2024-09-10 15:34:50,428 Latency for request 3136d1f8 with model gpt2-124m: 1.1548 seconds
2024-09-10 15:34:50,428 127.0.0.1 - - [10/Sep/2024 15:34:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:50,428 Updated batch size:4
2024-09-10 15:34:50,428 Loading model gpt2medium-355m
2024-09-10 15:34:50,608 Request with ID 6dcb405f for model gpt2medium-355m received
2024-09-10 15:34:50,609 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:50,609 127.0.0.1 - - [10/Sep/2024 15:34:50] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:50,612 Time limit condition met for model gpt2medium-355m
2024-09-10 15:34:50,994 Request with ID fbc141ee for model distilgpt2-124m received
2024-09-10 15:34:50,994 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:50,995 Batch size condition met for model distilgpt2-124m
2024-09-10 15:34:51,298 Request with ID 849f2f01 for model distilgpt2-124m received
2024-09-10 15:34:51,298 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 15:34:51,298 127.0.0.1 - - [10/Sep/2024 15:34:51] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:51,863 Request with ID 8a096cf4 for model gpt2-124m received
2024-09-10 15:34:51,863 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:34:51,863 Adjusted time limit for model gpt2-124m: 13.6819 seconds
2024-09-10 15:34:51,863 127.0.0.1 - - [10/Sep/2024 15:34:51] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:52,007 Request with ID 6a9e4bd7 for model distilgpt2-124m received
2024-09-10 15:34:52,007 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:52,007 127.0.0.1 - - [10/Sep/2024 15:34:52] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:52,210 Request with ID f00b841a for model distilgpt2-124m received
2024-09-10 15:34:52,210 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:52,211 127.0.0.1 - - [10/Sep/2024 15:34:52] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:52,328 Request with ID 576725f1 for model distilgpt2-124m received
2024-09-10 15:34:52,328 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:52,328 Batch size condition met for model distilgpt2-124m
2024-09-10 15:34:53,165 Request with ID 52690718 for model distilgpt2-124m received
2024-09-10 15:34:53,166 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:34:53,166 127.0.0.1 - - [10/Sep/2024 15:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:53,256 Request with ID 2e19740c for model distilgpt2-124m received
2024-09-10 15:34:53,256 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:34:53,256 127.0.0.1 - - [10/Sep/2024 15:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:53,402 Request with ID 8cbf2aeb for model gpt2medium-355m received
2024-09-10 15:34:53,403 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:53,403 127.0.0.1 - - [10/Sep/2024 15:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:53,515 Processed batch: ['8231eef3', '76393fe6', 'ce9692a4', 'aa23bdfe'] with model gpt2medium-355m in 2.9727 seconds
2024-09-10 15:34:53,515 Latency for request 8231eef3 with model gpt2medium-355m: 7.4969 seconds
2024-09-10 15:34:53,516 Request with ID d8faff96 for model gpt2-124m received
2024-09-10 15:34:53,516 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:53,516 127.0.0.1 - - [10/Sep/2024 15:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:53,517 Latency for request 76393fe6 with model gpt2medium-355m: 6.2922 seconds
2024-09-10 15:34:53,518 Latency for request ce9692a4 with model gpt2medium-355m: 5.5700 seconds
2024-09-10 15:34:53,518 Latency for request aa23bdfe with model gpt2medium-355m: 3.9671 seconds
2024-09-10 15:34:53,518 127.0.0.1 - - [10/Sep/2024 15:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:53,519 Updated batch size:2
2024-09-10 15:34:53,519 Loading model gpt2medium-355m
2024-09-10 15:34:53,995 Request with ID 8f71d37a for model gpt2-124m received
2024-09-10 15:34:53,995 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:53,996 127.0.0.1 - - [10/Sep/2024 15:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:54,112 Request with ID 364fc93b for model gpt2-124m received
2024-09-10 15:34:54,112 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:34:54,112 Batch size condition met for model gpt2-124m
2024-09-10 15:34:54,190 Request with ID b3320d65 for model gpt2medium-355m received
2024-09-10 15:34:54,190 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:54,190 Adjusted time limit for model gpt2medium-355m: 11.8759 seconds
2024-09-10 15:34:54,190 127.0.0.1 - - [10/Sep/2024 15:34:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:54,429 Request with ID 0cb8a282 for model gpt2-124m received
2024-09-10 15:34:54,429 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:54,429 127.0.0.1 - - [10/Sep/2024 15:34:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:54,942 Request with ID dd7bf0c8 for model distilgpt2-124m received
2024-09-10 15:34:54,943 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:54,943 127.0.0.1 - - [10/Sep/2024 15:34:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:55,440 Request with ID 0caaf608 for model gpt2-124m received
2024-09-10 15:34:55,440 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:34:55,440 127.0.0.1 - - [10/Sep/2024 15:34:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:55,542 Request with ID a6500c12 for model gpt2medium-355m received
2024-09-10 15:34:55,542 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:34:55,542 127.0.0.1 - - [10/Sep/2024 15:34:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:55,716 Request with ID f47b5408 for model distilgpt2-124m received
2024-09-10 15:34:55,716 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:34:55,716 Batch size condition met for model distilgpt2-124m
2024-09-10 15:34:56,047 Processed batch: ['4bcbd8e6', '6dcb405f'] with model gpt2medium-355m in 2.5285 seconds
2024-09-10 15:34:56,047 Latency for request 4bcbd8e6 with model gpt2medium-355m: 6.2523 seconds
2024-09-10 15:34:56,048 Latency for request 6dcb405f with model gpt2medium-355m: 5.4389 seconds
2024-09-10 15:34:56,049 Updated batch size:4
2024-09-10 15:34:56,049 Loading model distilgpt2-124m
2024-09-10 15:34:56,172 Request with ID 133d8d7e for model distilgpt2-124m received
2024-09-10 15:34:56,172 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:56,172 127.0.0.1 - - [10/Sep/2024 15:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:56,480 Request with ID 64a466b1 for model distilgpt2-124m received
2024-09-10 15:34:56,480 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:34:56,480 127.0.0.1 - - [10/Sep/2024 15:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:56,705 Request with ID 96718dc2 for model gpt2medium-355m received
2024-09-10 15:34:56,705 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:34:56,705 Adjusted time limit for model gpt2medium-355m: 11.8803 seconds
2024-09-10 15:34:56,705 Batch size condition met for model gpt2medium-355m
2024-09-10 15:34:56,715 Processed batch: ['52690718', '2e19740c', 'dd7bf0c8', 'f47b5408'] with model distilgpt2-124m in 0.6038 seconds
2024-09-10 15:34:56,715 Latency for request 52690718 with model distilgpt2-124m: 3.5494 seconds
2024-09-10 15:34:56,716 Latency for request 2e19740c with model distilgpt2-124m: 3.4590 seconds
2024-09-10 15:34:56,717 Latency for request dd7bf0c8 with model distilgpt2-124m: 1.7724 seconds
2024-09-10 15:34:56,717 Latency for request f47b5408 with model distilgpt2-124m: 0.9987 seconds
2024-09-10 15:34:56,717 127.0.0.1 - - [10/Sep/2024 15:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:56,717 No batch to process for model distilgpt2-124m
2024-09-10 15:34:56,717 127.0.0.1 - - [10/Sep/2024 15:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:56,717 Updated batch size:4
2024-09-10 15:34:56,718 Loading model gpt2-124m
2024-09-10 15:34:57,742 Request with ID 629d56ff for model distilgpt2-124m received
2024-09-10 15:34:57,743 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:34:57,743 Adjusted time limit for model distilgpt2-124m: 14.1814 seconds
2024-09-10 15:34:57,743 127.0.0.1 - - [10/Sep/2024 15:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:57,930 Request with ID 0f49d732 for model gpt2medium-355m received
2024-09-10 15:34:57,931 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:34:57,931 127.0.0.1 - - [10/Sep/2024 15:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:57,939 Processed batch: ['8a096cf4', 'd8faff96', '8f71d37a', '364fc93b'] with model gpt2-124m in 1.1502 seconds
2024-09-10 15:34:57,939 Latency for request 8a096cf4 with model gpt2-124m: 6.0762 seconds
2024-09-10 15:34:57,940 Latency for request d8faff96 with model gpt2-124m: 4.4225 seconds
2024-09-10 15:34:57,940 Latency for request 8f71d37a with model gpt2-124m: 3.9435 seconds
2024-09-10 15:34:57,940 Latency for request 364fc93b with model gpt2-124m: 3.8270 seconds
2024-09-10 15:34:57,940 127.0.0.1 - - [10/Sep/2024 15:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:57,940 No batch to process for model distilgpt2-124m
2024-09-10 15:34:57,941 127.0.0.1 - - [10/Sep/2024 15:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:34:57,941 Updated batch size:4
2024-09-10 15:34:57,941 Loading model gpt2medium-355m
2024-09-10 15:34:58,961 Request with ID 753d2cbc for model distilgpt2-124m received
2024-09-10 15:34:58,961 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:34:58,961 Batch size condition met for model distilgpt2-124m
2024-09-10 15:34:59,411 Request with ID ff62da77 for model distilgpt2-124m received
2024-09-10 15:34:59,411 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:34:59,411 127.0.0.1 - - [10/Sep/2024 15:34:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:00,649 Request with ID a2d74f98 for model gpt2medium-355m received
2024-09-10 15:35:00,649 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:35:00,649 127.0.0.1 - - [10/Sep/2024 15:35:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:00,714 Time limit condition met for model gpt2medium-355m
2024-09-10 15:35:00,822 Processed batch: ['8cbf2aeb', 'b3320d65', 'a6500c12', '96718dc2'] with model gpt2medium-355m in 2.7614 seconds
2024-09-10 15:35:00,822 Latency for request 8cbf2aeb with model gpt2medium-355m: 7.4195 seconds
2024-09-10 15:35:00,823 Latency for request b3320d65 with model gpt2medium-355m: 6.6319 seconds
2024-09-10 15:35:00,824 Latency for request a6500c12 with model gpt2medium-355m: 5.2797 seconds
2024-09-10 15:35:00,824 Latency for request 96718dc2 with model gpt2medium-355m: 4.1169 seconds
2024-09-10 15:35:00,824 127.0.0.1 - - [10/Sep/2024 15:35:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:00,824 Updated batch size:4
2024-09-10 15:35:00,824 Loading model distilgpt2-124m
2024-09-10 15:35:01,328 Request with ID c012ff32 for model gpt2-124m received
2024-09-10 15:35:01,328 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:35:01,328 Adjusted time limit for model gpt2-124m: 13.6863 seconds
2024-09-10 15:35:01,328 127.0.0.1 - - [10/Sep/2024 15:35:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:01,484 Processed batch: ['133d8d7e', '64a466b1', '629d56ff', '753d2cbc'] with model distilgpt2-124m in 0.5969 seconds
2024-09-10 15:35:01,484 Latency for request 133d8d7e with model distilgpt2-124m: 5.3119 seconds
2024-09-10 15:35:01,486 Latency for request 64a466b1 with model distilgpt2-124m: 5.0040 seconds
2024-09-10 15:35:01,486 Latency for request 629d56ff with model distilgpt2-124m: 3.7414 seconds
2024-09-10 15:35:01,486 Latency for request 753d2cbc with model distilgpt2-124m: 2.5232 seconds
2024-09-10 15:35:01,487 127.0.0.1 - - [10/Sep/2024 15:35:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:01,487 Updated batch size:2
2024-09-10 15:35:01,487 Loading model gpt2medium-355m
2024-09-10 15:35:01,602 Request with ID 43cf4b63 for model gpt2-124m received
2024-09-10 15:35:01,602 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:35:01,603 Batch size condition met for model gpt2-124m
2024-09-10 15:35:01,747 Request with ID 59eecd98 for model distilgpt2-124m received
2024-09-10 15:35:01,748 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:35:01,748 Adjusted time limit for model distilgpt2-124m: 14.1775 seconds
2024-09-10 15:35:01,748 127.0.0.1 - - [10/Sep/2024 15:35:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:02,024 Request with ID 84cdff40 for model gpt2medium-355m received
2024-09-10 15:35:02,024 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:35:02,024 Adjusted time limit for model gpt2medium-355m: 11.8759 seconds
2024-09-10 15:35:02,024 127.0.0.1 - - [10/Sep/2024 15:35:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:03,113 Request with ID 9b7fbabd for model distilgpt2-124m received
2024-09-10 15:35:03,113 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:35:03,114 127.0.0.1 - - [10/Sep/2024 15:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:03,352 Request with ID caccf977 for model gpt2medium-355m received
2024-09-10 15:35:03,352 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:35:03,352 127.0.0.1 - - [10/Sep/2024 15:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:03,723 Request with ID a290b78c for model distilgpt2-124m received
2024-09-10 15:35:03,723 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:35:03,723 Batch size condition met for model distilgpt2-124m
2024-09-10 15:35:04,191 Processed batch: ['0f49d732', 'a2d74f98'] with model gpt2medium-355m in 2.5530 seconds
2024-09-10 15:35:04,191 Latency for request 0f49d732 with model gpt2medium-355m: 6.2603 seconds
2024-09-10 15:35:04,192 Latency for request a2d74f98 with model gpt2medium-355m: 3.5418 seconds
2024-09-10 15:35:04,192 Updated batch size:4
2024-09-10 15:35:04,192 Loading model gpt2-124m
2024-09-10 15:35:04,378 Request with ID de5d8416 for model gpt2medium-355m received
2024-09-10 15:35:04,378 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:35:04,378 Adjusted time limit for model gpt2medium-355m: 11.8798 seconds
2024-09-10 15:35:04,378 127.0.0.1 - - [10/Sep/2024 15:35:04] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:05,291 Request with ID 046a4eeb for model distilgpt2-124m received
2024-09-10 15:35:05,291 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:35:05,291 127.0.0.1 - - [10/Sep/2024 15:35:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:05,336 Request with ID 676d3a93 for model gpt2-124m received
2024-09-10 15:35:05,337 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:35:05,337 127.0.0.1 - - [10/Sep/2024 15:35:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:05,499 Processed batch: ['0cb8a282', '0caaf608', 'c012ff32', '43cf4b63'] with model gpt2-124m in 1.2316 seconds
2024-09-10 15:35:05,499 Latency for request 0cb8a282 with model gpt2-124m: 11.0701 seconds
2024-09-10 15:35:05,500 Latency for request 0caaf608 with model gpt2-124m: 10.0589 seconds
2024-09-10 15:35:05,500 Latency for request c012ff32 with model gpt2-124m: 4.1713 seconds
2024-09-10 15:35:05,501 Latency for request 43cf4b63 with model gpt2-124m: 3.8968 seconds
2024-09-10 15:35:05,501 127.0.0.1 - - [10/Sep/2024 15:35:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:05,501 Updated batch size:4
2024-09-10 15:35:05,501 Loading model distilgpt2-124m
2024-09-10 15:35:06,123 Request with ID 3051081b for model distilgpt2-124m received
2024-09-10 15:35:06,123 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:35:06,123 127.0.0.1 - - [10/Sep/2024 15:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:06,169 Processed batch: ['ff62da77', '59eecd98', '9b7fbabd', 'a290b78c'] with model distilgpt2-124m in 0.5939 seconds
2024-09-10 15:35:06,169 Latency for request ff62da77 with model distilgpt2-124m: 6.7578 seconds
2024-09-10 15:35:06,170 Latency for request 59eecd98 with model distilgpt2-124m: 4.4215 seconds
2024-09-10 15:35:06,170 Latency for request 9b7fbabd with model distilgpt2-124m: 3.0558 seconds
2024-09-10 15:35:06,170 Latency for request a290b78c with model distilgpt2-124m: 2.4463 seconds
2024-09-10 15:35:06,171 127.0.0.1 - - [10/Sep/2024 15:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:06,850 Request with ID 13b19563 for model gpt2medium-355m received
2024-09-10 15:35:06,851 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:35:06,851 Batch size condition met for model gpt2medium-355m
2024-09-10 15:35:06,851 Updated batch size:4
2024-09-10 15:35:06,851 Loading model gpt2medium-355m
2024-09-10 15:35:07,311 Request with ID 8268ed6e for model distilgpt2-124m received
2024-09-10 15:35:07,311 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:35:07,311 Adjusted time limit for model distilgpt2-124m: 14.1775 seconds
2024-09-10 15:35:07,312 127.0.0.1 - - [10/Sep/2024 15:35:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:07,724 Request with ID 69f529a0 for model distilgpt2-124m received
2024-09-10 15:35:07,724 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:35:07,724 Batch size condition met for model distilgpt2-124m
2024-09-10 15:35:07,922 Request with ID dc0d8169 for model gpt2medium-355m received
2024-09-10 15:35:07,923 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:35:07,923 127.0.0.1 - - [10/Sep/2024 15:35:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:07,949 Time limit condition met for model gpt2medium-355m
2024-09-10 15:35:08,029 Request with ID 59a32b75 for model distilgpt2-124m received
2024-09-10 15:35:08,029 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:35:08,029 127.0.0.1 - - [10/Sep/2024 15:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:08,192 Request with ID 1826f2e9 for model gpt2medium-355m received
2024-09-10 15:35:08,192 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:35:08,192 127.0.0.1 - - [10/Sep/2024 15:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:08,657 Request with ID 72e3171a for model gpt2-124m received
2024-09-10 15:35:08,657 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:35:08,657 Adjusted time limit for model gpt2-124m: 13.6819 seconds
2024-09-10 15:35:08,657 127.0.0.1 - - [10/Sep/2024 15:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:08,972 Request with ID 95918930 for model gpt2-124m received
2024-09-10 15:35:08,972 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:35:08,972 127.0.0.1 - - [10/Sep/2024 15:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:09,025 Request with ID 48dbe49e for model gpt2medium-355m received
2024-09-10 15:35:09,025 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:35:09,025 127.0.0.1 - - [10/Sep/2024 15:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:09,134 Request with ID 6f6a7036 for model gpt2-124m received
2024-09-10 15:35:09,134 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:35:09,134 Batch size condition met for model gpt2-124m
2024-09-10 15:35:09,707 Request with ID a18be643 for model gpt2medium-355m received
2024-09-10 15:35:09,707 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:35:09,707 127.0.0.1 - - [10/Sep/2024 15:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:09,829 Request with ID 3ca9aabb for model gpt2-124m received
2024-09-10 15:35:09,830 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:35:09,830 127.0.0.1 - - [10/Sep/2024 15:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:09,847 Request with ID 69ab0440 for model distilgpt2-124m received
2024-09-10 15:35:09,847 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:35:09,848 127.0.0.1 - - [10/Sep/2024 15:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:10,163 Request with ID 1b96623d for model gpt2medium-355m received
2024-09-10 15:35:10,163 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:35:10,163 Batch size condition met for model gpt2medium-355m
2024-09-10 15:35:10,189 Processed batch: ['84cdff40', 'caccf977', 'de5d8416', '13b19563'] with model gpt2medium-355m in 3.1790 seconds
2024-09-10 15:35:10,189 Latency for request 84cdff40 with model gpt2medium-355m: 8.1651 seconds
2024-09-10 15:35:10,189 Latency for request caccf977 with model gpt2medium-355m: 6.8369 seconds
2024-09-10 15:35:10,190 Latency for request de5d8416 with model gpt2medium-355m: 5.8107 seconds
2024-09-10 15:35:10,190 Latency for request 13b19563 with model gpt2medium-355m: 3.3386 seconds
2024-09-10 15:35:10,190 127.0.0.1 - - [10/Sep/2024 15:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:10,190 Updated batch size:4
2024-09-10 15:35:10,191 Loading model distilgpt2-124m
2024-09-10 15:35:10,609 Request with ID 3f57f9d7 for model distilgpt2-124m received
2024-09-10 15:35:10,609 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:35:10,609 127.0.0.1 - - [10/Sep/2024 15:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:10,796 Processed batch: ['046a4eeb', '3051081b', '8268ed6e', '69f529a0'] with model distilgpt2-124m in 0.5435 seconds
2024-09-10 15:35:10,797 Latency for request 046a4eeb with model distilgpt2-124m: 5.5057 seconds
2024-09-10 15:35:10,798 Latency for request 3051081b with model distilgpt2-124m: 4.6734 seconds
2024-09-10 15:35:10,798 Latency for request 8268ed6e with model distilgpt2-124m: 3.4851 seconds
2024-09-10 15:35:10,798 Latency for request 69f529a0 with model distilgpt2-124m: 3.0727 seconds
2024-09-10 15:35:10,799 127.0.0.1 - - [10/Sep/2024 15:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:10,799 Updated batch size:4
2024-09-10 15:35:10,799 Loading model gpt2medium-355m
2024-09-10 15:35:10,915 Request with ID 942fb5da for model distilgpt2-124m received
2024-09-10 15:35:10,915 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:35:10,915 Adjusted time limit for model distilgpt2-124m: 14.1882 seconds
2024-09-10 15:35:10,915 Batch size condition met for model distilgpt2-124m
2024-09-10 15:35:10,965 Request with ID 6ee71314 for model gpt2-124m received
2024-09-10 15:35:10,965 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:35:10,965 127.0.0.1 - - [10/Sep/2024 15:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:11,197 Request with ID 12ec4f8c for model gpt2-124m received
2024-09-10 15:35:11,197 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:35:11,197 127.0.0.1 - - [10/Sep/2024 15:35:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:11,382 Request with ID 29789914 for model gpt2-124m received
2024-09-10 15:35:11,382 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:35:11,382 Batch size condition met for model gpt2-124m
2024-09-10 15:35:11,715 Request with ID 64c3c2c7 for model gpt2-124m received
2024-09-10 15:35:11,715 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 15:35:11,715 127.0.0.1 - - [10/Sep/2024 15:35:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:11,878 Request with ID 40f33397 for model gpt2medium-355m received
2024-09-10 15:35:11,878 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:35:11,878 Adjusted time limit for model gpt2medium-355m: 11.8759 seconds
2024-09-10 15:35:11,878 127.0.0.1 - - [10/Sep/2024 15:35:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:12,137 Request with ID 59ac41b6 for model gpt2medium-355m received
2024-09-10 15:35:12,137 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:35:12,137 127.0.0.1 - - [10/Sep/2024 15:35:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:12,221 Request with ID 7df2dbfe for model gpt2-124m received
2024-09-10 15:35:12,221 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:35:12,221 127.0.0.1 - - [10/Sep/2024 15:35:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:12,466 Request with ID d33964af for model gpt2-124m received
2024-09-10 15:35:12,466 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:35:12,466 127.0.0.1 - - [10/Sep/2024 15:35:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:13,196 Request with ID 4c725c6d for model gpt2-124m received
2024-09-10 15:35:13,196 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:35:13,196 Batch size condition met for model gpt2-124m
2024-09-10 15:35:13,422 Request with ID df816519 for model gpt2medium-355m received
2024-09-10 15:35:13,422 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:35:13,422 127.0.0.1 - - [10/Sep/2024 15:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:13,604 Request with ID 92b273ca for model gpt2medium-355m received
2024-09-10 15:35:13,604 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:35:13,604 Batch size condition met for model gpt2medium-355m
2024-09-10 15:35:13,887 Request with ID 7a5c841c for model gpt2-124m received
2024-09-10 15:35:13,888 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 15:35:13,888 127.0.0.1 - - [10/Sep/2024 15:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:14,081 Processed batch: ['1826f2e9', '48dbe49e', 'a18be643', '1b96623d'] with model gpt2medium-355m in 3.1609 seconds
2024-09-10 15:35:14,081 Latency for request 1826f2e9 with model gpt2medium-355m: 5.8891 seconds
2024-09-10 15:35:14,082 Latency for request 48dbe49e with model gpt2medium-355m: 5.0564 seconds
2024-09-10 15:35:14,083 Latency for request a18be643 with model gpt2medium-355m: 4.3742 seconds
2024-09-10 15:35:14,083 Latency for request 1b96623d with model gpt2medium-355m: 3.9182 seconds
2024-09-10 15:35:14,083 Updated batch size:4
2024-09-10 15:35:14,083 Loading model gpt2-124m
2024-09-10 15:35:14,149 Request with ID 91dc42ea for model distilgpt2-124m received
2024-09-10 15:35:14,149 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:35:14,149 127.0.0.1 - - [10/Sep/2024 15:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:14,483 Request with ID e2e34f0f for model gpt2medium-355m received
2024-09-10 15:35:14,483 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:35:14,483 Adjusted time limit for model gpt2medium-355m: 11.8798 seconds
2024-09-10 15:35:14,483 127.0.0.1 - - [10/Sep/2024 15:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:14,907 Request with ID 55be5acf for model gpt2-124m received
2024-09-10 15:35:14,907 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:35:14,908 127.0.0.1 - - [10/Sep/2024 15:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:15,071 Request with ID 9bc4b909 for model distilgpt2-124m received
2024-09-10 15:35:15,071 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:35:15,071 127.0.0.1 - - [10/Sep/2024 15:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:15,155 Request with ID 5aa4aab6 for model distilgpt2-124m received
2024-09-10 15:35:15,155 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:35:15,155 127.0.0.1 - - [10/Sep/2024 15:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:15,222 Processed batch: ['64c3c2c7', '7df2dbfe', 'd33964af', '4c725c6d'] with model gpt2-124m in 1.0631 seconds
2024-09-10 15:35:15,222 Latency for request 64c3c2c7 with model gpt2-124m: 3.5069 seconds
2024-09-10 15:35:15,222 Latency for request 7df2dbfe with model gpt2-124m: 3.0011 seconds
2024-09-10 15:35:15,223 Latency for request d33964af with model gpt2-124m: 2.7561 seconds
2024-09-10 15:35:15,223 Latency for request 4c725c6d with model gpt2-124m: 2.0256 seconds
2024-09-10 15:35:15,223 127.0.0.1 - - [10/Sep/2024 15:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:15,223 Updated batch size:4
2024-09-10 15:35:15,223 Loading model gpt2medium-355m
2024-09-10 15:35:15,315 Request with ID 31e05e79 for model gpt2-124m received
2024-09-10 15:35:15,315 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:35:15,315 Adjusted time limit for model gpt2-124m: 13.6926 seconds
2024-09-10 15:35:15,315 127.0.0.1 - - [10/Sep/2024 15:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:15,711 Request with ID 3ac484df for model distilgpt2-124m received
2024-09-10 15:35:15,711 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:35:15,711 Batch size condition met for model distilgpt2-124m
2024-09-10 15:35:16,049 Request with ID 26d47f90 for model gpt2-124m received
2024-09-10 15:35:16,049 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:35:16,049 Batch size condition met for model gpt2-124m
2024-09-10 15:35:16,916 Request with ID 386a14ba for model gpt2-124m received
2024-09-10 15:35:16,916 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:35:16,917 127.0.0.1 - - [10/Sep/2024 15:35:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:17,566 Request with ID e2cbf103 for model gpt2medium-355m received
2024-09-10 15:35:17,566 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:35:17,566 127.0.0.1 - - [10/Sep/2024 15:35:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:18,202 Processed batch: ['40f33397', '59ac41b6', 'df816519', '92b273ca'] with model gpt2medium-355m in 2.8554 seconds
2024-09-10 15:35:18,202 Latency for request 40f33397 with model gpt2medium-355m: 6.3238 seconds
2024-09-10 15:35:18,204 Latency for request 59ac41b6 with model gpt2medium-355m: 6.0653 seconds
2024-09-10 15:35:18,204 Latency for request df816519 with model gpt2medium-355m: 4.7798 seconds
2024-09-10 15:35:18,204 Latency for request 92b273ca with model gpt2medium-355m: 4.5982 seconds
2024-09-10 15:35:18,205 127.0.0.1 - - [10/Sep/2024 15:35:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:18,205 Updated batch size:4
2024-09-10 15:35:18,205 Loading model distilgpt2-124m
2024-09-10 15:35:18,845 Request with ID f51a28c9 for model distilgpt2-124m received
2024-09-10 15:35:18,845 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 15:35:18,845 127.0.0.1 - - [10/Sep/2024 15:35:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:18,923 Processed batch: ['91dc42ea', '9bc4b909', '5aa4aab6', '3ac484df'] with model distilgpt2-124m in 0.6521 seconds
2024-09-10 15:35:18,923 Latency for request 91dc42ea with model distilgpt2-124m: 4.7737 seconds
2024-09-10 15:35:18,925 Latency for request 9bc4b909 with model distilgpt2-124m: 3.8522 seconds
2024-09-10 15:35:18,925 Latency for request 5aa4aab6 with model distilgpt2-124m: 3.7678 seconds
2024-09-10 15:35:18,925 Latency for request 3ac484df with model distilgpt2-124m: 3.2121 seconds
2024-09-10 15:35:18,926 127.0.0.1 - - [10/Sep/2024 15:35:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:18,926 Updated batch size:4
2024-09-10 15:35:18,926 Loading model gpt2-124m
2024-09-10 15:35:19,012 Request with ID 57efa9ac for model distilgpt2-124m received
2024-09-10 15:35:19,012 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 15:35:19,012 Adjusted time limit for model distilgpt2-124m: 14.1814 seconds
2024-09-10 15:35:19,012 127.0.0.1 - - [10/Sep/2024 15:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:19,057 Request with ID b00ba747 for model distilgpt2-124m received
2024-09-10 15:35:19,057 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 15:35:19,057 127.0.0.1 - - [10/Sep/2024 15:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:19,493 Request with ID 543c3145 for model gpt2-124m received
2024-09-10 15:35:19,493 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-10 15:35:19,493 127.0.0.1 - - [10/Sep/2024 15:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:19,591 Request with ID 3b80e530 for model gpt2-124m received
2024-09-10 15:35:19,591 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:35:19,592 127.0.0.1 - - [10/Sep/2024 15:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:20,074 Processed batch: ['7a5c841c', '55be5acf', '31e05e79', '26d47f90'] with model gpt2-124m in 1.0737 seconds
2024-09-10 15:35:20,074 Latency for request 7a5c841c with model gpt2-124m: 6.1861 seconds
2024-09-10 15:35:20,075 Latency for request 55be5acf with model gpt2-124m: 5.1663 seconds
2024-09-10 15:35:20,075 Latency for request 31e05e79 with model gpt2-124m: 4.7588 seconds
2024-09-10 15:35:20,075 Latency for request 26d47f90 with model gpt2-124m: 4.0249 seconds
2024-09-10 15:35:20,076 127.0.0.1 - - [10/Sep/2024 15:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:20,076 No batch to process for model gpt2-124m
2024-09-10 15:35:20,076 127.0.0.1 - - [10/Sep/2024 15:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:20,076 No batch to process for model gpt2medium-355m
2024-09-10 15:35:20,076 127.0.0.1 - - [10/Sep/2024 15:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:20,076 No batch to process for model distilgpt2-124m
2024-09-10 15:35:20,076 127.0.0.1 - - [10/Sep/2024 15:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:20,076 No batch to process for model gpt2-124m
2024-09-10 15:35:20,077 127.0.0.1 - - [10/Sep/2024 15:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:20,659 Request with ID da962242 for model gpt2-124m received
2024-09-10 15:35:20,660 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:35:20,660 Adjusted time limit for model gpt2-124m: 13.6858 seconds
2024-09-10 15:35:20,660 Batch size condition met for model gpt2-124m
2024-09-10 15:35:20,660 Updated batch size:4
2024-09-10 15:35:20,660 Loading model gpt2-124m
2024-09-10 15:35:21,773 Processed batch: ['386a14ba', '543c3145', '3b80e530', 'da962242'] with model gpt2-124m in 1.1124 seconds
2024-09-10 15:35:21,773 Latency for request 386a14ba with model gpt2-124m: 4.8570 seconds
2024-09-10 15:35:21,774 Latency for request 543c3145 with model gpt2-124m: 2.2803 seconds
2024-09-10 15:35:21,775 Latency for request 3b80e530 with model gpt2-124m: 2.1820 seconds
2024-09-10 15:35:21,775 Latency for request da962242 with model gpt2-124m: 1.1140 seconds
2024-09-10 15:35:21,776 127.0.0.1 - - [10/Sep/2024 15:35:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:35:32,493 Time limit condition met for model distilgpt2-124m
2024-09-10 15:35:32,493 Updated batch size:4
2024-09-10 15:35:32,494 Loading model distilgpt2-124m
2024-09-10 15:35:33,116 Processed batch: ['f51a28c9', '57efa9ac', 'b00ba747', '5635'] with model distilgpt2-124m in 0.5376 seconds
2024-09-10 15:35:33,116 Latency for request f51a28c9 with model distilgpt2-124m: 14.2713 seconds
2024-09-10 15:35:33,117 Latency for request 57efa9ac with model distilgpt2-124m: 14.1039 seconds
2024-09-10 15:35:33,117 Latency for request b00ba747 with model distilgpt2-124m: 14.0590 seconds
2024-09-10 15:35:33,118 Latency for request 5635 with model distilgpt2-124m: 0.6226 seconds
