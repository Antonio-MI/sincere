2024-09-10 15:01:52,938 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.11.77:5000
2024-09-10 15:01:52,939 [33mPress CTRL+C to quit[0m
2024-09-10 15:01:52,950 Request with ID 2f9062bf for model gpt2medium-355m received
2024-09-10 15:01:52,951 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 15:01:52,951 Adjusted time limit for model gpt2medium-355m: 9.9550 seconds
2024-09-10 15:01:52,951 127.0.0.1 - - [10/Sep/2024 15:01:52] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:52,992 Request with ID 308bf710 for model gpt2-124m received
2024-09-10 15:01:52,992 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 15:01:52,992 Adjusted time limit for model gpt2-124m: 13.3502 seconds
2024-09-10 15:01:52,992 127.0.0.1 - - [10/Sep/2024 15:01:52] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:53,007 Request with ID af93fb08 for model distilgpt2-124m received
2024-09-10 15:01:53,007 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 15:01:53,007 Adjusted time limit for model distilgpt2-124m: 14.2150 seconds
2024-09-10 15:01:53,008 127.0.0.1 - - [10/Sep/2024 15:01:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:53,011 Request with ID 3599119c for model gpt2-124m received
2024-09-10 15:01:53,011 Adjusted time limit based on total queue size 4: 11.2500 seconds
2024-09-10 15:01:53,011 127.0.0.1 - - [10/Sep/2024 15:01:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:53,151 Request with ID a39c33b2 for model gpt2-124m received
2024-09-10 15:01:53,151 Adjusted time limit based on total queue size 5: 11.2500 seconds
2024-09-10 15:01:53,152 127.0.0.1 - - [10/Sep/2024 15:01:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:53,275 Request with ID 9f9e3177 for model distilgpt2-124m received
2024-09-10 15:01:53,275 Adjusted time limit based on total queue size 6: 11.2500 seconds
2024-09-10 15:01:53,275 127.0.0.1 - - [10/Sep/2024 15:01:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:53,457 Request with ID 5c915730 for model gpt2-124m received
2024-09-10 15:01:53,458 Adjusted time limit based on total queue size 7: 11.2500 seconds
2024-09-10 15:01:53,459 127.0.0.1 - - [10/Sep/2024 15:01:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:53,616 Request with ID 8e052322 for model gpt2medium-355m received
2024-09-10 15:01:53,616 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-10 15:01:53,617 127.0.0.1 - - [10/Sep/2024 15:01:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:53,852 Request with ID dc157f77 for model distilgpt2-124m received
2024-09-10 15:01:53,853 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-10 15:01:53,853 127.0.0.1 - - [10/Sep/2024 15:01:53] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:54,127 Request with ID 66be3ad5 for model gpt2medium-355m received
2024-09-10 15:01:54,127 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:01:54,128 127.0.0.1 - - [10/Sep/2024 15:01:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:54,419 Request with ID 2a824ace for model gpt2-124m received
2024-09-10 15:01:54,419 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:01:54,419 127.0.0.1 - - [10/Sep/2024 15:01:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:54,789 Request with ID a6db486c for model gpt2medium-355m received
2024-09-10 15:01:54,789 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:01:54,790 127.0.0.1 - - [10/Sep/2024 15:01:54] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:55,009 Request with ID 388045af for model gpt2-124m received
2024-09-10 15:01:55,009 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:01:55,010 127.0.0.1 - - [10/Sep/2024 15:01:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:55,212 Request with ID 4ec576c0 for model distilgpt2-124m received
2024-09-10 15:01:55,213 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:01:55,213 127.0.0.1 - - [10/Sep/2024 15:01:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:55,856 Request with ID d50c49cd for model gpt2-124m received
2024-09-10 15:01:55,857 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:01:55,857 127.0.0.1 - - [10/Sep/2024 15:01:55] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:56,578 Request with ID b9ce9524 for model gpt2-124m received
2024-09-10 15:01:56,579 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:01:56,579 127.0.0.1 - - [10/Sep/2024 15:01:56] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:57,017 Request with ID 508afe6a for model distilgpt2-124m received
2024-09-10 15:01:57,017 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 15:01:57,017 127.0.0.1 - - [10/Sep/2024 15:01:57] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:58,709 Request with ID 8e162b08 for model gpt2-124m received
2024-09-10 15:01:58,709 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 15:01:58,710 127.0.0.1 - - [10/Sep/2024 15:01:58] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:59,458 Request with ID 171dceaf for model gpt2medium-355m received
2024-09-10 15:01:59,459 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 15:01:59,459 127.0.0.1 - - [10/Sep/2024 15:01:59] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:01:59,483 Time limit condition met for model gpt2medium-355m
2024-09-10 15:01:59,483 Updated batch size:8
2024-09-10 15:01:59,483 Loading model gpt2medium-355m
2024-09-10 15:02:00,020 Request with ID 0ee7b9b2 for model gpt2medium-355m received
2024-09-10 15:02:00,020 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:02:00,020 127.0.0.1 - - [10/Sep/2024 15:02:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:00,401 Request with ID dec2075c for model gpt2medium-355m received
2024-09-10 15:02:00,401 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:02:00,401 127.0.0.1 - - [10/Sep/2024 15:02:00] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:01,096 Request with ID f6ae6577 for model gpt2medium-355m received
2024-09-10 15:02:01,096 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 15:02:01,096 127.0.0.1 - - [10/Sep/2024 15:02:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:01,521 Request with ID 741af6fd for model gpt2-124m received
2024-09-10 15:02:01,521 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 15:02:01,521 127.0.0.1 - - [10/Sep/2024 15:02:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:01,766 Request with ID 9ac6f84d for model distilgpt2-124m received
2024-09-10 15:02:01,766 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 15:02:01,766 127.0.0.1 - - [10/Sep/2024 15:02:01] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:02,404 Request with ID ceb1e64f for model distilgpt2-124m received
2024-09-10 15:02:02,404 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 15:02:02,405 127.0.0.1 - - [10/Sep/2024 15:02:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:02,750 Processed batch: ['2f9062bf', '8e052322', '66be3ad5', 'a6db486c', '171dceaf', '14f2', 'b982', '4a6a'] with model gpt2medium-355m in 3.1092 seconds
2024-09-10 15:02:02,750 Latency for request 2f9062bf with model gpt2medium-355m: 9.7992 seconds
2024-09-10 15:02:02,751 Latency for request 8e052322 with model gpt2medium-355m: 9.1336 seconds
2024-09-10 15:02:02,752 Latency for request 66be3ad5 with model gpt2medium-355m: 8.6228 seconds
2024-09-10 15:02:02,752 Latency for request a6db486c with model gpt2medium-355m: 7.9607 seconds
2024-09-10 15:02:02,752 Latency for request 171dceaf with model gpt2medium-355m: 3.2914 seconds
2024-09-10 15:02:02,752 Latency for request 14f2 with model gpt2medium-355m: 3.2665 seconds
2024-09-10 15:02:02,753 Latency for request b982 with model gpt2medium-355m: 3.2664 seconds
2024-09-10 15:02:02,753 Latency for request 4a6a with model gpt2medium-355m: 3.2664 seconds
2024-09-10 15:02:02,946 Request with ID 124eae3a for model distilgpt2-124m received
2024-09-10 15:02:02,946 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 15:02:02,946 127.0.0.1 - - [10/Sep/2024 15:02:02] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:03,023 Request with ID 25ac19ad for model gpt2-124m received
2024-09-10 15:02:03,023 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 15:02:03,023 127.0.0.1 - - [10/Sep/2024 15:02:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:03,733 Request with ID f89cf89d for model gpt2medium-355m received
2024-09-10 15:02:03,733 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 15:02:03,733 Adjusted time limit for model gpt2medium-355m: 9.9443 seconds
2024-09-10 15:02:03,734 127.0.0.1 - - [10/Sep/2024 15:02:03] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:04,007 Time limit condition met for model gpt2-124m
2024-09-10 15:02:04,007 Updated batch size:16
2024-09-10 15:02:04,007 Loading model gpt2-124m
2024-09-10 15:02:04,197 Request with ID 387a64b0 for model gpt2medium-355m received
2024-09-10 15:02:04,197 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:02:04,197 127.0.0.1 - - [10/Sep/2024 15:02:04] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:04,259 Request with ID db69e972 for model gpt2medium-355m received
2024-09-10 15:02:04,259 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:02:04,259 127.0.0.1 - - [10/Sep/2024 15:02:04] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:05,148 Request with ID a8284def for model gpt2medium-355m received
2024-09-10 15:02:05,148 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:02:05,148 127.0.0.1 - - [10/Sep/2024 15:02:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:05,578 Request with ID efd80503 for model gpt2-124m received
2024-09-10 15:02:05,578 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:02:05,578 127.0.0.1 - - [10/Sep/2024 15:02:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:05,920 Processed batch: ['308bf710', '3599119c', 'a39c33b2', '5c915730', '2a824ace', '388045af', 'd50c49cd', 'b9ce9524', '8e162b08', '741af6fd', '25ac19ad', 'cadf', '9dfd', '93e3', 'e73a', 'd80e'] with model gpt2-124m in 1.8420 seconds
2024-09-10 15:02:05,920 Latency for request 308bf710 with model gpt2-124m: 12.9287 seconds
2024-09-10 15:02:05,921 Latency for request 3599119c with model gpt2-124m: 12.9092 seconds
2024-09-10 15:02:05,922 Latency for request a39c33b2 with model gpt2-124m: 12.7693 seconds
2024-09-10 15:02:05,922 Latency for request 5c915730 with model gpt2-124m: 12.4629 seconds
2024-09-10 15:02:05,922 Latency for request 2a824ace with model gpt2-124m: 11.5010 seconds
2024-09-10 15:02:05,922 Latency for request 388045af with model gpt2-124m: 10.9114 seconds
2024-09-10 15:02:05,923 Latency for request d50c49cd with model gpt2-124m: 10.0638 seconds
2024-09-10 15:02:05,923 Latency for request b9ce9524 with model gpt2-124m: 9.3418 seconds
2024-09-10 15:02:05,923 Latency for request 8e162b08 with model gpt2-124m: 7.2111 seconds
2024-09-10 15:02:05,923 Latency for request 741af6fd with model gpt2-124m: 4.3993 seconds
2024-09-10 15:02:05,923 Latency for request 25ac19ad with model gpt2-124m: 2.8972 seconds
2024-09-10 15:02:05,924 Latency for request cadf with model gpt2-124m: 1.9135 seconds
2024-09-10 15:02:05,924 Latency for request 9dfd with model gpt2-124m: 1.9135 seconds
2024-09-10 15:02:05,924 Latency for request 93e3 with model gpt2-124m: 1.9135 seconds
2024-09-10 15:02:05,924 Latency for request e73a with model gpt2-124m: 1.9135 seconds
2024-09-10 15:02:05,924 Latency for request d80e with model gpt2-124m: 1.9135 seconds
2024-09-10 15:02:05,935 Request with ID 161f6b56 for model gpt2medium-355m received
2024-09-10 15:02:05,935 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 15:02:05,935 127.0.0.1 - - [10/Sep/2024 15:02:05] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:06,030 Time limit condition met for model gpt2medium-355m
2024-09-10 15:02:06,030 Updated batch size:8
2024-09-10 15:02:06,030 Loading model gpt2medium-355m
2024-09-10 15:02:06,199 Request with ID b4e16751 for model gpt2medium-355m received
2024-09-10 15:02:06,199 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:02:06,199 127.0.0.1 - - [10/Sep/2024 15:02:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:06,368 Request with ID 55f4665f for model gpt2-124m received
2024-09-10 15:02:06,368 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:02:06,368 Adjusted time limit for model gpt2-124m: 13.3395 seconds
2024-09-10 15:02:06,368 127.0.0.1 - - [10/Sep/2024 15:02:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:06,934 Request with ID 50e4b589 for model gpt2medium-355m received
2024-09-10 15:02:06,934 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:02:06,935 127.0.0.1 - - [10/Sep/2024 15:02:06] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:07,566 Request with ID 4fdc432b for model distilgpt2-124m received
2024-09-10 15:02:07,566 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:02:07,566 127.0.0.1 - - [10/Sep/2024 15:02:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:07,993 Request with ID 9503282d for model gpt2-124m received
2024-09-10 15:02:07,993 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:02:07,993 127.0.0.1 - - [10/Sep/2024 15:02:07] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:08,165 Request with ID 5bf7841c for model gpt2medium-355m received
2024-09-10 15:02:08,165 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:02:08,165 127.0.0.1 - - [10/Sep/2024 15:02:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:08,415 Request with ID 6f1e11f8 for model gpt2-124m received
2024-09-10 15:02:08,415 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:02:08,415 127.0.0.1 - - [10/Sep/2024 15:02:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:08,427 Request with ID add22b52 for model gpt2-124m received
2024-09-10 15:02:08,427 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 15:02:08,427 127.0.0.1 - - [10/Sep/2024 15:02:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:08,860 Request with ID 8ce554e7 for model gpt2-124m received
2024-09-10 15:02:08,860 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 15:02:08,860 127.0.0.1 - - [10/Sep/2024 15:02:08] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:09,084 Request with ID 3f72217d for model distilgpt2-124m received
2024-09-10 15:02:09,084 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 15:02:09,084 127.0.0.1 - - [10/Sep/2024 15:02:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:09,292 Request with ID bb574162 for model distilgpt2-124m received
2024-09-10 15:02:09,292 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 15:02:09,292 127.0.0.1 - - [10/Sep/2024 15:02:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:09,645 Processed batch: ['0ee7b9b2', 'dec2075c', 'f6ae6577', 'f89cf89d', '387a64b0', 'db69e972', 'a8284def', '161f6b56'] with model gpt2medium-355m in 3.4700 seconds
2024-09-10 15:02:09,645 Latency for request 0ee7b9b2 with model gpt2medium-355m: 9.6246 seconds
2024-09-10 15:02:09,645 Latency for request dec2075c with model gpt2medium-355m: 9.2439 seconds
2024-09-10 15:02:09,646 Latency for request f6ae6577 with model gpt2medium-355m: 8.5492 seconds
2024-09-10 15:02:09,646 Latency for request f89cf89d with model gpt2medium-355m: 5.9121 seconds
2024-09-10 15:02:09,646 Latency for request 387a64b0 with model gpt2medium-355m: 5.4476 seconds
2024-09-10 15:02:09,647 Latency for request db69e972 with model gpt2medium-355m: 5.3857 seconds
2024-09-10 15:02:09,647 Latency for request a8284def with model gpt2medium-355m: 4.4966 seconds
2024-09-10 15:02:09,647 Latency for request 161f6b56 with model gpt2medium-355m: 3.7094 seconds
2024-09-10 15:02:09,647 Time limit condition met for model distilgpt2-124m
2024-09-10 15:02:09,647 Updated batch size:16
2024-09-10 15:02:09,647 Loading model distilgpt2-124m
2024-09-10 15:02:09,886 Request with ID db9c650c for model distilgpt2-124m received
2024-09-10 15:02:09,886 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-10 15:02:09,886 127.0.0.1 - - [10/Sep/2024 15:02:09] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:10,016 Request with ID f96c257c for model distilgpt2-124m received
2024-09-10 15:02:10,016 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-10 15:02:10,017 127.0.0.1 - - [10/Sep/2024 15:02:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:10,366 Request with ID 33016d02 for model distilgpt2-124m received
2024-09-10 15:02:10,366 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-10 15:02:10,367 127.0.0.1 - - [10/Sep/2024 15:02:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:10,573 Request with ID 82696cbf for model distilgpt2-124m received
2024-09-10 15:02:10,573 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:02:10,573 127.0.0.1 - - [10/Sep/2024 15:02:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:10,811 Request with ID 4e436916 for model distilgpt2-124m received
2024-09-10 15:02:10,811 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:02:10,811 127.0.0.1 - - [10/Sep/2024 15:02:10] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:11,093 Request with ID f588ed76 for model distilgpt2-124m received
2024-09-10 15:02:11,093 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:02:11,093 127.0.0.1 - - [10/Sep/2024 15:02:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:11,280 Request with ID 78c4666f for model distilgpt2-124m received
2024-09-10 15:02:11,280 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:02:11,280 127.0.0.1 - - [10/Sep/2024 15:02:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:11,401 Processed batch: ['af93fb08', '9f9e3177', 'dc157f77', '4ec576c0', '508afe6a', '9ac6f84d', 'ceb1e64f', '124eae3a', '4fdc432b', '3f72217d', 'bb574162', 'f302', '11c5', '2faf', 'eacd', 'e58f'] with model distilgpt2-124m in 1.6972 seconds
2024-09-10 15:02:11,401 Latency for request af93fb08 with model distilgpt2-124m: 18.3939 seconds
2024-09-10 15:02:11,402 Latency for request 9f9e3177 with model distilgpt2-124m: 18.1264 seconds
2024-09-10 15:02:11,402 Latency for request dc157f77 with model distilgpt2-124m: 17.5487 seconds
2024-09-10 15:02:11,402 Latency for request 4ec576c0 with model distilgpt2-124m: 16.1887 seconds
2024-09-10 15:02:11,403 Latency for request 508afe6a with model distilgpt2-124m: 14.3843 seconds
2024-09-10 15:02:11,403 Latency for request 9ac6f84d with model distilgpt2-124m: 9.6350 seconds
2024-09-10 15:02:11,403 Latency for request ceb1e64f with model distilgpt2-124m: 8.9967 seconds
2024-09-10 15:02:11,403 Latency for request 124eae3a with model distilgpt2-124m: 8.4553 seconds
2024-09-10 15:02:11,404 Latency for request 4fdc432b with model distilgpt2-124m: 3.8352 seconds
2024-09-10 15:02:11,404 Latency for request 3f72217d with model distilgpt2-124m: 2.3173 seconds
2024-09-10 15:02:11,404 Latency for request bb574162 with model distilgpt2-124m: 2.1092 seconds
2024-09-10 15:02:11,404 Latency for request f302 with model distilgpt2-124m: 1.7537 seconds
2024-09-10 15:02:11,404 Latency for request 11c5 with model distilgpt2-124m: 1.7537 seconds
2024-09-10 15:02:11,405 Latency for request 2faf with model distilgpt2-124m: 1.7537 seconds
2024-09-10 15:02:11,405 Latency for request eacd with model distilgpt2-124m: 1.7537 seconds
2024-09-10 15:02:11,405 Latency for request e58f with model distilgpt2-124m: 1.7537 seconds
2024-09-10 15:02:12,038 Request with ID 0b66aa1b for model gpt2medium-355m received
2024-09-10 15:02:12,038 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 15:02:12,038 Adjusted time limit for model gpt2medium-355m: 9.9487 seconds
2024-09-10 15:02:12,039 127.0.0.1 - - [10/Sep/2024 15:02:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:12,285 Request with ID 2f26c63f for model gpt2-124m received
2024-09-10 15:02:12,285 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 15:02:12,286 127.0.0.1 - - [10/Sep/2024 15:02:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:13,283 Request with ID 8fece960 for model gpt2-124m received
2024-09-10 15:02:13,283 Adjusted time limit based on total queue size 19: 3.7500 seconds
2024-09-10 15:02:13,284 127.0.0.1 - - [10/Sep/2024 15:02:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:13,900 Request with ID 8293b718 for model distilgpt2-124m received
2024-09-10 15:02:13,900 Adjusted time limit based on total queue size 20: 3.7500 seconds
2024-09-10 15:02:13,901 Adjusted time limit for model distilgpt2-124m: 14.2087 seconds
2024-09-10 15:02:13,901 127.0.0.1 - - [10/Sep/2024 15:02:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:14,394 Request with ID e36d6539 for model distilgpt2-124m received
2024-09-10 15:02:14,394 Adjusted time limit based on total queue size 21: 3.7500 seconds
2024-09-10 15:02:14,395 127.0.0.1 - - [10/Sep/2024 15:02:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:14,545 Request with ID 9f23cd86 for model gpt2-124m received
2024-09-10 15:02:14,545 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 15:02:14,546 127.0.0.1 - - [10/Sep/2024 15:02:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:15,138 Request with ID 0a3995c8 for model gpt2-124m received
2024-09-10 15:02:15,138 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 15:02:15,139 127.0.0.1 - - [10/Sep/2024 15:02:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:15,245 Request with ID 2eb2150d for model gpt2-124m received
2024-09-10 15:02:15,245 Adjusted time limit based on total queue size 24: 3.7500 seconds
2024-09-10 15:02:15,246 127.0.0.1 - - [10/Sep/2024 15:02:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:15,503 Request with ID f1f66ed2 for model gpt2-124m received
2024-09-10 15:02:15,504 Adjusted time limit based on total queue size 25: 3.7500 seconds
2024-09-10 15:02:15,504 127.0.0.1 - - [10/Sep/2024 15:02:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:15,789 Request with ID 86e7f281 for model gpt2medium-355m received
2024-09-10 15:02:15,789 Adjusted time limit based on total queue size 26: 3.7500 seconds
2024-09-10 15:02:15,789 127.0.0.1 - - [10/Sep/2024 15:02:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:16,441 Request with ID 53ed5162 for model gpt2medium-355m received
2024-09-10 15:02:16,441 Adjusted time limit based on total queue size 27: 3.7500 seconds
2024-09-10 15:02:16,442 127.0.0.1 - - [10/Sep/2024 15:02:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:16,499 Time limit condition met for model gpt2medium-355m
2024-09-10 15:02:16,500 Updated batch size:8
2024-09-10 15:02:16,500 Loading model gpt2medium-355m
2024-09-10 15:02:16,619 Request with ID c11cd71c for model gpt2-124m received
2024-09-10 15:02:16,620 Adjusted time limit based on total queue size 22: 3.7500 seconds
2024-09-10 15:02:16,620 127.0.0.1 - - [10/Sep/2024 15:02:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:16,755 Request with ID 8527578e for model gpt2-124m received
2024-09-10 15:02:16,755 Adjusted time limit based on total queue size 23: 3.7500 seconds
2024-09-10 15:02:16,755 127.0.0.1 - - [10/Sep/2024 15:02:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:17,153 Request with ID c42a4ac1 for model distilgpt2-124m received
2024-09-10 15:02:17,153 Adjusted time limit based on total queue size 24: 3.7500 seconds
2024-09-10 15:02:17,153 127.0.0.1 - - [10/Sep/2024 15:02:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:17,535 Request with ID ba4cd1b5 for model gpt2-124m received
2024-09-10 15:02:17,535 Adjusted time limit based on total queue size 25: 3.7500 seconds
2024-09-10 15:02:17,535 127.0.0.1 - - [10/Sep/2024 15:02:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:17,644 Request with ID f548fe0c for model gpt2medium-355m received
2024-09-10 15:02:17,644 Adjusted time limit based on total queue size 26: 3.7500 seconds
2024-09-10 15:02:17,644 127.0.0.1 - - [10/Sep/2024 15:02:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:17,977 Request with ID 2e2cf720 for model distilgpt2-124m received
2024-09-10 15:02:17,978 Adjusted time limit based on total queue size 27: 3.7500 seconds
2024-09-10 15:02:17,978 127.0.0.1 - - [10/Sep/2024 15:02:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:18,223 Request with ID cbf668af for model gpt2-124m received
2024-09-10 15:02:18,223 Adjusted time limit based on total queue size 28: 3.7500 seconds
2024-09-10 15:02:18,223 Batch size condition met for model gpt2-124m
2024-09-10 15:02:18,366 Request with ID 1b3f9328 for model gpt2medium-355m received
2024-09-10 15:02:18,366 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-10 15:02:18,366 127.0.0.1 - - [10/Sep/2024 15:02:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:19,075 Request with ID 57185c7e for model gpt2-124m received
2024-09-10 15:02:19,075 Adjusted time limit based on total queue size 14: 7.5000 seconds
2024-09-10 15:02:19,075 127.0.0.1 - - [10/Sep/2024 15:02:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:19,692 Request with ID 91c8bee9 for model gpt2-124m received
2024-09-10 15:02:19,692 Adjusted time limit based on total queue size 15: 7.5000 seconds
2024-09-10 15:02:19,692 127.0.0.1 - - [10/Sep/2024 15:02:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:19,969 Request with ID 8d8deb93 for model gpt2medium-355m received
2024-09-10 15:02:19,969 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:02:19,969 127.0.0.1 - - [10/Sep/2024 15:02:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:20,217 Request with ID 81c3aa4a for model gpt2medium-355m received
2024-09-10 15:02:20,217 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 15:02:20,217 127.0.0.1 - - [10/Sep/2024 15:02:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:20,384 Processed batch: ['b4e16751', '50e4b589', '5bf7841c', '0b66aa1b', '86e7f281', '53ed5162', 'dd5a', 'ff59'] with model gpt2medium-355m in 3.7299 seconds
2024-09-10 15:02:20,384 Latency for request b4e16751 with model gpt2medium-355m: 14.1856 seconds
2024-09-10 15:02:20,385 Latency for request 50e4b589 with model gpt2medium-355m: 13.4499 seconds
2024-09-10 15:02:20,385 Latency for request 5bf7841c with model gpt2medium-355m: 12.2198 seconds
2024-09-10 15:02:20,386 Latency for request 0b66aa1b with model gpt2medium-355m: 8.3460 seconds
2024-09-10 15:02:20,386 Latency for request 86e7f281 with model gpt2medium-355m: 4.5958 seconds
2024-09-10 15:02:20,386 Latency for request 53ed5162 with model gpt2medium-355m: 3.9435 seconds
2024-09-10 15:02:20,386 Latency for request dd5a with model gpt2medium-355m: 3.8847 seconds
2024-09-10 15:02:20,387 Latency for request ff59 with model gpt2medium-355m: 3.8847 seconds
2024-09-10 15:02:20,387 Updated batch size:16
2024-09-10 15:02:20,387 Loading model gpt2-124m
2024-09-10 15:02:20,488 Time limit condition met for model gpt2-124m
2024-09-10 15:02:20,698 Request with ID 65353aeb for model distilgpt2-124m received
2024-09-10 15:02:20,698 Adjusted time limit based on total queue size 16: 3.7500 seconds
2024-09-10 15:02:20,698 127.0.0.1 - - [10/Sep/2024 15:02:20] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:21,030 Request with ID 9cf0d647 for model gpt2medium-355m received
2024-09-10 15:02:21,030 Adjusted time limit based on total queue size 17: 3.7500 seconds
2024-09-10 15:02:21,030 Adjusted time limit for model gpt2medium-355m: 9.9482 seconds
2024-09-10 15:02:21,030 127.0.0.1 - - [10/Sep/2024 15:02:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:21,416 Request with ID bfa36ae4 for model distilgpt2-124m received
2024-09-10 15:02:21,416 Adjusted time limit based on total queue size 18: 3.7500 seconds
2024-09-10 15:02:21,416 127.0.0.1 - - [10/Sep/2024 15:02:21] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:22,439 Processed batch: ['efd80503', '55f4665f', '9503282d', '6f1e11f8', 'add22b52', '8ce554e7', '2f26c63f', '8fece960', '9f23cd86', '0a3995c8', '2eb2150d', 'f1f66ed2', 'c11cd71c', '8527578e', 'ba4cd1b5', 'cbf668af'] with model gpt2-124m in 1.9832 seconds
2024-09-10 15:02:22,439 Latency for request efd80503 with model gpt2-124m: 16.8609 seconds
2024-09-10 15:02:22,440 Latency for request 55f4665f with model gpt2-124m: 16.0707 seconds
2024-09-10 15:02:22,440 Latency for request 9503282d with model gpt2-124m: 14.4465 seconds
2024-09-10 15:02:22,441 Latency for request 6f1e11f8 with model gpt2-124m: 14.0242 seconds
2024-09-10 15:02:22,441 Latency for request add22b52 with model gpt2-124m: 14.0124 seconds
2024-09-10 15:02:22,441 Latency for request 8ce554e7 with model gpt2-124m: 13.5792 seconds
2024-09-10 15:02:22,441 Latency for request 2f26c63f with model gpt2-124m: 10.1541 seconds
2024-09-10 15:02:22,442 Latency for request 8fece960 with model gpt2-124m: 9.1561 seconds
2024-09-10 15:02:22,442 Latency for request 9f23cd86 with model gpt2-124m: 7.8943 seconds
2024-09-10 15:02:22,442 Latency for request 0a3995c8 with model gpt2-124m: 7.3014 seconds
2024-09-10 15:02:22,442 Latency for request 2eb2150d with model gpt2-124m: 7.1940 seconds
2024-09-10 15:02:22,442 Latency for request f1f66ed2 with model gpt2-124m: 6.9356 seconds
2024-09-10 15:02:22,443 Latency for request c11cd71c with model gpt2-124m: 5.8197 seconds
2024-09-10 15:02:22,443 Latency for request 8527578e with model gpt2-124m: 5.6841 seconds
2024-09-10 15:02:22,443 Latency for request ba4cd1b5 with model gpt2-124m: 4.9039 seconds
2024-09-10 15:02:22,443 Latency for request cbf668af with model gpt2-124m: 4.2164 seconds
2024-09-10 15:02:22,444 127.0.0.1 - - [10/Sep/2024 15:02:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 15:02:22,444 Updated batch size:4
2024-09-10 15:02:22,444 Loading model gpt2-124m
2024-09-10 15:02:23,415 Processed batch: ['57185c7e', '91c8bee9', '0cb3', 'eb5c'] with model gpt2-124m in 0.9709 seconds
2024-09-10 15:02:23,415 Latency for request 57185c7e with model gpt2-124m: 4.3397 seconds
2024-09-10 15:02:23,416 Latency for request 91c8bee9 with model gpt2-124m: 3.7230 seconds
2024-09-10 15:02:23,416 Latency for request 0cb3 with model gpt2-124m: 0.9712 seconds
2024-09-10 15:02:23,417 Latency for request eb5c with model gpt2-124m: 0.9712 seconds
2024-09-10 15:02:25,492 Time limit condition met for model gpt2medium-355m
2024-09-10 15:02:25,493 Updated batch size:8
2024-09-10 15:02:25,493 Loading model gpt2medium-355m
2024-09-10 15:02:29,615 Processed batch: ['f548fe0c', '1b3f9328', '8d8deb93', '81c3aa4a', '9cf0d647', '1b2f', '244d', '9d08'] with model gpt2medium-355m in 3.9575 seconds
2024-09-10 15:02:29,615 Latency for request f548fe0c with model gpt2medium-355m: 11.9707 seconds
2024-09-10 15:02:29,616 Latency for request 1b3f9328 with model gpt2medium-355m: 11.2485 seconds
2024-09-10 15:02:29,616 Latency for request 8d8deb93 with model gpt2medium-355m: 9.6460 seconds
2024-09-10 15:02:29,617 Latency for request 81c3aa4a with model gpt2medium-355m: 9.3976 seconds
2024-09-10 15:02:29,617 Latency for request 9cf0d647 with model gpt2medium-355m: 8.5848 seconds
2024-09-10 15:02:29,617 Latency for request 1b2f with model gpt2medium-355m: 4.1218 seconds
2024-09-10 15:02:29,617 Latency for request 244d with model gpt2medium-355m: 4.1218 seconds
2024-09-10 15:02:29,618 Latency for request 9d08 with model gpt2medium-355m: 4.1218 seconds
2024-09-10 15:02:29,719 Time limit condition met for model distilgpt2-124m
2024-09-10 15:02:29,719 Updated batch size:16
2024-09-10 15:02:29,719 Loading model distilgpt2-124m
2024-09-10 15:02:30,970 Processed batch: ['db9c650c', 'f96c257c', '33016d02', '82696cbf', '4e436916', 'f588ed76', '78c4666f', '8293b718', 'e36d6539', 'c42a4ac1', '2e2cf720', '65353aeb', 'bfa36ae4', '4cee', '173b', 'b7fd'] with model distilgpt2-124m in 1.1940 seconds
2024-09-10 15:02:30,970 Latency for request db9c650c with model distilgpt2-124m: 21.0839 seconds
2024-09-10 15:02:30,971 Latency for request f96c257c with model distilgpt2-124m: 20.9536 seconds
2024-09-10 15:02:30,971 Latency for request 33016d02 with model distilgpt2-124m: 20.6034 seconds
2024-09-10 15:02:30,971 Latency for request 82696cbf with model distilgpt2-124m: 20.3965 seconds
2024-09-10 15:02:30,972 Latency for request 4e436916 with model distilgpt2-124m: 20.1586 seconds
2024-09-10 15:02:30,972 Latency for request f588ed76 with model distilgpt2-124m: 19.8767 seconds
2024-09-10 15:02:30,972 Latency for request 78c4666f with model distilgpt2-124m: 19.6900 seconds
2024-09-10 15:02:30,972 Latency for request 8293b718 with model distilgpt2-124m: 17.0699 seconds
2024-09-10 15:02:30,973 Latency for request e36d6539 with model distilgpt2-124m: 16.5760 seconds
2024-09-10 15:02:30,973 Latency for request c42a4ac1 with model distilgpt2-124m: 13.8165 seconds
2024-09-10 15:02:30,973 Latency for request 2e2cf720 with model distilgpt2-124m: 12.9922 seconds
2024-09-10 15:02:30,973 Latency for request 65353aeb with model distilgpt2-124m: 10.2715 seconds
2024-09-10 15:02:30,974 Latency for request bfa36ae4 with model distilgpt2-124m: 9.5536 seconds
2024-09-10 15:02:30,974 Latency for request 4cee with model distilgpt2-124m: 1.2510 seconds
2024-09-10 15:02:30,974 Latency for request 173b with model distilgpt2-124m: 1.2510 seconds
2024-09-10 15:02:30,974 Latency for request b7fd with model distilgpt2-124m: 1.2510 seconds
2024-09-10 15:02:30,974 Total time: 38.0244 seconds
2024-09-10 15:02:30,974 Total inference time: 21.9539 seconds
2024-09-10 15:02:30,974 Inference time as percentage of total time: 57.74%
