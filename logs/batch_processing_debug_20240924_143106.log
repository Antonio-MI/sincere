2024-09-24 14:31:06,390 Using device: cuda
2024-09-24 14:31:06,390 Scheduling mode set as BestBatch
2024-09-24 14:31:06,390 Monitoring status set to True
2024-09-24 14:31:21,454 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.122.143:5000
2024-09-24 14:31:21,454 [33mPress CTRL+C to quit[0m
2024-09-24 14:31:22,228 127.0.0.1 - - [24/Sep/2024 14:31:22] "GET /health HTTP/1.1" 200 -
2024-09-24 14:31:22,608 Request with ID ddc2d8e7 for model gemma-7b received
2024-09-24 14:31:22,609 127.0.0.1 - - [24/Sep/2024 14:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:22,799 Request with ID ad444181 for model llama3-8b received
2024-09-24 14:31:22,800 127.0.0.1 - - [24/Sep/2024 14:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:22,813 Request with ID 52a6e5d8 for model llama3-8b received
2024-09-24 14:31:22,814 127.0.0.1 - - [24/Sep/2024 14:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:22,931 Request with ID 9721f51d for model granite-7b received
2024-09-24 14:31:22,932 127.0.0.1 - - [24/Sep/2024 14:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:23,371 Request with ID 7226f3a5 for model llama3-8b received
2024-09-24 14:31:23,372 127.0.0.1 - - [24/Sep/2024 14:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:23,373 Request with ID 2ed579ad for model gemma-7b received
2024-09-24 14:31:23,374 127.0.0.1 - - [24/Sep/2024 14:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:23,418 Request with ID 357435ec for model granite-7b received
2024-09-24 14:31:23,419 127.0.0.1 - - [24/Sep/2024 14:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:23,422 Request with ID f7062efb for model llama3-8b received
2024-09-24 14:31:23,422 127.0.0.1 - - [24/Sep/2024 14:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:23,442 Request with ID fc5f8ede for model gemma-7b received
2024-09-24 14:31:23,442 127.0.0.1 - - [24/Sep/2024 14:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:23,455 Request with ID 675f28b1 for model gemma-7b received
2024-09-24 14:31:23,455 127.0.0.1 - - [24/Sep/2024 14:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:23,969 Request with ID 960374ec for model granite-7b received
2024-09-24 14:31:23,970 127.0.0.1 - - [24/Sep/2024 14:31:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:24,088 Request with ID fc16a1cd for model llama3-8b received
2024-09-24 14:31:24,089 127.0.0.1 - - [24/Sep/2024 14:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:24,091 Request with ID d631acdc for model llama3-8b received
2024-09-24 14:31:24,091 127.0.0.1 - - [24/Sep/2024 14:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:24,300 Request with ID 4d3e3c8c for model gemma-7b received
2024-09-24 14:31:24,300 127.0.0.1 - - [24/Sep/2024 14:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:24,445 Request with ID 65223b5e for model granite-7b received
2024-09-24 14:31:24,445 127.0.0.1 - - [24/Sep/2024 14:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:24,747 Request with ID f0bbedef for model gemma-7b received
2024-09-24 14:31:24,748 127.0.0.1 - - [24/Sep/2024 14:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:24,926 Request with ID f18891d0 for model llama3-8b received
2024-09-24 14:31:24,926 127.0.0.1 - - [24/Sep/2024 14:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:25,026 Request with ID 20ef72bb for model llama3-8b received
2024-09-24 14:31:25,026 127.0.0.1 - - [24/Sep/2024 14:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:25,214 Request with ID c22519f3 for model gemma-7b received
2024-09-24 14:31:25,214 127.0.0.1 - - [24/Sep/2024 14:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:25,542 Request with ID 2788ef20 for model gemma-7b received
2024-09-24 14:31:25,543 127.0.0.1 - - [24/Sep/2024 14:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:25,649 Request with ID 1f2ff158 for model granite-7b received
2024-09-24 14:31:25,650 127.0.0.1 - - [24/Sep/2024 14:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:25,699 Request with ID 59639c32 for model llama3-8b received
2024-09-24 14:31:25,700 127.0.0.1 - - [24/Sep/2024 14:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:25,812 Request with ID a55a785b for model llama3-8b received
2024-09-24 14:31:25,813 127.0.0.1 - - [24/Sep/2024 14:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:25,854 Request with ID 7870e665 for model llama3-8b received
2024-09-24 14:31:25,854 127.0.0.1 - - [24/Sep/2024 14:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:25,864 Request with ID 947e2112 for model gemma-7b received
2024-09-24 14:31:25,864 127.0.0.1 - - [24/Sep/2024 14:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:25,910 Request with ID 28101df9 for model gemma-7b received
2024-09-24 14:31:25,911 127.0.0.1 - - [24/Sep/2024 14:31:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:26,067 Request with ID db6db436 for model llama3-8b received
2024-09-24 14:31:26,068 127.0.0.1 - - [24/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:26,076 Request with ID b1f26aaf for model llama3-8b received
2024-09-24 14:31:26,077 127.0.0.1 - - [24/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:26,316 Request with ID fafda923 for model gemma-7b received
2024-09-24 14:31:26,317 127.0.0.1 - - [24/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:26,324 Request with ID 4140d61c for model llama3-8b received
2024-09-24 14:31:26,325 127.0.0.1 - - [24/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:26,439 Request with ID 4932c436 for model llama3-8b received
2024-09-24 14:31:26,439 127.0.0.1 - - [24/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:26,456 Request with ID ccbb5c24 for model llama3-8b received
2024-09-24 14:31:26,457 127.0.0.1 - - [24/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:26,619 Request with ID d00bc02d for model llama3-8b received
2024-09-24 14:31:26,620 127.0.0.1 - - [24/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:26,706 Request with ID 0111bae1 for model llama3-8b received
2024-09-24 14:31:26,707 127.0.0.1 - - [24/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:26,721 Request with ID 3508c233 for model gemma-7b received
2024-09-24 14:31:26,722 127.0.0.1 - - [24/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:27,006 Request with ID d6760180 for model llama3-8b received
2024-09-24 14:31:27,007 127.0.0.1 - - [24/Sep/2024 14:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:27,157 Request with ID 87c4e50e for model llama3-8b received
2024-09-24 14:31:27,157 127.0.0.1 - - [24/Sep/2024 14:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:27,190 Request with ID 4f4ae06f for model llama3-8b received
2024-09-24 14:31:27,190 127.0.0.1 - - [24/Sep/2024 14:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:27,341 Request with ID 1f83f94e for model llama3-8b received
2024-09-24 14:31:27,341 127.0.0.1 - - [24/Sep/2024 14:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:27,549 Request with ID 1bc41e90 for model llama3-8b received
2024-09-24 14:31:27,549 127.0.0.1 - - [24/Sep/2024 14:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:27,576 Request with ID 947d588f for model llama3-8b received
2024-09-24 14:31:27,576 127.0.0.1 - - [24/Sep/2024 14:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:27,785 Request with ID a18cf8e4 for model gemma-7b received
2024-09-24 14:31:27,785 127.0.0.1 - - [24/Sep/2024 14:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:27,800 Request with ID 65adc477 for model llama3-8b received
2024-09-24 14:31:27,800 127.0.0.1 - - [24/Sep/2024 14:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:27,801 Request with ID f4255303 for model llama3-8b received
2024-09-24 14:31:27,802 127.0.0.1 - - [24/Sep/2024 14:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:27,804 Request with ID 371365c2 for model llama3-8b received
2024-09-24 14:31:27,805 127.0.0.1 - - [24/Sep/2024 14:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:27,887 Request with ID 8997379f for model gemma-7b received
2024-09-24 14:31:27,887 127.0.0.1 - - [24/Sep/2024 14:31:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:28,246 Request with ID aa063081 for model llama3-8b received
2024-09-24 14:31:28,247 127.0.0.1 - - [24/Sep/2024 14:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:28,312 Request with ID 2c2e1a32 for model llama3-8b received
2024-09-24 14:31:28,312 127.0.0.1 - - [24/Sep/2024 14:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:28,724 Request with ID 503539b9 for model gemma-7b received
2024-09-24 14:31:28,725 127.0.0.1 - - [24/Sep/2024 14:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:28,729 Request with ID bc53403c for model llama3-8b received
2024-09-24 14:31:28,729 127.0.0.1 - - [24/Sep/2024 14:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:28,798 Request with ID e57a92b3 for model gemma-7b received
2024-09-24 14:31:28,798 127.0.0.1 - - [24/Sep/2024 14:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:29,098 Request with ID 0b2eff82 for model gemma-7b received
2024-09-24 14:31:29,098 127.0.0.1 - - [24/Sep/2024 14:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:29,184 Request with ID cf345615 for model llama3-8b received
2024-09-24 14:31:29,184 127.0.0.1 - - [24/Sep/2024 14:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:29,298 Request with ID 92ee2dd3 for model gemma-7b received
2024-09-24 14:31:29,298 127.0.0.1 - - [24/Sep/2024 14:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:29,333 Request with ID 1de5e007 for model gemma-7b received
2024-09-24 14:31:29,334 127.0.0.1 - - [24/Sep/2024 14:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:29,461 Request with ID c66dec68 for model gemma-7b received
2024-09-24 14:31:29,461 127.0.0.1 - - [24/Sep/2024 14:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:29,675 Request with ID 12dcdd67 for model gemma-7b received
2024-09-24 14:31:29,675 127.0.0.1 - - [24/Sep/2024 14:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:29,765 Request with ID ad0736d4 for model llama3-8b received
2024-09-24 14:31:29,765 127.0.0.1 - - [24/Sep/2024 14:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:29,908 Request with ID 4a6a2193 for model llama3-8b received
2024-09-24 14:31:29,908 127.0.0.1 - - [24/Sep/2024 14:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:29,941 Request with ID b43caa6b for model gemma-7b received
2024-09-24 14:31:29,942 127.0.0.1 - - [24/Sep/2024 14:31:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:30,092 Request with ID 13001f22 for model llama3-8b received
2024-09-24 14:31:30,092 127.0.0.1 - - [24/Sep/2024 14:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:30,321 Request with ID abbf8c3c for model gemma-7b received
2024-09-24 14:31:30,321 127.0.0.1 - - [24/Sep/2024 14:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:30,336 Request with ID f08b5684 for model llama3-8b received
2024-09-24 14:31:30,337 127.0.0.1 - - [24/Sep/2024 14:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:30,375 Request with ID 6c4fe897 for model gemma-7b received
2024-09-24 14:31:30,376 127.0.0.1 - - [24/Sep/2024 14:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:30,881 Request with ID 95d34105 for model gemma-7b received
2024-09-24 14:31:30,881 127.0.0.1 - - [24/Sep/2024 14:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:30,894 Request with ID 30420d72 for model llama3-8b received
2024-09-24 14:31:30,894 127.0.0.1 - - [24/Sep/2024 14:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:31,022 Request with ID 410c5acd for model gemma-7b received
2024-09-24 14:31:31,022 127.0.0.1 - - [24/Sep/2024 14:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:31,174 Request with ID b25daac5 for model llama3-8b received
2024-09-24 14:31:31,174 127.0.0.1 - - [24/Sep/2024 14:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:31,240 Request with ID f0b2bd14 for model llama3-8b received
2024-09-24 14:31:31,240 127.0.0.1 - - [24/Sep/2024 14:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:31,251 Request with ID 0e1a0ccc for model llama3-8b received
2024-09-24 14:31:31,251 127.0.0.1 - - [24/Sep/2024 14:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:31,371 Request with ID cbb3d776 for model llama3-8b received
2024-09-24 14:31:31,373 Request with ID 60fda2f3 for model gemma-7b received
2024-09-24 14:31:31,373 127.0.0.1 - - [24/Sep/2024 14:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:31,374 127.0.0.1 - - [24/Sep/2024 14:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:31,457 Request with ID 60eab38a for model gemma-7b received
2024-09-24 14:31:31,457 127.0.0.1 - - [24/Sep/2024 14:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:31,614 Request with ID cba81395 for model gemma-7b received
2024-09-24 14:31:31,614 127.0.0.1 - - [24/Sep/2024 14:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:31,787 Request with ID d18fefb3 for model llama3-8b received
2024-09-24 14:31:31,788 127.0.0.1 - - [24/Sep/2024 14:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:31,948 Request with ID a1557d42 for model llama3-8b received
2024-09-24 14:31:31,949 127.0.0.1 - - [24/Sep/2024 14:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:31,963 Request with ID 7e9ed753 for model gemma-7b received
2024-09-24 14:31:31,963 127.0.0.1 - - [24/Sep/2024 14:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:31,999 Request with ID 6b48d45d for model llama3-8b received
2024-09-24 14:31:31,999 127.0.0.1 - - [24/Sep/2024 14:31:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:32,085 Request with ID 46ce9086 for model llama3-8b received
2024-09-24 14:31:32,085 127.0.0.1 - - [24/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:32,285 Request with ID 411f34ad for model llama3-8b received
2024-09-24 14:31:32,285 127.0.0.1 - - [24/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:32,425 Request with ID 0701bee7 for model gemma-7b received
2024-09-24 14:31:32,425 127.0.0.1 - - [24/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:32,587 Request with ID e3d9b332 for model llama3-8b received
2024-09-24 14:31:32,588 127.0.0.1 - - [24/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:32,771 Request with ID 2735660c for model llama3-8b received
2024-09-24 14:31:32,772 127.0.0.1 - - [24/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:32,852 Request with ID 22219161 for model llama3-8b received
2024-09-24 14:31:32,853 127.0.0.1 - - [24/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:32,911 Request with ID 839dec6a for model llama3-8b received
2024-09-24 14:31:32,912 127.0.0.1 - - [24/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:32,963 Request with ID 32401f8a for model llama3-8b received
2024-09-24 14:31:32,963 127.0.0.1 - - [24/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:33,380 Request with ID 0707edea for model granite-7b received
2024-09-24 14:31:33,381 127.0.0.1 - - [24/Sep/2024 14:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:33,427 Request with ID fa8f6a0c for model gemma-7b received
2024-09-24 14:31:33,428 127.0.0.1 - - [24/Sep/2024 14:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:33,511 Request with ID 2e161841 for model llama3-8b received
2024-09-24 14:31:33,512 127.0.0.1 - - [24/Sep/2024 14:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:33,857 Request with ID a397670d for model llama3-8b received
2024-09-24 14:31:33,857 127.0.0.1 - - [24/Sep/2024 14:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:33,867 Request with ID 0dd7a996 for model llama3-8b received
2024-09-24 14:31:33,867 127.0.0.1 - - [24/Sep/2024 14:31:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:34,446 Request with ID 2a56046f for model gemma-7b received
2024-09-24 14:31:34,447 127.0.0.1 - - [24/Sep/2024 14:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:34,496 Request with ID d20e8475 for model gemma-7b received
2024-09-24 14:31:34,496 127.0.0.1 - - [24/Sep/2024 14:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:34,540 Request with ID 163e370a for model llama3-8b received
2024-09-24 14:31:34,541 127.0.0.1 - - [24/Sep/2024 14:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:34,795 Request with ID d2aec5dd for model granite-7b received
2024-09-24 14:31:34,796 127.0.0.1 - - [24/Sep/2024 14:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:34,797 Request with ID 72dd2318 for model llama3-8b received
2024-09-24 14:31:34,797 127.0.0.1 - - [24/Sep/2024 14:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:34,929 Request with ID c89efa72 for model granite-7b received
2024-09-24 14:31:34,929 Moving batch for granite-7b from incoming to running due to dynamic batch size 8
2024-09-24 14:31:34,929 Dynamic batch size condition met for model granite-7b
2024-09-24 14:31:34,929 Next: call load_model for granite-7b
2024-09-24 14:31:35,254 Request with ID f2dc89bf for model gemma-7b received
2024-09-24 14:31:35,255 127.0.0.1 - - [24/Sep/2024 14:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:35,257 Request with ID cba7111c for model granite-7b received
2024-09-24 14:31:35,257 127.0.0.1 - - [24/Sep/2024 14:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:35,425 Request with ID 8660a519 for model llama3-8b received
2024-09-24 14:31:35,427 127.0.0.1 - - [24/Sep/2024 14:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:35,578 Request with ID c01b6f9b for model gemma-7b received
2024-09-24 14:31:35,580 Request with ID cb71b54a for model granite-7b received
2024-09-24 14:31:35,580 127.0.0.1 - - [24/Sep/2024 14:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:35,581 127.0.0.1 - - [24/Sep/2024 14:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:35,697 Request with ID 7d2b492d for model llama3-8b received
2024-09-24 14:31:35,697 127.0.0.1 - - [24/Sep/2024 14:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:35,724 Request with ID d5710096 for model llama3-8b received
2024-09-24 14:31:35,724 127.0.0.1 - - [24/Sep/2024 14:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:35,743 Request with ID 030b55c1 for model llama3-8b received
2024-09-24 14:31:35,743 127.0.0.1 - - [24/Sep/2024 14:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:35,903 Request with ID a5f60eeb for model llama3-8b received
2024-09-24 14:31:35,903 127.0.0.1 - - [24/Sep/2024 14:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:35,944 Request with ID d5442770 for model granite-7b received
2024-09-24 14:31:35,945 127.0.0.1 - - [24/Sep/2024 14:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:35,948 Request with ID 23ae43b0 for model granite-7b received
2024-09-24 14:31:35,948 127.0.0.1 - - [24/Sep/2024 14:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:36,020 Request with ID 5b45099a for model llama3-8b received
2024-09-24 14:31:36,021 127.0.0.1 - - [24/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:36,047 Request with ID f0b61b6d for model llama3-8b received
2024-09-24 14:31:36,047 127.0.0.1 - - [24/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:36,081 Request with ID d3307e51 for model llama3-8b received
2024-09-24 14:31:36,082 127.0.0.1 - - [24/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:36,218 Request with ID 03d7da55 for model llama3-8b received
2024-09-24 14:31:36,219 Batch size condition met for model llama3-8b
2024-09-24 14:31:36,387 Request with ID 6bdaf47e for model llama3-8b received
2024-09-24 14:31:36,388 127.0.0.1 - - [24/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:36,555 Request with ID 69478e63 for model gemma-7b received
2024-09-24 14:31:36,557 127.0.0.1 - - [24/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:36,732 Request with ID 65c99017 for model granite-7b received
2024-09-24 14:31:36,733 127.0.0.1 - - [24/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:36,738 Request with ID 4c0bbf78 for model llama3-8b received
2024-09-24 14:31:36,739 127.0.0.1 - - [24/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:36,763 Request with ID 59cc3ad2 for model gemma-7b received
2024-09-24 14:31:36,763 127.0.0.1 - - [24/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:36,844 Request with ID c796144b for model gemma-7b received
2024-09-24 14:31:36,844 127.0.0.1 - - [24/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:36,964 Request with ID 79cd0a8d for model llama3-8b received
2024-09-24 14:31:36,965 127.0.0.1 - - [24/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:37,100 Request with ID fff16d0e for model llama3-8b received
2024-09-24 14:31:37,101 127.0.0.1 - - [24/Sep/2024 14:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:37,464 Request with ID e96941c0 for model llama3-8b received
2024-09-24 14:31:37,465 127.0.0.1 - - [24/Sep/2024 14:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:37,590 Request with ID fa243adb for model llama3-8b received
2024-09-24 14:31:37,591 127.0.0.1 - - [24/Sep/2024 14:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:37,653 Request with ID 6b9d1cac for model llama3-8b received
2024-09-24 14:31:37,653 127.0.0.1 - - [24/Sep/2024 14:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:37,754 Request with ID aea05533 for model llama3-8b received
2024-09-24 14:31:37,754 127.0.0.1 - - [24/Sep/2024 14:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:37,969 Request with ID ee445673 for model llama3-8b received
2024-09-24 14:31:37,970 127.0.0.1 - - [24/Sep/2024 14:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:37,997 Request with ID 2f10cddc for model gemma-7b received
2024-09-24 14:31:37,998 127.0.0.1 - - [24/Sep/2024 14:31:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:38,001 Request with ID 59fb6b55 for model llama3-8b received
2024-09-24 14:31:38,002 127.0.0.1 - - [24/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:38,010 Request with ID 2742218a for model gemma-7b received
2024-09-24 14:31:38,011 127.0.0.1 - - [24/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:38,201 Request with ID 8f1a0a9b for model gemma-7b received
2024-09-24 14:31:38,201 127.0.0.1 - - [24/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:38,242 Request with ID f931d995 for model llama3-8b received
2024-09-24 14:31:38,243 127.0.0.1 - - [24/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:38,368 Request with ID d03b49f6 for model granite-7b received
2024-09-24 14:31:38,369 127.0.0.1 - - [24/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:38,437 Request with ID ba319391 for model gemma-7b received
2024-09-24 14:31:38,437 127.0.0.1 - - [24/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:38,612 Request with ID c468979b for model llama3-8b received
2024-09-24 14:31:38,612 127.0.0.1 - - [24/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:38,671 Request with ID c608bd98 for model gemma-7b received
2024-09-24 14:31:38,672 127.0.0.1 - - [24/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:39,007 Request with ID 7c865bc4 for model gemma-7b received
2024-09-24 14:31:39,008 127.0.0.1 - - [24/Sep/2024 14:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:39,151 Request with ID 77b8042f for model gemma-7b received
2024-09-24 14:31:39,152 127.0.0.1 - - [24/Sep/2024 14:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:39,248 Request with ID 72d17b97 for model llama3-8b received
2024-09-24 14:31:39,249 127.0.0.1 - - [24/Sep/2024 14:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:39,297 Request with ID e0fa7706 for model granite-7b received
2024-09-24 14:31:39,298 127.0.0.1 - - [24/Sep/2024 14:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:39,305 Request with ID 0c73293f for model gemma-7b received
2024-09-24 14:31:39,305 127.0.0.1 - - [24/Sep/2024 14:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:39,701 Request with ID f25f30fd for model llama3-8b received
2024-09-24 14:31:39,701 127.0.0.1 - - [24/Sep/2024 14:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:39,713 Request with ID 43590a7c for model gemma-7b received
2024-09-24 14:31:39,713 127.0.0.1 - - [24/Sep/2024 14:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:39,865 Request with ID 41741b36 for model llama3-8b received
2024-09-24 14:31:39,866 127.0.0.1 - - [24/Sep/2024 14:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:39,868 Request with ID ee9c1ee4 for model llama3-8b received
2024-09-24 14:31:39,869 127.0.0.1 - - [24/Sep/2024 14:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:40,559 Request with ID 22113855 for model llama3-8b received
2024-09-24 14:31:40,559 127.0.0.1 - - [24/Sep/2024 14:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:40,833 Request with ID 47d32d79 for model llama3-8b received
2024-09-24 14:31:40,834 127.0.0.1 - - [24/Sep/2024 14:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:41,269 Request with ID 93a46af2 for model llama3-8b received
2024-09-24 14:31:41,269 127.0.0.1 - - [24/Sep/2024 14:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:41,282 Request with ID 9876206f for model llama3-8b received
2024-09-24 14:31:41,283 127.0.0.1 - - [24/Sep/2024 14:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:41,315 Request with ID af96f4c7 for model llama3-8b received
2024-09-24 14:31:41,316 127.0.0.1 - - [24/Sep/2024 14:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:41,535 Request with ID 9210c4a2 for model llama3-8b received
2024-09-24 14:31:41,536 Request with ID 271db351 for model llama3-8b received
2024-09-24 14:31:41,536 127.0.0.1 - - [24/Sep/2024 14:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:41,537 127.0.0.1 - - [24/Sep/2024 14:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:41,773 Request with ID dbbe2570 for model llama3-8b received
2024-09-24 14:31:41,774 127.0.0.1 - - [24/Sep/2024 14:31:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:42,309 Request with ID 12a15970 for model gemma-7b received
2024-09-24 14:31:42,309 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-24 14:31:42,309 Dynamic batch size condition met for model gemma-7b
2024-09-24 14:31:42,464 Request with ID cd1b5764 for model llama3-8b received
2024-09-24 14:31:42,465 127.0.0.1 - - [24/Sep/2024 14:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:42,568 Request with ID db3edd91 for model gemma-7b received
2024-09-24 14:31:42,569 127.0.0.1 - - [24/Sep/2024 14:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:42,619 Request with ID fbb62a38 for model granite-7b received
2024-09-24 14:31:42,620 127.0.0.1 - - [24/Sep/2024 14:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:42,700 Request with ID a633cca5 for model llama3-8b received
2024-09-24 14:31:42,701 127.0.0.1 - - [24/Sep/2024 14:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:42,884 Request with ID 21088791 for model llama3-8b received
2024-09-24 14:31:42,885 127.0.0.1 - - [24/Sep/2024 14:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:43,057 Request with ID 89b97c12 for model gemma-7b received
2024-09-24 14:31:43,058 127.0.0.1 - - [24/Sep/2024 14:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:43,123 Request with ID 8212e31c for model gemma-7b received
2024-09-24 14:31:43,123 127.0.0.1 - - [24/Sep/2024 14:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:43,379 Request with ID d247e71e for model llama3-8b received
2024-09-24 14:31:43,380 127.0.0.1 - - [24/Sep/2024 14:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:43,583 Request with ID 30e32001 for model llama3-8b received
2024-09-24 14:31:43,584 127.0.0.1 - - [24/Sep/2024 14:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:43,589 Request with ID 6d7ac4fc for model granite-7b received
2024-09-24 14:31:43,589 127.0.0.1 - - [24/Sep/2024 14:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:43,916 Request with ID 37bd4b3e for model gemma-7b received
2024-09-24 14:31:43,917 127.0.0.1 - - [24/Sep/2024 14:31:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:44,066 Request with ID 6916dda8 for model llama3-8b received
2024-09-24 14:31:44,067 127.0.0.1 - - [24/Sep/2024 14:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:44,216 Request with ID 80a02385 for model llama3-8b received
2024-09-24 14:31:44,217 127.0.0.1 - - [24/Sep/2024 14:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:44,278 Request with ID deea21b2 for model granite-7b received
2024-09-24 14:31:44,279 127.0.0.1 - - [24/Sep/2024 14:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:44,321 Request with ID 51e3aba0 for model gemma-7b received
2024-09-24 14:31:44,321 127.0.0.1 - - [24/Sep/2024 14:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:44,335 Request with ID 77b9844d for model gemma-7b received
2024-09-24 14:31:44,336 127.0.0.1 - - [24/Sep/2024 14:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:44,363 Request with ID dc0bf740 for model gemma-7b received
2024-09-24 14:31:44,363 127.0.0.1 - - [24/Sep/2024 14:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:44,397 Request with ID dc22021b for model granite-7b received
2024-09-24 14:31:44,397 127.0.0.1 - - [24/Sep/2024 14:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:44,857 Request with ID 27f27574 for model llama3-8b received
2024-09-24 14:31:44,858 127.0.0.1 - - [24/Sep/2024 14:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:44,955 Request with ID b1175fea for model llama3-8b received
2024-09-24 14:31:44,956 127.0.0.1 - - [24/Sep/2024 14:31:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:45,072 Request with ID ae46f3a3 for model gemma-7b received
2024-09-24 14:31:45,073 127.0.0.1 - - [24/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:45,082 Request with ID ea3b611b for model llama3-8b received
2024-09-24 14:31:45,082 127.0.0.1 - - [24/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:45,246 Request with ID 33eaf149 for model llama3-8b received
2024-09-24 14:31:45,246 127.0.0.1 - - [24/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:45,257 Request with ID 09cae368 for model llama3-8b received
2024-09-24 14:31:45,257 127.0.0.1 - - [24/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:45,264 Request with ID 019eef5f for model gemma-7b received
2024-09-24 14:31:45,265 127.0.0.1 - - [24/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:45,475 Request with ID 3c1d6d58 for model llama3-8b received
2024-09-24 14:31:45,476 127.0.0.1 - - [24/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:45,577 Request with ID 384aa4ff for model gemma-7b received
2024-09-24 14:31:45,577 127.0.0.1 - - [24/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:45,758 Request with ID 2187b238 for model llama3-8b received
2024-09-24 14:31:45,759 127.0.0.1 - - [24/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:45,840 Request with ID 9a1241f7 for model gemma-7b received
2024-09-24 14:31:45,840 127.0.0.1 - - [24/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:45,848 Request with ID 2c4b8ccb for model llama3-8b received
2024-09-24 14:31:45,848 127.0.0.1 - - [24/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:45,945 Request with ID d54d4892 for model llama3-8b received
2024-09-24 14:31:45,945 127.0.0.1 - - [24/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:46,048 Request with ID 3592d54f for model llama3-8b received
2024-09-24 14:31:46,048 127.0.0.1 - - [24/Sep/2024 14:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:46,084 Request with ID b23e2290 for model gemma-7b received
2024-09-24 14:31:46,084 127.0.0.1 - - [24/Sep/2024 14:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:46,126 Request with ID ef1e514e for model llama3-8b received
2024-09-24 14:31:46,126 127.0.0.1 - - [24/Sep/2024 14:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:46,306 Request with ID 06449ecc for model gemma-7b received
2024-09-24 14:31:46,306 127.0.0.1 - - [24/Sep/2024 14:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:46,322 Request with ID f76e8c3b for model llama3-8b received
2024-09-24 14:31:46,322 127.0.0.1 - - [24/Sep/2024 14:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:46,509 Request with ID 33ef92b8 for model llama3-8b received
2024-09-24 14:31:46,509 127.0.0.1 - - [24/Sep/2024 14:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:46,624 Loaded model granite-7b
2024-09-24 14:31:46,628 Batch processing started for model granite-7b
2024-09-24 14:31:46,942 Request with ID 44a6c7d7 for model llama3-8b received
2024-09-24 14:31:46,943 127.0.0.1 - - [24/Sep/2024 14:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:46,960 Request with ID 6ffac3ca for model llama3-8b received
2024-09-24 14:31:46,962 127.0.0.1 - - [24/Sep/2024 14:31:46] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:47,115 Request with ID 96aaa695 for model llama3-8b received
2024-09-24 14:31:47,116 127.0.0.1 - - [24/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:47,237 Request with ID 975b71f6 for model llama3-8b received
2024-09-24 14:31:47,237 127.0.0.1 - - [24/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:47,301 Request with ID b17c4542 for model llama3-8b received
2024-09-24 14:31:47,302 127.0.0.1 - - [24/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:47,402 Request with ID e4df6140 for model gemma-7b received
2024-09-24 14:31:47,403 127.0.0.1 - - [24/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:47,526 Request with ID 398c2f95 for model llama3-8b received
2024-09-24 14:31:47,527 127.0.0.1 - - [24/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:47,546 Request with ID 9b0e93ad for model llama3-8b received
2024-09-24 14:31:47,547 127.0.0.1 - - [24/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:47,556 Request with ID 538ca071 for model llama3-8b received
2024-09-24 14:31:47,556 127.0.0.1 - - [24/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:47,643 Request with ID 55d62f40 for model gemma-7b received
2024-09-24 14:31:47,643 127.0.0.1 - - [24/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:47,753 Request with ID 754d476c for model llama3-8b received
2024-09-24 14:31:47,754 127.0.0.1 - - [24/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:47,831 Request with ID 41d6c061 for model llama3-8b received
2024-09-24 14:31:47,832 127.0.0.1 - - [24/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:47,983 Request with ID 4e61abae for model gemma-7b received
2024-09-24 14:31:47,983 127.0.0.1 - - [24/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,036 Request with ID 3669f9b9 for model llama3-8b received
2024-09-24 14:31:48,037 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,177 Request with ID c14ac518 for model llama3-8b received
2024-09-24 14:31:48,177 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,209 Request with ID a484c28b for model gemma-7b received
2024-09-24 14:31:48,209 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,264 Request with ID a695e132 for model llama3-8b received
2024-09-24 14:31:48,265 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,361 Request with ID d2648dbb for model gemma-7b received
2024-09-24 14:31:48,362 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,419 Request with ID 3041cb9c for model gemma-7b received
2024-09-24 14:31:48,419 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,468 Request with ID 67a29917 for model llama3-8b received
2024-09-24 14:31:48,469 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,479 Request with ID 6c743a7b for model llama3-8b received
2024-09-24 14:31:48,480 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,489 Request with ID 4ed4ee9c for model llama3-8b received
2024-09-24 14:31:48,490 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,501 Request with ID c1bc6267 for model gemma-7b received
2024-09-24 14:31:48,501 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,531 Request with ID fac439a4 for model llama3-8b received
2024-09-24 14:31:48,532 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,567 Request with ID c9455e34 for model gemma-7b received
2024-09-24 14:31:48,567 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,647 Request with ID 556bfea4 for model granite-7b received
2024-09-24 14:31:48,647 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,667 Request with ID bd91e20f for model llama3-8b received
2024-09-24 14:31:48,668 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:48,952 Request with ID cc53b807 for model granite-7b received
2024-09-24 14:31:48,953 127.0.0.1 - - [24/Sep/2024 14:31:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:49,207 Request with ID ec430693 for model gemma-7b received
2024-09-24 14:31:49,207 127.0.0.1 - - [24/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:49,215 Processed batch: ['9721f51d', '357435ec', '960374ec', '65223b5e', '1f2ff158', '0707edea', 'd2aec5dd', 'c89efa72'] with model granite-7b in 2.5864 seconds
2024-09-24 14:31:49,215 Saving sys info
2024-09-24 14:31:49,248 Request with ID f27db080 for model gemma-7b received
2024-09-24 14:31:49,249 127.0.0.1 - - [24/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:49,259 Latency for request 9721f51d with model granite-7b: 26.2830 seconds
2024-09-24 14:31:49,259 Saving results with gpu monitoring
2024-09-24 14:31:49,265 Latency for request 357435ec with model granite-7b: 25.7960 seconds
2024-09-24 14:31:49,265 Saving results with gpu monitoring
2024-09-24 14:31:49,267 Latency for request 960374ec with model granite-7b: 25.2460 seconds
2024-09-24 14:31:49,267 Saving results with gpu monitoring
2024-09-24 14:31:49,269 Latency for request 65223b5e with model granite-7b: 24.7700 seconds
2024-09-24 14:31:49,269 Saving results with gpu monitoring
2024-09-24 14:31:49,271 Latency for request 1f2ff158 with model granite-7b: 23.5660 seconds
2024-09-24 14:31:49,271 Saving results with gpu monitoring
2024-09-24 14:31:49,273 Latency for request 0707edea with model granite-7b: 15.8350 seconds
2024-09-24 14:31:49,273 Saving results with gpu monitoring
2024-09-24 14:31:49,275 Latency for request d2aec5dd with model granite-7b: 14.4200 seconds
2024-09-24 14:31:49,275 Saving results with gpu monitoring
2024-09-24 14:31:49,277 Latency for request c89efa72 with model granite-7b: 14.2860 seconds
2024-09-24 14:31:49,277 Saving results with gpu monitoring
2024-09-24 14:31:49,279 127.0.0.1 - - [24/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:49,279 Next: call load_model for llama3-8b
2024-09-24 14:31:49,359 Unloaded previous model
2024-09-24 14:31:49,361 Request with ID 17037915 for model gemma-7b received
2024-09-24 14:31:49,363 127.0.0.1 - - [24/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:49,563 Request with ID 6f766c22 for model llama3-8b received
2024-09-24 14:31:49,565 127.0.0.1 - - [24/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:49,566 Request with ID 92b1eb37 for model gemma-7b received
2024-09-24 14:31:49,567 127.0.0.1 - - [24/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:49,660 Request with ID 598e39f7 for model granite-7b received
2024-09-24 14:31:49,661 127.0.0.1 - - [24/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:49,776 Request with ID f856e762 for model llama3-8b received
2024-09-24 14:31:49,782 Batch size condition met for model llama3-8b
2024-09-24 14:31:49,942 Request with ID d0e52a9b for model llama3-8b received
2024-09-24 14:31:49,946 127.0.0.1 - - [24/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:49,998 Request with ID 0f27b020 for model llama3-8b received
2024-09-24 14:31:50,002 127.0.0.1 - - [24/Sep/2024 14:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:50,036 Request with ID 620be039 for model granite-7b received
2024-09-24 14:31:50,038 127.0.0.1 - - [24/Sep/2024 14:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:50,162 Request with ID 3a56b7e1 for model gemma-7b received
2024-09-24 14:31:50,166 127.0.0.1 - - [24/Sep/2024 14:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:50,191 Request with ID 27a22259 for model granite-7b received
2024-09-24 14:31:50,194 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-24 14:31:50,194 Dynamic batch size condition met for model granite-7b
2024-09-24 14:31:50,360 Request with ID 3b87af3e for model granite-7b received
2024-09-24 14:31:50,363 127.0.0.1 - - [24/Sep/2024 14:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:50,569 Request with ID 4b485504 for model gemma-7b received
2024-09-24 14:31:50,571 127.0.0.1 - - [24/Sep/2024 14:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:50,578 Request with ID 719d4ea5 for model llama3-8b received
2024-09-24 14:31:50,582 127.0.0.1 - - [24/Sep/2024 14:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:50,591 Request with ID 6b47c122 for model gemma-7b received
2024-09-24 14:31:50,594 127.0.0.1 - - [24/Sep/2024 14:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:50,607 Request with ID 2b974200 for model llama3-8b received
2024-09-24 14:31:50,608 127.0.0.1 - - [24/Sep/2024 14:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:50,798 Request with ID 564a9cc4 for model llama3-8b received
2024-09-24 14:31:50,799 127.0.0.1 - - [24/Sep/2024 14:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:50,954 Request with ID 5e378353 for model gemma-7b received
2024-09-24 14:31:50,955 127.0.0.1 - - [24/Sep/2024 14:31:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:51,005 Request with ID e8527a73 for model gemma-7b received
2024-09-24 14:31:51,005 127.0.0.1 - - [24/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:51,173 Request with ID 9744f723 for model llama3-8b received
2024-09-24 14:31:51,174 127.0.0.1 - - [24/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:51,358 Request with ID 6eb9cb49 for model llama3-8b received
2024-09-24 14:31:51,358 127.0.0.1 - - [24/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:51,378 Request with ID cdc1e89f for model llama3-8b received
2024-09-24 14:31:51,379 127.0.0.1 - - [24/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:51,438 Request with ID ae7e7ea9 for model gemma-7b received
2024-09-24 14:31:51,439 127.0.0.1 - - [24/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:51,447 Request with ID f359541f for model llama3-8b received
2024-09-24 14:31:51,448 127.0.0.1 - - [24/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:51,459 Request with ID 7c0c3393 for model llama3-8b received
2024-09-24 14:31:51,459 127.0.0.1 - - [24/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:51,640 Request with ID 173e918b for model llama3-8b received
2024-09-24 14:31:51,641 127.0.0.1 - - [24/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:51,759 Request with ID aec19ab2 for model llama3-8b received
2024-09-24 14:31:51,759 127.0.0.1 - - [24/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:51,982 Request with ID 82372896 for model llama3-8b received
2024-09-24 14:31:51,982 127.0.0.1 - - [24/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:52,321 Request with ID 3b4d1692 for model gemma-7b received
2024-09-24 14:31:52,322 127.0.0.1 - - [24/Sep/2024 14:31:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:52,382 Request with ID 219da765 for model llama3-8b received
2024-09-24 14:31:52,382 127.0.0.1 - - [24/Sep/2024 14:31:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:52,388 Request with ID 195c1fcd for model gemma-7b received
2024-09-24 14:31:52,389 127.0.0.1 - - [24/Sep/2024 14:31:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:52,589 Request with ID 5c674f1e for model gemma-7b received
2024-09-24 14:31:52,590 127.0.0.1 - - [24/Sep/2024 14:31:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:52,613 Request with ID 7328d4f0 for model gemma-7b received
2024-09-24 14:31:52,613 127.0.0.1 - - [24/Sep/2024 14:31:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:52,741 Request with ID e189f345 for model gemma-7b received
2024-09-24 14:31:52,741 127.0.0.1 - - [24/Sep/2024 14:31:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:52,854 Request with ID 69d007a3 for model llama3-8b received
2024-09-24 14:31:52,854 127.0.0.1 - - [24/Sep/2024 14:31:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:52,913 Request with ID d88fed4a for model llama3-8b received
2024-09-24 14:31:52,914 127.0.0.1 - - [24/Sep/2024 14:31:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:53,002 Request with ID ec532a3a for model gemma-7b received
2024-09-24 14:31:53,003 127.0.0.1 - - [24/Sep/2024 14:31:53] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:53,098 Request with ID b8b84400 for model llama3-8b received
2024-09-24 14:31:53,099 127.0.0.1 - - [24/Sep/2024 14:31:53] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:53,225 Request with ID 84c1702a for model llama3-8b received
2024-09-24 14:31:53,226 127.0.0.1 - - [24/Sep/2024 14:31:53] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:53,276 Request with ID a759472f for model gemma-7b received
2024-09-24 14:31:53,278 127.0.0.1 - - [24/Sep/2024 14:31:53] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:53,296 Request with ID 55029a39 for model llama3-8b received
2024-09-24 14:31:53,296 127.0.0.1 - - [24/Sep/2024 14:31:53] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:53,412 Request with ID d5091450 for model llama3-8b received
2024-09-24 14:31:53,412 127.0.0.1 - - [24/Sep/2024 14:31:53] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:54,155 Request with ID 87f37ce6 for model llama3-8b received
2024-09-24 14:31:54,155 127.0.0.1 - - [24/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:54,345 Request with ID 8fdf5775 for model gemma-7b received
2024-09-24 14:31:54,346 127.0.0.1 - - [24/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:54,503 Request with ID 71fc1b80 for model llama3-8b received
2024-09-24 14:31:54,504 127.0.0.1 - - [24/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:54,557 Request with ID 15b6b5db for model gemma-7b received
2024-09-24 14:31:54,557 127.0.0.1 - - [24/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:54,793 Request with ID 1e110dad for model llama3-8b received
2024-09-24 14:31:54,794 127.0.0.1 - - [24/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:54,814 Request with ID 4ca4c6ee for model llama3-8b received
2024-09-24 14:31:54,815 127.0.0.1 - - [24/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:55,001 Request with ID 4c1d3fbe for model llama3-8b received
2024-09-24 14:31:55,002 127.0.0.1 - - [24/Sep/2024 14:31:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:55,107 Request with ID 8b0384b9 for model gemma-7b received
2024-09-24 14:31:55,108 127.0.0.1 - - [24/Sep/2024 14:31:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:55,162 Request with ID 19432e99 for model llama3-8b received
2024-09-24 14:31:55,163 127.0.0.1 - - [24/Sep/2024 14:31:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:55,216 Request with ID 67429e55 for model llama3-8b received
2024-09-24 14:31:55,216 127.0.0.1 - - [24/Sep/2024 14:31:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:55,259 Request with ID 8c61f5e9 for model gemma-7b received
2024-09-24 14:31:55,260 127.0.0.1 - - [24/Sep/2024 14:31:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:55,372 Request with ID ae8c9649 for model gemma-7b received
2024-09-24 14:31:55,373 127.0.0.1 - - [24/Sep/2024 14:31:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:55,535 Request with ID 5d254420 for model llama3-8b received
2024-09-24 14:31:55,536 127.0.0.1 - - [24/Sep/2024 14:31:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:55,763 Request with ID 86a16055 for model llama3-8b received
2024-09-24 14:31:55,763 127.0.0.1 - - [24/Sep/2024 14:31:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:55,918 Request with ID 69e83cbe for model llama3-8b received
2024-09-24 14:31:55,919 127.0.0.1 - - [24/Sep/2024 14:31:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:56,087 Request with ID 85ec1eb5 for model gemma-7b received
2024-09-24 14:31:56,087 127.0.0.1 - - [24/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:56,121 Request with ID 24ec688c for model gemma-7b received
2024-09-24 14:31:56,121 127.0.0.1 - - [24/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:56,351 Request with ID 1c4c6f0e for model gemma-7b received
2024-09-24 14:31:56,351 127.0.0.1 - - [24/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:56,384 Request with ID 72e5af68 for model gemma-7b received
2024-09-24 14:31:56,385 127.0.0.1 - - [24/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:56,392 Request with ID ed29d375 for model llama3-8b received
2024-09-24 14:31:56,392 127.0.0.1 - - [24/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:56,394 Request with ID b8ff57f8 for model gemma-7b received
2024-09-24 14:31:56,394 127.0.0.1 - - [24/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:56,463 Request with ID fcd353cb for model llama3-8b received
2024-09-24 14:31:56,463 127.0.0.1 - - [24/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:56,517 Request with ID 31dc309f for model llama3-8b received
2024-09-24 14:31:56,517 127.0.0.1 - - [24/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:56,595 Request with ID 5df518fb for model granite-7b received
2024-09-24 14:31:56,595 127.0.0.1 - - [24/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:56,901 Request with ID b12f63e1 for model gemma-7b received
2024-09-24 14:31:56,902 127.0.0.1 - - [24/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:56,989 Request with ID 4cff8033 for model granite-7b received
2024-09-24 14:31:56,990 127.0.0.1 - - [24/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:57,037 Request with ID a542a35c for model llama3-8b received
2024-09-24 14:31:57,037 127.0.0.1 - - [24/Sep/2024 14:31:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:57,164 Request with ID a37ab0bd for model llama3-8b received
2024-09-24 14:31:57,164 127.0.0.1 - - [24/Sep/2024 14:31:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:57,629 Request with ID f3e6277e for model llama3-8b received
2024-09-24 14:31:57,630 127.0.0.1 - - [24/Sep/2024 14:31:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:57,878 Request with ID a0aef6fa for model llama3-8b received
2024-09-24 14:31:57,878 127.0.0.1 - - [24/Sep/2024 14:31:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:57,967 Request with ID 521f6491 for model gemma-7b received
2024-09-24 14:31:57,968 127.0.0.1 - - [24/Sep/2024 14:31:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:58,032 Request with ID b3371286 for model llama3-8b received
2024-09-24 14:31:58,033 127.0.0.1 - - [24/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:58,062 Request with ID 9e15bae6 for model gemma-7b received
2024-09-24 14:31:58,062 127.0.0.1 - - [24/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:58,290 Request with ID 11eaa55e for model gemma-7b received
2024-09-24 14:31:58,291 127.0.0.1 - - [24/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:58,448 Request with ID 05ff5d06 for model llama3-8b received
2024-09-24 14:31:58,448 127.0.0.1 - - [24/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:58,531 Request with ID 5715893f for model llama3-8b received
2024-09-24 14:31:58,532 127.0.0.1 - - [24/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:58,545 Request with ID 6315e2b9 for model llama3-8b received
2024-09-24 14:31:58,546 127.0.0.1 - - [24/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:58,607 Request with ID c088ca06 for model llama3-8b received
2024-09-24 14:31:58,607 127.0.0.1 - - [24/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:58,702 Request with ID 480f812b for model llama3-8b received
2024-09-24 14:31:58,702 127.0.0.1 - - [24/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:58,932 Request with ID 70dd4581 for model llama3-8b received
2024-09-24 14:31:58,933 127.0.0.1 - - [24/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:58,969 Request with ID 3d0d80b5 for model llama3-8b received
2024-09-24 14:31:58,970 127.0.0.1 - - [24/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:58,973 Request with ID c481f2e9 for model granite-7b received
2024-09-24 14:31:58,974 127.0.0.1 - - [24/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:59,009 Request with ID cbb01d1b for model llama3-8b received
2024-09-24 14:31:59,010 127.0.0.1 - - [24/Sep/2024 14:31:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:59,233 Request with ID f0d0f92e for model llama3-8b received
2024-09-24 14:31:59,234 127.0.0.1 - - [24/Sep/2024 14:31:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:59,252 Request with ID 8b1c8bda for model gemma-7b received
2024-09-24 14:31:59,252 127.0.0.1 - - [24/Sep/2024 14:31:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:59,538 Request with ID f16e5991 for model llama3-8b received
2024-09-24 14:31:59,538 127.0.0.1 - - [24/Sep/2024 14:31:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:59,706 Request with ID 5c4eec52 for model gemma-7b received
2024-09-24 14:31:59,706 127.0.0.1 - - [24/Sep/2024 14:31:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:31:59,969 Request with ID cd86a542 for model llama3-8b received
2024-09-24 14:31:59,970 127.0.0.1 - - [24/Sep/2024 14:31:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:00,250 Request with ID b24807f2 for model gemma-7b received
2024-09-24 14:32:00,251 127.0.0.1 - - [24/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:00,470 Request with ID a50d0146 for model llama3-8b received
2024-09-24 14:32:00,470 127.0.0.1 - - [24/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:00,511 Request with ID d808790d for model llama3-8b received
2024-09-24 14:32:00,512 127.0.0.1 - - [24/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:00,613 Request with ID 435d18ec for model gemma-7b received
2024-09-24 14:32:00,614 127.0.0.1 - - [24/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:00,986 Request with ID 64d843eb for model gemma-7b received
2024-09-24 14:32:00,986 127.0.0.1 - - [24/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:01,241 Request with ID 1d092d0a for model llama3-8b received
2024-09-24 14:32:01,242 127.0.0.1 - - [24/Sep/2024 14:32:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:01,444 Request with ID a433e271 for model llama3-8b received
2024-09-24 14:32:01,444 127.0.0.1 - - [24/Sep/2024 14:32:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:01,571 Request with ID cb86b485 for model llama3-8b received
2024-09-24 14:32:01,571 127.0.0.1 - - [24/Sep/2024 14:32:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:01,641 Request with ID 8dd38fe5 for model llama3-8b received
2024-09-24 14:32:01,641 127.0.0.1 - - [24/Sep/2024 14:32:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:01,791 Request with ID a42ec9a7 for model granite-7b received
2024-09-24 14:32:01,792 127.0.0.1 - - [24/Sep/2024 14:32:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:02,102 Request with ID e3d63bd6 for model llama3-8b received
2024-09-24 14:32:02,102 127.0.0.1 - - [24/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:02,142 Request with ID 18d355f2 for model llama3-8b received
2024-09-24 14:32:02,142 127.0.0.1 - - [24/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:02,365 Request with ID 0c9f8368 for model gemma-7b received
2024-09-24 14:32:02,365 127.0.0.1 - - [24/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:02,384 Request with ID bfdee1d8 for model llama3-8b received
2024-09-24 14:32:02,385 127.0.0.1 - - [24/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:02,645 Request with ID 83bdf9b6 for model gemma-7b received
2024-09-24 14:32:02,646 127.0.0.1 - - [24/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:02,773 Request with ID 615880f9 for model llama3-8b received
2024-09-24 14:32:02,773 127.0.0.1 - - [24/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:03,002 Request with ID 67a22547 for model llama3-8b received
2024-09-24 14:32:03,003 127.0.0.1 - - [24/Sep/2024 14:32:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:03,009 Request with ID 3b5d24b4 for model llama3-8b received
2024-09-24 14:32:03,009 127.0.0.1 - - [24/Sep/2024 14:32:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:03,020 Request with ID d18fa51b for model gemma-7b received
2024-09-24 14:32:03,020 127.0.0.1 - - [24/Sep/2024 14:32:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:03,085 Request with ID 2d89670c for model llama3-8b received
2024-09-24 14:32:03,085 127.0.0.1 - - [24/Sep/2024 14:32:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:03,396 Request with ID c1c27ef8 for model gemma-7b received
2024-09-24 14:32:03,397 127.0.0.1 - - [24/Sep/2024 14:32:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:03,502 Request with ID 22e33733 for model gemma-7b received
2024-09-24 14:32:03,502 127.0.0.1 - - [24/Sep/2024 14:32:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:03,889 Request with ID b4cc74cf for model llama3-8b received
2024-09-24 14:32:03,889 127.0.0.1 - - [24/Sep/2024 14:32:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:03,920 Request with ID f887f26a for model gemma-7b received
2024-09-24 14:32:03,920 127.0.0.1 - - [24/Sep/2024 14:32:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:04,035 Request with ID 1e2b0ac1 for model gemma-7b received
2024-09-24 14:32:04,036 Batch size condition met for model gemma-7b
2024-09-24 14:32:04,159 Request with ID cd5a2f36 for model gemma-7b received
2024-09-24 14:32:04,160 127.0.0.1 - - [24/Sep/2024 14:32:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:04,215 Request with ID a139ac74 for model llama3-8b received
2024-09-24 14:32:04,216 Batch size condition met for model llama3-8b
2024-09-24 14:32:04,363 Request with ID 1e5a77d0 for model llama3-8b received
2024-09-24 14:32:04,364 127.0.0.1 - - [24/Sep/2024 14:32:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:04,373 Request with ID 8f0ade4f for model granite-7b received
2024-09-24 14:32:04,374 127.0.0.1 - - [24/Sep/2024 14:32:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:04,805 Request with ID 5ce04a98 for model llama3-8b received
2024-09-24 14:32:04,805 127.0.0.1 - - [24/Sep/2024 14:32:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:04,863 Request with ID e0012325 for model llama3-8b received
2024-09-24 14:32:04,863 127.0.0.1 - - [24/Sep/2024 14:32:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:04,939 Request with ID a141fbf0 for model llama3-8b received
2024-09-24 14:32:04,940 127.0.0.1 - - [24/Sep/2024 14:32:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:05,199 Request with ID b421485f for model llama3-8b received
2024-09-24 14:32:05,200 127.0.0.1 - - [24/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:05,380 Request with ID 72d0961c for model llama3-8b received
2024-09-24 14:32:05,380 127.0.0.1 - - [24/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:05,619 Request with ID b4949379 for model llama3-8b received
2024-09-24 14:32:05,620 127.0.0.1 - - [24/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:05,769 Request with ID ff86099b for model llama3-8b received
2024-09-24 14:32:05,769 127.0.0.1 - - [24/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:05,774 Request with ID d2feeb2a for model llama3-8b received
2024-09-24 14:32:05,774 127.0.0.1 - - [24/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:06,695 Request with ID 4ae18fa9 for model llama3-8b received
2024-09-24 14:32:06,695 127.0.0.1 - - [24/Sep/2024 14:32:06] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:07,006 Request with ID 29e5b692 for model llama3-8b received
2024-09-24 14:32:07,006 127.0.0.1 - - [24/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:07,051 Request with ID 71c12a67 for model llama3-8b received
2024-09-24 14:32:07,052 127.0.0.1 - - [24/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:07,251 Request with ID 19d71b6c for model granite-7b received
2024-09-24 14:32:07,252 127.0.0.1 - - [24/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:07,329 Request with ID 050782ec for model llama3-8b received
2024-09-24 14:32:07,329 127.0.0.1 - - [24/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:07,334 Request with ID d362dd6b for model gemma-7b received
2024-09-24 14:32:07,335 127.0.0.1 - - [24/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:07,465 Loaded model llama3-8b
2024-09-24 14:32:07,472 Request with ID 7c69419b for model llama3-8b received
2024-09-24 14:32:07,473 127.0.0.1 - - [24/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:07,475 Batch processing started for model llama3-8b
2024-09-24 14:32:07,536 Request with ID f3cdcca1 for model llama3-8b received
2024-09-24 14:32:07,536 127.0.0.1 - - [24/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:07,645 Request with ID 61ddb1be for model llama3-8b received
2024-09-24 14:32:07,646 127.0.0.1 - - [24/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:07,814 Request with ID 9dced723 for model llama3-8b received
2024-09-24 14:32:07,815 127.0.0.1 - - [24/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:08,078 Request with ID b6aa7a65 for model llama3-8b received
2024-09-24 14:32:08,078 127.0.0.1 - - [24/Sep/2024 14:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:08,661 Request with ID ce024f62 for model llama3-8b received
2024-09-24 14:32:08,661 127.0.0.1 - - [24/Sep/2024 14:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:08,757 Request with ID 16ad66fd for model llama3-8b received
2024-09-24 14:32:08,757 127.0.0.1 - - [24/Sep/2024 14:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:09,532 Request with ID b47b9c8f for model llama3-8b received
2024-09-24 14:32:09,532 127.0.0.1 - - [24/Sep/2024 14:32:09] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:09,598 Request with ID 01f41237 for model llama3-8b received
2024-09-24 14:32:09,598 127.0.0.1 - - [24/Sep/2024 14:32:09] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:09,708 Request with ID 18259ba9 for model llama3-8b received
2024-09-24 14:32:09,709 127.0.0.1 - - [24/Sep/2024 14:32:09] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:09,892 Request with ID 64bfffa1 for model gemma-7b received
2024-09-24 14:32:09,893 127.0.0.1 - - [24/Sep/2024 14:32:09] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:09,987 Request with ID 92f0ae5b for model llama3-8b received
2024-09-24 14:32:09,987 127.0.0.1 - - [24/Sep/2024 14:32:09] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:10,031 Request with ID bb186627 for model gemma-7b received
2024-09-24 14:32:10,032 127.0.0.1 - - [24/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:10,066 Request with ID 251a388c for model granite-7b received
2024-09-24 14:32:10,066 127.0.0.1 - - [24/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:10,618 Request with ID 3879f33e for model gemma-7b received
2024-09-24 14:32:10,619 127.0.0.1 - - [24/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:10,763 Request with ID 1b3b20c4 for model llama3-8b received
2024-09-24 14:32:10,763 127.0.0.1 - - [24/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:10,801 Request with ID 64d564e4 for model llama3-8b received
2024-09-24 14:32:10,802 127.0.0.1 - - [24/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:11,075 Request with ID 3e546249 for model llama3-8b received
2024-09-24 14:32:11,075 127.0.0.1 - - [24/Sep/2024 14:32:11] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:11,643 Request with ID b7e35b59 for model gemma-7b received
2024-09-24 14:32:11,643 127.0.0.1 - - [24/Sep/2024 14:32:11] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:12,002 Request with ID bdf3f8da for model llama3-8b received
2024-09-24 14:32:12,003 127.0.0.1 - - [24/Sep/2024 14:32:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:12,093 Request with ID b6ab7195 for model gemma-7b received
2024-09-24 14:32:12,094 127.0.0.1 - - [24/Sep/2024 14:32:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:12,098 Request with ID ac3fe013 for model gemma-7b received
2024-09-24 14:32:12,098 127.0.0.1 - - [24/Sep/2024 14:32:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:12,108 Request with ID 1e193ae2 for model llama3-8b received
2024-09-24 14:32:12,108 127.0.0.1 - - [24/Sep/2024 14:32:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:12,438 Request with ID c202d56a for model llama3-8b received
2024-09-24 14:32:12,439 127.0.0.1 - - [24/Sep/2024 14:32:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:12,477 Request with ID 069b8a1a for model llama3-8b received
2024-09-24 14:32:12,477 127.0.0.1 - - [24/Sep/2024 14:32:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:12,500 Request with ID b130eced for model llama3-8b received
2024-09-24 14:32:12,501 127.0.0.1 - - [24/Sep/2024 14:32:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:12,626 Request with ID f9cca238 for model llama3-8b received
2024-09-24 14:32:12,626 127.0.0.1 - - [24/Sep/2024 14:32:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:12,740 Request with ID 8f9058b2 for model llama3-8b received
2024-09-24 14:32:12,740 127.0.0.1 - - [24/Sep/2024 14:32:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:12,818 Request with ID f186d514 for model gemma-7b received
2024-09-24 14:32:12,819 127.0.0.1 - - [24/Sep/2024 14:32:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:12,836 Request with ID 950a97b6 for model llama3-8b received
2024-09-24 14:32:12,837 127.0.0.1 - - [24/Sep/2024 14:32:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:13,087 Request with ID fe62cfd4 for model gemma-7b received
2024-09-24 14:32:13,087 127.0.0.1 - - [24/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:13,424 Request with ID 91ed232f for model granite-7b received
2024-09-24 14:32:13,424 Moving batch for granite-7b from incoming to running due to dynamic batch size 8
2024-09-24 14:32:13,425 Dynamic batch size condition met for model granite-7b
2024-09-24 14:32:13,491 Request with ID 0ab88c49 for model granite-7b received
2024-09-24 14:32:13,492 127.0.0.1 - - [24/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:13,642 Request with ID cd9fae9b for model llama3-8b received
2024-09-24 14:32:13,642 127.0.0.1 - - [24/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:13,652 Request with ID fe63dd22 for model llama3-8b received
2024-09-24 14:32:13,652 127.0.0.1 - - [24/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:13,664 Request with ID af0bc20c for model granite-7b received
2024-09-24 14:32:13,664 127.0.0.1 - - [24/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:13,934 Request with ID f3f7ef31 for model llama3-8b received
2024-09-24 14:32:13,935 127.0.0.1 - - [24/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:14,154 Request with ID c2aa11eb for model llama3-8b received
2024-09-24 14:32:14,154 127.0.0.1 - - [24/Sep/2024 14:32:14] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:14,253 Request with ID b2462647 for model gemma-7b received
2024-09-24 14:32:14,253 127.0.0.1 - - [24/Sep/2024 14:32:14] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:14,518 Request with ID 420a973e for model llama3-8b received
2024-09-24 14:32:14,519 127.0.0.1 - - [24/Sep/2024 14:32:14] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:14,773 Request with ID ca8ba8e5 for model gemma-7b received
2024-09-24 14:32:14,774 127.0.0.1 - - [24/Sep/2024 14:32:14] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:14,808 Request with ID 9374117b for model llama3-8b received
2024-09-24 14:32:14,808 127.0.0.1 - - [24/Sep/2024 14:32:14] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:14,930 Request with ID f0308a41 for model gemma-7b received
2024-09-24 14:32:14,931 127.0.0.1 - - [24/Sep/2024 14:32:14] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:15,198 Request with ID 00aaf0f5 for model llama3-8b received
2024-09-24 14:32:15,198 127.0.0.1 - - [24/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:15,463 Request with ID 0f2bf110 for model gemma-7b received
2024-09-24 14:32:15,464 127.0.0.1 - - [24/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:15,515 Request with ID 8a9b8d96 for model gemma-7b received
2024-09-24 14:32:15,516 127.0.0.1 - - [24/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:15,731 Request with ID a5f4a04e for model llama3-8b received
2024-09-24 14:32:15,733 Request with ID 58db77df for model granite-7b received
2024-09-24 14:32:15,733 127.0.0.1 - - [24/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:15,734 127.0.0.1 - - [24/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:15,783 Request with ID 7a711184 for model llama3-8b received
2024-09-24 14:32:15,783 127.0.0.1 - - [24/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:15,822 Request with ID 5b1bcd28 for model granite-7b received
2024-09-24 14:32:15,823 127.0.0.1 - - [24/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:16,038 Request with ID 043f1346 for model gemma-7b received
2024-09-24 14:32:16,039 127.0.0.1 - - [24/Sep/2024 14:32:16] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:16,219 Request with ID d1474c4b for model llama3-8b received
2024-09-24 14:32:16,220 127.0.0.1 - - [24/Sep/2024 14:32:16] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:16,439 Processed batch: ['ad444181', '52a6e5d8', '7226f3a5', 'f7062efb', 'fc16a1cd', 'd631acdc', 'f18891d0', '20ef72bb', '59639c32', 'a55a785b', '7870e665', 'db6db436', 'b1f26aaf', '4140d61c', '4932c436', 'ccbb5c24', 'd00bc02d', '0111bae1', 'd6760180', '87c4e50e', '4f4ae06f', '1f83f94e', '1bc41e90', '947d588f', '65adc477', 'f4255303', '371365c2', 'aa063081', '2c2e1a32', 'bc53403c', 'cf345615', 'ad0736d4', '4a6a2193', '13001f22', 'f08b5684', '30420d72', 'b25daac5', 'f0b2bd14', '0e1a0ccc', 'cbb3d776', 'd18fefb3', 'a1557d42', '6b48d45d', '46ce9086', '411f34ad', 'e3d9b332', '2735660c', '22219161', '839dec6a', '32401f8a', '2e161841', 'a397670d', '0dd7a996', '163e370a', '72dd2318', '8660a519', '7d2b492d', 'd5710096', '030b55c1', 'a5f60eeb', '5b45099a', 'f0b61b6d', 'd3307e51', '03d7da55'] with model llama3-8b in 8.9632 seconds
2024-09-24 14:32:16,439 Saving sys info
2024-09-24 14:32:16,451 Request with ID 5b17d25a for model llama3-8b received
2024-09-24 14:32:16,451 127.0.0.1 - - [24/Sep/2024 14:32:16] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:16,473 Latency for request ad444181 with model llama3-8b: 53.6390 seconds
2024-09-24 14:32:16,473 Saving results with gpu monitoring
2024-09-24 14:32:16,477 Latency for request 52a6e5d8 with model llama3-8b: 53.6250 seconds
2024-09-24 14:32:16,477 Saving results with gpu monitoring
2024-09-24 14:32:16,479 Latency for request 7226f3a5 with model llama3-8b: 53.0680 seconds
2024-09-24 14:32:16,479 Saving results with gpu monitoring
2024-09-24 14:32:16,481 Latency for request f7062efb with model llama3-8b: 53.0170 seconds
2024-09-24 14:32:16,481 Saving results with gpu monitoring
2024-09-24 14:32:16,483 Latency for request fc16a1cd with model llama3-8b: 52.3510 seconds
2024-09-24 14:32:16,483 Saving results with gpu monitoring
2024-09-24 14:32:16,485 Latency for request d631acdc with model llama3-8b: 52.3480 seconds
2024-09-24 14:32:16,485 Saving results with gpu monitoring
2024-09-24 14:32:16,487 Latency for request f18891d0 with model llama3-8b: 51.5130 seconds
2024-09-24 14:32:16,487 Saving results with gpu monitoring
2024-09-24 14:32:16,489 Latency for request 20ef72bb with model llama3-8b: 51.4130 seconds
2024-09-24 14:32:16,489 Saving results with gpu monitoring
2024-09-24 14:32:16,491 Latency for request 59639c32 with model llama3-8b: 50.7390 seconds
2024-09-24 14:32:16,491 Saving results with gpu monitoring
2024-09-24 14:32:16,493 Latency for request a55a785b with model llama3-8b: 50.6260 seconds
2024-09-24 14:32:16,493 Saving results with gpu monitoring
2024-09-24 14:32:16,495 Latency for request 7870e665 with model llama3-8b: 50.5850 seconds
2024-09-24 14:32:16,495 Saving results with gpu monitoring
2024-09-24 14:32:16,497 Latency for request db6db436 with model llama3-8b: 50.3720 seconds
2024-09-24 14:32:16,497 Saving results with gpu monitoring
2024-09-24 14:32:16,499 Latency for request b1f26aaf with model llama3-8b: 50.3630 seconds
2024-09-24 14:32:16,499 Saving results with gpu monitoring
2024-09-24 14:32:16,501 Latency for request 4140d61c with model llama3-8b: 50.1150 seconds
2024-09-24 14:32:16,501 Saving results with gpu monitoring
2024-09-24 14:32:16,503 Latency for request 4932c436 with model llama3-8b: 50.0000 seconds
2024-09-24 14:32:16,503 Saving results with gpu monitoring
2024-09-24 14:32:16,505 Latency for request ccbb5c24 with model llama3-8b: 49.9830 seconds
2024-09-24 14:32:16,505 Saving results with gpu monitoring
2024-09-24 14:32:16,507 Latency for request d00bc02d with model llama3-8b: 49.8200 seconds
2024-09-24 14:32:16,507 Saving results with gpu monitoring
2024-09-24 14:32:16,509 Latency for request 0111bae1 with model llama3-8b: 49.7330 seconds
2024-09-24 14:32:16,509 Saving results with gpu monitoring
2024-09-24 14:32:16,511 Latency for request d6760180 with model llama3-8b: 49.4320 seconds
2024-09-24 14:32:16,511 Saving results with gpu monitoring
2024-09-24 14:32:16,513 Latency for request 87c4e50e with model llama3-8b: 49.2820 seconds
2024-09-24 14:32:16,513 Saving results with gpu monitoring
2024-09-24 14:32:16,515 Latency for request 4f4ae06f with model llama3-8b: 49.2490 seconds
2024-09-24 14:32:16,515 Saving results with gpu monitoring
2024-09-24 14:32:16,517 Latency for request 1f83f94e with model llama3-8b: 49.0980 seconds
2024-09-24 14:32:16,517 Saving results with gpu monitoring
2024-09-24 14:32:16,519 Latency for request 1bc41e90 with model llama3-8b: 48.8900 seconds
2024-09-24 14:32:16,519 Saving results with gpu monitoring
2024-09-24 14:32:16,521 Latency for request 947d588f with model llama3-8b: 48.8630 seconds
2024-09-24 14:32:16,521 Saving results with gpu monitoring
2024-09-24 14:32:16,523 Latency for request 65adc477 with model llama3-8b: 48.6390 seconds
2024-09-24 14:32:16,523 Saving results with gpu monitoring
2024-09-24 14:32:16,525 Latency for request f4255303 with model llama3-8b: 48.6370 seconds
2024-09-24 14:32:16,525 Saving results with gpu monitoring
2024-09-24 14:32:16,527 Latency for request 371365c2 with model llama3-8b: 48.6350 seconds
2024-09-24 14:32:16,527 Saving results with gpu monitoring
2024-09-24 14:32:16,529 Latency for request aa063081 with model llama3-8b: 48.1920 seconds
2024-09-24 14:32:16,529 Saving results with gpu monitoring
2024-09-24 14:32:16,531 Latency for request 2c2e1a32 with model llama3-8b: 48.1270 seconds
2024-09-24 14:32:16,531 Saving results with gpu monitoring
2024-09-24 14:32:16,533 Latency for request bc53403c with model llama3-8b: 47.7100 seconds
2024-09-24 14:32:16,533 Saving results with gpu monitoring
2024-09-24 14:32:16,534 Latency for request cf345615 with model llama3-8b: 47.2550 seconds
2024-09-24 14:32:16,535 Saving results with gpu monitoring
2024-09-24 14:32:16,537 Latency for request ad0736d4 with model llama3-8b: 46.6740 seconds
2024-09-24 14:32:16,537 Saving results with gpu monitoring
2024-09-24 14:32:16,539 Latency for request 4a6a2193 with model llama3-8b: 46.5310 seconds
2024-09-24 14:32:16,539 Saving results with gpu monitoring
2024-09-24 14:32:16,540 Latency for request 13001f22 with model llama3-8b: 46.3470 seconds
2024-09-24 14:32:16,541 Saving results with gpu monitoring
2024-09-24 14:32:16,542 Latency for request f08b5684 with model llama3-8b: 46.1030 seconds
2024-09-24 14:32:16,542 Saving results with gpu monitoring
2024-09-24 14:32:16,544 Latency for request 30420d72 with model llama3-8b: 45.5450 seconds
2024-09-24 14:32:16,544 Saving results with gpu monitoring
2024-09-24 14:32:16,546 Latency for request b25daac5 with model llama3-8b: 45.2650 seconds
2024-09-24 14:32:16,546 Saving results with gpu monitoring
2024-09-24 14:32:16,548 Latency for request f0b2bd14 with model llama3-8b: 45.1990 seconds
2024-09-24 14:32:16,548 Saving results with gpu monitoring
2024-09-24 14:32:16,550 Latency for request 0e1a0ccc with model llama3-8b: 45.1880 seconds
2024-09-24 14:32:16,550 Saving results with gpu monitoring
2024-09-24 14:32:16,552 Latency for request cbb3d776 with model llama3-8b: 45.0670 seconds
2024-09-24 14:32:16,552 Saving results with gpu monitoring
2024-09-24 14:32:16,554 Latency for request d18fefb3 with model llama3-8b: 44.6520 seconds
2024-09-24 14:32:16,554 Saving results with gpu monitoring
2024-09-24 14:32:16,556 Latency for request a1557d42 with model llama3-8b: 44.4900 seconds
2024-09-24 14:32:16,556 Saving results with gpu monitoring
2024-09-24 14:32:16,558 Latency for request 6b48d45d with model llama3-8b: 44.4400 seconds
2024-09-24 14:32:16,558 Saving results with gpu monitoring
2024-09-24 14:32:16,560 Latency for request 46ce9086 with model llama3-8b: 44.3540 seconds
2024-09-24 14:32:16,560 Saving results with gpu monitoring
2024-09-24 14:32:16,562 Latency for request 411f34ad with model llama3-8b: 44.1540 seconds
2024-09-24 14:32:16,562 Saving results with gpu monitoring
2024-09-24 14:32:16,564 Latency for request e3d9b332 with model llama3-8b: 43.8520 seconds
2024-09-24 14:32:16,564 Saving results with gpu monitoring
2024-09-24 14:32:16,566 Latency for request 2735660c with model llama3-8b: 43.6680 seconds
2024-09-24 14:32:16,566 Saving results with gpu monitoring
2024-09-24 14:32:16,568 Latency for request 22219161 with model llama3-8b: 43.5860 seconds
2024-09-24 14:32:16,568 Saving results with gpu monitoring
2024-09-24 14:32:16,570 Latency for request 839dec6a with model llama3-8b: 43.5280 seconds
2024-09-24 14:32:16,570 Saving results with gpu monitoring
2024-09-24 14:32:16,572 Latency for request 32401f8a with model llama3-8b: 43.4760 seconds
2024-09-24 14:32:16,572 Saving results with gpu monitoring
2024-09-24 14:32:16,574 Latency for request 2e161841 with model llama3-8b: 42.9270 seconds
2024-09-24 14:32:16,574 Saving results with gpu monitoring
2024-09-24 14:32:16,576 Latency for request a397670d with model llama3-8b: 42.5820 seconds
2024-09-24 14:32:16,576 Saving results with gpu monitoring
2024-09-24 14:32:16,578 Latency for request 0dd7a996 with model llama3-8b: 42.5720 seconds
2024-09-24 14:32:16,578 Saving results with gpu monitoring
2024-09-24 14:32:16,580 Latency for request 163e370a with model llama3-8b: 41.8980 seconds
2024-09-24 14:32:16,580 Saving results with gpu monitoring
2024-09-24 14:32:16,582 Latency for request 72dd2318 with model llama3-8b: 41.6420 seconds
2024-09-24 14:32:16,582 Saving results with gpu monitoring
2024-09-24 14:32:16,584 Latency for request 8660a519 with model llama3-8b: 41.0130 seconds
2024-09-24 14:32:16,584 Saving results with gpu monitoring
2024-09-24 14:32:16,586 Latency for request 7d2b492d with model llama3-8b: 40.7420 seconds
2024-09-24 14:32:16,586 Saving results with gpu monitoring
2024-09-24 14:32:16,588 Latency for request d5710096 with model llama3-8b: 40.7150 seconds
2024-09-24 14:32:16,588 Saving results with gpu monitoring
2024-09-24 14:32:16,590 Latency for request 030b55c1 with model llama3-8b: 40.6960 seconds
2024-09-24 14:32:16,590 Saving results with gpu monitoring
2024-09-24 14:32:16,592 Latency for request a5f60eeb with model llama3-8b: 40.5360 seconds
2024-09-24 14:32:16,592 Saving results with gpu monitoring
2024-09-24 14:32:16,594 Latency for request 5b45099a with model llama3-8b: 40.4180 seconds
2024-09-24 14:32:16,594 Saving results with gpu monitoring
2024-09-24 14:32:16,596 Latency for request f0b61b6d with model llama3-8b: 40.3920 seconds
2024-09-24 14:32:16,596 Saving results with gpu monitoring
2024-09-24 14:32:16,598 Latency for request d3307e51 with model llama3-8b: 40.3570 seconds
2024-09-24 14:32:16,598 Saving results with gpu monitoring
2024-09-24 14:32:16,600 Latency for request 03d7da55 with model llama3-8b: 40.2210 seconds
2024-09-24 14:32:16,600 Saving results with gpu monitoring
2024-09-24 14:32:16,602 127.0.0.1 - - [24/Sep/2024 14:32:16] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:16,602 Next: call load_model for gemma-7b
2024-09-24 14:32:16,698 Unloaded previous model
2024-09-24 14:32:17,191 Request with ID 3765b5f9 for model llama3-8b received
2024-09-24 14:32:17,193 127.0.0.1 - - [24/Sep/2024 14:32:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:17,194 Request with ID bbbfe07d for model granite-7b received
2024-09-24 14:32:17,197 127.0.0.1 - - [24/Sep/2024 14:32:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:17,198 Request with ID 51a993d2 for model llama3-8b received
2024-09-24 14:32:17,200 127.0.0.1 - - [24/Sep/2024 14:32:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:17,202 Request with ID b98256d3 for model gemma-7b received
2024-09-24 14:32:17,203 127.0.0.1 - - [24/Sep/2024 14:32:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:17,205 Request with ID a9b5a928 for model llama3-8b received
2024-09-24 14:32:17,206 127.0.0.1 - - [24/Sep/2024 14:32:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:17,213 Request with ID c5a32989 for model gemma-7b received
2024-09-24 14:32:17,213 127.0.0.1 - - [24/Sep/2024 14:32:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:17,445 Request with ID f9045774 for model granite-7b received
2024-09-24 14:32:17,446 127.0.0.1 - - [24/Sep/2024 14:32:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:17,695 Request with ID 2b32d138 for model llama3-8b received
2024-09-24 14:32:17,697 127.0.0.1 - - [24/Sep/2024 14:32:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:17,714 Request with ID 9c7126c2 for model llama3-8b received
2024-09-24 14:32:17,812 127.0.0.1 - - [24/Sep/2024 14:32:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:17,827 Request with ID eac84f7c for model llama3-8b received
2024-09-24 14:32:17,827 127.0.0.1 - - [24/Sep/2024 14:32:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:17,840 Request with ID bc6a52e1 for model llama3-8b received
2024-09-24 14:32:17,842 127.0.0.1 - - [24/Sep/2024 14:32:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:18,118 Request with ID 4dd1ce25 for model gemma-7b received
2024-09-24 14:32:18,119 Request with ID c186bd67 for model gemma-7b received
2024-09-24 14:32:18,120 127.0.0.1 - - [24/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:18,120 127.0.0.1 - - [24/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:18,121 Request with ID 4cbc66a7 for model llama3-8b received
2024-09-24 14:32:18,123 Request with ID 517eb80e for model gemma-7b received
2024-09-24 14:32:18,124 127.0.0.1 - - [24/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:18,125 127.0.0.1 - - [24/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:18,128 Request with ID 41bc8b3c for model gemma-7b received
2024-09-24 14:32:18,128 127.0.0.1 - - [24/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:18,178 Request with ID 174b1f7a for model gemma-7b received
2024-09-24 14:32:18,178 127.0.0.1 - - [24/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:18,208 Request with ID 891d4c16 for model llama3-8b received
2024-09-24 14:32:18,209 127.0.0.1 - - [24/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:18,368 Request with ID f6632730 for model llama3-8b received
2024-09-24 14:32:18,369 127.0.0.1 - - [24/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:18,450 Request with ID 29f0cfe2 for model gemma-7b received
2024-09-24 14:32:18,451 127.0.0.1 - - [24/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:18,479 Request with ID 79d43af5 for model llama3-8b received
2024-09-24 14:32:18,480 127.0.0.1 - - [24/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:18,715 Request with ID 10b3b523 for model granite-7b received
2024-09-24 14:32:18,715 127.0.0.1 - - [24/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:18,916 Request with ID a28d0d98 for model granite-7b received
2024-09-24 14:32:18,917 127.0.0.1 - - [24/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:19,236 Request with ID 5f40e5b3 for model llama3-8b received
2024-09-24 14:32:19,237 127.0.0.1 - - [24/Sep/2024 14:32:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:19,251 Request with ID 49bef0bf for model gemma-7b received
2024-09-24 14:32:19,252 127.0.0.1 - - [24/Sep/2024 14:32:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:19,357 Request with ID 7e2f9e8c for model gemma-7b received
2024-09-24 14:32:19,358 127.0.0.1 - - [24/Sep/2024 14:32:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:19,489 Request with ID 703ee4b2 for model llama3-8b received
2024-09-24 14:32:19,490 127.0.0.1 - - [24/Sep/2024 14:32:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:19,563 Request with ID 6789cca2 for model llama3-8b received
2024-09-24 14:32:19,564 127.0.0.1 - - [24/Sep/2024 14:32:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:19,567 Request with ID 52e0532b for model llama3-8b received
2024-09-24 14:32:19,568 127.0.0.1 - - [24/Sep/2024 14:32:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:19,631 Request with ID f0506577 for model llama3-8b received
2024-09-24 14:32:19,632 127.0.0.1 - - [24/Sep/2024 14:32:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:19,766 Request with ID 4d095151 for model llama3-8b received
2024-09-24 14:32:19,766 127.0.0.1 - - [24/Sep/2024 14:32:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:19,957 Request with ID 7c7f68fe for model llama3-8b received
2024-09-24 14:32:19,957 Batch size condition met for model llama3-8b
2024-09-24 14:32:20,132 Request with ID e43754b1 for model gemma-7b received
2024-09-24 14:32:20,133 127.0.0.1 - - [24/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:20,675 Request with ID e5340528 for model granite-7b received
2024-09-24 14:32:20,675 127.0.0.1 - - [24/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:20,759 Request with ID 1d4b18fb for model llama3-8b received
2024-09-24 14:32:20,759 127.0.0.1 - - [24/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:20,863 Request with ID f25261ac for model llama3-8b received
2024-09-24 14:32:20,863 127.0.0.1 - - [24/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:20,873 Request with ID 839d1392 for model gemma-7b received
2024-09-24 14:32:20,873 127.0.0.1 - - [24/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:20,878 Request with ID 838ab297 for model gemma-7b received
2024-09-24 14:32:20,878 127.0.0.1 - - [24/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:20,929 Request with ID b3670cad for model llama3-8b received
2024-09-24 14:32:20,929 127.0.0.1 - - [24/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:21,133 Request with ID 7d69d2ad for model gemma-7b received
2024-09-24 14:32:21,133 127.0.0.1 - - [24/Sep/2024 14:32:21] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:21,147 Request with ID 8b2857ab for model gemma-7b received
2024-09-24 14:32:21,148 127.0.0.1 - - [24/Sep/2024 14:32:21] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:21,433 Request with ID aa6b1bc2 for model llama3-8b received
2024-09-24 14:32:21,433 127.0.0.1 - - [24/Sep/2024 14:32:21] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:21,439 Request with ID 33a85193 for model gemma-7b received
2024-09-24 14:32:21,440 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-24 14:32:21,440 Dynamic batch size condition met for model gemma-7b
2024-09-24 14:32:21,784 Request with ID d69515ec for model llama3-8b received
2024-09-24 14:32:21,785 127.0.0.1 - - [24/Sep/2024 14:32:21] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:22,002 Request with ID 89a9239a for model llama3-8b received
2024-09-24 14:32:22,003 127.0.0.1 - - [24/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:22,004 Request with ID db48b3b2 for model llama3-8b received
2024-09-24 14:32:22,005 127.0.0.1 - - [24/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:22,105 Request with ID c5ef94f0 for model llama3-8b received
2024-09-24 14:32:22,106 127.0.0.1 - - [24/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:22,236 Request with ID 6cc44efa for model gemma-7b received
2024-09-24 14:32:22,237 127.0.0.1 - - [24/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:22,310 Request with ID d0623e95 for model llama3-8b received
2024-09-24 14:32:22,310 127.0.0.1 - - [24/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:22,393 Request with ID 74afeb3a for model gemma-7b received
2024-09-24 14:32:22,394 127.0.0.1 - - [24/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:22,860 Request with ID c7f8be06 for model gemma-7b received
2024-09-24 14:32:22,860 127.0.0.1 - - [24/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:23,056 Request with ID c48d3655 for model granite-7b received
2024-09-24 14:32:23,057 127.0.0.1 - - [24/Sep/2024 14:32:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:23,079 Request with ID 6c312872 for model llama3-8b received
2024-09-24 14:32:23,079 127.0.0.1 - - [24/Sep/2024 14:32:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:23,113 Request with ID 956cda42 for model llama3-8b received
2024-09-24 14:32:23,113 127.0.0.1 - - [24/Sep/2024 14:32:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:23,246 Request with ID 99b7bbbd for model llama3-8b received
2024-09-24 14:32:23,246 127.0.0.1 - - [24/Sep/2024 14:32:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:23,278 Request with ID 81400fd0 for model gemma-7b received
2024-09-24 14:32:23,279 127.0.0.1 - - [24/Sep/2024 14:32:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:23,509 Request with ID 9cc3167c for model llama3-8b received
2024-09-24 14:32:23,510 127.0.0.1 - - [24/Sep/2024 14:32:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:23,681 Request with ID 950b1a1c for model llama3-8b received
2024-09-24 14:32:23,681 127.0.0.1 - - [24/Sep/2024 14:32:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:23,848 Request with ID 4df05a41 for model granite-7b received
2024-09-24 14:32:23,849 127.0.0.1 - - [24/Sep/2024 14:32:23] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:24,103 Request with ID 962d885b for model llama3-8b received
2024-09-24 14:32:24,103 127.0.0.1 - - [24/Sep/2024 14:32:24] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:24,105 Request with ID 8c4be0a4 for model llama3-8b received
2024-09-24 14:32:24,106 127.0.0.1 - - [24/Sep/2024 14:32:24] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:24,222 Request with ID f8ae6abd for model llama3-8b received
2024-09-24 14:32:24,223 127.0.0.1 - - [24/Sep/2024 14:32:24] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:24,829 Request with ID 96e28863 for model llama3-8b received
2024-09-24 14:32:24,830 127.0.0.1 - - [24/Sep/2024 14:32:24] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:24,860 Request with ID 804d1e38 for model llama3-8b received
2024-09-24 14:32:24,861 127.0.0.1 - - [24/Sep/2024 14:32:24] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:25,028 Request with ID 366144c4 for model llama3-8b received
2024-09-24 14:32:25,029 127.0.0.1 - - [24/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:25,329 Request with ID c84b8cee for model llama3-8b received
2024-09-24 14:32:25,330 127.0.0.1 - - [24/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:25,473 Request with ID b14ca584 for model gemma-7b received
2024-09-24 14:32:25,473 127.0.0.1 - - [24/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:25,632 Request with ID 5057e73d for model gemma-7b received
2024-09-24 14:32:25,633 127.0.0.1 - - [24/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:25,889 Request with ID 52153509 for model llama3-8b received
2024-09-24 14:32:25,889 127.0.0.1 - - [24/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:25,999 Request with ID 2efd79e3 for model granite-7b received
2024-09-24 14:32:26,000 127.0.0.1 - - [24/Sep/2024 14:32:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:26,133 Request with ID 2083c454 for model gemma-7b received
2024-09-24 14:32:26,134 127.0.0.1 - - [24/Sep/2024 14:32:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:26,378 Request with ID bb7e985b for model gemma-7b received
2024-09-24 14:32:26,379 127.0.0.1 - - [24/Sep/2024 14:32:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:26,565 Request with ID 2dc2b660 for model gemma-7b received
2024-09-24 14:32:26,566 127.0.0.1 - - [24/Sep/2024 14:32:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:26,599 Request with ID e5d5fefd for model gemma-7b received
2024-09-24 14:32:26,600 127.0.0.1 - - [24/Sep/2024 14:32:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:26,693 Request with ID 57271fcd for model llama3-8b received
2024-09-24 14:32:26,693 127.0.0.1 - - [24/Sep/2024 14:32:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:26,713 Request with ID 4d16f7f9 for model llama3-8b received
2024-09-24 14:32:26,714 127.0.0.1 - - [24/Sep/2024 14:32:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:26,869 Request with ID 00c6b279 for model gemma-7b received
2024-09-24 14:32:26,870 127.0.0.1 - - [24/Sep/2024 14:32:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:26,930 Request with ID 8805b5de for model gemma-7b received
2024-09-24 14:32:26,931 127.0.0.1 - - [24/Sep/2024 14:32:26] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,027 Request with ID 109a56d6 for model llama3-8b received
2024-09-24 14:32:27,028 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,159 Request with ID 554e8ee3 for model llama3-8b received
2024-09-24 14:32:27,160 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,238 Request with ID 80d2ba48 for model gemma-7b received
2024-09-24 14:32:27,239 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,246 Request with ID 73a4d4bc for model llama3-8b received
2024-09-24 14:32:27,247 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,251 Request with ID 83170993 for model gemma-7b received
2024-09-24 14:32:27,252 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,278 Request with ID 1a21e547 for model gemma-7b received
2024-09-24 14:32:27,278 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,369 Request with ID bf165072 for model llama3-8b received
2024-09-24 14:32:27,369 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,433 Request with ID c0eed571 for model llama3-8b received
2024-09-24 14:32:27,433 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,436 Request with ID d83f3bc7 for model llama3-8b received
2024-09-24 14:32:27,437 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,691 Request with ID 7df9dbc9 for model gemma-7b received
2024-09-24 14:32:27,692 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,785 Request with ID eb7954c0 for model llama3-8b received
2024-09-24 14:32:27,786 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,804 Request with ID e77d9084 for model gemma-7b received
2024-09-24 14:32:27,805 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:27,958 Request with ID df2d950b for model llama3-8b received
2024-09-24 14:32:27,959 127.0.0.1 - - [24/Sep/2024 14:32:27] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:28,398 Request with ID dc7e6a19 for model llama3-8b received
2024-09-24 14:32:28,399 127.0.0.1 - - [24/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:28,421 Request with ID 4622d022 for model llama3-8b received
2024-09-24 14:32:28,422 127.0.0.1 - - [24/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:28,447 Request with ID 5ab5b661 for model llama3-8b received
2024-09-24 14:32:28,448 127.0.0.1 - - [24/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:28,593 Request with ID 97ce95f3 for model gemma-7b received
2024-09-24 14:32:28,594 127.0.0.1 - - [24/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:28,893 Request with ID 25595042 for model llama3-8b received
2024-09-24 14:32:28,893 127.0.0.1 - - [24/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:28,895 Request with ID 0f7808b9 for model llama3-8b received
2024-09-24 14:32:28,896 127.0.0.1 - - [24/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:29,138 Request with ID af3d59ca for model llama3-8b received
2024-09-24 14:32:29,139 127.0.0.1 - - [24/Sep/2024 14:32:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:29,203 Request with ID 09245d5b for model llama3-8b received
2024-09-24 14:32:29,204 127.0.0.1 - - [24/Sep/2024 14:32:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:29,258 Request with ID 953ea3c8 for model llama3-8b received
2024-09-24 14:32:29,258 127.0.0.1 - - [24/Sep/2024 14:32:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:29,307 Request with ID 72d9b97d for model llama3-8b received
2024-09-24 14:32:29,307 127.0.0.1 - - [24/Sep/2024 14:32:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:29,500 Request with ID 310be9ba for model gemma-7b received
2024-09-24 14:32:29,500 127.0.0.1 - - [24/Sep/2024 14:32:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:29,633 Request with ID 79f68411 for model llama3-8b received
2024-09-24 14:32:29,633 127.0.0.1 - - [24/Sep/2024 14:32:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:29,707 Request with ID b57ef3b4 for model gemma-7b received
2024-09-24 14:32:29,707 127.0.0.1 - - [24/Sep/2024 14:32:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:29,963 Request with ID d98cb430 for model gemma-7b received
2024-09-24 14:32:29,964 127.0.0.1 - - [24/Sep/2024 14:32:29] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:30,096 Request with ID f83d6ad8 for model llama3-8b received
2024-09-24 14:32:30,096 127.0.0.1 - - [24/Sep/2024 14:32:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:30,156 Request with ID 01a4ecb8 for model llama3-8b received
2024-09-24 14:32:30,157 127.0.0.1 - - [24/Sep/2024 14:32:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:30,257 Request with ID 724e2e7a for model granite-7b received
2024-09-24 14:32:30,258 127.0.0.1 - - [24/Sep/2024 14:32:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:30,369 Request with ID ca75e664 for model llama3-8b received
2024-09-24 14:32:30,370 127.0.0.1 - - [24/Sep/2024 14:32:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:30,430 Request with ID 6a260567 for model llama3-8b received
2024-09-24 14:32:30,430 127.0.0.1 - - [24/Sep/2024 14:32:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:30,433 Request with ID 6aa874d7 for model gemma-7b received
2024-09-24 14:32:30,434 127.0.0.1 - - [24/Sep/2024 14:32:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:30,456 Request with ID f8ce0cc9 for model llama3-8b received
2024-09-24 14:32:30,456 127.0.0.1 - - [24/Sep/2024 14:32:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:30,554 Request with ID a2e14a7a for model llama3-8b received
2024-09-24 14:32:30,629 127.0.0.1 - - [24/Sep/2024 14:32:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:30,766 Request with ID f880c42d for model llama3-8b received
2024-09-24 14:32:30,766 127.0.0.1 - - [24/Sep/2024 14:32:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:30,925 Loaded model gemma-7b
2024-09-24 14:32:30,928 Batch processing started for model gemma-7b
2024-09-24 14:32:30,983 Request with ID 06783bac for model llama3-8b received
2024-09-24 14:32:30,983 127.0.0.1 - - [24/Sep/2024 14:32:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:30,993 Request with ID d15c6351 for model llama3-8b received
2024-09-24 14:32:30,994 127.0.0.1 - - [24/Sep/2024 14:32:30] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:31,002 Request with ID fca8cb53 for model llama3-8b received
2024-09-24 14:32:31,002 127.0.0.1 - - [24/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:31,030 Request with ID 4b5a8908 for model llama3-8b received
2024-09-24 14:32:31,031 127.0.0.1 - - [24/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:31,069 Request with ID a6e37492 for model llama3-8b received
2024-09-24 14:32:31,070 127.0.0.1 - - [24/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:31,168 Request with ID 547defd4 for model llama3-8b received
2024-09-24 14:32:31,169 127.0.0.1 - - [24/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:31,327 Request with ID c6f71075 for model gemma-7b received
2024-09-24 14:32:31,328 127.0.0.1 - - [24/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:31,353 Request with ID 81c03e95 for model llama3-8b received
2024-09-24 14:32:31,354 127.0.0.1 - - [24/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:31,510 Request with ID b12adbdc for model gemma-7b received
2024-09-24 14:32:31,511 127.0.0.1 - - [24/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:31,924 Request with ID b5bfe902 for model granite-7b received
2024-09-24 14:32:31,924 127.0.0.1 - - [24/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:32,138 Request with ID 16161183 for model granite-7b received
2024-09-24 14:32:32,138 127.0.0.1 - - [24/Sep/2024 14:32:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:32,265 Request with ID 513d6481 for model llama3-8b received
2024-09-24 14:32:32,265 127.0.0.1 - - [24/Sep/2024 14:32:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:32,298 Request with ID f790c293 for model llama3-8b received
2024-09-24 14:32:32,298 127.0.0.1 - - [24/Sep/2024 14:32:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:32,323 Request with ID 8ebdb651 for model llama3-8b received
2024-09-24 14:32:32,323 127.0.0.1 - - [24/Sep/2024 14:32:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:32,614 Request with ID e9610a70 for model llama3-8b received
2024-09-24 14:32:32,614 127.0.0.1 - - [24/Sep/2024 14:32:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:32,652 Request with ID 0640cf41 for model gemma-7b received
2024-09-24 14:32:32,652 127.0.0.1 - - [24/Sep/2024 14:32:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:32,871 Request with ID 28045251 for model llama3-8b received
2024-09-24 14:32:32,871 127.0.0.1 - - [24/Sep/2024 14:32:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:32,891 Request with ID df5520e7 for model llama3-8b received
2024-09-24 14:32:32,892 127.0.0.1 - - [24/Sep/2024 14:32:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:32,915 Request with ID 5cec2c48 for model llama3-8b received
2024-09-24 14:32:32,916 127.0.0.1 - - [24/Sep/2024 14:32:32] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:32,998 Request with ID ff02493f for model granite-7b received
2024-09-24 14:32:32,998 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-24 14:32:32,998 Dynamic batch size condition met for model granite-7b
2024-09-24 14:32:33,128 Request with ID bfd063bf for model gemma-7b received
2024-09-24 14:32:33,128 127.0.0.1 - - [24/Sep/2024 14:32:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:33,256 Request with ID c5a5230e for model gemma-7b received
2024-09-24 14:32:33,257 127.0.0.1 - - [24/Sep/2024 14:32:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:33,370 Request with ID c14285a3 for model llama3-8b received
2024-09-24 14:32:33,371 Batch size condition met for model llama3-8b
2024-09-24 14:32:33,389 Request with ID a54077d0 for model llama3-8b received
2024-09-24 14:32:33,390 127.0.0.1 - - [24/Sep/2024 14:32:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:33,549 Request with ID 81e7de63 for model gemma-7b received
2024-09-24 14:32:33,550 127.0.0.1 - - [24/Sep/2024 14:32:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:33,764 Request with ID 3a0debf2 for model llama3-8b received
2024-09-24 14:32:33,765 127.0.0.1 - - [24/Sep/2024 14:32:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:33,874 Request with ID 4bcbe925 for model llama3-8b received
2024-09-24 14:32:33,875 127.0.0.1 - - [24/Sep/2024 14:32:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:33,913 Request with ID 6118c0c7 for model llama3-8b received
2024-09-24 14:32:33,914 127.0.0.1 - - [24/Sep/2024 14:32:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:33,941 Request with ID 415d2135 for model gemma-7b received
2024-09-24 14:32:33,942 127.0.0.1 - - [24/Sep/2024 14:32:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:33,999 Request with ID be0d06a7 for model llama3-8b received
2024-09-24 14:32:33,999 127.0.0.1 - - [24/Sep/2024 14:32:33] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:34,224 Request with ID 2a4bf4a9 for model llama3-8b received
2024-09-24 14:32:34,224 127.0.0.1 - - [24/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:34,258 Request with ID 8ee4dc1c for model llama3-8b received
2024-09-24 14:32:34,259 127.0.0.1 - - [24/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:34,355 Request with ID 242c1414 for model gemma-7b received
2024-09-24 14:32:34,356 127.0.0.1 - - [24/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:34,496 Request with ID 7fc4e8f3 for model llama3-8b received
2024-09-24 14:32:34,496 127.0.0.1 - - [24/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:34,599 Request with ID fad86ea5 for model llama3-8b received
2024-09-24 14:32:34,600 127.0.0.1 - - [24/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:34,607 Request with ID ac34cc47 for model llama3-8b received
2024-09-24 14:32:34,608 127.0.0.1 - - [24/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:34,632 Request with ID 4a393804 for model gemma-7b received
2024-09-24 14:32:34,632 127.0.0.1 - - [24/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:34,701 Request with ID 7384728d for model llama3-8b received
2024-09-24 14:32:34,702 Request with ID 15e65a9c for model llama3-8b received
2024-09-24 14:32:34,703 127.0.0.1 - - [24/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:34,704 127.0.0.1 - - [24/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:34,903 Request with ID 565e418d for model gemma-7b received
2024-09-24 14:32:34,903 127.0.0.1 - - [24/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:34,919 Request with ID 55370ddc for model llama3-8b received
2024-09-24 14:32:34,919 127.0.0.1 - - [24/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:35,248 Request with ID c9ddd01b for model gemma-7b received
2024-09-24 14:32:35,249 127.0.0.1 - - [24/Sep/2024 14:32:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:35,389 Request with ID 8f1dc140 for model llama3-8b received
2024-09-24 14:32:35,390 127.0.0.1 - - [24/Sep/2024 14:32:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:35,401 Request with ID 68c42707 for model llama3-8b received
2024-09-24 14:32:35,402 127.0.0.1 - - [24/Sep/2024 14:32:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:35,521 Request with ID 459815e8 for model llama3-8b received
2024-09-24 14:32:35,521 127.0.0.1 - - [24/Sep/2024 14:32:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:35,525 Request with ID 7af7910d for model gemma-7b received
2024-09-24 14:32:35,525 127.0.0.1 - - [24/Sep/2024 14:32:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:35,580 Request with ID c2bd84c9 for model gemma-7b received
2024-09-24 14:32:35,580 127.0.0.1 - - [24/Sep/2024 14:32:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:35,615 Request with ID 78ce3f54 for model llama3-8b received
2024-09-24 14:32:35,616 127.0.0.1 - - [24/Sep/2024 14:32:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:35,658 Request with ID ae9cf07c for model llama3-8b received
2024-09-24 14:32:35,658 127.0.0.1 - - [24/Sep/2024 14:32:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:35,750 Request with ID 41c2d70b for model llama3-8b received
2024-09-24 14:32:35,751 127.0.0.1 - - [24/Sep/2024 14:32:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:35,860 Request with ID 6f0770fb for model llama3-8b received
2024-09-24 14:32:35,860 127.0.0.1 - - [24/Sep/2024 14:32:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:35,891 Request with ID 6e7e916f for model gemma-7b received
2024-09-24 14:32:35,892 127.0.0.1 - - [24/Sep/2024 14:32:35] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:36,105 Request with ID 3dc6ea45 for model llama3-8b received
2024-09-24 14:32:36,106 127.0.0.1 - - [24/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:36,202 Request with ID b7f62d21 for model gemma-7b received
2024-09-24 14:32:36,203 127.0.0.1 - - [24/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:36,234 Request with ID 28268676 for model gemma-7b received
2024-09-24 14:32:36,234 127.0.0.1 - - [24/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:36,237 Request with ID cde9cfe2 for model gemma-7b received
2024-09-24 14:32:36,238 127.0.0.1 - - [24/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:36,634 Request with ID d121973e for model llama3-8b received
2024-09-24 14:32:36,635 127.0.0.1 - - [24/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:36,852 Request with ID c31f6037 for model llama3-8b received
2024-09-24 14:32:36,852 127.0.0.1 - - [24/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:36,899 Request with ID 303d8588 for model llama3-8b received
2024-09-24 14:32:36,900 127.0.0.1 - - [24/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:37,018 Request with ID 3aba7327 for model llama3-8b received
2024-09-24 14:32:37,019 127.0.0.1 - - [24/Sep/2024 14:32:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:37,066 Request with ID 5f950690 for model llama3-8b received
2024-09-24 14:32:37,067 127.0.0.1 - - [24/Sep/2024 14:32:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:37,122 Processed batch: ['db3edd91', '89b97c12', '8212e31c', '37bd4b3e', '51e3aba0', '77b9844d', 'dc0bf740', 'ae46f3a3', '019eef5f', '384aa4ff', '9a1241f7', 'b23e2290', '06449ecc', 'e4df6140', '55d62f40', '4e61abae', 'a484c28b', 'd2648dbb', '3041cb9c', 'c1bc6267', 'c9455e34', 'ec430693', 'f27db080', '17037915', '92b1eb37', '3a56b7e1', '4b485504', '6b47c122', '5e378353', 'e8527a73', 'ae7e7ea9', '3b4d1692', '195c1fcd', '5c674f1e', '7328d4f0', 'e189f345', 'ec532a3a', 'a759472f', '8fdf5775', '15b6b5db', '8b0384b9', '8c61f5e9', 'ae8c9649', '85ec1eb5', '24ec688c', '1c4c6f0e', '72e5af68', 'b8ff57f8', 'b12f63e1', '521f6491', '9e15bae6', '11eaa55e', '8b1c8bda', '5c4eec52', 'b24807f2', '435d18ec', '64d843eb', '0c9f8368', '83bdf9b6', 'd18fa51b', 'c1c27ef8', '22e33733', 'f887f26a', '1e2b0ac1'] with model gemma-7b in 6.1936 seconds
2024-09-24 14:32:37,122 Saving sys info
2024-09-24 14:32:37,183 Latency for request db3edd91 with model gemma-7b: 54.5540 seconds
2024-09-24 14:32:37,184 Saving results with gpu monitoring
2024-09-24 14:32:37,186 Latency for request 89b97c12 with model gemma-7b: 54.0640 seconds
2024-09-24 14:32:37,186 Saving results with gpu monitoring
2024-09-24 14:32:37,189 Latency for request 8212e31c with model gemma-7b: 53.9990 seconds
2024-09-24 14:32:37,189 Saving results with gpu monitoring
2024-09-24 14:32:37,191 Latency for request 37bd4b3e with model gemma-7b: 53.2050 seconds
2024-09-24 14:32:37,191 Saving results with gpu monitoring
2024-09-24 14:32:37,192 Latency for request 51e3aba0 with model gemma-7b: 52.8010 seconds
2024-09-24 14:32:37,193 Saving results with gpu monitoring
2024-09-24 14:32:37,194 Latency for request 77b9844d with model gemma-7b: 52.7860 seconds
2024-09-24 14:32:37,194 Saving results with gpu monitoring
2024-09-24 14:32:37,196 Latency for request dc0bf740 with model gemma-7b: 52.7590 seconds
2024-09-24 14:32:37,196 Saving results with gpu monitoring
2024-09-24 14:32:37,198 Latency for request ae46f3a3 with model gemma-7b: 52.0500 seconds
2024-09-24 14:32:37,198 Saving results with gpu monitoring
2024-09-24 14:32:37,200 Latency for request 019eef5f with model gemma-7b: 51.8580 seconds
2024-09-24 14:32:37,200 Saving results with gpu monitoring
2024-09-24 14:32:37,202 Latency for request 384aa4ff with model gemma-7b: 51.5450 seconds
2024-09-24 14:32:37,202 Saving results with gpu monitoring
2024-09-24 14:32:37,204 Latency for request 9a1241f7 with model gemma-7b: 51.2820 seconds
2024-09-24 14:32:37,204 Saving results with gpu monitoring
2024-09-24 14:32:37,206 Latency for request b23e2290 with model gemma-7b: 51.0380 seconds
2024-09-24 14:32:37,207 Saving results with gpu monitoring
2024-09-24 14:32:37,209 Latency for request 06449ecc with model gemma-7b: 50.8160 seconds
2024-09-24 14:32:37,209 Saving results with gpu monitoring
2024-09-24 14:32:37,212 Request with ID 6ccefd9d for model gemma-7b received
2024-09-24 14:32:37,212 Latency for request e4df6140 with model gemma-7b: 49.7200 seconds
2024-09-24 14:32:37,213 127.0.0.1 - - [24/Sep/2024 14:32:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:37,213 Saving results with gpu monitoring
2024-09-24 14:32:37,215 Latency for request 55d62f40 with model gemma-7b: 49.4790 seconds
2024-09-24 14:32:37,215 Saving results with gpu monitoring
2024-09-24 14:32:37,217 Latency for request 4e61abae with model gemma-7b: 49.1390 seconds
2024-09-24 14:32:37,217 Saving results with gpu monitoring
2024-09-24 14:32:37,219 Latency for request a484c28b with model gemma-7b: 48.9130 seconds
2024-09-24 14:32:37,219 Saving results with gpu monitoring
2024-09-24 14:32:37,221 Latency for request d2648dbb with model gemma-7b: 48.7610 seconds
2024-09-24 14:32:37,221 Saving results with gpu monitoring
2024-09-24 14:32:37,224 Latency for request 3041cb9c with model gemma-7b: 48.7030 seconds
2024-09-24 14:32:37,224 Saving results with gpu monitoring
2024-09-24 14:32:37,226 Latency for request c1bc6267 with model gemma-7b: 48.6210 seconds
2024-09-24 14:32:37,226 Saving results with gpu monitoring
2024-09-24 14:32:37,228 Latency for request c9455e34 with model gemma-7b: 48.5550 seconds
2024-09-24 14:32:37,228 Saving results with gpu monitoring
2024-09-24 14:32:37,230 Latency for request ec430693 with model gemma-7b: 47.9150 seconds
2024-09-24 14:32:37,230 Saving results with gpu monitoring
2024-09-24 14:32:37,232 Latency for request f27db080 with model gemma-7b: 47.8730 seconds
2024-09-24 14:32:37,232 Saving results with gpu monitoring
2024-09-24 14:32:37,234 Latency for request 17037915 with model gemma-7b: 47.7600 seconds
2024-09-24 14:32:37,234 Saving results with gpu monitoring
2024-09-24 14:32:37,236 Latency for request 92b1eb37 with model gemma-7b: 47.5550 seconds
2024-09-24 14:32:37,236 Saving results with gpu monitoring
2024-09-24 14:32:37,238 Latency for request 3a56b7e1 with model gemma-7b: 46.9600 seconds
2024-09-24 14:32:37,238 Saving results with gpu monitoring
2024-09-24 14:32:37,240 Latency for request 4b485504 with model gemma-7b: 46.5530 seconds
2024-09-24 14:32:37,240 Saving results with gpu monitoring
2024-09-24 14:32:37,242 Latency for request 6b47c122 with model gemma-7b: 46.5300 seconds
2024-09-24 14:32:37,242 Saving results with gpu monitoring
2024-09-24 14:32:37,244 Latency for request 5e378353 with model gemma-7b: 46.1680 seconds
2024-09-24 14:32:37,244 Saving results with gpu monitoring
2024-09-24 14:32:37,246 Latency for request e8527a73 with model gemma-7b: 46.1170 seconds
2024-09-24 14:32:37,246 Saving results with gpu monitoring
2024-09-24 14:32:37,248 Latency for request ae7e7ea9 with model gemma-7b: 45.6830 seconds
2024-09-24 14:32:37,248 Saving results with gpu monitoring
2024-09-24 14:32:37,250 Latency for request 3b4d1692 with model gemma-7b: 44.8010 seconds
2024-09-24 14:32:37,250 Saving results with gpu monitoring
2024-09-24 14:32:37,252 Latency for request 195c1fcd with model gemma-7b: 44.7330 seconds
2024-09-24 14:32:37,252 Saving results with gpu monitoring
2024-09-24 14:32:37,254 Latency for request 5c674f1e with model gemma-7b: 44.5320 seconds
2024-09-24 14:32:37,254 Saving results with gpu monitoring
2024-09-24 14:32:37,256 Latency for request 7328d4f0 with model gemma-7b: 44.5090 seconds
2024-09-24 14:32:37,256 Saving results with gpu monitoring
2024-09-24 14:32:37,258 Latency for request e189f345 with model gemma-7b: 44.3810 seconds
2024-09-24 14:32:37,258 Saving results with gpu monitoring
2024-09-24 14:32:37,260 Latency for request ec532a3a with model gemma-7b: 44.1190 seconds
2024-09-24 14:32:37,260 Saving results with gpu monitoring
2024-09-24 14:32:37,262 Latency for request a759472f with model gemma-7b: 43.8450 seconds
2024-09-24 14:32:37,262 Saving results with gpu monitoring
2024-09-24 14:32:37,264 Latency for request 8fdf5775 with model gemma-7b: 42.7770 seconds
2024-09-24 14:32:37,264 Saving results with gpu monitoring
2024-09-24 14:32:37,266 Latency for request 15b6b5db with model gemma-7b: 42.5650 seconds
2024-09-24 14:32:37,266 Saving results with gpu monitoring
2024-09-24 14:32:37,268 Latency for request 8b0384b9 with model gemma-7b: 42.0140 seconds
2024-09-24 14:32:37,268 Saving results with gpu monitoring
2024-09-24 14:32:37,270 Latency for request 8c61f5e9 with model gemma-7b: 41.8630 seconds
2024-09-24 14:32:37,270 Saving results with gpu monitoring
2024-09-24 14:32:37,272 Latency for request ae8c9649 with model gemma-7b: 41.7500 seconds
2024-09-24 14:32:37,272 Saving results with gpu monitoring
2024-09-24 14:32:37,274 Latency for request 85ec1eb5 with model gemma-7b: 41.0350 seconds
2024-09-24 14:32:37,274 Saving results with gpu monitoring
2024-09-24 14:32:37,276 Latency for request 24ec688c with model gemma-7b: 41.0010 seconds
2024-09-24 14:32:37,276 Saving results with gpu monitoring
2024-09-24 14:32:37,278 Latency for request 1c4c6f0e with model gemma-7b: 40.7710 seconds
2024-09-24 14:32:37,278 Saving results with gpu monitoring
2024-09-24 14:32:37,280 Latency for request 72e5af68 with model gemma-7b: 40.7370 seconds
2024-09-24 14:32:37,280 Saving results with gpu monitoring
2024-09-24 14:32:37,282 Latency for request b8ff57f8 with model gemma-7b: 40.7280 seconds
2024-09-24 14:32:37,282 Saving results with gpu monitoring
2024-09-24 14:32:37,283 Latency for request b12f63e1 with model gemma-7b: 40.2210 seconds
2024-09-24 14:32:37,284 Saving results with gpu monitoring
2024-09-24 14:32:37,285 Latency for request 521f6491 with model gemma-7b: 39.1550 seconds
2024-09-24 14:32:37,285 Saving results with gpu monitoring
2024-09-24 14:32:37,287 Latency for request 9e15bae6 with model gemma-7b: 39.0600 seconds
2024-09-24 14:32:37,287 Saving results with gpu monitoring
2024-09-24 14:32:37,289 Latency for request 11eaa55e with model gemma-7b: 38.8320 seconds
2024-09-24 14:32:37,289 Saving results with gpu monitoring
2024-09-24 14:32:37,291 Latency for request 8b1c8bda with model gemma-7b: 37.8700 seconds
2024-09-24 14:32:37,291 Saving results with gpu monitoring
2024-09-24 14:32:37,293 Latency for request 5c4eec52 with model gemma-7b: 37.4160 seconds
2024-09-24 14:32:37,293 Saving results with gpu monitoring
2024-09-24 14:32:37,295 Latency for request b24807f2 with model gemma-7b: 36.8710 seconds
2024-09-24 14:32:37,295 Saving results with gpu monitoring
2024-09-24 14:32:37,297 Latency for request 435d18ec with model gemma-7b: 36.5080 seconds
2024-09-24 14:32:37,297 Saving results with gpu monitoring
2024-09-24 14:32:37,299 Latency for request 64d843eb with model gemma-7b: 36.1360 seconds
2024-09-24 14:32:37,299 Saving results with gpu monitoring
2024-09-24 14:32:37,301 Latency for request 0c9f8368 with model gemma-7b: 34.7570 seconds
2024-09-24 14:32:37,301 Saving results with gpu monitoring
2024-09-24 14:32:37,303 Latency for request 83bdf9b6 with model gemma-7b: 34.4760 seconds
2024-09-24 14:32:37,303 Saving results with gpu monitoring
2024-09-24 14:32:37,305 Latency for request d18fa51b with model gemma-7b: 34.1020 seconds
2024-09-24 14:32:37,305 Saving results with gpu monitoring
2024-09-24 14:32:37,307 Latency for request c1c27ef8 with model gemma-7b: 33.7250 seconds
2024-09-24 14:32:37,307 Saving results with gpu monitoring
2024-09-24 14:32:37,309 Latency for request 22e33733 with model gemma-7b: 33.6200 seconds
2024-09-24 14:32:37,309 Saving results with gpu monitoring
2024-09-24 14:32:37,311 Latency for request f887f26a with model gemma-7b: 33.2020 seconds
2024-09-24 14:32:37,311 Saving results with gpu monitoring
2024-09-24 14:32:37,313 Latency for request 1e2b0ac1 with model gemma-7b: 33.0870 seconds
2024-09-24 14:32:37,313 Saving results with gpu monitoring
2024-09-24 14:32:37,315 127.0.0.1 - - [24/Sep/2024 14:32:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:37,315 Next: call load_model for llama3-8b
2024-09-24 14:32:37,447 Unloaded previous model
2024-09-24 14:32:37,662 Request with ID 28c94e2d for model llama3-8b received
2024-09-24 14:32:37,664 127.0.0.1 - - [24/Sep/2024 14:32:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:37,666 Request with ID 4c09222e for model gemma-7b received
2024-09-24 14:32:37,666 127.0.0.1 - - [24/Sep/2024 14:32:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:37,737 Request with ID e113e063 for model gemma-7b received
2024-09-24 14:32:37,740 127.0.0.1 - - [24/Sep/2024 14:32:37] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:38,052 Request with ID fa6dc8fa for model granite-7b received
2024-09-24 14:32:38,053 127.0.0.1 - - [24/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:38,159 Request with ID fc7877a9 for model llama3-8b received
2024-09-24 14:32:38,160 127.0.0.1 - - [24/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:38,164 Request with ID 37b902a3 for model llama3-8b received
2024-09-24 14:32:38,165 127.0.0.1 - - [24/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:38,439 Request with ID 1112a1c8 for model llama3-8b received
2024-09-24 14:32:38,439 127.0.0.1 - - [24/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:38,869 Request with ID 3b698410 for model gemma-7b received
2024-09-24 14:32:38,869 127.0.0.1 - - [24/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:38,876 Request with ID 7b6dc5bc for model gemma-7b received
2024-09-24 14:32:38,877 127.0.0.1 - - [24/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:38,891 Request with ID 035217c9 for model granite-7b received
2024-09-24 14:32:38,892 127.0.0.1 - - [24/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:38,983 Request with ID e63772c4 for model gemma-7b received
2024-09-24 14:32:38,983 127.0.0.1 - - [24/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:39,017 Request with ID 17a8b92a for model gemma-7b received
2024-09-24 14:32:39,017 127.0.0.1 - - [24/Sep/2024 14:32:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:39,142 Request with ID aa132414 for model llama3-8b received
2024-09-24 14:32:39,143 127.0.0.1 - - [24/Sep/2024 14:32:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:39,305 Request with ID 795f32e3 for model llama3-8b received
2024-09-24 14:32:39,305 127.0.0.1 - - [24/Sep/2024 14:32:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:39,382 Request with ID 976a3adb for model gemma-7b received
2024-09-24 14:32:39,383 127.0.0.1 - - [24/Sep/2024 14:32:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:39,477 Request with ID 17dc2c8b for model gemma-7b received
2024-09-24 14:32:39,477 127.0.0.1 - - [24/Sep/2024 14:32:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:39,538 Request with ID 0e98e920 for model gemma-7b received
2024-09-24 14:32:39,539 127.0.0.1 - - [24/Sep/2024 14:32:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:39,557 Request with ID 505544e6 for model gemma-7b received
2024-09-24 14:32:39,557 127.0.0.1 - - [24/Sep/2024 14:32:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:39,737 Request with ID d4489971 for model llama3-8b received
2024-09-24 14:32:39,738 127.0.0.1 - - [24/Sep/2024 14:32:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:39,770 Request with ID 4d4460c9 for model gemma-7b received
2024-09-24 14:32:39,771 127.0.0.1 - - [24/Sep/2024 14:32:39] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:40,236 Request with ID 28257613 for model llama3-8b received
2024-09-24 14:32:40,237 127.0.0.1 - - [24/Sep/2024 14:32:40] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:40,321 Request with ID aba7bf71 for model llama3-8b received
2024-09-24 14:32:40,322 127.0.0.1 - - [24/Sep/2024 14:32:40] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:40,399 Request with ID b2777126 for model granite-7b received
2024-09-24 14:32:40,400 127.0.0.1 - - [24/Sep/2024 14:32:40] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:40,484 Request with ID 63ad2552 for model llama3-8b received
2024-09-24 14:32:40,485 127.0.0.1 - - [24/Sep/2024 14:32:40] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:40,520 Request with ID bbf8f71d for model llama3-8b received
2024-09-24 14:32:40,521 127.0.0.1 - - [24/Sep/2024 14:32:40] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:40,581 Request with ID 6f42356e for model llama3-8b received
2024-09-24 14:32:40,581 127.0.0.1 - - [24/Sep/2024 14:32:40] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:40,646 Request with ID e66f9a8c for model gemma-7b received
2024-09-24 14:32:40,646 127.0.0.1 - - [24/Sep/2024 14:32:40] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:40,782 Request with ID 79a47a01 for model llama3-8b received
2024-09-24 14:32:40,782 127.0.0.1 - - [24/Sep/2024 14:32:40] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:40,855 Request with ID 12b212cb for model gemma-7b received
2024-09-24 14:32:40,856 127.0.0.1 - - [24/Sep/2024 14:32:40] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:41,191 Request with ID 5e7f94bf for model llama3-8b received
2024-09-24 14:32:41,192 127.0.0.1 - - [24/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:41,278 Request with ID 98142dab for model llama3-8b received
2024-09-24 14:32:41,279 127.0.0.1 - - [24/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:41,406 Request with ID ce21b347 for model llama3-8b received
2024-09-24 14:32:41,407 127.0.0.1 - - [24/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:41,484 Request with ID 3c2bcdc9 for model llama3-8b received
2024-09-24 14:32:41,484 127.0.0.1 - - [24/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:41,558 Request with ID 7df0fbdd for model granite-7b received
2024-09-24 14:32:41,559 127.0.0.1 - - [24/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:41,570 Request with ID bbd5b610 for model llama3-8b received
2024-09-24 14:32:41,571 127.0.0.1 - - [24/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:41,775 Request with ID 113b95b6 for model llama3-8b received
2024-09-24 14:32:41,776 127.0.0.1 - - [24/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:41,838 Request with ID dabb1d39 for model gemma-7b received
2024-09-24 14:32:41,838 127.0.0.1 - - [24/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:41,893 Request with ID d7206d9b for model llama3-8b received
2024-09-24 14:32:41,893 127.0.0.1 - - [24/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:42,086 Request with ID 00a97724 for model gemma-7b received
2024-09-24 14:32:42,087 127.0.0.1 - - [24/Sep/2024 14:32:42] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:42,100 Request with ID 4c430854 for model llama3-8b received
2024-09-24 14:32:42,100 127.0.0.1 - - [24/Sep/2024 14:32:42] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:42,143 Request with ID 6df84952 for model granite-7b received
2024-09-24 14:32:42,143 127.0.0.1 - - [24/Sep/2024 14:32:42] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:42,234 Request with ID 69b6a8da for model llama3-8b received
2024-09-24 14:32:42,234 127.0.0.1 - - [24/Sep/2024 14:32:42] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:42,267 Request with ID de707fa5 for model gemma-7b received
2024-09-24 14:32:42,267 127.0.0.1 - - [24/Sep/2024 14:32:42] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:42,388 Request with ID 345391d9 for model granite-7b received
2024-09-24 14:32:42,388 127.0.0.1 - - [24/Sep/2024 14:32:42] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:42,792 Request with ID 6ad9af62 for model granite-7b received
2024-09-24 14:32:42,793 127.0.0.1 - - [24/Sep/2024 14:32:42] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:43,255 Request with ID f45f5c31 for model llama3-8b received
2024-09-24 14:32:43,256 Request with ID dd836f04 for model llama3-8b received
2024-09-24 14:32:43,256 127.0.0.1 - - [24/Sep/2024 14:32:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:43,257 127.0.0.1 - - [24/Sep/2024 14:32:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:43,416 Request with ID 2ead7771 for model llama3-8b received
2024-09-24 14:32:43,417 127.0.0.1 - - [24/Sep/2024 14:32:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:43,439 Request with ID 357cfd8d for model gemma-7b received
2024-09-24 14:32:43,440 127.0.0.1 - - [24/Sep/2024 14:32:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:43,771 Request with ID c5e19bbe for model gemma-7b received
2024-09-24 14:32:43,771 127.0.0.1 - - [24/Sep/2024 14:32:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:43,872 Request with ID 213363ac for model gemma-7b received
2024-09-24 14:32:43,872 127.0.0.1 - - [24/Sep/2024 14:32:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:43,900 Request with ID 36462902 for model granite-7b received
2024-09-24 14:32:43,901 127.0.0.1 - - [24/Sep/2024 14:32:43] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:44,513 Request with ID 13ebffe2 for model llama3-8b received
2024-09-24 14:32:44,513 127.0.0.1 - - [24/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:44,762 Request with ID 37f33c34 for model llama3-8b received
2024-09-24 14:32:44,762 127.0.0.1 - - [24/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:44,799 Request with ID c0f15a38 for model llama3-8b received
2024-09-24 14:32:44,799 127.0.0.1 - - [24/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:44,903 Request with ID 1d853333 for model llama3-8b received
2024-09-24 14:32:44,904 127.0.0.1 - - [24/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:44,928 Request with ID 56c979ce for model llama3-8b received
2024-09-24 14:32:44,928 127.0.0.1 - - [24/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:44,969 Request with ID 2fd0b442 for model gemma-7b received
2024-09-24 14:32:44,969 127.0.0.1 - - [24/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:45,160 Request with ID 2d43dc9d for model llama3-8b received
2024-09-24 14:32:45,160 127.0.0.1 - - [24/Sep/2024 14:32:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:45,218 Request with ID e0ebfe4c for model llama3-8b received
2024-09-24 14:32:45,218 127.0.0.1 - - [24/Sep/2024 14:32:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:45,385 Request with ID 0c067ae2 for model llama3-8b received
2024-09-24 14:32:45,386 127.0.0.1 - - [24/Sep/2024 14:32:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:45,505 Request with ID 546b4c3c for model llama3-8b received
2024-09-24 14:32:45,506 127.0.0.1 - - [24/Sep/2024 14:32:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:45,653 Request with ID 94221e5c for model llama3-8b received
2024-09-24 14:32:45,654 127.0.0.1 - - [24/Sep/2024 14:32:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:45,918 Request with ID 4cb71379 for model gemma-7b received
2024-09-24 14:32:45,918 127.0.0.1 - - [24/Sep/2024 14:32:45] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:46,021 Request with ID aa00ba50 for model llama3-8b received
2024-09-24 14:32:46,022 127.0.0.1 - - [24/Sep/2024 14:32:46] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:46,624 Request with ID 943e17df for model llama3-8b received
2024-09-24 14:32:46,624 127.0.0.1 - - [24/Sep/2024 14:32:46] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:46,827 Request with ID 8714dd75 for model llama3-8b received
2024-09-24 14:32:46,827 Batch size condition met for model llama3-8b
2024-09-24 14:32:46,949 Request with ID a2f4ac62 for model llama3-8b received
2024-09-24 14:32:46,950 127.0.0.1 - - [24/Sep/2024 14:32:46] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:47,118 Request with ID 17b4d393 for model llama3-8b received
2024-09-24 14:32:47,120 Request with ID 3f7b2b8c for model granite-7b received
2024-09-24 14:32:47,120 127.0.0.1 - - [24/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:47,121 127.0.0.1 - - [24/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:47,184 Request with ID 2ec2ae31 for model llama3-8b received
2024-09-24 14:32:47,185 127.0.0.1 - - [24/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:47,364 Request with ID 3ffd32a0 for model llama3-8b received
2024-09-24 14:32:47,365 127.0.0.1 - - [24/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:47,445 Request with ID 32d9d33d for model gemma-7b received
2024-09-24 14:32:47,445 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-24 14:32:47,446 Dynamic batch size condition met for model gemma-7b
2024-09-24 14:32:47,507 Request with ID e5fdc404 for model llama3-8b received
2024-09-24 14:32:47,508 127.0.0.1 - - [24/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:47,781 Request with ID d76a5384 for model gemma-7b received
2024-09-24 14:32:47,782 127.0.0.1 - - [24/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:47,920 Request with ID 08bab6b3 for model llama3-8b received
2024-09-24 14:32:47,921 Request with ID ae729396 for model gemma-7b received
2024-09-24 14:32:47,922 127.0.0.1 - - [24/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:47,922 127.0.0.1 - - [24/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:47,946 Request with ID 49400972 for model granite-7b received
2024-09-24 14:32:47,947 127.0.0.1 - - [24/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:48,059 Request with ID 300ba46f for model llama3-8b received
2024-09-24 14:32:48,060 127.0.0.1 - - [24/Sep/2024 14:32:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:48,073 Request with ID 3e157f06 for model llama3-8b received
2024-09-24 14:32:48,073 127.0.0.1 - - [24/Sep/2024 14:32:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:48,081 Request with ID ee04b55c for model llama3-8b received
2024-09-24 14:32:48,081 127.0.0.1 - - [24/Sep/2024 14:32:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:48,199 Request with ID 10cfb611 for model gemma-7b received
2024-09-24 14:32:48,199 127.0.0.1 - - [24/Sep/2024 14:32:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:48,327 Request with ID 33af6529 for model llama3-8b received
2024-09-24 14:32:48,327 127.0.0.1 - - [24/Sep/2024 14:32:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:48,500 Request with ID 1d4f5dd3 for model llama3-8b received
2024-09-24 14:32:48,500 127.0.0.1 - - [24/Sep/2024 14:32:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:48,696 Request with ID c784e475 for model llama3-8b received
2024-09-24 14:32:48,697 127.0.0.1 - - [24/Sep/2024 14:32:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:48,717 Request with ID 356c27ff for model llama3-8b received
2024-09-24 14:32:48,717 127.0.0.1 - - [24/Sep/2024 14:32:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:48,846 Request with ID 0b4905db for model gemma-7b received
2024-09-24 14:32:48,847 127.0.0.1 - - [24/Sep/2024 14:32:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:48,866 Request with ID d1379ae9 for model llama3-8b received
2024-09-24 14:32:48,867 127.0.0.1 - - [24/Sep/2024 14:32:48] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:49,207 Request with ID eb6e8a7d for model gemma-7b received
2024-09-24 14:32:49,208 127.0.0.1 - - [24/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:49,336 Request with ID cac3cfdb for model llama3-8b received
2024-09-24 14:32:49,337 127.0.0.1 - - [24/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:49,352 Request with ID 12e74ce2 for model llama3-8b received
2024-09-24 14:32:49,352 127.0.0.1 - - [24/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:49,526 Request with ID 988fd0f4 for model llama3-8b received
2024-09-24 14:32:49,527 127.0.0.1 - - [24/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:49,552 Request with ID 685497d7 for model llama3-8b received
2024-09-24 14:32:49,553 127.0.0.1 - - [24/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:49,576 Request with ID a61837a7 for model granite-7b received
2024-09-24 14:32:49,576 127.0.0.1 - - [24/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:49,801 Request with ID 717e052d for model llama3-8b received
2024-09-24 14:32:49,801 127.0.0.1 - - [24/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:50,134 Request with ID ef827e25 for model llama3-8b received
2024-09-24 14:32:50,135 127.0.0.1 - - [24/Sep/2024 14:32:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:50,168 Request with ID 104cdf06 for model llama3-8b received
2024-09-24 14:32:50,168 127.0.0.1 - - [24/Sep/2024 14:32:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:50,194 Request with ID 09822940 for model llama3-8b received
2024-09-24 14:32:50,195 127.0.0.1 - - [24/Sep/2024 14:32:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:50,543 Request with ID 7d294ec4 for model granite-7b received
2024-09-24 14:32:50,544 127.0.0.1 - - [24/Sep/2024 14:32:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:50,725 Request with ID 8d6039d9 for model llama3-8b received
2024-09-24 14:32:50,725 127.0.0.1 - - [24/Sep/2024 14:32:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:50,899 Request with ID c63ed0ce for model granite-7b received
2024-09-24 14:32:50,899 127.0.0.1 - - [24/Sep/2024 14:32:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:50,932 Request with ID e231088a for model gemma-7b received
2024-09-24 14:32:50,933 127.0.0.1 - - [24/Sep/2024 14:32:50] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:51,254 Request with ID 1a664768 for model llama3-8b received
2024-09-24 14:32:51,255 127.0.0.1 - - [24/Sep/2024 14:32:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:51,264 Request with ID 24be42e2 for model granite-7b received
2024-09-24 14:32:51,264 127.0.0.1 - - [24/Sep/2024 14:32:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:51,269 Request with ID b40f1c0b for model gemma-7b received
2024-09-24 14:32:51,270 127.0.0.1 - - [24/Sep/2024 14:32:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:51,568 Request with ID beaa2d5f for model llama3-8b received
2024-09-24 14:32:51,569 127.0.0.1 - - [24/Sep/2024 14:32:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:51,628 Request with ID 88f35b59 for model llama3-8b received
2024-09-24 14:32:51,629 127.0.0.1 - - [24/Sep/2024 14:32:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:51,727 Loaded model llama3-8b
2024-09-24 14:32:51,730 Batch processing started for model llama3-8b
2024-09-24 14:32:51,817 Request with ID 5160de69 for model gemma-7b received
2024-09-24 14:32:51,818 127.0.0.1 - - [24/Sep/2024 14:32:51] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:52,059 Request with ID 96590a0b for model granite-7b received
2024-09-24 14:32:52,060 127.0.0.1 - - [24/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:52,357 Request with ID 0a22911d for model gemma-7b received
2024-09-24 14:32:52,358 127.0.0.1 - - [24/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:52,405 Request with ID b5e46137 for model gemma-7b received
2024-09-24 14:32:52,406 127.0.0.1 - - [24/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:52,696 Request with ID 7ea95fa5 for model llama3-8b received
2024-09-24 14:32:52,697 127.0.0.1 - - [24/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:52,797 Request with ID 1dd04c3a for model llama3-8b received
2024-09-24 14:32:52,798 127.0.0.1 - - [24/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:53,145 Request with ID 23f7383a for model llama3-8b received
2024-09-24 14:32:53,145 127.0.0.1 - - [24/Sep/2024 14:32:53] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:53,340 Request with ID 14f0cffc for model llama3-8b received
2024-09-24 14:32:53,340 127.0.0.1 - - [24/Sep/2024 14:32:53] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:53,828 Request with ID 3b55a847 for model gemma-7b received
2024-09-24 14:32:53,829 127.0.0.1 - - [24/Sep/2024 14:32:53] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:53,881 Request with ID 1ffc874a for model llama3-8b received
2024-09-24 14:32:53,881 127.0.0.1 - - [24/Sep/2024 14:32:53] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:53,999 Request with ID c418ee8b for model granite-7b received
2024-09-24 14:32:53,999 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-24 14:32:54,000 Dynamic batch size condition met for model granite-7b
2024-09-24 14:32:54,160 Request with ID 04efcef5 for model gemma-7b received
2024-09-24 14:32:54,161 127.0.0.1 - - [24/Sep/2024 14:32:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:54,399 Request with ID 2211f7fc for model llama3-8b received
2024-09-24 14:32:54,400 127.0.0.1 - - [24/Sep/2024 14:32:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:54,432 Request with ID 78f50e58 for model llama3-8b received
2024-09-24 14:32:54,433 127.0.0.1 - - [24/Sep/2024 14:32:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:54,441 Request with ID d7aa5efc for model llama3-8b received
2024-09-24 14:32:54,442 127.0.0.1 - - [24/Sep/2024 14:32:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:54,454 Request with ID 72f060d5 for model llama3-8b received
2024-09-24 14:32:54,455 127.0.0.1 - - [24/Sep/2024 14:32:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:54,527 Request with ID 65d50e7d for model llama3-8b received
2024-09-24 14:32:54,527 127.0.0.1 - - [24/Sep/2024 14:32:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:54,558 Request with ID 6ffccc3e for model llama3-8b received
2024-09-24 14:32:54,558 127.0.0.1 - - [24/Sep/2024 14:32:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:54,637 Request with ID 0f38c4d3 for model granite-7b received
2024-09-24 14:32:54,638 127.0.0.1 - - [24/Sep/2024 14:32:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:54,730 Request with ID ed00845a for model gemma-7b received
2024-09-24 14:32:54,731 127.0.0.1 - - [24/Sep/2024 14:32:54] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:55,210 Request with ID 45667fd1 for model llama3-8b received
2024-09-24 14:32:55,211 127.0.0.1 - - [24/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:55,264 Request with ID 4816ee56 for model llama3-8b received
2024-09-24 14:32:55,264 127.0.0.1 - - [24/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:55,444 Request with ID da30703f for model llama3-8b received
2024-09-24 14:32:55,445 127.0.0.1 - - [24/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:55,473 Request with ID 050b1ada for model llama3-8b received
2024-09-24 14:32:55,473 127.0.0.1 - - [24/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:55,731 Request with ID a4898be1 for model llama3-8b received
2024-09-24 14:32:55,731 127.0.0.1 - - [24/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:55,835 Request with ID dfe098aa for model granite-7b received
2024-09-24 14:32:55,835 127.0.0.1 - - [24/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:55,914 Request with ID 7f054174 for model gemma-7b received
2024-09-24 14:32:55,915 127.0.0.1 - - [24/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:55,979 Request with ID 4f9631e4 for model gemma-7b received
2024-09-24 14:32:55,979 127.0.0.1 - - [24/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:56,056 Request with ID 35d842a0 for model granite-7b received
2024-09-24 14:32:56,057 127.0.0.1 - - [24/Sep/2024 14:32:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:56,131 Request with ID c2b15f67 for model gemma-7b received
2024-09-24 14:32:56,131 127.0.0.1 - - [24/Sep/2024 14:32:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:56,225 Request with ID 76a8d5d8 for model llama3-8b received
2024-09-24 14:32:56,225 127.0.0.1 - - [24/Sep/2024 14:32:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:56,266 Request with ID c92f2293 for model gemma-7b received
2024-09-24 14:32:56,266 127.0.0.1 - - [24/Sep/2024 14:32:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:56,577 Request with ID d0e43a8c for model llama3-8b received
2024-09-24 14:32:56,577 127.0.0.1 - - [24/Sep/2024 14:32:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:56,653 Request with ID 879a597e for model llama3-8b received
2024-09-24 14:32:56,654 127.0.0.1 - - [24/Sep/2024 14:32:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:56,952 Request with ID 8fd85184 for model gemma-7b received
2024-09-24 14:32:56,952 127.0.0.1 - - [24/Sep/2024 14:32:56] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:57,042 Request with ID 60ad6091 for model gemma-7b received
2024-09-24 14:32:57,042 127.0.0.1 - - [24/Sep/2024 14:32:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:57,325 Request with ID 54deb785 for model llama3-8b received
2024-09-24 14:32:57,325 127.0.0.1 - - [24/Sep/2024 14:32:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:57,372 Request with ID e1c4460b for model llama3-8b received
2024-09-24 14:32:57,373 127.0.0.1 - - [24/Sep/2024 14:32:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:57,390 Request with ID 6e6eba96 for model llama3-8b received
2024-09-24 14:32:57,390 127.0.0.1 - - [24/Sep/2024 14:32:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:57,820 Request with ID 4560e0ad for model llama3-8b received
2024-09-24 14:32:57,821 127.0.0.1 - - [24/Sep/2024 14:32:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:57,838 Request with ID 483ba8cb for model llama3-8b received
2024-09-24 14:32:57,838 127.0.0.1 - - [24/Sep/2024 14:32:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:57,862 Request with ID 2af7f20e for model llama3-8b received
2024-09-24 14:32:57,863 127.0.0.1 - - [24/Sep/2024 14:32:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:57,998 Request with ID 10711e9d for model granite-7b received
2024-09-24 14:32:57,999 127.0.0.1 - - [24/Sep/2024 14:32:57] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:58,001 Request with ID 9ab8574f for model llama3-8b received
2024-09-24 14:32:58,002 127.0.0.1 - - [24/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:58,014 Request with ID 7f443177 for model gemma-7b received
2024-09-24 14:32:58,015 127.0.0.1 - - [24/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:58,261 Request with ID 21dea51c for model llama3-8b received
2024-09-24 14:32:58,262 127.0.0.1 - - [24/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:58,276 Request with ID a239ff6d for model llama3-8b received
2024-09-24 14:32:58,276 127.0.0.1 - - [24/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:58,411 Request with ID baeb19a6 for model llama3-8b received
2024-09-24 14:32:58,411 127.0.0.1 - - [24/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:58,677 Request with ID d1344bca for model gemma-7b received
2024-09-24 14:32:58,678 127.0.0.1 - - [24/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:58,834 Request with ID a5491b96 for model gemma-7b received
2024-09-24 14:32:58,835 127.0.0.1 - - [24/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:58,870 Request with ID c32f7be9 for model llama3-8b received
2024-09-24 14:32:58,870 127.0.0.1 - - [24/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:59,040 Request with ID b4498f13 for model llama3-8b received
2024-09-24 14:32:59,040 127.0.0.1 - - [24/Sep/2024 14:32:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:59,173 Request with ID 12142833 for model gemma-7b received
2024-09-24 14:32:59,174 127.0.0.1 - - [24/Sep/2024 14:32:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:59,406 Request with ID 69d19c56 for model llama3-8b received
2024-09-24 14:32:59,406 127.0.0.1 - - [24/Sep/2024 14:32:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:59,443 Request with ID 5a09526c for model gemma-7b received
2024-09-24 14:32:59,443 127.0.0.1 - - [24/Sep/2024 14:32:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:59,586 Request with ID ec799bca for model gemma-7b received
2024-09-24 14:32:59,588 Request with ID 1fd58ad1 for model gemma-7b received
2024-09-24 14:32:59,588 127.0.0.1 - - [24/Sep/2024 14:32:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:59,589 127.0.0.1 - - [24/Sep/2024 14:32:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:59,832 Request with ID 984510eb for model llama3-8b received
2024-09-24 14:32:59,833 127.0.0.1 - - [24/Sep/2024 14:32:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:59,841 Request with ID 9be2f732 for model llama3-8b received
2024-09-24 14:32:59,842 127.0.0.1 - - [24/Sep/2024 14:32:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:32:59,992 Request with ID 37fba178 for model gemma-7b received
2024-09-24 14:32:59,993 127.0.0.1 - - [24/Sep/2024 14:32:59] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:00,050 Request with ID bda0d0c3 for model granite-7b received
2024-09-24 14:33:00,050 127.0.0.1 - - [24/Sep/2024 14:33:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:00,096 Request with ID 5d9b14db for model llama3-8b received
2024-09-24 14:33:00,097 127.0.0.1 - - [24/Sep/2024 14:33:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:00,280 Request with ID e9c82220 for model llama3-8b received
2024-09-24 14:33:00,280 127.0.0.1 - - [24/Sep/2024 14:33:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:00,318 Request with ID c2a1a15a for model llama3-8b received
2024-09-24 14:33:00,319 127.0.0.1 - - [24/Sep/2024 14:33:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:00,423 Request with ID b91d7410 for model llama3-8b received
2024-09-24 14:33:00,424 Batch size condition met for model llama3-8b
2024-09-24 14:33:00,502 Request with ID 5df30696 for model llama3-8b received
2024-09-24 14:33:00,502 127.0.0.1 - - [24/Sep/2024 14:33:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:00,563 Request with ID 57008ae2 for model llama3-8b received
2024-09-24 14:33:00,564 127.0.0.1 - - [24/Sep/2024 14:33:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:00,646 Request with ID c849688f for model granite-7b received
2024-09-24 14:33:00,647 127.0.0.1 - - [24/Sep/2024 14:33:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:00,849 Request with ID b03f3d77 for model llama3-8b received
2024-09-24 14:33:00,851 Request with ID b952b58d for model llama3-8b received
2024-09-24 14:33:00,852 127.0.0.1 - - [24/Sep/2024 14:33:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:00,859 127.0.0.1 - - [24/Sep/2024 14:33:00] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:00,880 Processed batch: ['1d4b18fb', 'f25261ac', 'b3670cad', 'aa6b1bc2', 'd69515ec', '89a9239a', 'db48b3b2', 'c5ef94f0', 'd0623e95', '6c312872', '956cda42', '99b7bbbd', '9cc3167c', '950b1a1c', '962d885b', '8c4be0a4', 'f8ae6abd', '96e28863', '804d1e38', '366144c4', 'c84b8cee', '52153509', '57271fcd', '4d16f7f9', '109a56d6', '554e8ee3', '73a4d4bc', 'bf165072', 'c0eed571', 'd83f3bc7', 'eb7954c0', 'df2d950b', 'dc7e6a19', '4622d022', '5ab5b661', '25595042', '0f7808b9', 'af3d59ca', '09245d5b', '953ea3c8', '72d9b97d', '79f68411', 'f83d6ad8', '01a4ecb8', 'ca75e664', '6a260567', 'f8ce0cc9', 'a2e14a7a', 'f880c42d', '06783bac', 'd15c6351', 'fca8cb53', '4b5a8908', 'a6e37492', '547defd4', '81c03e95', '513d6481', 'f790c293', '8ebdb651', 'e9610a70', '28045251', 'df5520e7', '5cec2c48', 'c14285a3'] with model llama3-8b in 9.1499 seconds
2024-09-24 14:33:00,880 Saving sys info
2024-09-24 14:33:00,919 Latency for request 1d4b18fb with model llama3-8b: 40.1210 seconds
2024-09-24 14:33:00,919 Saving results with gpu monitoring
2024-09-24 14:33:00,922 Latency for request f25261ac with model llama3-8b: 40.0170 seconds
2024-09-24 14:33:00,923 Saving results with gpu monitoring
2024-09-24 14:33:00,925 Latency for request b3670cad with model llama3-8b: 39.9510 seconds
2024-09-24 14:33:00,925 Saving results with gpu monitoring
2024-09-24 14:33:00,927 Latency for request aa6b1bc2 with model llama3-8b: 39.4480 seconds
2024-09-24 14:33:00,927 Saving results with gpu monitoring
2024-09-24 14:33:00,929 Latency for request d69515ec with model llama3-8b: 39.0960 seconds
2024-09-24 14:33:00,929 Saving results with gpu monitoring
2024-09-24 14:33:00,931 Latency for request 89a9239a with model llama3-8b: 38.8780 seconds
2024-09-24 14:33:00,931 Saving results with gpu monitoring
2024-09-24 14:33:00,933 Latency for request db48b3b2 with model llama3-8b: 38.8760 seconds
2024-09-24 14:33:00,933 Saving results with gpu monitoring
2024-09-24 14:33:00,934 Latency for request c5ef94f0 with model llama3-8b: 38.7750 seconds
2024-09-24 14:33:00,935 Saving results with gpu monitoring
2024-09-24 14:33:00,936 Latency for request d0623e95 with model llama3-8b: 38.5700 seconds
2024-09-24 14:33:00,937 Saving results with gpu monitoring
2024-09-24 14:33:00,938 Latency for request 6c312872 with model llama3-8b: 37.8010 seconds
2024-09-24 14:33:00,939 Saving results with gpu monitoring
2024-09-24 14:33:00,940 Latency for request 956cda42 with model llama3-8b: 37.7670 seconds
2024-09-24 14:33:00,940 Saving results with gpu monitoring
2024-09-24 14:33:00,942 Latency for request 99b7bbbd with model llama3-8b: 37.6340 seconds
2024-09-24 14:33:00,942 Saving results with gpu monitoring
2024-09-24 14:33:00,944 Latency for request 9cc3167c with model llama3-8b: 37.3710 seconds
2024-09-24 14:33:00,944 Saving results with gpu monitoring
2024-09-24 14:33:00,946 Latency for request 950b1a1c with model llama3-8b: 37.2000 seconds
2024-09-24 14:33:00,946 Saving results with gpu monitoring
2024-09-24 14:33:00,948 Latency for request 962d885b with model llama3-8b: 36.7780 seconds
2024-09-24 14:33:00,948 Saving results with gpu monitoring
2024-09-24 14:33:00,950 Latency for request 8c4be0a4 with model llama3-8b: 36.7750 seconds
2024-09-24 14:33:00,950 Saving results with gpu monitoring
2024-09-24 14:33:00,952 Latency for request f8ae6abd with model llama3-8b: 36.6580 seconds
2024-09-24 14:33:00,952 Saving results with gpu monitoring
2024-09-24 14:33:00,954 Latency for request 96e28863 with model llama3-8b: 36.0510 seconds
2024-09-24 14:33:00,954 Saving results with gpu monitoring
2024-09-24 14:33:00,956 Latency for request 804d1e38 with model llama3-8b: 36.0200 seconds
2024-09-24 14:33:00,956 Saving results with gpu monitoring
2024-09-24 14:33:00,958 Latency for request 366144c4 with model llama3-8b: 35.8520 seconds
2024-09-24 14:33:00,958 Saving results with gpu monitoring
2024-09-24 14:33:00,960 Latency for request c84b8cee with model llama3-8b: 35.5510 seconds
2024-09-24 14:33:00,960 Saving results with gpu monitoring
2024-09-24 14:33:00,962 Latency for request 52153509 with model llama3-8b: 34.9910 seconds
2024-09-24 14:33:00,962 Saving results with gpu monitoring
2024-09-24 14:33:00,964 Latency for request 57271fcd with model llama3-8b: 34.1870 seconds
2024-09-24 14:33:00,964 Saving results with gpu monitoring
2024-09-24 14:33:00,966 Latency for request 4d16f7f9 with model llama3-8b: 34.1670 seconds
2024-09-24 14:33:00,966 Saving results with gpu monitoring
2024-09-24 14:33:00,968 Latency for request 109a56d6 with model llama3-8b: 33.8530 seconds
2024-09-24 14:33:00,968 Saving results with gpu monitoring
2024-09-24 14:33:00,970 Latency for request 554e8ee3 with model llama3-8b: 33.7210 seconds
2024-09-24 14:33:00,970 Saving results with gpu monitoring
2024-09-24 14:33:00,972 Latency for request 73a4d4bc with model llama3-8b: 33.6340 seconds
2024-09-24 14:33:00,972 Saving results with gpu monitoring
2024-09-24 14:33:00,974 Latency for request bf165072 with model llama3-8b: 33.5120 seconds
2024-09-24 14:33:00,974 Saving results with gpu monitoring
2024-09-24 14:33:00,976 Latency for request c0eed571 with model llama3-8b: 33.4470 seconds
2024-09-24 14:33:00,976 Saving results with gpu monitoring
2024-09-24 14:33:00,978 Latency for request d83f3bc7 with model llama3-8b: 33.4440 seconds
2024-09-24 14:33:00,978 Saving results with gpu monitoring
2024-09-24 14:33:00,980 Latency for request eb7954c0 with model llama3-8b: 33.0950 seconds
2024-09-24 14:33:00,980 Saving results with gpu monitoring
2024-09-24 14:33:00,982 Latency for request df2d950b with model llama3-8b: 32.9220 seconds
2024-09-24 14:33:00,982 Saving results with gpu monitoring
2024-09-24 14:33:00,984 Latency for request dc7e6a19 with model llama3-8b: 32.4820 seconds
2024-09-24 14:33:00,984 Saving results with gpu monitoring
2024-09-24 14:33:00,986 Latency for request 4622d022 with model llama3-8b: 32.4590 seconds
2024-09-24 14:33:00,986 Saving results with gpu monitoring
2024-09-24 14:33:00,988 Latency for request 5ab5b661 with model llama3-8b: 32.4330 seconds
2024-09-24 14:33:00,988 Saving results with gpu monitoring
2024-09-24 14:33:00,990 Latency for request 25595042 with model llama3-8b: 31.9870 seconds
2024-09-24 14:33:00,990 Saving results with gpu monitoring
2024-09-24 14:33:00,992 Latency for request 0f7808b9 with model llama3-8b: 31.9850 seconds
2024-09-24 14:33:00,992 Saving results with gpu monitoring
2024-09-24 14:33:00,994 Latency for request af3d59ca with model llama3-8b: 31.7420 seconds
2024-09-24 14:33:00,994 Saving results with gpu monitoring
2024-09-24 14:33:00,996 Latency for request 09245d5b with model llama3-8b: 31.6770 seconds
2024-09-24 14:33:00,996 Saving results with gpu monitoring
2024-09-24 14:33:00,998 Latency for request 953ea3c8 with model llama3-8b: 31.6220 seconds
2024-09-24 14:33:00,998 Saving results with gpu monitoring
2024-09-24 14:33:01,000 Latency for request 72d9b97d with model llama3-8b: 31.5730 seconds
2024-09-24 14:33:01,000 Saving results with gpu monitoring
2024-09-24 14:33:01,001 Latency for request 79f68411 with model llama3-8b: 31.2470 seconds
2024-09-24 14:33:01,002 Saving results with gpu monitoring
2024-09-24 14:33:01,003 Latency for request f83d6ad8 with model llama3-8b: 30.7840 seconds
2024-09-24 14:33:01,004 Saving results with gpu monitoring
2024-09-24 14:33:01,005 Latency for request 01a4ecb8 with model llama3-8b: 30.7240 seconds
2024-09-24 14:33:01,005 Saving results with gpu monitoring
2024-09-24 14:33:01,007 Latency for request ca75e664 with model llama3-8b: 30.5110 seconds
2024-09-24 14:33:01,007 Saving results with gpu monitoring
2024-09-24 14:33:01,009 Latency for request 6a260567 with model llama3-8b: 30.4500 seconds
2024-09-24 14:33:01,009 Saving results with gpu monitoring
2024-09-24 14:33:01,011 Latency for request f8ce0cc9 with model llama3-8b: 30.4240 seconds
2024-09-24 14:33:01,011 Saving results with gpu monitoring
2024-09-24 14:33:01,013 Latency for request a2e14a7a with model llama3-8b: 30.3260 seconds
2024-09-24 14:33:01,013 Saving results with gpu monitoring
2024-09-24 14:33:01,015 Latency for request f880c42d with model llama3-8b: 30.1150 seconds
2024-09-24 14:33:01,015 Saving results with gpu monitoring
2024-09-24 14:33:01,017 Latency for request 06783bac with model llama3-8b: 29.8970 seconds
2024-09-24 14:33:01,017 Saving results with gpu monitoring
2024-09-24 14:33:01,019 Latency for request d15c6351 with model llama3-8b: 29.8870 seconds
2024-09-24 14:33:01,019 Saving results with gpu monitoring
2024-09-24 14:33:01,021 Latency for request fca8cb53 with model llama3-8b: 29.8780 seconds
2024-09-24 14:33:01,021 Saving results with gpu monitoring
2024-09-24 14:33:01,023 Latency for request 4b5a8908 with model llama3-8b: 29.8500 seconds
2024-09-24 14:33:01,023 Saving results with gpu monitoring
2024-09-24 14:33:01,025 Latency for request a6e37492 with model llama3-8b: 29.8110 seconds
2024-09-24 14:33:01,025 Saving results with gpu monitoring
2024-09-24 14:33:01,027 Latency for request 547defd4 with model llama3-8b: 29.7120 seconds
2024-09-24 14:33:01,027 Saving results with gpu monitoring
2024-09-24 14:33:01,029 Latency for request 81c03e95 with model llama3-8b: 29.5270 seconds
2024-09-24 14:33:01,029 Saving results with gpu monitoring
2024-09-24 14:33:01,031 Latency for request 513d6481 with model llama3-8b: 28.6160 seconds
2024-09-24 14:33:01,031 Saving results with gpu monitoring
2024-09-24 14:33:01,033 Latency for request f790c293 with model llama3-8b: 28.5820 seconds
2024-09-24 14:33:01,033 Saving results with gpu monitoring
2024-09-24 14:33:01,035 Latency for request 8ebdb651 with model llama3-8b: 28.5570 seconds
2024-09-24 14:33:01,035 Saving results with gpu monitoring
2024-09-24 14:33:01,037 Latency for request e9610a70 with model llama3-8b: 28.2660 seconds
2024-09-24 14:33:01,037 Saving results with gpu monitoring
2024-09-24 14:33:01,039 Latency for request 28045251 with model llama3-8b: 28.0100 seconds
2024-09-24 14:33:01,039 Saving results with gpu monitoring
2024-09-24 14:33:01,041 Latency for request df5520e7 with model llama3-8b: 27.9890 seconds
2024-09-24 14:33:01,041 Saving results with gpu monitoring
2024-09-24 14:33:01,043 Latency for request 5cec2c48 with model llama3-8b: 27.9650 seconds
2024-09-24 14:33:01,043 Saving results with gpu monitoring
2024-09-24 14:33:01,045 Latency for request c14285a3 with model llama3-8b: 27.5100 seconds
2024-09-24 14:33:01,045 Saving results with gpu monitoring
2024-09-24 14:33:01,047 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:01,047 Next: call load_model for granite-7b
2024-09-24 14:33:01,155 Unloaded previous model
2024-09-24 14:33:01,156 Request with ID 55ddc237 for model llama3-8b received
2024-09-24 14:33:01,157 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:01,159 Request with ID cc6d2621 for model llama3-8b received
2024-09-24 14:33:01,159 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:01,235 Request with ID be4b0871 for model gemma-7b received
2024-09-24 14:33:01,236 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:01,237 Request with ID 5bcb0dbb for model granite-7b received
2024-09-24 14:33:01,237 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:01,242 Request with ID f8a42c53 for model llama3-8b received
2024-09-24 14:33:01,242 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:01,244 Request with ID 44d9d5c7 for model granite-7b received
2024-09-24 14:33:01,245 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:01,546 Request with ID de87f7b7 for model llama3-8b received
2024-09-24 14:33:01,552 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:01,687 Request with ID 46f17f0f for model llama3-8b received
2024-09-24 14:33:01,687 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:01,696 Request with ID b52eba9c for model llama3-8b received
2024-09-24 14:33:01,700 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:01,904 Request with ID 0050093e for model llama3-8b received
2024-09-24 14:33:01,905 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:01,906 Request with ID 3082493e for model llama3-8b received
2024-09-24 14:33:01,906 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:01,979 Request with ID bbf367c6 for model gemma-7b received
2024-09-24 14:33:01,980 127.0.0.1 - - [24/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:02,010 Request with ID 358688f9 for model llama3-8b received
2024-09-24 14:33:02,011 127.0.0.1 - - [24/Sep/2024 14:33:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:02,015 Request with ID da22a843 for model llama3-8b received
2024-09-24 14:33:02,016 127.0.0.1 - - [24/Sep/2024 14:33:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:02,300 Request with ID 091a408e for model llama3-8b received
2024-09-24 14:33:02,301 127.0.0.1 - - [24/Sep/2024 14:33:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:02,348 Request with ID da34a747 for model llama3-8b received
2024-09-24 14:33:02,348 127.0.0.1 - - [24/Sep/2024 14:33:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:02,629 Request with ID 9a7fe56a for model llama3-8b received
2024-09-24 14:33:02,629 127.0.0.1 - - [24/Sep/2024 14:33:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:02,755 Request with ID befabd3a for model llama3-8b received
2024-09-24 14:33:02,755 127.0.0.1 - - [24/Sep/2024 14:33:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:02,884 Request with ID 65d7bc01 for model llama3-8b received
2024-09-24 14:33:02,884 127.0.0.1 - - [24/Sep/2024 14:33:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:02,898 Request with ID 3335fe4b for model llama3-8b received
2024-09-24 14:33:02,898 127.0.0.1 - - [24/Sep/2024 14:33:02] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:03,343 Request with ID 976928f8 for model llama3-8b received
2024-09-24 14:33:03,343 127.0.0.1 - - [24/Sep/2024 14:33:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:03,460 Request with ID a48dc75f for model llama3-8b received
2024-09-24 14:33:03,460 127.0.0.1 - - [24/Sep/2024 14:33:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:03,587 Request with ID 5f3b8bff for model granite-7b received
2024-09-24 14:33:03,588 127.0.0.1 - - [24/Sep/2024 14:33:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:03,705 Request with ID e65e2f5f for model gemma-7b received
2024-09-24 14:33:03,706 127.0.0.1 - - [24/Sep/2024 14:33:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:03,747 Request with ID 97ebac17 for model gemma-7b received
2024-09-24 14:33:03,747 127.0.0.1 - - [24/Sep/2024 14:33:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:03,831 Request with ID c24b054d for model llama3-8b received
2024-09-24 14:33:03,831 127.0.0.1 - - [24/Sep/2024 14:33:03] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:03,907 Request with ID 18a7d43e for model gemma-7b received
2024-09-24 14:33:03,907 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-24 14:33:03,908 Dynamic batch size condition met for model gemma-7b
2024-09-24 14:33:04,000 Request with ID 8c521e3f for model llama3-8b received
2024-09-24 14:33:04,001 127.0.0.1 - - [24/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:04,007 Request with ID 29ad3195 for model granite-7b received
2024-09-24 14:33:04,007 127.0.0.1 - - [24/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:04,116 Request with ID bce31126 for model llama3-8b received
2024-09-24 14:33:04,116 Request with ID 9de4e74b for model llama3-8b received
2024-09-24 14:33:04,117 127.0.0.1 - - [24/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:04,118 127.0.0.1 - - [24/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:04,141 Request with ID 20b627f2 for model llama3-8b received
2024-09-24 14:33:04,141 127.0.0.1 - - [24/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:04,184 Request with ID 926f10a1 for model llama3-8b received
2024-09-24 14:33:04,184 127.0.0.1 - - [24/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:04,450 Request with ID fe0d1cc4 for model llama3-8b received
2024-09-24 14:33:04,451 127.0.0.1 - - [24/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:04,538 Request with ID b7954282 for model llama3-8b received
2024-09-24 14:33:04,539 127.0.0.1 - - [24/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:04,557 Request with ID 01d2bcee for model gemma-7b received
2024-09-24 14:33:04,558 127.0.0.1 - - [24/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:04,722 Request with ID 7ac3097f for model llama3-8b received
2024-09-24 14:33:04,722 127.0.0.1 - - [24/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:04,880 Request with ID 94815f5e for model llama3-8b received
2024-09-24 14:33:04,880 127.0.0.1 - - [24/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:05,271 Request with ID 52f3dd65 for model llama3-8b received
2024-09-24 14:33:05,272 Request with ID b4a2faa8 for model granite-7b received
2024-09-24 14:33:05,272 127.0.0.1 - - [24/Sep/2024 14:33:05] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:05,273 127.0.0.1 - - [24/Sep/2024 14:33:05] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:05,530 Request with ID 121f6ce2 for model gemma-7b received
2024-09-24 14:33:05,530 127.0.0.1 - - [24/Sep/2024 14:33:05] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:05,591 Request with ID 83193b4b for model gemma-7b received
2024-09-24 14:33:05,592 127.0.0.1 - - [24/Sep/2024 14:33:05] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:05,608 Request with ID eaf39259 for model llama3-8b received
2024-09-24 14:33:05,609 127.0.0.1 - - [24/Sep/2024 14:33:05] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:05,618 Request with ID 23bed027 for model llama3-8b received
2024-09-24 14:33:05,619 127.0.0.1 - - [24/Sep/2024 14:33:05] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:05,759 Request with ID 65d722ae for model llama3-8b received
2024-09-24 14:33:05,759 127.0.0.1 - - [24/Sep/2024 14:33:05] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:06,048 Request with ID 1f9da666 for model granite-7b received
2024-09-24 14:33:06,049 127.0.0.1 - - [24/Sep/2024 14:33:06] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:06,163 Request with ID 57fc5fef for model gemma-7b received
2024-09-24 14:33:06,163 127.0.0.1 - - [24/Sep/2024 14:33:06] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:06,291 Request with ID 77355619 for model llama3-8b received
2024-09-24 14:33:06,292 127.0.0.1 - - [24/Sep/2024 14:33:06] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:06,300 Request with ID 5cf4d687 for model llama3-8b received
2024-09-24 14:33:06,301 127.0.0.1 - - [24/Sep/2024 14:33:06] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:06,518 Request with ID 499cbd7d for model gemma-7b received
2024-09-24 14:33:06,519 127.0.0.1 - - [24/Sep/2024 14:33:06] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:06,603 Request with ID 1204becd for model granite-7b received
2024-09-24 14:33:06,604 127.0.0.1 - - [24/Sep/2024 14:33:06] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:06,621 Request with ID 356b9197 for model gemma-7b received
2024-09-24 14:33:06,621 127.0.0.1 - - [24/Sep/2024 14:33:06] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:06,702 Request with ID 2fa6c917 for model llama3-8b received
2024-09-24 14:33:06,703 127.0.0.1 - - [24/Sep/2024 14:33:06] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:06,937 Request with ID 0dc25bd5 for model llama3-8b received
2024-09-24 14:33:06,938 127.0.0.1 - - [24/Sep/2024 14:33:06] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:07,003 Request with ID 3f76e33b for model llama3-8b received
2024-09-24 14:33:07,004 127.0.0.1 - - [24/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:07,252 Request with ID ac5a3b53 for model llama3-8b received
2024-09-24 14:33:07,253 127.0.0.1 - - [24/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:07,455 Request with ID 9271c1d7 for model llama3-8b received
2024-09-24 14:33:07,455 127.0.0.1 - - [24/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:07,565 Request with ID 312beca4 for model llama3-8b received
2024-09-24 14:33:07,565 127.0.0.1 - - [24/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:07,614 Request with ID a2d2ab1b for model gemma-7b received
2024-09-24 14:33:07,615 127.0.0.1 - - [24/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:07,617 Request with ID 379e70e8 for model llama3-8b received
2024-09-24 14:33:07,617 127.0.0.1 - - [24/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:07,678 Request with ID 62701748 for model gemma-7b received
2024-09-24 14:33:07,679 127.0.0.1 - - [24/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:07,956 Request with ID 69e8d838 for model granite-7b received
2024-09-24 14:33:07,957 127.0.0.1 - - [24/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:08,088 Request with ID 0a5bc383 for model granite-7b received
2024-09-24 14:33:08,088 127.0.0.1 - - [24/Sep/2024 14:33:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:08,149 Request with ID 3ce778d8 for model llama3-8b received
2024-09-24 14:33:08,150 127.0.0.1 - - [24/Sep/2024 14:33:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:08,163 Request with ID cdaa96c8 for model llama3-8b received
2024-09-24 14:33:08,164 127.0.0.1 - - [24/Sep/2024 14:33:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:08,222 Request with ID 3572c147 for model llama3-8b received
2024-09-24 14:33:08,222 127.0.0.1 - - [24/Sep/2024 14:33:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:08,300 Request with ID ab99ea4d for model gemma-7b received
2024-09-24 14:33:08,300 127.0.0.1 - - [24/Sep/2024 14:33:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:08,436 Request with ID b5baea23 for model llama3-8b received
2024-09-24 14:33:08,437 127.0.0.1 - - [24/Sep/2024 14:33:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:08,480 Request with ID c1c29b51 for model gemma-7b received
2024-09-24 14:33:08,480 127.0.0.1 - - [24/Sep/2024 14:33:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:08,485 Request with ID acbb307b for model llama3-8b received
2024-09-24 14:33:08,485 127.0.0.1 - - [24/Sep/2024 14:33:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:08,554 Request with ID acea7345 for model gemma-7b received
2024-09-24 14:33:08,555 127.0.0.1 - - [24/Sep/2024 14:33:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:08,576 Request with ID f6d96ffc for model gemma-7b received
2024-09-24 14:33:08,576 127.0.0.1 - - [24/Sep/2024 14:33:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:08,867 Request with ID 25a16f6a for model llama3-8b received
2024-09-24 14:33:08,867 127.0.0.1 - - [24/Sep/2024 14:33:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:08,915 Request with ID e8863f0f for model llama3-8b received
2024-09-24 14:33:08,916 127.0.0.1 - - [24/Sep/2024 14:33:08] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:09,016 Request with ID 0895ff3b for model gemma-7b received
2024-09-24 14:33:09,017 127.0.0.1 - - [24/Sep/2024 14:33:09] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:09,427 Request with ID 308217dd for model granite-7b received
2024-09-24 14:33:09,428 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-24 14:33:09,429 Dynamic batch size condition met for model granite-7b
2024-09-24 14:33:09,869 Request with ID 0c7ac4e0 for model llama3-8b received
2024-09-24 14:33:09,869 127.0.0.1 - - [24/Sep/2024 14:33:09] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:09,889 Request with ID 418650b4 for model llama3-8b received
2024-09-24 14:33:09,890 127.0.0.1 - - [24/Sep/2024 14:33:09] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:10,071 Request with ID d675856c for model llama3-8b received
2024-09-24 14:33:10,072 127.0.0.1 - - [24/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:10,129 Request with ID e8b8fd2f for model gemma-7b received
2024-09-24 14:33:10,129 127.0.0.1 - - [24/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:10,158 Request with ID 8a681def for model gemma-7b received
2024-09-24 14:33:10,158 127.0.0.1 - - [24/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:10,199 Request with ID 95cc10d4 for model llama3-8b received
2024-09-24 14:33:10,200 127.0.0.1 - - [24/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:10,300 Request with ID cc938586 for model llama3-8b received
2024-09-24 14:33:10,300 127.0.0.1 - - [24/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:11,322 Request with ID d3455d5d for model llama3-8b received
2024-09-24 14:33:11,322 127.0.0.1 - - [24/Sep/2024 14:33:11] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:11,407 Request with ID 7f6c5103 for model gemma-7b received
2024-09-24 14:33:11,408 127.0.0.1 - - [24/Sep/2024 14:33:11] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:11,605 Request with ID 9e4d9757 for model llama3-8b received
2024-09-24 14:33:11,606 127.0.0.1 - - [24/Sep/2024 14:33:11] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:11,626 Request with ID 9155a891 for model llama3-8b received
2024-09-24 14:33:11,626 127.0.0.1 - - [24/Sep/2024 14:33:11] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:11,926 Request with ID c877d51c for model llama3-8b received
2024-09-24 14:33:11,927 127.0.0.1 - - [24/Sep/2024 14:33:11] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:12,227 Request with ID 6d532a33 for model gemma-7b received
2024-09-24 14:33:12,228 127.0.0.1 - - [24/Sep/2024 14:33:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:12,305 Request with ID bfa053b3 for model gemma-7b received
2024-09-24 14:33:12,306 127.0.0.1 - - [24/Sep/2024 14:33:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:12,505 Request with ID da0f673e for model llama3-8b received
2024-09-24 14:33:12,506 127.0.0.1 - - [24/Sep/2024 14:33:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:12,509 Request with ID 5d04752d for model gemma-7b received
2024-09-24 14:33:12,510 127.0.0.1 - - [24/Sep/2024 14:33:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:12,590 Request with ID c413e2c8 for model llama3-8b received
2024-09-24 14:33:12,590 127.0.0.1 - - [24/Sep/2024 14:33:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:12,676 Request with ID f6d7223a for model gemma-7b received
2024-09-24 14:33:12,676 127.0.0.1 - - [24/Sep/2024 14:33:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:12,719 Request with ID 197afab5 for model llama3-8b received
2024-09-24 14:33:12,720 Batch size condition met for model llama3-8b
2024-09-24 14:33:12,839 Request with ID 787832c1 for model llama3-8b received
2024-09-24 14:33:12,840 127.0.0.1 - - [24/Sep/2024 14:33:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:12,949 Request with ID 3014dacc for model llama3-8b received
2024-09-24 14:33:12,950 127.0.0.1 - - [24/Sep/2024 14:33:12] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:13,027 Request with ID 3974819c for model llama3-8b received
2024-09-24 14:33:13,028 127.0.0.1 - - [24/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:13,209 Request with ID 11b8af82 for model llama3-8b received
2024-09-24 14:33:13,210 127.0.0.1 - - [24/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:13,237 Request with ID b43720da for model llama3-8b received
2024-09-24 14:33:13,238 127.0.0.1 - - [24/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:13,313 Request with ID 327158cb for model gemma-7b received
2024-09-24 14:33:13,314 127.0.0.1 - - [24/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:13,347 Request with ID 9fb5b01a for model llama3-8b received
2024-09-24 14:33:13,348 127.0.0.1 - - [24/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:13,438 Request with ID 4239c1bc for model llama3-8b received
2024-09-24 14:33:13,439 127.0.0.1 - - [24/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:13,441 Request with ID 49d11588 for model llama3-8b received
2024-09-24 14:33:13,442 127.0.0.1 - - [24/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:13,603 Request with ID a16a447e for model llama3-8b received
2024-09-24 14:33:13,604 127.0.0.1 - - [24/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:13,735 Request with ID 2a8edb7b for model llama3-8b received
2024-09-24 14:33:13,736 127.0.0.1 - - [24/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:13,777 Request with ID 1f40a426 for model llama3-8b received
2024-09-24 14:33:13,778 127.0.0.1 - - [24/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:13,975 Request with ID 7c278cbe for model gemma-7b received
2024-09-24 14:33:13,976 127.0.0.1 - - [24/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:14,632 Request with ID 9a1e16af for model granite-7b received
2024-09-24 14:33:14,633 127.0.0.1 - - [24/Sep/2024 14:33:14] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:14,800 Request with ID fc14a261 for model llama3-8b received
2024-09-24 14:33:14,801 127.0.0.1 - - [24/Sep/2024 14:33:14] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:14,810 Request with ID 68466816 for model llama3-8b received
2024-09-24 14:33:14,810 127.0.0.1 - - [24/Sep/2024 14:33:14] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:15,026 Loaded model granite-7b
2024-09-24 14:33:15,032 Request with ID 31b8e914 for model llama3-8b received
2024-09-24 14:33:15,033 127.0.0.1 - - [24/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:15,036 Batch processing started for model granite-7b
2024-09-24 14:33:15,231 Request with ID a2e5e176 for model granite-7b received
2024-09-24 14:33:15,231 127.0.0.1 - - [24/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:15,297 Request with ID 2744beff for model granite-7b received
2024-09-24 14:33:15,298 127.0.0.1 - - [24/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:15,344 Request with ID ba348e31 for model llama3-8b received
2024-09-24 14:33:15,345 127.0.0.1 - - [24/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:15,715 Request with ID f6b2a76c for model granite-7b received
2024-09-24 14:33:15,716 127.0.0.1 - - [24/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:15,729 Request with ID d02ba0d2 for model gemma-7b received
2024-09-24 14:33:15,729 127.0.0.1 - - [24/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:15,739 Request with ID e3dab235 for model llama3-8b received
2024-09-24 14:33:15,740 127.0.0.1 - - [24/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:15,896 Request with ID 9c8e2f58 for model llama3-8b received
2024-09-24 14:33:15,897 127.0.0.1 - - [24/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:16,036 Request with ID 9d080745 for model gemma-7b received
2024-09-24 14:33:16,037 127.0.0.1 - - [24/Sep/2024 14:33:16] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:16,079 Request with ID 4c2139eb for model llama3-8b received
2024-09-24 14:33:16,079 127.0.0.1 - - [24/Sep/2024 14:33:16] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:16,145 Request with ID 8e278179 for model granite-7b received
2024-09-24 14:33:16,146 127.0.0.1 - - [24/Sep/2024 14:33:16] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:16,256 Request with ID 7bb763f1 for model llama3-8b received
2024-09-24 14:33:16,257 127.0.0.1 - - [24/Sep/2024 14:33:16] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:16,373 Request with ID 2bdbe01f for model llama3-8b received
2024-09-24 14:33:16,374 127.0.0.1 - - [24/Sep/2024 14:33:16] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:16,555 Request with ID 2bacd25c for model llama3-8b received
2024-09-24 14:33:16,555 127.0.0.1 - - [24/Sep/2024 14:33:16] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:16,644 Request with ID a5ddd712 for model llama3-8b received
2024-09-24 14:33:16,644 127.0.0.1 - - [24/Sep/2024 14:33:16] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:16,861 Request with ID 77ea496d for model granite-7b received
2024-09-24 14:33:16,862 127.0.0.1 - - [24/Sep/2024 14:33:16] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:17,006 Request with ID a7d68737 for model gemma-7b received
2024-09-24 14:33:17,007 127.0.0.1 - - [24/Sep/2024 14:33:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:17,050 Request with ID 38286b88 for model llama3-8b received
2024-09-24 14:33:17,050 127.0.0.1 - - [24/Sep/2024 14:33:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:17,070 Request with ID cff18eb4 for model llama3-8b received
2024-09-24 14:33:17,071 127.0.0.1 - - [24/Sep/2024 14:33:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:17,137 Request with ID db06ab7a for model gemma-7b received
2024-09-24 14:33:17,137 127.0.0.1 - - [24/Sep/2024 14:33:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:17,155 Request with ID 147bada2 for model llama3-8b received
2024-09-24 14:33:17,155 127.0.0.1 - - [24/Sep/2024 14:33:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:17,196 Request with ID 3ca68437 for model granite-7b received
2024-09-24 14:33:17,196 127.0.0.1 - - [24/Sep/2024 14:33:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:17,289 Request with ID fdb68766 for model gemma-7b received
2024-09-24 14:33:17,289 127.0.0.1 - - [24/Sep/2024 14:33:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:17,445 Request with ID 1928a822 for model llama3-8b received
2024-09-24 14:33:17,446 Request with ID cad09c88 for model granite-7b received
2024-09-24 14:33:17,446 127.0.0.1 - - [24/Sep/2024 14:33:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:17,447 127.0.0.1 - - [24/Sep/2024 14:33:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:17,616 Processed batch: ['fa6dc8fa', '035217c9', 'b2777126', '7df0fbdd', '6df84952', '345391d9', '6ad9af62', '36462902', '3f7b2b8c', '49400972', 'a61837a7', '7d294ec4', 'c63ed0ce', '24be42e2', '96590a0b', 'c418ee8b'] with model granite-7b in 2.5796 seconds
2024-09-24 14:33:17,616 Saving sys info
2024-09-24 14:33:17,648 Latency for request fa6dc8fa with model granite-7b: 39.5640 seconds
2024-09-24 14:33:17,648 Saving results with gpu monitoring
2024-09-24 14:33:17,652 Latency for request 035217c9 with model granite-7b: 38.7240 seconds
2024-09-24 14:33:17,652 Saving results with gpu monitoring
2024-09-24 14:33:17,654 Latency for request b2777126 with model granite-7b: 37.2160 seconds
2024-09-24 14:33:17,654 Saving results with gpu monitoring
2024-09-24 14:33:17,656 Latency for request 7df0fbdd with model granite-7b: 36.0580 seconds
2024-09-24 14:33:17,656 Saving results with gpu monitoring
2024-09-24 14:33:17,658 Latency for request 6df84952 with model granite-7b: 35.4730 seconds
2024-09-24 14:33:17,658 Saving results with gpu monitoring
2024-09-24 14:33:17,660 Latency for request 345391d9 with model granite-7b: 35.2280 seconds
2024-09-24 14:33:17,660 Saving results with gpu monitoring
2024-09-24 14:33:17,662 Latency for request 6ad9af62 with model granite-7b: 34.8240 seconds
2024-09-24 14:33:17,662 Saving results with gpu monitoring
2024-09-24 14:33:17,664 Latency for request 36462902 with model granite-7b: 33.7160 seconds
2024-09-24 14:33:17,664 Saving results with gpu monitoring
2024-09-24 14:33:17,666 Latency for request 3f7b2b8c with model granite-7b: 30.4960 seconds
2024-09-24 14:33:17,666 Saving results with gpu monitoring
2024-09-24 14:33:17,668 Latency for request 49400972 with model granite-7b: 29.6690 seconds
2024-09-24 14:33:17,668 Saving results with gpu monitoring
2024-09-24 14:33:17,670 Latency for request a61837a7 with model granite-7b: 28.0400 seconds
2024-09-24 14:33:17,670 Saving results with gpu monitoring
2024-09-24 14:33:17,671 Latency for request 7d294ec4 with model granite-7b: 27.0720 seconds
2024-09-24 14:33:17,671 Saving results with gpu monitoring
2024-09-24 14:33:17,673 Latency for request c63ed0ce with model granite-7b: 26.7170 seconds
2024-09-24 14:33:17,673 Saving results with gpu monitoring
2024-09-24 14:33:17,675 Latency for request 24be42e2 with model granite-7b: 26.3520 seconds
2024-09-24 14:33:17,675 Saving results with gpu monitoring
2024-09-24 14:33:17,677 Latency for request 96590a0b with model granite-7b: 25.5570 seconds
2024-09-24 14:33:17,677 Saving results with gpu monitoring
2024-09-24 14:33:17,679 Latency for request c418ee8b with model granite-7b: 23.6170 seconds
2024-09-24 14:33:17,679 Saving results with gpu monitoring
2024-09-24 14:33:17,682 127.0.0.1 - - [24/Sep/2024 14:33:17] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:17,682 Next: call load_model for gemma-7b
2024-09-24 14:33:17,770 Unloaded previous model
2024-09-24 14:33:18,236 Request with ID 19eeece3 for model gemma-7b received
2024-09-24 14:33:18,237 Request with ID cabc0556 for model llama3-8b received
2024-09-24 14:33:18,237 127.0.0.1 - - [24/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:18,239 127.0.0.1 - - [24/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:18,240 Request with ID 9a0dd9a1 for model llama3-8b received
2024-09-24 14:33:18,242 127.0.0.1 - - [24/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:18,244 Request with ID cd400ec4 for model llama3-8b received
2024-09-24 14:33:18,245 127.0.0.1 - - [24/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:18,247 Request with ID f573f650 for model llama3-8b received
2024-09-24 14:33:18,248 127.0.0.1 - - [24/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:18,320 Request with ID 58a5aa5a for model llama3-8b received
2024-09-24 14:33:18,323 127.0.0.1 - - [24/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:18,460 Request with ID f2fb0492 for model gemma-7b received
2024-09-24 14:33:18,463 127.0.0.1 - - [24/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:18,805 Request with ID d0c98d9b for model llama3-8b received
2024-09-24 14:33:18,806 127.0.0.1 - - [24/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:18,958 Request with ID 095da9f3 for model llama3-8b received
2024-09-24 14:33:18,958 127.0.0.1 - - [24/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:19,316 Request with ID c13b2ebe for model gemma-7b received
2024-09-24 14:33:19,411 127.0.0.1 - - [24/Sep/2024 14:33:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:19,452 Request with ID a2e964a3 for model llama3-8b received
2024-09-24 14:33:19,452 127.0.0.1 - - [24/Sep/2024 14:33:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:19,465 Request with ID 2759caa0 for model llama3-8b received
2024-09-24 14:33:19,466 127.0.0.1 - - [24/Sep/2024 14:33:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:19,554 Request with ID 432f0d4f for model llama3-8b received
2024-09-24 14:33:19,555 127.0.0.1 - - [24/Sep/2024 14:33:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:19,571 Request with ID 87ae38a7 for model llama3-8b received
2024-09-24 14:33:19,572 127.0.0.1 - - [24/Sep/2024 14:33:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:19,573 Request with ID b03fd798 for model llama3-8b received
2024-09-24 14:33:19,574 127.0.0.1 - - [24/Sep/2024 14:33:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:19,640 Request with ID 083fb797 for model llama3-8b received
2024-09-24 14:33:19,640 127.0.0.1 - - [24/Sep/2024 14:33:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:19,800 Request with ID 9b3bf714 for model llama3-8b received
2024-09-24 14:33:19,800 127.0.0.1 - - [24/Sep/2024 14:33:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:19,881 Request with ID bfec5803 for model llama3-8b received
2024-09-24 14:33:19,881 127.0.0.1 - - [24/Sep/2024 14:33:19] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:20,083 Request with ID f76f4d6e for model llama3-8b received
2024-09-24 14:33:20,083 127.0.0.1 - - [24/Sep/2024 14:33:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:20,126 Request with ID 56ea088f for model llama3-8b received
2024-09-24 14:33:20,127 127.0.0.1 - - [24/Sep/2024 14:33:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:20,144 Request with ID d2f5fb73 for model llama3-8b received
2024-09-24 14:33:20,145 127.0.0.1 - - [24/Sep/2024 14:33:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:20,152 Request with ID 99a96ac2 for model llama3-8b received
2024-09-24 14:33:20,152 127.0.0.1 - - [24/Sep/2024 14:33:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:20,181 Request with ID 71782a5f for model granite-7b received
2024-09-24 14:33:20,182 127.0.0.1 - - [24/Sep/2024 14:33:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:20,187 Request with ID c7fbd7d0 for model granite-7b received
2024-09-24 14:33:20,188 127.0.0.1 - - [24/Sep/2024 14:33:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:20,203 Request with ID ecf0a52e for model llama3-8b received
2024-09-24 14:33:20,204 127.0.0.1 - - [24/Sep/2024 14:33:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:20,216 Request with ID f7ba6418 for model gemma-7b received
2024-09-24 14:33:20,217 127.0.0.1 - - [24/Sep/2024 14:33:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:20,522 Request with ID 313a6b6e for model llama3-8b received
2024-09-24 14:33:20,523 127.0.0.1 - - [24/Sep/2024 14:33:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:20,898 Request with ID 8e281528 for model llama3-8b received
2024-09-24 14:33:20,899 127.0.0.1 - - [24/Sep/2024 14:33:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:20,964 Request with ID df5abbc7 for model llama3-8b received
2024-09-24 14:33:20,965 127.0.0.1 - - [24/Sep/2024 14:33:20] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:21,003 Request with ID 36b058af for model llama3-8b received
2024-09-24 14:33:21,003 127.0.0.1 - - [24/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:21,420 Request with ID 8c271cc1 for model llama3-8b received
2024-09-24 14:33:21,421 127.0.0.1 - - [24/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:21,607 Request with ID 7a0ce553 for model gemma-7b received
2024-09-24 14:33:21,607 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-24 14:33:21,608 Dynamic batch size condition met for model gemma-7b
2024-09-24 14:33:21,852 Request with ID 22a4834f for model llama3-8b received
2024-09-24 14:33:21,853 127.0.0.1 - - [24/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:22,060 Request with ID 264666de for model gemma-7b received
2024-09-24 14:33:22,060 127.0.0.1 - - [24/Sep/2024 14:33:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:22,134 Request with ID 6d3b3549 for model gemma-7b received
2024-09-24 14:33:22,135 127.0.0.1 - - [24/Sep/2024 14:33:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:22,321 Request with ID 340dfabe for model granite-7b received
2024-09-24 14:33:22,322 127.0.0.1 - - [24/Sep/2024 14:33:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:22,366 Request with ID 9630f728 for model llama3-8b received
2024-09-24 14:33:22,367 127.0.0.1 - - [24/Sep/2024 14:33:22] "POST /inference HTTP/1.1" 200 -
2024-09-24 14:33:22,611 Waiting for running processes to finish
2024-09-24 14:33:24,614 Waiting for running processes to finish
2024-09-24 14:33:26,617 Waiting for running processes to finish
2024-09-24 14:33:28,619 Waiting for running processes to finish
2024-09-24 14:33:30,622 Waiting for running processes to finish
2024-09-24 14:33:32,624 Waiting for running processes to finish
