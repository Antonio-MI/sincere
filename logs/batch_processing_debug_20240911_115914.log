2024-09-11 11:59:14,818 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.212:5000
2024-09-11 11:59:14,818 [33mPress CTRL+C to quit[0m
2024-09-11 11:59:16,789 Request with ID 7bcc092a for model gpt2-124m received
2024-09-11 11:59:16,789 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-11 11:59:16,789 Adjusted time limit for model gpt2-124m: 13.6926 seconds
2024-09-11 11:59:16,789 127.0.0.1 - - [11/Sep/2024 11:59:16] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:17,617 Request with ID 74f823f6 for model gpt2-124m received
2024-09-11 11:59:17,618 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-11 11:59:17,618 127.0.0.1 - - [11/Sep/2024 11:59:17] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:17,950 Request with ID 1c9a4707 for model gpt2medium-355m received
2024-09-11 11:59:17,951 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-11 11:59:17,951 Adjusted time limit for model gpt2medium-355m: 11.8866 seconds
2024-09-11 11:59:17,951 127.0.0.1 - - [11/Sep/2024 11:59:17] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:18,013 Request with ID 2bd85cb6 for model gpt2-124m received
2024-09-11 11:59:18,013 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-11 11:59:18,014 127.0.0.1 - - [11/Sep/2024 11:59:18] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:18,385 Request with ID bbe806fd for model gpt2-124m received
2024-09-11 11:59:18,385 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-11 11:59:18,386 127.0.0.1 - - [11/Sep/2024 11:59:18] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:19,049 Request with ID 0ac7a9d8 for model distilgpt2-124m received
2024-09-11 11:59:19,049 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-11 11:59:19,050 Adjusted time limit for model distilgpt2-124m: 14.1882 seconds
2024-09-11 11:59:19,050 127.0.0.1 - - [11/Sep/2024 11:59:19] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:19,657 Request with ID 9778aa8c for model distilgpt2-124m received
2024-09-11 11:59:19,658 Adjusted time limit based on total queue size 7: 9.0000 seconds
2024-09-11 11:59:19,658 127.0.0.1 - - [11/Sep/2024 11:59:19] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:20,226 Request with ID 205a61ee for model gpt2medium-355m received
2024-09-11 11:59:20,227 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-11 11:59:20,227 127.0.0.1 - - [11/Sep/2024 11:59:20] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:20,619 Request with ID 01382880 for model distilgpt2-124m received
2024-09-11 11:59:20,620 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-11 11:59:20,620 127.0.0.1 - - [11/Sep/2024 11:59:20] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:21,075 Request with ID 98392b85 for model gpt2medium-355m received
2024-09-11 11:59:21,075 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-11 11:59:21,075 127.0.0.1 - - [11/Sep/2024 11:59:21] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:21,176 Time limit condition met for model gpt2medium-355m
2024-09-11 11:59:21,176 Updated batch size:4
2024-09-11 11:59:21,176 Loading model gpt2medium-355m
2024-09-11 11:59:21,563 Request with ID ff8e6619 for model gpt2-124m received
2024-09-11 11:59:21,563 Adjusted time limit based on total queue size 8: 7.5000 seconds
2024-09-11 11:59:21,563 127.0.0.1 - - [11/Sep/2024 11:59:21] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:22,174 Request with ID 22e4a3b8 for model gpt2medium-355m received
2024-09-11 11:59:22,174 Adjusted time limit based on total queue size 9: 7.5000 seconds
2024-09-11 11:59:22,174 127.0.0.1 - - [11/Sep/2024 11:59:22] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:22,537 Request with ID 0494eb8c for model gpt2-124m received
2024-09-11 11:59:22,538 Adjusted time limit based on total queue size 10: 7.5000 seconds
2024-09-11 11:59:22,538 127.0.0.1 - - [11/Sep/2024 11:59:22] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:22,874 Request with ID ddf65d7c for model distilgpt2-124m received
2024-09-11 11:59:22,874 Adjusted time limit based on total queue size 11: 7.5000 seconds
2024-09-11 11:59:22,874 127.0.0.1 - - [11/Sep/2024 11:59:22] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:23,902 Processed batch: ['1c9a4707', '205a61ee', '98392b85', '216e'] with model gpt2medium-355m in 2.5864 seconds
2024-09-11 11:59:23,902 Latency for request 1c9a4707 with model gpt2medium-355m: 5.9520 seconds
2024-09-11 11:59:23,903 Latency for request 205a61ee with model gpt2medium-355m: 3.6757 seconds
2024-09-11 11:59:23,904 Latency for request 98392b85 with model gpt2medium-355m: 2.8272 seconds
2024-09-11 11:59:23,904 Latency for request 216e with model gpt2medium-355m: 2.7262 seconds
2024-09-11 11:59:23,946 Request with ID f2cef5f7 for model gpt2-124m received
2024-09-11 11:59:23,946 Adjusted time limit based on total queue size 12: 7.5000 seconds
2024-09-11 11:59:23,946 127.0.0.1 - - [11/Sep/2024 11:59:23] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:25,146 Request with ID 1a6ac9b2 for model gpt2-124m received
2024-09-11 11:59:25,146 Adjusted time limit based on total queue size 13: 7.5000 seconds
2024-09-11 11:59:25,146 Batch size condition met for model gpt2-124m
2024-09-11 11:59:25,146 Updated batch size:8
2024-09-11 11:59:25,146 Loading model gpt2-124m
2024-09-11 11:59:25,772 Time limit condition met for model gpt2-124m
2024-09-11 11:59:25,880 Request with ID 84a98972 for model distilgpt2-124m received
2024-09-11 11:59:25,880 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-11 11:59:25,880 127.0.0.1 - - [11/Sep/2024 11:59:25] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:26,343 Processed batch: ['7bcc092a', '74f823f6', '2bd85cb6', 'bbe806fd', 'ff8e6619', '0494eb8c', 'f2cef5f7', '1a6ac9b2'] with model gpt2-124m in 1.1225 seconds
2024-09-11 11:59:26,343 Latency for request 7bcc092a with model gpt2-124m: 9.5537 seconds
2024-09-11 11:59:26,343 Latency for request 74f823f6 with model gpt2-124m: 8.7252 seconds
2024-09-11 11:59:26,344 Latency for request 2bd85cb6 with model gpt2-124m: 8.3297 seconds
2024-09-11 11:59:26,344 Latency for request bbe806fd with model gpt2-124m: 7.9577 seconds
2024-09-11 11:59:26,344 Latency for request ff8e6619 with model gpt2-124m: 4.7796 seconds
2024-09-11 11:59:26,344 Latency for request 0494eb8c with model gpt2-124m: 3.8051 seconds
2024-09-11 11:59:26,345 Latency for request f2cef5f7 with model gpt2-124m: 2.3962 seconds
2024-09-11 11:59:26,345 Latency for request 1a6ac9b2 with model gpt2-124m: 1.1970 seconds
2024-09-11 11:59:26,345 127.0.0.1 - - [11/Sep/2024 11:59:26] "POST /inference HTTP/1.1" 200 -
2024-09-11 11:59:26,345 No batch to process for model gpt2-124m
2024-09-11 11:59:31,438 Total time: 14.6493 seconds
2024-09-11 11:59:31,439 Total inference time: 3.7090 seconds
2024-09-11 11:59:31,439 Inference time as percentage of total time: 25.32%
2024-09-11 11:59:31,859 Time limit condition met for model distilgpt2-124m
2024-09-11 11:59:31,859 Updated batch size:8
2024-09-11 11:59:31,859 Loading model distilgpt2-124m
2024-09-11 11:59:32,782 Processed batch: ['0ac7a9d8', '9778aa8c', '01382880', 'ddf65d7c', '84a98972', '205f', '2d6c', '2510'] with model distilgpt2-124m in 0.8374 seconds
2024-09-11 11:59:32,783 Latency for request 0ac7a9d8 with model distilgpt2-124m: 13.7334 seconds
2024-09-11 11:59:32,783 Latency for request 9778aa8c with model distilgpt2-124m: 13.1250 seconds
2024-09-11 11:59:32,784 Latency for request 01382880 with model distilgpt2-124m: 12.1632 seconds
2024-09-11 11:59:32,784 Latency for request ddf65d7c with model distilgpt2-124m: 9.9084 seconds
2024-09-11 11:59:32,784 Latency for request 84a98972 with model distilgpt2-124m: 6.9027 seconds
2024-09-11 11:59:32,784 Latency for request 205f with model distilgpt2-124m: 0.9234 seconds
2024-09-11 11:59:32,785 Latency for request 2d6c with model distilgpt2-124m: 0.9233 seconds
2024-09-11 11:59:32,785 Latency for request 2510 with model distilgpt2-124m: 0.9233 seconds
