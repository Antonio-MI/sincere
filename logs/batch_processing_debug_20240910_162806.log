2024-09-10 16:28:11,847 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://9.74.11.77:5000
2024-09-10 16:28:11,847 [33mPress CTRL+C to quit[0m
2024-09-10 16:28:11,849 Request with ID 344ae007 for model gpt2-124m received
2024-09-10 16:28:11,849 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 16:28:11,849 Adjusted time limit for model gpt2-124m: 13.6926 seconds
2024-09-10 16:28:11,850 127.0.0.1 - - [10/Sep/2024 16:28:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:11,859 Request with ID bcdd9981 for model gpt2-124m received
2024-09-10 16:28:11,859 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 16:28:11,859 127.0.0.1 - - [10/Sep/2024 16:28:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:11,887 Request with ID 74d6de8b for model gpt2medium-355m received
2024-09-10 16:28:11,887 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 16:28:11,887 Adjusted time limit for model gpt2medium-355m: 11.8866 seconds
2024-09-10 16:28:11,887 127.0.0.1 - - [10/Sep/2024 16:28:11] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:11,951 Remaining requests condition met for model gpt2-124m
2024-09-10 16:28:11,951 Updated batch size:2
2024-09-10 16:28:11,951 Loading model gpt2-124m
2024-09-10 16:28:12,119 Request with ID 118caaa7 for model gpt2-124m received
2024-09-10 16:28:12,119 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 16:28:12,119 127.0.0.1 - - [10/Sep/2024 16:28:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:12,432 Request with ID d8121f29 for model gpt2-124m received
2024-09-10 16:28:12,432 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 16:28:12,432 127.0.0.1 - - [10/Sep/2024 16:28:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:12,609 Processed batch: ['344ae007', 'bcdd9981'] with model gpt2-124m in 0.5709 seconds
2024-09-10 16:28:12,609 Latency for request 344ae007 with model gpt2-124m: 0.7593 seconds
2024-09-10 16:28:12,610 Latency for request bcdd9981 with model gpt2-124m: 0.7498 seconds
2024-09-10 16:28:12,610 Remaining requests condition met for model gpt2medium-355m
2024-09-10 16:28:12,610 Updated batch size:1
2024-09-10 16:28:12,610 Loading model gpt2medium-355m
2024-09-10 16:28:12,782 Request with ID 02b3d543 for model distilgpt2-124m received
2024-09-10 16:28:12,782 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 16:28:12,782 Adjusted time limit for model distilgpt2-124m: 14.1775 seconds
2024-09-10 16:28:12,782 127.0.0.1 - - [10/Sep/2024 16:28:12] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:13,392 Request with ID fe48ba8b for model distilgpt2-124m received
2024-09-10 16:28:13,392 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 16:28:13,392 127.0.0.1 - - [10/Sep/2024 16:28:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:13,934 Processed batch: ['74d6de8b'] with model gpt2medium-355m in 1.2237 seconds
2024-09-10 16:28:13,934 Latency for request 74d6de8b with model gpt2medium-355m: 2.0473 seconds
2024-09-10 16:28:13,957 Request with ID 85c4c1d1 for model gpt2medium-355m received
2024-09-10 16:28:13,957 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 16:28:13,957 Adjusted time limit for model gpt2medium-355m: 11.8759 seconds
2024-09-10 16:28:13,957 127.0.0.1 - - [10/Sep/2024 16:28:13] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:14,040 Remaining requests condition met for model gpt2-124m
2024-09-10 16:28:14,040 Updated batch size:2
2024-09-10 16:28:14,040 Loading model gpt2-124m
2024-09-10 16:28:14,350 Request with ID 7827eee1 for model distilgpt2-124m received
2024-09-10 16:28:14,350 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 16:28:14,350 127.0.0.1 - - [10/Sep/2024 16:28:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:14,761 Processed batch: ['118caaa7', 'd8121f29'] with model gpt2-124m in 0.6570 seconds
2024-09-10 16:28:14,761 Latency for request 118caaa7 with model gpt2-124m: 2.6418 seconds
2024-09-10 16:28:14,762 Latency for request d8121f29 with model gpt2-124m: 2.3288 seconds
2024-09-10 16:28:14,762 Remaining requests condition met for model gpt2medium-355m
2024-09-10 16:28:14,762 Updated batch size:1
2024-09-10 16:28:14,762 Loading model gpt2medium-355m
2024-09-10 16:28:14,844 Request with ID e224e078 for model gpt2medium-355m received
2024-09-10 16:28:14,844 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 16:28:14,844 127.0.0.1 - - [10/Sep/2024 16:28:14] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:15,295 Request with ID 56b3202c for model gpt2-124m received
2024-09-10 16:28:15,295 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 16:28:15,295 Adjusted time limit for model gpt2-124m: 13.6819 seconds
2024-09-10 16:28:15,295 127.0.0.1 - - [10/Sep/2024 16:28:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:15,906 Request with ID 5b16a7cd for model gpt2medium-355m received
2024-09-10 16:28:15,906 Adjusted time limit based on total queue size 6: 9.0000 seconds
2024-09-10 16:28:15,907 127.0.0.1 - - [10/Sep/2024 16:28:15] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:16,111 Processed batch: ['85c4c1d1'] with model gpt2medium-355m in 1.1945 seconds
2024-09-10 16:28:16,112 Latency for request 85c4c1d1 with model gpt2medium-355m: 2.1542 seconds
2024-09-10 16:28:16,112 Remaining requests condition met for model distilgpt2-124m
2024-09-10 16:28:16,112 Updated batch size:4
2024-09-10 16:28:16,112 Loading model distilgpt2-124m
2024-09-10 16:28:16,270 Request with ID 74647295 for model gpt2-124m received
2024-09-10 16:28:16,270 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 16:28:16,270 127.0.0.1 - - [10/Sep/2024 16:28:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:16,606 Request with ID a231e0c9 for model distilgpt2-124m received
2024-09-10 16:28:16,606 Adjusted time limit based on total queue size 5: 9.0000 seconds
2024-09-10 16:28:16,606 127.0.0.1 - - [10/Sep/2024 16:28:16] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:16,806 Processed batch: ['02b3d543', 'fe48ba8b', '7827eee1', '73df'] with model distilgpt2-124m in 0.6326 seconds
2024-09-10 16:28:16,806 Latency for request 02b3d543 with model distilgpt2-124m: 4.0238 seconds
2024-09-10 16:28:16,807 Latency for request fe48ba8b with model distilgpt2-124m: 3.4143 seconds
2024-09-10 16:28:16,807 Latency for request 7827eee1 with model distilgpt2-124m: 2.4562 seconds
2024-09-10 16:28:16,807 Latency for request 73df with model distilgpt2-124m: 0.6937 seconds
2024-09-10 16:28:16,913 Remaining requests condition met for model gpt2-124m
2024-09-10 16:28:16,913 Updated batch size:2
2024-09-10 16:28:16,913 Loading model gpt2-124m
2024-09-10 16:28:17,602 Processed batch: ['56b3202c', '74647295'] with model gpt2-124m in 0.6299 seconds
2024-09-10 16:28:17,602 Latency for request 56b3202c with model gpt2-124m: 2.3084 seconds
2024-09-10 16:28:17,603 Latency for request 74647295 with model gpt2-124m: 1.3337 seconds
2024-09-10 16:28:17,603 Remaining requests condition met for model gpt2medium-355m
2024-09-10 16:28:17,603 Updated batch size:2
2024-09-10 16:28:17,603 Loading model gpt2medium-355m
2024-09-10 16:28:17,677 Request with ID 01d95c59 for model gpt2-124m received
2024-09-10 16:28:17,677 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 16:28:17,677 Adjusted time limit for model gpt2-124m: 13.6926 seconds
2024-09-10 16:28:17,678 127.0.0.1 - - [10/Sep/2024 16:28:17] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:18,874 Request with ID 57dd0ca6 for model gpt2-124m received
2024-09-10 16:28:18,875 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 16:28:18,875 127.0.0.1 - - [10/Sep/2024 16:28:18] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:19,607 Request with ID 9e74db9b for model distilgpt2-124m received
2024-09-10 16:28:19,607 Adjusted time limit based on total queue size 4: 9.0000 seconds
2024-09-10 16:28:19,607 Adjusted time limit for model distilgpt2-124m: 14.1775 seconds
2024-09-10 16:28:19,607 127.0.0.1 - - [10/Sep/2024 16:28:19] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:19,949 Processed batch: ['e224e078', '5b16a7cd'] with model gpt2medium-355m in 2.2483 seconds
2024-09-10 16:28:19,949 Latency for request e224e078 with model gpt2medium-355m: 5.1100 seconds
2024-09-10 16:28:19,950 Latency for request 5b16a7cd with model gpt2medium-355m: 4.0473 seconds
2024-09-10 16:28:19,950 Remaining requests condition met for model distilgpt2-124m
2024-09-10 16:28:19,950 Updated batch size:2
2024-09-10 16:28:19,950 Loading model distilgpt2-124m
2024-09-10 16:28:20,461 Processed batch: ['a231e0c9', '9e74db9b'] with model distilgpt2-124m in 0.4591 seconds
2024-09-10 16:28:20,461 Latency for request a231e0c9 with model distilgpt2-124m: 3.8598 seconds
2024-09-10 16:28:20,461 Latency for request 9e74db9b with model distilgpt2-124m: 0.8549 seconds
2024-09-10 16:28:20,567 Remaining requests condition met for model gpt2-124m
2024-09-10 16:28:20,567 Updated batch size:2
2024-09-10 16:28:20,567 Loading model gpt2-124m
2024-09-10 16:28:21,253 Processed batch: ['01d95c59', '57dd0ca6'] with model gpt2-124m in 0.6247 seconds
2024-09-10 16:28:21,253 Latency for request 01d95c59 with model gpt2-124m: 3.5805 seconds
2024-09-10 16:28:21,253 Latency for request 57dd0ca6 with model gpt2-124m: 2.3815 seconds
2024-09-10 16:28:21,254 Total time: 9.4107 seconds
2024-09-10 16:28:21,254 Total inference time: 8.2406 seconds
2024-09-10 16:28:21,254 Inference time as percentage of total time: 87.57%
2024-09-10 16:28:21,254 Total time: 9.4107 seconds
2024-09-10 16:28:21,254 Total inference time: 8.2406 seconds
2024-09-10 16:28:21,254 Inference time as percentage of total time: 87.57%
2024-09-10 16:28:21,356 Total time: 9.5135 seconds
2024-09-10 16:28:21,356 Total inference time: 8.2406 seconds
2024-09-10 16:28:21,356 Inference time as percentage of total time: 86.62%
2024-09-10 16:28:21,461 Total time: 9.6186 seconds
2024-09-10 16:28:21,461 Total inference time: 8.2406 seconds
2024-09-10 16:28:21,461 Inference time as percentage of total time: 85.67%
2024-09-10 16:28:21,566 Total time: 9.7237 seconds
2024-09-10 16:28:21,566 Total inference time: 8.2406 seconds
2024-09-10 16:28:21,566 Inference time as percentage of total time: 84.75%
2024-09-10 16:28:21,671 Total time: 9.8289 seconds
2024-09-10 16:28:21,672 Total inference time: 8.2406 seconds
2024-09-10 16:28:21,672 Inference time as percentage of total time: 83.84%
2024-09-10 16:28:21,776 Total time: 9.9333 seconds
2024-09-10 16:28:21,776 Total inference time: 8.2406 seconds
2024-09-10 16:28:21,776 Inference time as percentage of total time: 82.96%
2024-09-10 16:28:21,878 Total time: 10.0358 seconds
2024-09-10 16:28:21,878 Total inference time: 8.2406 seconds
2024-09-10 16:28:21,878 Inference time as percentage of total time: 82.11%
2024-09-10 16:28:21,980 Total time: 10.1380 seconds
2024-09-10 16:28:21,980 Total inference time: 8.2406 seconds
2024-09-10 16:28:21,980 Inference time as percentage of total time: 81.28%
2024-09-10 16:28:22,085 Total time: 10.2434 seconds
2024-09-10 16:28:22,086 Total inference time: 8.2406 seconds
2024-09-10 16:28:22,086 Inference time as percentage of total time: 80.45%
2024-09-10 16:28:22,190 Total time: 10.3485 seconds
2024-09-10 16:28:22,191 Total inference time: 8.2406 seconds
2024-09-10 16:28:22,191 Inference time as percentage of total time: 79.63%
2024-09-10 16:28:22,296 Total time: 10.4545 seconds
2024-09-10 16:28:22,296 Total inference time: 8.2406 seconds
2024-09-10 16:28:22,297 Inference time as percentage of total time: 78.82%
2024-09-10 16:28:22,402 Total time: 10.5603 seconds
2024-09-10 16:28:22,402 Total inference time: 8.2406 seconds
2024-09-10 16:28:22,402 Inference time as percentage of total time: 78.03%
2024-09-10 16:28:22,421 Request with ID 296f5185 for model gpt2-124m received
2024-09-10 16:28:22,421 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 16:28:22,421 Adjusted time limit for model gpt2-124m: 13.6858 seconds
2024-09-10 16:28:22,422 127.0.0.1 - - [10/Sep/2024 16:28:22] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:22,506 Remaining requests condition met for model gpt2-124m
2024-09-10 16:28:22,507 Updated batch size:1
2024-09-10 16:28:22,507 Loading model gpt2-124m
2024-09-10 16:28:22,877 Processed batch: ['296f5185'] with model gpt2-124m in 0.3696 seconds
2024-09-10 16:28:22,877 Latency for request 296f5185 with model gpt2-124m: 0.4566 seconds
2024-09-10 16:28:22,877 Total time: 11.0365 seconds
2024-09-10 16:28:22,877 Total inference time: 8.6102 seconds
2024-09-10 16:28:22,877 Inference time as percentage of total time: 78.02%
2024-09-10 16:28:22,877 Total time: 11.0366 seconds
2024-09-10 16:28:22,877 Total inference time: 8.6102 seconds
2024-09-10 16:28:22,878 Inference time as percentage of total time: 78.02%
2024-09-10 16:28:22,980 Total time: 11.1391 seconds
2024-09-10 16:28:22,980 Total inference time: 8.6102 seconds
2024-09-10 16:28:22,980 Inference time as percentage of total time: 77.30%
2024-09-10 16:28:23,080 Total time: 11.2393 seconds
2024-09-10 16:28:23,080 Total inference time: 8.6102 seconds
2024-09-10 16:28:23,080 Inference time as percentage of total time: 76.61%
2024-09-10 16:28:23,185 Total time: 11.3444 seconds
2024-09-10 16:28:23,185 Total inference time: 8.6102 seconds
2024-09-10 16:28:23,185 Inference time as percentage of total time: 75.90%
2024-09-10 16:28:23,290 Total time: 11.4496 seconds
2024-09-10 16:28:23,290 Total inference time: 8.6102 seconds
2024-09-10 16:28:23,291 Inference time as percentage of total time: 75.20%
2024-09-10 16:28:23,396 Total time: 11.5554 seconds
2024-09-10 16:28:23,396 Total inference time: 8.6102 seconds
2024-09-10 16:28:23,396 Inference time as percentage of total time: 74.51%
2024-09-10 16:28:23,498 Total time: 11.6575 seconds
2024-09-10 16:28:23,498 Total inference time: 8.6102 seconds
2024-09-10 16:28:23,498 Inference time as percentage of total time: 73.86%
2024-09-10 16:28:23,603 Total time: 11.7632 seconds
2024-09-10 16:28:23,604 Total inference time: 8.6102 seconds
2024-09-10 16:28:23,604 Inference time as percentage of total time: 73.20%
2024-09-10 16:28:23,665 Request with ID 6dfd0854 for model gpt2medium-355m received
2024-09-10 16:28:23,666 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 16:28:23,666 Adjusted time limit for model gpt2medium-355m: 11.8798 seconds
2024-09-10 16:28:23,666 127.0.0.1 - - [10/Sep/2024 16:28:23] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:23,707 Remaining requests condition met for model gpt2medium-355m
2024-09-10 16:28:23,707 Updated batch size:1
2024-09-10 16:28:23,707 Loading model gpt2medium-355m
2024-09-10 16:28:24,602 Request with ID 951a9184 for model gpt2medium-355m received
2024-09-10 16:28:24,602 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 16:28:24,602 127.0.0.1 - - [10/Sep/2024 16:28:24] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:25,063 Processed batch: ['6dfd0854'] with model gpt2medium-355m in 1.2163 seconds
2024-09-10 16:28:25,064 Latency for request 6dfd0854 with model gpt2medium-355m: 1.3997 seconds
2024-09-10 16:28:25,168 Remaining requests condition met for model gpt2medium-355m
2024-09-10 16:28:25,168 Updated batch size:1
2024-09-10 16:28:25,168 Loading model gpt2medium-355m
2024-09-10 16:28:25,235 Request with ID 106bd833 for model gpt2medium-355m received
2024-09-10 16:28:25,235 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 16:28:25,235 Adjusted time limit for model gpt2medium-355m: 11.8759 seconds
2024-09-10 16:28:25,235 127.0.0.1 - - [10/Sep/2024 16:28:25] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:26,314 Processed batch: ['951a9184'] with model gpt2medium-355m in 1.1470 seconds
2024-09-10 16:28:26,314 Latency for request 951a9184 with model gpt2medium-355m: 1.7135 seconds
2024-09-10 16:28:26,390 Request with ID 0aedb90c for model gpt2medium-355m received
2024-09-10 16:28:26,391 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 16:28:26,391 Adjusted time limit for model gpt2medium-355m: 11.8759 seconds
2024-09-10 16:28:26,391 127.0.0.1 - - [10/Sep/2024 16:28:26] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:26,417 Remaining requests condition met for model gpt2medium-355m
2024-09-10 16:28:26,418 Updated batch size:2
2024-09-10 16:28:26,418 Loading model gpt2medium-355m
2024-09-10 16:28:27,099 Request with ID 507e8780 for model gpt2-124m received
2024-09-10 16:28:27,099 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 16:28:27,099 Adjusted time limit for model gpt2-124m: 13.6819 seconds
2024-09-10 16:28:27,099 127.0.0.1 - - [10/Sep/2024 16:28:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:27,505 Request with ID 8b80e0ea for model distilgpt2-124m received
2024-09-10 16:28:27,505 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 16:28:27,505 Adjusted time limit for model distilgpt2-124m: 14.1775 seconds
2024-09-10 16:28:27,506 127.0.0.1 - - [10/Sep/2024 16:28:27] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:28,566 Request with ID b1a9cac3 for model distilgpt2-124m received
2024-09-10 16:28:28,566 Adjusted time limit based on total queue size 3: 15.0000 seconds
2024-09-10 16:28:28,566 127.0.0.1 - - [10/Sep/2024 16:28:28] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:28,643 Processed batch: ['106bd833', '0aedb90c'] with model gpt2medium-355m in 2.2277 seconds
2024-09-10 16:28:28,644 Latency for request 106bd833 with model gpt2medium-355m: 3.4118 seconds
2024-09-10 16:28:28,644 Latency for request 0aedb90c with model gpt2medium-355m: 2.2549 seconds
2024-09-10 16:28:28,645 Remaining requests condition met for model distilgpt2-124m
2024-09-10 16:28:28,645 Updated batch size:2
2024-09-10 16:28:28,645 Loading model distilgpt2-124m
2024-09-10 16:28:29,231 Processed batch: ['8b80e0ea', 'b1a9cac3'] with model distilgpt2-124m in 0.5323 seconds
2024-09-10 16:28:29,231 Latency for request 8b80e0ea with model distilgpt2-124m: 1.7271 seconds
2024-09-10 16:28:29,233 Latency for request b1a9cac3 with model distilgpt2-124m: 0.6656 seconds
2024-09-10 16:28:29,338 Remaining requests condition met for model gpt2-124m
2024-09-10 16:28:29,338 Updated batch size:1
2024-09-10 16:28:29,338 Loading model gpt2-124m
2024-09-10 16:28:29,467 Request with ID eaf45df5 for model distilgpt2-124m received
2024-09-10 16:28:29,467 Adjusted time limit based on total queue size 1: 15.0000 seconds
2024-09-10 16:28:29,468 Adjusted time limit for model distilgpt2-124m: 14.1814 seconds
2024-09-10 16:28:29,468 127.0.0.1 - - [10/Sep/2024 16:28:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:29,595 Request with ID 8bb66471 for model gpt2-124m received
2024-09-10 16:28:29,595 Adjusted time limit based on total queue size 2: 15.0000 seconds
2024-09-10 16:28:29,595 127.0.0.1 - - [10/Sep/2024 16:28:29] "POST /inference HTTP/1.1" 200 -
2024-09-10 16:28:29,872 Processed batch: ['507e8780'] with model gpt2-124m in 0.4702 seconds
2024-09-10 16:28:29,872 Latency for request 507e8780 with model gpt2-124m: 2.7749 seconds
2024-09-10 16:28:29,873 Remaining requests condition met for model distilgpt2-124m
2024-09-10 16:28:29,873 Updated batch size:1
2024-09-10 16:28:29,873 Loading model distilgpt2-124m
2024-09-10 16:28:30,267 Processed batch: ['eaf45df5'] with model distilgpt2-124m in 0.3389 seconds
2024-09-10 16:28:30,267 Latency for request eaf45df5 with model distilgpt2-124m: 0.8002 seconds
2024-09-10 16:28:30,373 Remaining requests condition met for model gpt2-124m
2024-09-10 16:28:30,373 Updated batch size:1
2024-09-10 16:28:30,373 Loading model gpt2-124m
2024-09-10 16:28:30,843 Processed batch: ['8bb66471'] with model gpt2-124m in 0.4013 seconds
2024-09-10 16:28:30,843 Latency for request 8bb66471 with model gpt2-124m: 1.2486 seconds
2024-09-10 16:28:30,844 Total time: 19.0106 seconds
2024-09-10 16:28:30,844 Total inference time: 14.9438 seconds
2024-09-10 16:28:30,844 Inference time as percentage of total time: 78.61%
2024-09-10 16:28:30,844 Total time: 19.0106 seconds
2024-09-10 16:28:30,844 Total inference time: 14.9438 seconds
2024-09-10 16:28:30,844 Inference time as percentage of total time: 78.61%
2024-09-10 16:28:30,947 Total time: 19.1134 seconds
2024-09-10 16:28:30,947 Total inference time: 14.9438 seconds
2024-09-10 16:28:30,947 Inference time as percentage of total time: 78.19%
2024-09-10 16:28:31,052 Total time: 19.2186 seconds
2024-09-10 16:28:31,052 Total inference time: 14.9438 seconds
2024-09-10 16:28:31,052 Inference time as percentage of total time: 77.76%
2024-09-10 16:28:31,156 Total time: 19.3228 seconds
2024-09-10 16:28:31,156 Total inference time: 14.9438 seconds
2024-09-10 16:28:31,156 Inference time as percentage of total time: 77.34%
2024-09-10 16:28:31,261 Total time: 19.4280 seconds
2024-09-10 16:28:31,261 Total inference time: 14.9438 seconds
2024-09-10 16:28:31,261 Inference time as percentage of total time: 76.92%
2024-09-10 16:28:31,366 Total time: 19.5332 seconds
2024-09-10 16:28:31,367 Total inference time: 14.9438 seconds
2024-09-10 16:28:31,367 Inference time as percentage of total time: 76.50%
2024-09-10 16:28:31,470 Total time: 19.6363 seconds
2024-09-10 16:28:31,470 Total inference time: 14.9438 seconds
2024-09-10 16:28:31,470 Inference time as percentage of total time: 76.10%
2024-09-10 16:28:31,575 Total time: 19.7416 seconds
2024-09-10 16:28:31,575 Total inference time: 14.9438 seconds
2024-09-10 16:28:31,575 Inference time as percentage of total time: 75.70%
2024-09-10 16:28:31,680 Total time: 19.8474 seconds
2024-09-10 16:28:31,681 Total inference time: 14.9438 seconds
2024-09-10 16:28:31,681 Inference time as percentage of total time: 75.29%
2024-09-10 16:28:31,785 Total time: 19.9522 seconds
2024-09-10 16:28:31,785 Total inference time: 14.9438 seconds
2024-09-10 16:28:31,786 Inference time as percentage of total time: 74.90%
2024-09-10 16:28:31,891 Total time: 20.0580 seconds
2024-09-10 16:28:31,891 Total inference time: 14.9438 seconds
2024-09-10 16:28:31,891 Inference time as percentage of total time: 74.50%
2024-09-10 16:28:31,993 Total time: 20.1605 seconds
2024-09-10 16:28:31,993 Total inference time: 14.9438 seconds
2024-09-10 16:28:31,993 Inference time as percentage of total time: 74.12%
2024-09-10 16:28:32,098 Total time: 20.2657 seconds
2024-09-10 16:28:32,099 Total inference time: 14.9438 seconds
2024-09-10 16:28:32,099 Inference time as percentage of total time: 73.74%
2024-09-10 16:28:32,204 Total time: 20.3710 seconds
2024-09-10 16:28:32,204 Total inference time: 14.9438 seconds
2024-09-10 16:28:32,204 Inference time as percentage of total time: 73.36%
2024-09-10 16:28:32,308 Total time: 20.4751 seconds
2024-09-10 16:28:32,308 Total inference time: 14.9438 seconds
2024-09-10 16:28:32,308 Inference time as percentage of total time: 72.99%
2024-09-10 16:28:32,414 Total time: 20.5810 seconds
2024-09-10 16:28:32,414 Total inference time: 14.9438 seconds
2024-09-10 16:28:32,414 Inference time as percentage of total time: 72.61%
2024-09-10 16:28:32,518 Total time: 20.6853 seconds
2024-09-10 16:28:32,518 Total inference time: 14.9438 seconds
2024-09-10 16:28:32,518 Inference time as percentage of total time: 72.24%
2024-09-10 16:28:32,619 Total time: 20.7865 seconds
2024-09-10 16:28:32,619 Total inference time: 14.9438 seconds
2024-09-10 16:28:32,620 Inference time as percentage of total time: 71.89%
2024-09-10 16:28:32,725 Total time: 20.8924 seconds
2024-09-10 16:28:32,725 Total inference time: 14.9438 seconds
2024-09-10 16:28:32,725 Inference time as percentage of total time: 71.53%
2024-09-10 16:28:32,830 Total time: 20.9981 seconds
2024-09-10 16:28:32,831 Total inference time: 14.9438 seconds
2024-09-10 16:28:32,831 Inference time as percentage of total time: 71.17%
2024-09-10 16:28:32,933 Total time: 21.1010 seconds
2024-09-10 16:28:32,934 Total inference time: 14.9438 seconds
2024-09-10 16:28:32,934 Inference time as percentage of total time: 70.82%
2024-09-10 16:28:33,039 Total time: 21.2067 seconds
2024-09-10 16:28:33,039 Total inference time: 14.9438 seconds
2024-09-10 16:28:33,039 Inference time as percentage of total time: 70.47%
2024-09-10 16:28:33,144 Total time: 21.3123 seconds
2024-09-10 16:28:33,145 Total inference time: 14.9438 seconds
2024-09-10 16:28:33,145 Inference time as percentage of total time: 70.12%
2024-09-10 16:28:33,250 Total time: 21.4181 seconds
2024-09-10 16:28:33,250 Total inference time: 14.9438 seconds
2024-09-10 16:28:33,251 Inference time as percentage of total time: 69.77%
2024-09-10 16:28:33,352 Total time: 21.5198 seconds
2024-09-10 16:28:33,352 Total inference time: 14.9438 seconds
2024-09-10 16:28:33,352 Inference time as percentage of total time: 69.44%
2024-09-10 16:28:33,456 Total time: 21.6241 seconds
2024-09-10 16:28:33,456 Total inference time: 14.9438 seconds
2024-09-10 16:28:33,456 Inference time as percentage of total time: 69.11%
2024-09-10 16:28:33,559 Total time: 21.7267 seconds
2024-09-10 16:28:33,559 Total inference time: 14.9438 seconds
2024-09-10 16:28:33,559 Inference time as percentage of total time: 68.78%
2024-09-10 16:28:33,664 Total time: 21.8318 seconds
2024-09-10 16:28:33,664 Total inference time: 14.9438 seconds
2024-09-10 16:28:33,664 Inference time as percentage of total time: 68.45%
2024-09-10 16:28:33,767 Total time: 21.9355 seconds
2024-09-10 16:28:33,768 Total inference time: 14.9438 seconds
2024-09-10 16:28:33,768 Inference time as percentage of total time: 68.13%
2024-09-10 16:28:33,873 Total time: 22.0412 seconds
2024-09-10 16:28:33,873 Total inference time: 14.9438 seconds
2024-09-10 16:28:33,873 Inference time as percentage of total time: 67.80%
2024-09-10 16:28:33,977 Total time: 22.1458 seconds
2024-09-10 16:28:33,978 Total inference time: 14.9438 seconds
2024-09-10 16:28:33,978 Inference time as percentage of total time: 67.48%
2024-09-10 16:28:34,083 Total time: 22.2515 seconds
2024-09-10 16:28:34,083 Total inference time: 14.9438 seconds
2024-09-10 16:28:34,084 Inference time as percentage of total time: 67.16%
2024-09-10 16:28:34,189 Total time: 22.3572 seconds
2024-09-10 16:28:34,189 Total inference time: 14.9438 seconds
2024-09-10 16:28:34,189 Inference time as percentage of total time: 66.84%
2024-09-10 16:28:34,291 Total time: 22.4600 seconds
2024-09-10 16:28:34,292 Total inference time: 14.9438 seconds
2024-09-10 16:28:34,292 Inference time as percentage of total time: 66.54%
2024-09-10 16:28:34,397 Total time: 22.5657 seconds
2024-09-10 16:28:34,397 Total inference time: 14.9438 seconds
2024-09-10 16:28:34,398 Inference time as percentage of total time: 66.22%
2024-09-10 16:28:34,503 Total time: 22.6716 seconds
2024-09-10 16:28:34,503 Total inference time: 14.9438 seconds
2024-09-10 16:28:34,504 Inference time as percentage of total time: 65.91%
2024-09-10 16:28:34,608 Total time: 22.7767 seconds
2024-09-10 16:28:34,608 Total inference time: 14.9438 seconds
2024-09-10 16:28:34,609 Inference time as percentage of total time: 65.61%
2024-09-10 16:28:34,713 Total time: 22.8818 seconds
2024-09-10 16:28:34,713 Total inference time: 14.9438 seconds
2024-09-10 16:28:34,714 Inference time as percentage of total time: 65.31%
2024-09-10 16:28:34,819 Total time: 22.9877 seconds
2024-09-10 16:28:34,819 Total inference time: 14.9438 seconds
2024-09-10 16:28:34,819 Inference time as percentage of total time: 65.01%
2024-09-10 16:28:34,923 Total time: 23.0916 seconds
2024-09-10 16:28:34,923 Total inference time: 14.9438 seconds
2024-09-10 16:28:34,923 Inference time as percentage of total time: 64.72%
2024-09-10 16:28:35,028 Total time: 23.1974 seconds
2024-09-10 16:28:35,029 Total inference time: 14.9438 seconds
2024-09-10 16:28:35,029 Inference time as percentage of total time: 64.42%
2024-09-10 16:28:35,132 Total time: 23.3009 seconds
2024-09-10 16:28:35,132 Total inference time: 14.9438 seconds
2024-09-10 16:28:35,132 Inference time as percentage of total time: 64.13%
2024-09-10 16:28:35,238 Total time: 23.4066 seconds
2024-09-10 16:28:35,238 Total inference time: 14.9438 seconds
2024-09-10 16:28:35,238 Inference time as percentage of total time: 63.84%
2024-09-10 16:28:35,343 Total time: 23.5119 seconds
2024-09-10 16:28:35,343 Total inference time: 14.9438 seconds
2024-09-10 16:28:35,343 Inference time as percentage of total time: 63.56%
2024-09-10 16:28:35,448 Total time: 23.6171 seconds
2024-09-10 16:28:35,448 Total inference time: 14.9438 seconds
2024-09-10 16:28:35,448 Inference time as percentage of total time: 63.28%
2024-09-10 16:28:35,554 Total time: 23.7229 seconds
2024-09-10 16:28:35,554 Total inference time: 14.9438 seconds
2024-09-10 16:28:35,554 Inference time as percentage of total time: 62.99%
2024-09-10 16:28:35,659 Total time: 23.8287 seconds
2024-09-10 16:28:35,660 Total inference time: 14.9438 seconds
2024-09-10 16:28:35,660 Inference time as percentage of total time: 62.71%
2024-09-10 16:28:35,765 Total time: 23.9345 seconds
2024-09-10 16:28:35,766 Total inference time: 14.9438 seconds
2024-09-10 16:28:35,766 Inference time as percentage of total time: 62.44%
2024-09-10 16:28:35,871 Total time: 24.0403 seconds
2024-09-10 16:28:35,871 Total inference time: 14.9438 seconds
2024-09-10 16:28:35,871 Inference time as percentage of total time: 62.16%
2024-09-10 16:28:35,972 Total time: 24.1419 seconds
2024-09-10 16:28:35,973 Total inference time: 14.9438 seconds
2024-09-10 16:28:35,973 Inference time as percentage of total time: 61.90%
2024-09-10 16:28:36,078 Total time: 24.2476 seconds
2024-09-10 16:28:36,078 Total inference time: 14.9438 seconds
2024-09-10 16:28:36,079 Inference time as percentage of total time: 61.63%
2024-09-10 16:28:36,179 Total time: 24.3484 seconds
2024-09-10 16:28:36,179 Total inference time: 14.9438 seconds
2024-09-10 16:28:36,179 Inference time as percentage of total time: 61.37%
2024-09-10 16:28:36,284 Total time: 24.4537 seconds
2024-09-10 16:28:36,284 Total inference time: 14.9438 seconds
2024-09-10 16:28:36,284 Inference time as percentage of total time: 61.11%
2024-09-10 16:28:36,389 Total time: 24.5589 seconds
2024-09-10 16:28:36,389 Total inference time: 14.9438 seconds
2024-09-10 16:28:36,390 Inference time as percentage of total time: 60.85%
2024-09-10 16:28:36,495 Total time: 24.6646 seconds
2024-09-10 16:28:36,495 Total inference time: 14.9438 seconds
2024-09-10 16:28:36,495 Inference time as percentage of total time: 60.59%
2024-09-10 16:28:36,601 Total time: 24.7704 seconds
2024-09-10 16:28:36,601 Total inference time: 14.9438 seconds
2024-09-10 16:28:36,601 Inference time as percentage of total time: 60.33%
2024-09-10 16:28:36,702 Total time: 24.8717 seconds
2024-09-10 16:28:36,702 Total inference time: 14.9438 seconds
2024-09-10 16:28:36,702 Inference time as percentage of total time: 60.08%
2024-09-10 16:28:36,808 Total time: 24.9776 seconds
2024-09-10 16:28:36,808 Total inference time: 14.9438 seconds
2024-09-10 16:28:36,808 Inference time as percentage of total time: 59.83%
2024-09-10 16:28:36,913 Total time: 25.0834 seconds
2024-09-10 16:28:36,914 Total inference time: 14.9438 seconds
2024-09-10 16:28:36,914 Inference time as percentage of total time: 59.58%
2024-09-10 16:28:37,016 Total time: 25.1856 seconds
2024-09-10 16:28:37,016 Total inference time: 14.9438 seconds
2024-09-10 16:28:37,016 Inference time as percentage of total time: 59.33%
2024-09-10 16:28:37,121 Total time: 25.2908 seconds
2024-09-10 16:28:37,121 Total inference time: 14.9438 seconds
2024-09-10 16:28:37,121 Inference time as percentage of total time: 59.09%
2024-09-10 16:28:37,226 Total time: 25.3961 seconds
2024-09-10 16:28:37,226 Total inference time: 14.9438 seconds
2024-09-10 16:28:37,226 Inference time as percentage of total time: 58.84%
2024-09-10 16:28:37,332 Total time: 25.5017 seconds
2024-09-10 16:28:37,332 Total inference time: 14.9438 seconds
2024-09-10 16:28:37,332 Inference time as percentage of total time: 58.60%
2024-09-10 16:28:37,438 Total time: 25.6079 seconds
2024-09-10 16:28:37,438 Total inference time: 14.9438 seconds
2024-09-10 16:28:37,438 Inference time as percentage of total time: 58.36%
2024-09-10 16:28:37,543 Total time: 25.7136 seconds
2024-09-10 16:28:37,544 Total inference time: 14.9438 seconds
2024-09-10 16:28:37,544 Inference time as percentage of total time: 58.12%
2024-09-10 16:28:37,649 Total time: 25.8188 seconds
2024-09-10 16:28:37,649 Total inference time: 14.9438 seconds
2024-09-10 16:28:37,649 Inference time as percentage of total time: 57.88%
2024-09-10 16:28:37,755 Total time: 25.9250 seconds
2024-09-10 16:28:37,755 Total inference time: 14.9438 seconds
2024-09-10 16:28:37,755 Inference time as percentage of total time: 57.64%
2024-09-10 16:28:37,860 Total time: 26.0307 seconds
2024-09-10 16:28:37,861 Total inference time: 14.9438 seconds
2024-09-10 16:28:37,861 Inference time as percentage of total time: 57.41%
2024-09-10 16:28:37,961 Total time: 26.1318 seconds
2024-09-10 16:28:37,962 Total inference time: 14.9438 seconds
2024-09-10 16:28:37,962 Inference time as percentage of total time: 57.19%
2024-09-10 16:28:38,067 Total time: 26.2378 seconds
2024-09-10 16:28:38,068 Total inference time: 14.9438 seconds
2024-09-10 16:28:38,068 Inference time as percentage of total time: 56.96%
2024-09-10 16:28:38,169 Total time: 26.3393 seconds
2024-09-10 16:28:38,169 Total inference time: 14.9438 seconds
2024-09-10 16:28:38,169 Inference time as percentage of total time: 56.74%
2024-09-10 16:28:38,275 Total time: 26.4452 seconds
2024-09-10 16:28:38,275 Total inference time: 14.9438 seconds
2024-09-10 16:28:38,275 Inference time as percentage of total time: 56.51%
2024-09-10 16:28:38,378 Total time: 26.5485 seconds
2024-09-10 16:28:38,378 Total inference time: 14.9438 seconds
2024-09-10 16:28:38,379 Inference time as percentage of total time: 56.29%
2024-09-10 16:28:38,482 Total time: 26.6522 seconds
2024-09-10 16:28:38,482 Total inference time: 14.9438 seconds
2024-09-10 16:28:38,482 Inference time as percentage of total time: 56.07%
2024-09-10 16:28:38,586 Total time: 26.7562 seconds
2024-09-10 16:28:38,586 Total inference time: 14.9438 seconds
2024-09-10 16:28:38,586 Inference time as percentage of total time: 55.85%
2024-09-10 16:28:38,692 Total time: 26.8623 seconds
2024-09-10 16:28:38,692 Total inference time: 14.9438 seconds
2024-09-10 16:28:38,692 Inference time as percentage of total time: 55.63%
2024-09-10 16:28:38,794 Total time: 26.9651 seconds
2024-09-10 16:28:38,795 Total inference time: 14.9438 seconds
2024-09-10 16:28:38,795 Inference time as percentage of total time: 55.42%
2024-09-10 16:28:38,897 Total time: 27.0678 seconds
2024-09-10 16:28:38,897 Total inference time: 14.9438 seconds
2024-09-10 16:28:38,898 Inference time as percentage of total time: 55.21%
2024-09-10 16:28:38,998 Total time: 27.1691 seconds
2024-09-10 16:28:38,998 Total inference time: 14.9438 seconds
2024-09-10 16:28:38,998 Inference time as percentage of total time: 55.00%
2024-09-10 16:28:39,104 Total time: 27.2745 seconds
2024-09-10 16:28:39,104 Total inference time: 14.9438 seconds
2024-09-10 16:28:39,104 Inference time as percentage of total time: 54.79%
2024-09-10 16:28:39,209 Total time: 27.3803 seconds
2024-09-10 16:28:39,210 Total inference time: 14.9438 seconds
2024-09-10 16:28:39,210 Inference time as percentage of total time: 54.58%
2024-09-10 16:28:39,315 Total time: 27.4855 seconds
2024-09-10 16:28:39,315 Total inference time: 14.9438 seconds
2024-09-10 16:28:39,315 Inference time as percentage of total time: 54.37%
2024-09-10 16:28:39,420 Total time: 27.5907 seconds
2024-09-10 16:28:39,420 Total inference time: 14.9438 seconds
2024-09-10 16:28:39,420 Inference time as percentage of total time: 54.16%
2024-09-10 16:28:39,526 Total time: 27.6967 seconds
2024-09-10 16:28:39,526 Total inference time: 14.9438 seconds
2024-09-10 16:28:39,526 Inference time as percentage of total time: 53.96%
2024-09-10 16:28:39,627 Total time: 27.7984 seconds
2024-09-10 16:28:39,628 Total inference time: 14.9438 seconds
2024-09-10 16:28:39,628 Inference time as percentage of total time: 53.76%
2024-09-10 16:28:39,733 Total time: 27.9043 seconds
2024-09-10 16:28:39,734 Total inference time: 14.9438 seconds
2024-09-10 16:28:39,734 Inference time as percentage of total time: 53.55%
2024-09-10 16:28:39,839 Total time: 28.0101 seconds
2024-09-10 16:28:39,839 Total inference time: 14.9438 seconds
2024-09-10 16:28:39,839 Inference time as percentage of total time: 53.35%
2024-09-10 16:28:39,945 Total time: 28.1159 seconds
2024-09-10 16:28:39,945 Total inference time: 14.9438 seconds
2024-09-10 16:28:39,945 Inference time as percentage of total time: 53.15%
2024-09-10 16:28:40,049 Total time: 28.2201 seconds
2024-09-10 16:28:40,049 Total inference time: 14.9438 seconds
2024-09-10 16:28:40,049 Inference time as percentage of total time: 52.95%
2024-09-10 16:28:40,154 Total time: 28.3252 seconds
2024-09-10 16:28:40,154 Total inference time: 14.9438 seconds
2024-09-10 16:28:40,154 Inference time as percentage of total time: 52.76%
2024-09-10 16:28:40,260 Total time: 28.4310 seconds
2024-09-10 16:28:40,260 Total inference time: 14.9438 seconds
2024-09-10 16:28:40,260 Inference time as percentage of total time: 52.56%
2024-09-10 16:28:40,360 Total time: 28.5318 seconds
2024-09-10 16:28:40,361 Total inference time: 14.9438 seconds
2024-09-10 16:28:40,361 Inference time as percentage of total time: 52.38%
2024-09-10 16:28:40,466 Total time: 28.6375 seconds
2024-09-10 16:28:40,466 Total inference time: 14.9438 seconds
2024-09-10 16:28:40,467 Inference time as percentage of total time: 52.18%
2024-09-10 16:28:40,570 Total time: 28.7416 seconds
2024-09-10 16:28:40,570 Total inference time: 14.9438 seconds
2024-09-10 16:28:40,571 Inference time as percentage of total time: 51.99%
2024-09-10 16:28:40,672 Total time: 28.8433 seconds
2024-09-10 16:28:40,672 Total inference time: 14.9438 seconds
2024-09-10 16:28:40,672 Inference time as percentage of total time: 51.81%
2024-09-10 16:28:40,777 Total time: 28.9484 seconds
2024-09-10 16:28:40,777 Total inference time: 14.9438 seconds
2024-09-10 16:28:40,777 Inference time as percentage of total time: 51.62%
2024-09-10 16:28:40,880 Total time: 29.0521 seconds
2024-09-10 16:28:40,881 Total inference time: 14.9438 seconds
2024-09-10 16:28:40,881 Inference time as percentage of total time: 51.44%
2024-09-10 16:28:40,984 Total time: 29.1552 seconds
2024-09-10 16:28:40,984 Total inference time: 14.9438 seconds
2024-09-10 16:28:40,984 Inference time as percentage of total time: 51.26%
2024-09-10 16:28:41,087 Total time: 29.2585 seconds
2024-09-10 16:28:41,087 Total inference time: 14.9438 seconds
2024-09-10 16:28:41,087 Inference time as percentage of total time: 51.08%
2024-09-10 16:28:41,188 Total time: 29.3602 seconds
2024-09-10 16:28:41,189 Total inference time: 14.9438 seconds
2024-09-10 16:28:41,189 Inference time as percentage of total time: 50.90%
2024-09-10 16:28:41,294 Total time: 29.4659 seconds
2024-09-10 16:28:41,294 Total inference time: 14.9438 seconds
2024-09-10 16:28:41,295 Inference time as percentage of total time: 50.72%
2024-09-10 16:28:41,396 Total time: 29.5677 seconds
2024-09-10 16:28:41,396 Total inference time: 14.9438 seconds
2024-09-10 16:28:41,396 Inference time as percentage of total time: 50.54%
2024-09-10 16:28:41,502 Total time: 29.6734 seconds
2024-09-10 16:28:41,502 Total inference time: 14.9438 seconds
2024-09-10 16:28:41,502 Inference time as percentage of total time: 50.36%
2024-09-10 16:28:41,607 Total time: 29.7790 seconds
2024-09-10 16:28:41,608 Total inference time: 14.9438 seconds
2024-09-10 16:28:41,608 Inference time as percentage of total time: 50.18%
2024-09-10 16:28:41,713 Total time: 29.8849 seconds
2024-09-10 16:28:41,713 Total inference time: 14.9438 seconds
2024-09-10 16:28:41,714 Inference time as percentage of total time: 50.00%
2024-09-10 16:28:41,819 Total time: 29.9907 seconds
2024-09-10 16:28:41,819 Total inference time: 14.9438 seconds
2024-09-10 16:28:41,819 Inference time as percentage of total time: 49.83%
2024-09-10 16:28:41,921 Total time: 30.0933 seconds
2024-09-10 16:28:41,922 Total inference time: 14.9438 seconds
2024-09-10 16:28:41,922 Inference time as percentage of total time: 49.66%
2024-09-10 16:28:42,026 Total time: 30.1985 seconds
2024-09-10 16:28:42,027 Total inference time: 14.9438 seconds
2024-09-10 16:28:42,027 Inference time as percentage of total time: 49.49%
2024-09-10 16:28:42,130 Total time: 30.3021 seconds
2024-09-10 16:28:42,130 Total inference time: 14.9438 seconds
2024-09-10 16:28:42,131 Inference time as percentage of total time: 49.32%
2024-09-10 16:28:42,236 Total time: 30.4079 seconds
2024-09-10 16:28:42,236 Total inference time: 14.9438 seconds
2024-09-10 16:28:42,236 Inference time as percentage of total time: 49.14%
2024-09-10 16:28:42,338 Total time: 30.5100 seconds
2024-09-10 16:28:42,338 Total inference time: 14.9438 seconds
2024-09-10 16:28:42,338 Inference time as percentage of total time: 48.98%
2024-09-10 16:28:42,444 Total time: 30.6157 seconds
2024-09-10 16:28:42,444 Total inference time: 14.9438 seconds
2024-09-10 16:28:42,444 Inference time as percentage of total time: 48.81%
2024-09-10 16:28:42,549 Total time: 30.7214 seconds
2024-09-10 16:28:42,550 Total inference time: 14.9438 seconds
2024-09-10 16:28:42,550 Inference time as percentage of total time: 48.64%
2024-09-10 16:28:42,655 Total time: 30.8271 seconds
2024-09-10 16:28:42,655 Total inference time: 14.9438 seconds
2024-09-10 16:28:42,655 Inference time as percentage of total time: 48.48%
2024-09-10 16:28:42,759 Total time: 30.9317 seconds
2024-09-10 16:28:42,760 Total inference time: 14.9438 seconds
2024-09-10 16:28:42,760 Inference time as percentage of total time: 48.31%
2024-09-10 16:28:42,865 Total time: 31.0374 seconds
2024-09-10 16:28:42,865 Total inference time: 14.9438 seconds
2024-09-10 16:28:42,866 Inference time as percentage of total time: 48.15%
2024-09-10 16:28:42,967 Total time: 31.1395 seconds
2024-09-10 16:28:42,967 Total inference time: 14.9438 seconds
2024-09-10 16:28:42,968 Inference time as percentage of total time: 47.99%
2024-09-10 16:28:43,069 Total time: 31.2416 seconds
2024-09-10 16:28:43,070 Total inference time: 14.9438 seconds
2024-09-10 16:28:43,070 Inference time as percentage of total time: 47.83%
2024-09-10 16:28:43,175 Total time: 31.3474 seconds
2024-09-10 16:28:43,175 Total inference time: 14.9438 seconds
2024-09-10 16:28:43,176 Inference time as percentage of total time: 47.67%
2024-09-10 16:28:43,280 Total time: 31.4521 seconds
2024-09-10 16:28:43,280 Total inference time: 14.9438 seconds
2024-09-10 16:28:43,280 Inference time as percentage of total time: 47.51%
2024-09-10 16:28:43,385 Total time: 31.5578 seconds
2024-09-10 16:28:43,386 Total inference time: 14.9438 seconds
2024-09-10 16:28:43,386 Inference time as percentage of total time: 47.35%
2024-09-10 16:28:43,487 Total time: 31.6591 seconds
2024-09-10 16:28:43,487 Total inference time: 14.9438 seconds
2024-09-10 16:28:43,487 Inference time as percentage of total time: 47.20%
2024-09-10 16:28:43,592 Total time: 31.7648 seconds
2024-09-10 16:28:43,593 Total inference time: 14.9438 seconds
2024-09-10 16:28:43,593 Inference time as percentage of total time: 47.05%
2024-09-10 16:28:43,696 Total time: 31.8684 seconds
2024-09-10 16:28:43,696 Total inference time: 14.9438 seconds
2024-09-10 16:28:43,696 Inference time as percentage of total time: 46.89%
2024-09-10 16:28:43,802 Total time: 31.9743 seconds
2024-09-10 16:28:43,802 Total inference time: 14.9438 seconds
2024-09-10 16:28:43,802 Inference time as percentage of total time: 46.74%
2024-09-10 16:28:43,907 Total time: 32.0801 seconds
2024-09-10 16:28:43,908 Total inference time: 14.9438 seconds
2024-09-10 16:28:43,908 Inference time as percentage of total time: 46.58%
2024-09-10 16:28:44,013 Total time: 32.1859 seconds
2024-09-10 16:28:44,014 Total inference time: 14.9438 seconds
2024-09-10 16:28:44,014 Inference time as percentage of total time: 46.43%
2024-09-10 16:28:44,118 Total time: 32.2902 seconds
2024-09-10 16:28:44,118 Total inference time: 14.9438 seconds
2024-09-10 16:28:44,118 Inference time as percentage of total time: 46.28%
2024-09-10 16:28:44,223 Total time: 32.3960 seconds
2024-09-10 16:28:44,224 Total inference time: 14.9438 seconds
2024-09-10 16:28:44,224 Inference time as percentage of total time: 46.13%
2024-09-10 16:28:44,329 Total time: 32.5017 seconds
2024-09-10 16:28:44,329 Total inference time: 14.9438 seconds
2024-09-10 16:28:44,329 Inference time as percentage of total time: 45.98%
2024-09-10 16:28:44,434 Total time: 32.6063 seconds
2024-09-10 16:28:44,434 Total inference time: 14.9438 seconds
2024-09-10 16:28:44,434 Inference time as percentage of total time: 45.83%
2024-09-10 16:28:44,537 Total time: 32.7100 seconds
2024-09-10 16:28:44,538 Total inference time: 14.9438 seconds
2024-09-10 16:28:44,538 Inference time as percentage of total time: 45.69%
2024-09-10 16:28:44,641 Total time: 32.8137 seconds
2024-09-10 16:28:44,641 Total inference time: 14.9438 seconds
2024-09-10 16:28:44,641 Inference time as percentage of total time: 45.54%
2024-09-10 16:28:44,742 Total time: 32.9151 seconds
2024-09-10 16:28:44,743 Total inference time: 14.9438 seconds
2024-09-10 16:28:44,743 Inference time as percentage of total time: 45.40%
2024-09-10 16:28:44,847 Total time: 33.0196 seconds
2024-09-10 16:28:44,847 Total inference time: 14.9438 seconds
2024-09-10 16:28:44,847 Inference time as percentage of total time: 45.26%
2024-09-10 16:28:44,953 Total time: 33.1254 seconds
2024-09-10 16:28:44,953 Total inference time: 14.9438 seconds
2024-09-10 16:28:44,953 Inference time as percentage of total time: 45.11%
2024-09-10 16:28:45,054 Total time: 33.2269 seconds
2024-09-10 16:28:45,054 Total inference time: 14.9438 seconds
2024-09-10 16:28:45,055 Inference time as percentage of total time: 44.98%
2024-09-10 16:28:45,160 Total time: 33.3328 seconds
2024-09-10 16:28:45,160 Total inference time: 14.9438 seconds
2024-09-10 16:28:45,160 Inference time as percentage of total time: 44.83%
2024-09-10 16:28:45,266 Total time: 33.4386 seconds
2024-09-10 16:28:45,266 Total inference time: 14.9438 seconds
2024-09-10 16:28:45,266 Inference time as percentage of total time: 44.69%
2024-09-10 16:28:45,371 Total time: 33.5444 seconds
2024-09-10 16:28:45,372 Total inference time: 14.9438 seconds
2024-09-10 16:28:45,372 Inference time as percentage of total time: 44.55%
2024-09-10 16:28:45,475 Total time: 33.6484 seconds
2024-09-10 16:28:45,476 Total inference time: 14.9438 seconds
2024-09-10 16:28:45,476 Inference time as percentage of total time: 44.41%
2024-09-10 16:28:45,581 Total time: 33.7542 seconds
2024-09-10 16:28:45,581 Total inference time: 14.9438 seconds
2024-09-10 16:28:45,582 Inference time as percentage of total time: 44.27%
2024-09-10 16:28:45,687 Total time: 33.8599 seconds
2024-09-10 16:28:45,687 Total inference time: 14.9438 seconds
2024-09-10 16:28:45,687 Inference time as percentage of total time: 44.13%
2024-09-10 16:28:45,793 Total time: 33.9657 seconds
2024-09-10 16:28:45,793 Total inference time: 14.9438 seconds
2024-09-10 16:28:45,793 Inference time as percentage of total time: 44.00%
2024-09-10 16:28:45,898 Total time: 34.0714 seconds
2024-09-10 16:28:45,899 Total inference time: 14.9438 seconds
2024-09-10 16:28:45,899 Inference time as percentage of total time: 43.86%
2024-09-10 16:28:46,004 Total time: 34.1771 seconds
2024-09-10 16:28:46,004 Total inference time: 14.9438 seconds
2024-09-10 16:28:46,004 Inference time as percentage of total time: 43.72%
2024-09-10 16:28:46,109 Total time: 34.2827 seconds
2024-09-10 16:28:46,110 Total inference time: 14.9438 seconds
2024-09-10 16:28:46,110 Inference time as percentage of total time: 43.59%
2024-09-10 16:28:46,215 Total time: 34.3881 seconds
2024-09-10 16:28:46,215 Total inference time: 14.9438 seconds
2024-09-10 16:28:46,215 Inference time as percentage of total time: 43.46%
2024-09-10 16:28:46,318 Total time: 34.4913 seconds
2024-09-10 16:28:46,318 Total inference time: 14.9438 seconds
2024-09-10 16:28:46,318 Inference time as percentage of total time: 43.33%
2024-09-10 16:28:46,424 Total time: 34.5969 seconds
2024-09-10 16:28:46,424 Total inference time: 14.9438 seconds
2024-09-10 16:28:46,424 Inference time as percentage of total time: 43.19%
2024-09-10 16:28:46,526 Total time: 34.6989 seconds
2024-09-10 16:28:46,526 Total inference time: 14.9438 seconds
2024-09-10 16:28:46,526 Inference time as percentage of total time: 43.07%
2024-09-10 16:28:46,631 Total time: 34.8045 seconds
2024-09-10 16:28:46,631 Total inference time: 14.9438 seconds
2024-09-10 16:28:46,632 Inference time as percentage of total time: 42.94%
2024-09-10 16:28:46,737 Total time: 34.9103 seconds
2024-09-10 16:28:46,737 Total inference time: 14.9438 seconds
2024-09-10 16:28:46,737 Inference time as percentage of total time: 42.81%
2024-09-10 16:28:46,843 Total time: 35.0162 seconds
2024-09-10 16:28:46,843 Total inference time: 14.9438 seconds
2024-09-10 16:28:46,843 Inference time as percentage of total time: 42.68%
2024-09-10 16:28:46,944 Total time: 35.1172 seconds
2024-09-10 16:28:46,944 Total inference time: 14.9438 seconds
2024-09-10 16:28:46,944 Inference time as percentage of total time: 42.55%
2024-09-10 16:28:47,048 Total time: 35.2215 seconds
2024-09-10 16:28:47,048 Total inference time: 14.9438 seconds
2024-09-10 16:28:47,048 Inference time as percentage of total time: 42.43%
2024-09-10 16:28:47,153 Total time: 35.3270 seconds
2024-09-10 16:28:47,154 Total inference time: 14.9438 seconds
2024-09-10 16:28:47,154 Inference time as percentage of total time: 42.30%
2024-09-10 16:28:47,258 Total time: 35.4318 seconds
2024-09-10 16:28:47,259 Total inference time: 14.9438 seconds
2024-09-10 16:28:47,259 Inference time as percentage of total time: 42.18%
2024-09-10 16:28:47,362 Total time: 35.5351 seconds
2024-09-10 16:28:47,362 Total inference time: 14.9438 seconds
2024-09-10 16:28:47,362 Inference time as percentage of total time: 42.05%
2024-09-10 16:28:47,463 Total time: 35.6368 seconds
2024-09-10 16:28:47,464 Total inference time: 14.9438 seconds
2024-09-10 16:28:47,464 Inference time as percentage of total time: 41.93%
2024-09-10 16:28:47,566 Total time: 35.7395 seconds
2024-09-10 16:28:47,566 Total inference time: 14.9438 seconds
2024-09-10 16:28:47,566 Inference time as percentage of total time: 41.81%
2024-09-10 16:28:47,670 Total time: 35.8433 seconds
2024-09-10 16:28:47,670 Total inference time: 14.9438 seconds
2024-09-10 16:28:47,670 Inference time as percentage of total time: 41.69%
2024-09-10 16:28:47,775 Total time: 35.9491 seconds
2024-09-10 16:28:47,776 Total inference time: 14.9438 seconds
2024-09-10 16:28:47,776 Inference time as percentage of total time: 41.57%
2024-09-10 16:28:47,878 Total time: 36.0512 seconds
2024-09-10 16:28:47,878 Total inference time: 14.9438 seconds
2024-09-10 16:28:47,878 Inference time as percentage of total time: 41.45%
2024-09-10 16:28:47,983 Total time: 36.1570 seconds
2024-09-10 16:28:47,984 Total inference time: 14.9438 seconds
2024-09-10 16:28:47,984 Inference time as percentage of total time: 41.33%
2024-09-10 16:28:48,089 Total time: 36.2627 seconds
2024-09-10 16:28:48,089 Total inference time: 14.9438 seconds
2024-09-10 16:28:48,089 Inference time as percentage of total time: 41.21%
2024-09-10 16:28:48,191 Total time: 36.3651 seconds
2024-09-10 16:28:48,192 Total inference time: 14.9438 seconds
2024-09-10 16:28:48,192 Inference time as percentage of total time: 41.09%
2024-09-10 16:28:48,297 Total time: 36.4709 seconds
2024-09-10 16:28:48,298 Total inference time: 14.9438 seconds
2024-09-10 16:28:48,298 Inference time as percentage of total time: 40.97%
2024-09-10 16:28:48,403 Total time: 36.5768 seconds
2024-09-10 16:28:48,403 Total inference time: 14.9438 seconds
2024-09-10 16:28:48,404 Inference time as percentage of total time: 40.86%
2024-09-10 16:28:48,508 Total time: 36.6818 seconds
2024-09-10 16:28:48,508 Total inference time: 14.9438 seconds
2024-09-10 16:28:48,508 Inference time as percentage of total time: 40.74%
2024-09-10 16:28:48,612 Total time: 36.7855 seconds
2024-09-10 16:28:48,612 Total inference time: 14.9438 seconds
2024-09-10 16:28:48,612 Inference time as percentage of total time: 40.62%
2024-09-10 16:28:48,714 Total time: 36.8882 seconds
2024-09-10 16:28:48,715 Total inference time: 14.9438 seconds
2024-09-10 16:28:48,715 Inference time as percentage of total time: 40.51%
2024-09-10 16:28:48,819 Total time: 36.9928 seconds
2024-09-10 16:28:48,819 Total inference time: 14.9438 seconds
2024-09-10 16:28:48,819 Inference time as percentage of total time: 40.40%
2024-09-10 16:28:48,925 Total time: 37.0986 seconds
2024-09-10 16:28:48,925 Total inference time: 14.9438 seconds
2024-09-10 16:28:48,925 Inference time as percentage of total time: 40.28%
2024-09-10 16:28:49,031 Total time: 37.2046 seconds
2024-09-10 16:28:49,031 Total inference time: 14.9438 seconds
2024-09-10 16:28:49,031 Inference time as percentage of total time: 40.17%
2024-09-10 16:28:49,132 Total time: 37.3063 seconds
2024-09-10 16:28:49,133 Total inference time: 14.9438 seconds
2024-09-10 16:28:49,133 Inference time as percentage of total time: 40.06%
2024-09-10 16:28:49,236 Total time: 37.4100 seconds
2024-09-10 16:28:49,236 Total inference time: 14.9438 seconds
2024-09-10 16:28:49,237 Inference time as percentage of total time: 39.95%
2024-09-10 16:28:49,341 Total time: 37.5151 seconds
2024-09-10 16:28:49,342 Total inference time: 14.9438 seconds
2024-09-10 16:28:49,342 Inference time as percentage of total time: 39.83%
2024-09-10 16:28:49,447 Total time: 37.6210 seconds
2024-09-10 16:28:49,447 Total inference time: 14.9438 seconds
2024-09-10 16:28:49,448 Inference time as percentage of total time: 39.72%
2024-09-10 16:28:49,553 Total time: 37.7269 seconds
2024-09-10 16:28:49,553 Total inference time: 14.9438 seconds
2024-09-10 16:28:49,554 Inference time as percentage of total time: 39.61%
2024-09-10 16:28:49,659 Total time: 37.8329 seconds
2024-09-10 16:28:49,659 Total inference time: 14.9438 seconds
2024-09-10 16:28:49,659 Inference time as percentage of total time: 39.50%
2024-09-10 16:28:49,765 Total time: 37.9387 seconds
2024-09-10 16:28:49,765 Total inference time: 14.9438 seconds
2024-09-10 16:28:49,765 Inference time as percentage of total time: 39.39%
2024-09-10 16:28:49,870 Total time: 38.0445 seconds
2024-09-10 16:28:49,871 Total inference time: 14.9438 seconds
2024-09-10 16:28:49,871 Inference time as percentage of total time: 39.28%
2024-09-10 16:28:49,974 Total time: 38.1484 seconds
2024-09-10 16:28:49,975 Total inference time: 14.9438 seconds
2024-09-10 16:28:49,975 Inference time as percentage of total time: 39.17%
2024-09-10 16:28:50,077 Total time: 38.2514 seconds
2024-09-10 16:28:50,078 Total inference time: 14.9438 seconds
2024-09-10 16:28:50,078 Inference time as percentage of total time: 39.07%
2024-09-10 16:28:50,183 Total time: 38.3574 seconds
2024-09-10 16:28:50,184 Total inference time: 14.9438 seconds
2024-09-10 16:28:50,184 Inference time as percentage of total time: 38.96%
2024-09-10 16:28:50,286 Total time: 38.4600 seconds
2024-09-10 16:28:50,286 Total inference time: 14.9438 seconds
2024-09-10 16:28:50,286 Inference time as percentage of total time: 38.86%
2024-09-10 16:28:50,392 Total time: 38.5658 seconds
2024-09-10 16:28:50,392 Total inference time: 14.9438 seconds
2024-09-10 16:28:50,392 Inference time as percentage of total time: 38.75%
2024-09-10 16:28:50,497 Total time: 38.6716 seconds
2024-09-10 16:28:50,498 Total inference time: 14.9438 seconds
2024-09-10 16:28:50,498 Inference time as percentage of total time: 38.64%
2024-09-10 16:28:50,603 Total time: 38.7773 seconds
2024-09-10 16:28:50,603 Total inference time: 14.9438 seconds
2024-09-10 16:28:50,604 Inference time as percentage of total time: 38.54%
2024-09-10 16:28:50,709 Total time: 38.8831 seconds
2024-09-10 16:28:50,709 Total inference time: 14.9438 seconds
2024-09-10 16:28:50,709 Inference time as percentage of total time: 38.43%
2024-09-10 16:28:50,811 Total time: 38.9855 seconds
2024-09-10 16:28:50,811 Total inference time: 14.9438 seconds
2024-09-10 16:28:50,812 Inference time as percentage of total time: 38.33%
2024-09-10 16:28:50,917 Total time: 39.0913 seconds
2024-09-10 16:28:50,917 Total inference time: 14.9438 seconds
2024-09-10 16:28:50,917 Inference time as percentage of total time: 38.23%
2024-09-10 16:28:51,023 Total time: 39.1970 seconds
2024-09-10 16:28:51,023 Total inference time: 14.9438 seconds
2024-09-10 16:28:51,023 Inference time as percentage of total time: 38.12%
2024-09-10 16:28:51,127 Total time: 39.3014 seconds
2024-09-10 16:28:51,127 Total inference time: 14.9438 seconds
2024-09-10 16:28:51,128 Inference time as percentage of total time: 38.02%
2024-09-10 16:28:51,233 Total time: 39.4071 seconds
2024-09-10 16:28:51,233 Total inference time: 14.9438 seconds
2024-09-10 16:28:51,233 Inference time as percentage of total time: 37.92%
2024-09-10 16:28:51,333 Total time: 39.5078 seconds
2024-09-10 16:28:51,334 Total inference time: 14.9438 seconds
2024-09-10 16:28:51,334 Inference time as percentage of total time: 37.82%
2024-09-10 16:28:51,439 Total time: 39.6136 seconds
2024-09-10 16:28:51,440 Total inference time: 14.9438 seconds
2024-09-10 16:28:51,440 Inference time as percentage of total time: 37.72%
2024-09-10 16:28:51,541 Total time: 39.7156 seconds
2024-09-10 16:28:51,542 Total inference time: 14.9438 seconds
2024-09-10 16:28:51,542 Inference time as percentage of total time: 37.63%
2024-09-10 16:28:51,647 Total time: 39.8215 seconds
2024-09-10 16:28:51,647 Total inference time: 14.9438 seconds
2024-09-10 16:28:51,648 Inference time as percentage of total time: 37.53%
2024-09-10 16:28:51,752 Total time: 39.9266 seconds
2024-09-10 16:28:51,752 Total inference time: 14.9438 seconds
2024-09-10 16:28:51,753 Inference time as percentage of total time: 37.43%
2024-09-10 16:28:51,858 Total time: 40.0324 seconds
2024-09-10 16:28:51,858 Total inference time: 14.9438 seconds
2024-09-10 16:28:51,858 Inference time as percentage of total time: 37.33%
2024-09-10 16:28:51,963 Total time: 40.1380 seconds
2024-09-10 16:28:51,964 Total inference time: 14.9438 seconds
2024-09-10 16:28:51,964 Inference time as percentage of total time: 37.23%
2024-09-10 16:28:52,069 Total time: 40.2437 seconds
2024-09-10 16:28:52,069 Total inference time: 14.9438 seconds
2024-09-10 16:28:52,070 Inference time as percentage of total time: 37.13%
2024-09-10 16:28:52,175 Total time: 40.3493 seconds
2024-09-10 16:28:52,175 Total inference time: 14.9438 seconds
2024-09-10 16:28:52,175 Inference time as percentage of total time: 37.04%
2024-09-10 16:28:52,278 Total time: 40.4521 seconds
2024-09-10 16:28:52,278 Total inference time: 14.9438 seconds
2024-09-10 16:28:52,278 Inference time as percentage of total time: 36.94%
2024-09-10 16:28:52,379 Total time: 40.5540 seconds
2024-09-10 16:28:52,380 Total inference time: 14.9438 seconds
2024-09-10 16:28:52,380 Inference time as percentage of total time: 36.85%
2024-09-10 16:28:52,480 Total time: 40.6550 seconds
2024-09-10 16:28:52,481 Total inference time: 14.9438 seconds
2024-09-10 16:28:52,481 Inference time as percentage of total time: 36.76%
2024-09-10 16:28:52,584 Total time: 40.7588 seconds
2024-09-10 16:28:52,585 Total inference time: 14.9438 seconds
2024-09-10 16:28:52,585 Inference time as percentage of total time: 36.66%
2024-09-10 16:28:52,685 Total time: 40.8600 seconds
2024-09-10 16:28:52,686 Total inference time: 14.9438 seconds
2024-09-10 16:28:52,686 Inference time as percentage of total time: 36.57%
2024-09-10 16:28:52,791 Total time: 40.9657 seconds
2024-09-10 16:28:52,791 Total inference time: 14.9438 seconds
2024-09-10 16:28:52,791 Inference time as percentage of total time: 36.48%
2024-09-10 16:28:52,897 Total time: 41.0713 seconds
2024-09-10 16:28:52,897 Total inference time: 14.9438 seconds
2024-09-10 16:28:52,897 Inference time as percentage of total time: 36.39%
2024-09-10 16:28:53,002 Total time: 41.1766 seconds
2024-09-10 16:28:53,002 Total inference time: 14.9438 seconds
2024-09-10 16:28:53,002 Inference time as percentage of total time: 36.29%
2024-09-10 16:28:53,108 Total time: 41.2823 seconds
2024-09-10 16:28:53,108 Total inference time: 14.9438 seconds
2024-09-10 16:28:53,108 Inference time as percentage of total time: 36.20%
2024-09-10 16:28:53,213 Total time: 41.3879 seconds
2024-09-10 16:28:53,213 Total inference time: 14.9438 seconds
2024-09-10 16:28:53,214 Inference time as percentage of total time: 36.11%
2024-09-10 16:28:53,318 Total time: 41.4933 seconds
2024-09-10 16:28:53,319 Total inference time: 14.9438 seconds
2024-09-10 16:28:53,319 Inference time as percentage of total time: 36.02%
2024-09-10 16:28:53,424 Total time: 41.5984 seconds
2024-09-10 16:28:53,424 Total inference time: 14.9438 seconds
2024-09-10 16:28:53,424 Inference time as percentage of total time: 35.92%
2024-09-10 16:28:53,525 Total time: 41.7000 seconds
2024-09-10 16:28:53,525 Total inference time: 14.9438 seconds
2024-09-10 16:28:53,526 Inference time as percentage of total time: 35.84%
2024-09-10 16:28:53,627 Total time: 41.8021 seconds
2024-09-10 16:28:53,628 Total inference time: 14.9438 seconds
2024-09-10 16:28:53,628 Inference time as percentage of total time: 35.75%
2024-09-10 16:28:53,733 Total time: 41.9077 seconds
2024-09-10 16:28:53,733 Total inference time: 14.9438 seconds
2024-09-10 16:28:53,733 Inference time as percentage of total time: 35.66%
2024-09-10 16:28:53,835 Total time: 42.0103 seconds
2024-09-10 16:28:53,836 Total inference time: 14.9438 seconds
2024-09-10 16:28:53,836 Inference time as percentage of total time: 35.57%
2024-09-10 16:28:53,937 Total time: 42.1120 seconds
2024-09-10 16:28:53,937 Total inference time: 14.9438 seconds
2024-09-10 16:28:53,938 Inference time as percentage of total time: 35.49%
2024-09-10 16:28:54,040 Total time: 42.2151 seconds
2024-09-10 16:28:54,040 Total inference time: 14.9438 seconds
2024-09-10 16:28:54,041 Inference time as percentage of total time: 35.40%
2024-09-10 16:28:54,146 Total time: 42.3207 seconds
2024-09-10 16:28:54,146 Total inference time: 14.9438 seconds
2024-09-10 16:28:54,146 Inference time as percentage of total time: 35.31%
2024-09-10 16:28:54,251 Total time: 42.4264 seconds
2024-09-10 16:28:54,252 Total inference time: 14.9438 seconds
2024-09-10 16:28:54,252 Inference time as percentage of total time: 35.22%
2024-09-10 16:28:54,357 Total time: 42.5317 seconds
2024-09-10 16:28:54,357 Total inference time: 14.9438 seconds
2024-09-10 16:28:54,357 Inference time as percentage of total time: 35.14%
2024-09-10 16:28:54,459 Total time: 42.6342 seconds
2024-09-10 16:28:54,460 Total inference time: 14.9438 seconds
2024-09-10 16:28:54,460 Inference time as percentage of total time: 35.05%
2024-09-10 16:28:54,564 Total time: 42.7392 seconds
2024-09-10 16:28:54,565 Total inference time: 14.9438 seconds
2024-09-10 16:28:54,565 Inference time as percentage of total time: 34.97%
2024-09-10 16:28:54,670 Total time: 42.8450 seconds
2024-09-10 16:28:54,670 Total inference time: 14.9438 seconds
2024-09-10 16:28:54,671 Inference time as percentage of total time: 34.88%
2024-09-10 16:28:54,773 Total time: 42.9484 seconds
2024-09-10 16:28:54,774 Total inference time: 14.9438 seconds
2024-09-10 16:28:54,774 Inference time as percentage of total time: 34.79%
2024-09-10 16:28:54,876 Total time: 43.0512 seconds
2024-09-10 16:28:54,877 Total inference time: 14.9438 seconds
2024-09-10 16:28:54,877 Inference time as percentage of total time: 34.71%
2024-09-10 16:28:54,980 Total time: 43.1555 seconds
2024-09-10 16:28:54,981 Total inference time: 14.9438 seconds
2024-09-10 16:28:54,981 Inference time as percentage of total time: 34.63%
2024-09-10 16:28:55,086 Total time: 43.2612 seconds
2024-09-10 16:28:55,086 Total inference time: 14.9438 seconds
2024-09-10 16:28:55,087 Inference time as percentage of total time: 34.54%
2024-09-10 16:28:55,190 Total time: 43.3651 seconds
2024-09-10 16:28:55,190 Total inference time: 14.9438 seconds
2024-09-10 16:28:55,191 Inference time as percentage of total time: 34.46%
2024-09-10 16:28:55,296 Total time: 43.4708 seconds
2024-09-10 16:28:55,296 Total inference time: 14.9438 seconds
2024-09-10 16:28:55,296 Inference time as percentage of total time: 34.38%
2024-09-10 16:28:55,399 Total time: 43.5738 seconds
2024-09-10 16:28:55,399 Total inference time: 14.9438 seconds
2024-09-10 16:28:55,399 Inference time as percentage of total time: 34.30%
2024-09-10 16:28:55,504 Total time: 43.6795 seconds
2024-09-10 16:28:55,505 Total inference time: 14.9438 seconds
2024-09-10 16:28:55,505 Inference time as percentage of total time: 34.21%
2024-09-10 16:28:55,606 Total time: 43.7814 seconds
2024-09-10 16:28:55,607 Total inference time: 14.9438 seconds
2024-09-10 16:28:55,607 Inference time as percentage of total time: 34.13%
2024-09-10 16:28:55,712 Total time: 43.8872 seconds
2024-09-10 16:28:55,712 Total inference time: 14.9438 seconds
2024-09-10 16:28:55,712 Inference time as percentage of total time: 34.05%
2024-09-10 16:28:55,818 Total time: 43.9929 seconds
2024-09-10 16:28:55,818 Total inference time: 14.9438 seconds
2024-09-10 16:28:55,818 Inference time as percentage of total time: 33.97%
2024-09-10 16:28:55,920 Total time: 44.0955 seconds
2024-09-10 16:28:55,921 Total inference time: 14.9438 seconds
2024-09-10 16:28:55,921 Inference time as percentage of total time: 33.89%
2024-09-10 16:28:56,026 Total time: 44.2012 seconds
2024-09-10 16:28:56,026 Total inference time: 14.9438 seconds
2024-09-10 16:28:56,026 Inference time as percentage of total time: 33.81%
2024-09-10 16:28:56,131 Total time: 44.3065 seconds
2024-09-10 16:28:56,132 Total inference time: 14.9438 seconds
2024-09-10 16:28:56,132 Inference time as percentage of total time: 33.73%
2024-09-10 16:28:56,237 Total time: 44.4122 seconds
2024-09-10 16:28:56,237 Total inference time: 14.9438 seconds
2024-09-10 16:28:56,237 Inference time as percentage of total time: 33.65%
2024-09-10 16:28:56,343 Total time: 44.5178 seconds
2024-09-10 16:28:56,343 Total inference time: 14.9438 seconds
2024-09-10 16:28:56,343 Inference time as percentage of total time: 33.57%
2024-09-10 16:28:56,448 Total time: 44.6235 seconds
2024-09-10 16:28:56,448 Total inference time: 14.9438 seconds
2024-09-10 16:28:56,449 Inference time as percentage of total time: 33.49%
2024-09-10 16:28:56,554 Total time: 44.7292 seconds
2024-09-10 16:28:56,554 Total inference time: 14.9438 seconds
2024-09-10 16:28:56,554 Inference time as percentage of total time: 33.41%
2024-09-10 16:28:56,656 Total time: 44.8317 seconds
2024-09-10 16:28:56,657 Total inference time: 14.9438 seconds
2024-09-10 16:28:56,657 Inference time as percentage of total time: 33.33%
2024-09-10 16:28:56,762 Total time: 44.9376 seconds
2024-09-10 16:28:56,763 Total inference time: 14.9438 seconds
2024-09-10 16:28:56,763 Inference time as percentage of total time: 33.25%
2024-09-10 16:28:56,867 Total time: 45.0418 seconds
2024-09-10 16:28:56,867 Total inference time: 14.9438 seconds
2024-09-10 16:28:56,867 Inference time as percentage of total time: 33.18%
2024-09-10 16:28:56,972 Total time: 45.1475 seconds
2024-09-10 16:28:56,972 Total inference time: 14.9438 seconds
2024-09-10 16:28:56,973 Inference time as percentage of total time: 33.10%
2024-09-10 16:28:57,076 Total time: 45.2514 seconds
2024-09-10 16:28:57,077 Total inference time: 14.9438 seconds
2024-09-10 16:28:57,077 Inference time as percentage of total time: 33.02%
2024-09-10 16:28:57,181 Total time: 45.3562 seconds
2024-09-10 16:28:57,181 Total inference time: 14.9438 seconds
2024-09-10 16:28:57,182 Inference time as percentage of total time: 32.95%
2024-09-10 16:28:57,287 Total time: 45.4621 seconds
2024-09-10 16:28:57,287 Total inference time: 14.9438 seconds
2024-09-10 16:28:57,287 Inference time as percentage of total time: 32.87%
2024-09-10 16:28:57,392 Total time: 45.5679 seconds
2024-09-10 16:28:57,393 Total inference time: 14.9438 seconds
2024-09-10 16:28:57,393 Inference time as percentage of total time: 32.79%
2024-09-10 16:28:57,498 Total time: 45.6736 seconds
2024-09-10 16:28:57,499 Total inference time: 14.9438 seconds
2024-09-10 16:28:57,499 Inference time as percentage of total time: 32.72%
2024-09-10 16:28:57,601 Total time: 45.7766 seconds
2024-09-10 16:28:57,602 Total inference time: 14.9438 seconds
2024-09-10 16:28:57,602 Inference time as percentage of total time: 32.65%
2024-09-10 16:28:57,707 Total time: 45.8824 seconds
2024-09-10 16:28:57,707 Total inference time: 14.9438 seconds
2024-09-10 16:28:57,707 Inference time as percentage of total time: 32.57%
2024-09-10 16:28:57,813 Total time: 45.9881 seconds
2024-09-10 16:28:57,813 Total inference time: 14.9438 seconds
2024-09-10 16:28:57,813 Inference time as percentage of total time: 32.50%
2024-09-10 16:28:57,918 Total time: 46.0937 seconds
2024-09-10 16:28:57,919 Total inference time: 14.9438 seconds
2024-09-10 16:28:57,919 Inference time as percentage of total time: 32.42%
2024-09-10 16:28:58,024 Total time: 46.1994 seconds
2024-09-10 16:28:58,024 Total inference time: 14.9438 seconds
2024-09-10 16:28:58,024 Inference time as percentage of total time: 32.35%
2024-09-10 16:28:58,130 Total time: 46.3051 seconds
2024-09-10 16:28:58,130 Total inference time: 14.9438 seconds
2024-09-10 16:28:58,130 Inference time as percentage of total time: 32.27%
2024-09-10 16:28:58,235 Total time: 46.4108 seconds
2024-09-10 16:28:58,236 Total inference time: 14.9438 seconds
2024-09-10 16:28:58,236 Inference time as percentage of total time: 32.20%
2024-09-10 16:28:58,341 Total time: 46.5164 seconds
2024-09-10 16:28:58,341 Total inference time: 14.9438 seconds
2024-09-10 16:28:58,341 Inference time as percentage of total time: 32.13%
2024-09-10 16:28:58,447 Total time: 46.6221 seconds
2024-09-10 16:28:58,447 Total inference time: 14.9438 seconds
2024-09-10 16:28:58,447 Inference time as percentage of total time: 32.05%
2024-09-10 16:28:58,552 Total time: 46.7277 seconds
2024-09-10 16:28:58,552 Total inference time: 14.9438 seconds
2024-09-10 16:28:58,553 Inference time as percentage of total time: 31.98%
2024-09-10 16:28:58,658 Total time: 46.8333 seconds
2024-09-10 16:28:58,658 Total inference time: 14.9438 seconds
2024-09-10 16:28:58,658 Inference time as percentage of total time: 31.91%
2024-09-10 16:28:58,760 Total time: 46.9354 seconds
2024-09-10 16:28:58,760 Total inference time: 14.9438 seconds
2024-09-10 16:28:58,760 Inference time as percentage of total time: 31.84%
2024-09-10 16:28:58,863 Total time: 47.0383 seconds
2024-09-10 16:28:58,863 Total inference time: 14.9438 seconds
2024-09-10 16:28:58,863 Inference time as percentage of total time: 31.77%
2024-09-10 16:28:58,968 Total time: 47.1432 seconds
2024-09-10 16:28:58,968 Total inference time: 14.9438 seconds
2024-09-10 16:28:58,968 Inference time as percentage of total time: 31.70%
2024-09-10 16:28:59,073 Total time: 47.2489 seconds
2024-09-10 16:28:59,074 Total inference time: 14.9438 seconds
2024-09-10 16:28:59,074 Inference time as percentage of total time: 31.63%
2024-09-10 16:28:59,176 Total time: 47.3521 seconds
2024-09-10 16:28:59,177 Total inference time: 14.9438 seconds
2024-09-10 16:28:59,177 Inference time as percentage of total time: 31.56%
2024-09-10 16:28:59,282 Total time: 47.4577 seconds
2024-09-10 16:28:59,282 Total inference time: 14.9438 seconds
2024-09-10 16:28:59,283 Inference time as percentage of total time: 31.49%
2024-09-10 16:28:59,388 Total time: 47.5634 seconds
2024-09-10 16:28:59,388 Total inference time: 14.9438 seconds
2024-09-10 16:28:59,388 Inference time as percentage of total time: 31.42%
2024-09-10 16:28:59,490 Total time: 47.6657 seconds
2024-09-10 16:28:59,490 Total inference time: 14.9438 seconds
2024-09-10 16:28:59,491 Inference time as percentage of total time: 31.35%
2024-09-10 16:28:59,594 Total time: 47.7698 seconds
2024-09-10 16:28:59,594 Total inference time: 14.9438 seconds
2024-09-10 16:28:59,595 Inference time as percentage of total time: 31.28%
2024-09-10 16:28:59,700 Total time: 47.8756 seconds
2024-09-10 16:28:59,700 Total inference time: 14.9438 seconds
2024-09-10 16:28:59,701 Inference time as percentage of total time: 31.21%
2024-09-10 16:28:59,806 Total time: 47.9815 seconds
2024-09-10 16:28:59,806 Total inference time: 14.9438 seconds
2024-09-10 16:28:59,806 Inference time as percentage of total time: 31.15%
2024-09-10 16:28:59,912 Total time: 48.0873 seconds
2024-09-10 16:28:59,912 Total inference time: 14.9438 seconds
2024-09-10 16:28:59,912 Inference time as percentage of total time: 31.08%
2024-09-10 16:29:00,014 Total time: 48.1896 seconds
2024-09-10 16:29:00,014 Total inference time: 14.9438 seconds
2024-09-10 16:29:00,014 Inference time as percentage of total time: 31.01%
2024-09-10 16:29:00,120 Total time: 48.2955 seconds
2024-09-10 16:29:00,120 Total inference time: 14.9438 seconds
2024-09-10 16:29:00,120 Inference time as percentage of total time: 30.94%
2024-09-10 16:29:00,223 Total time: 48.3984 seconds
2024-09-10 16:29:00,223 Total inference time: 14.9438 seconds
2024-09-10 16:29:00,223 Inference time as percentage of total time: 30.88%
2024-09-10 16:29:00,328 Total time: 48.5042 seconds
2024-09-10 16:29:00,329 Total inference time: 14.9438 seconds
2024-09-10 16:29:00,329 Inference time as percentage of total time: 30.81%
2024-09-10 16:29:00,434 Total time: 48.6099 seconds
2024-09-10 16:29:00,434 Total inference time: 14.9438 seconds
2024-09-10 16:29:00,435 Inference time as percentage of total time: 30.74%
2024-09-10 16:29:00,539 Total time: 48.7152 seconds
2024-09-10 16:29:00,540 Total inference time: 14.9438 seconds
2024-09-10 16:29:00,540 Inference time as percentage of total time: 30.68%
2024-09-10 16:29:00,645 Total time: 48.8211 seconds
2024-09-10 16:29:00,646 Total inference time: 14.9438 seconds
2024-09-10 16:29:00,646 Inference time as percentage of total time: 30.61%
2024-09-10 16:29:00,747 Total time: 48.9228 seconds
2024-09-10 16:29:00,747 Total inference time: 14.9438 seconds
2024-09-10 16:29:00,748 Inference time as percentage of total time: 30.55%
2024-09-10 16:29:00,853 Total time: 49.0286 seconds
2024-09-10 16:29:00,853 Total inference time: 14.9438 seconds
2024-09-10 16:29:00,853 Inference time as percentage of total time: 30.48%
2024-09-10 16:29:00,956 Total time: 49.1317 seconds
2024-09-10 16:29:00,956 Total inference time: 14.9438 seconds
2024-09-10 16:29:00,956 Inference time as percentage of total time: 30.42%
2024-09-10 16:29:01,060 Total time: 49.2360 seconds
2024-09-10 16:29:01,060 Total inference time: 14.9438 seconds
2024-09-10 16:29:01,061 Inference time as percentage of total time: 30.35%
2024-09-10 16:29:01,166 Total time: 49.3416 seconds
2024-09-10 16:29:01,166 Total inference time: 14.9438 seconds
2024-09-10 16:29:01,166 Inference time as percentage of total time: 30.29%
2024-09-10 16:29:01,272 Total time: 49.4474 seconds
2024-09-10 16:29:01,272 Total inference time: 14.9438 seconds
2024-09-10 16:29:01,272 Inference time as percentage of total time: 30.22%
2024-09-10 16:29:01,373 Total time: 49.5490 seconds
2024-09-10 16:29:01,373 Total inference time: 14.9438 seconds
2024-09-10 16:29:01,374 Inference time as percentage of total time: 30.16%
2024-09-10 16:29:01,475 Total time: 49.6512 seconds
2024-09-10 16:29:01,476 Total inference time: 14.9438 seconds
2024-09-10 16:29:01,476 Inference time as percentage of total time: 30.10%
2024-09-10 16:29:01,577 Total time: 49.7533 seconds
2024-09-10 16:29:01,578 Total inference time: 14.9438 seconds
2024-09-10 16:29:01,578 Inference time as percentage of total time: 30.04%
2024-09-10 16:29:01,683 Total time: 49.8585 seconds
2024-09-10 16:29:01,683 Total inference time: 14.9438 seconds
2024-09-10 16:29:01,683 Inference time as percentage of total time: 29.97%
2024-09-10 16:29:01,789 Total time: 49.9644 seconds
2024-09-10 16:29:01,789 Total inference time: 14.9438 seconds
2024-09-10 16:29:01,789 Inference time as percentage of total time: 29.91%
2024-09-10 16:29:01,894 Total time: 50.0703 seconds
2024-09-10 16:29:01,895 Total inference time: 14.9438 seconds
2024-09-10 16:29:01,895 Inference time as percentage of total time: 29.85%
2024-09-10 16:29:01,999 Total time: 50.1747 seconds
2024-09-10 16:29:01,999 Total inference time: 14.9438 seconds
2024-09-10 16:29:01,999 Inference time as percentage of total time: 29.78%
2024-09-10 16:29:02,104 Total time: 50.2802 seconds
2024-09-10 16:29:02,104 Total inference time: 14.9438 seconds
2024-09-10 16:29:02,105 Inference time as percentage of total time: 29.72%
2024-09-10 16:29:02,210 Total time: 50.3856 seconds
2024-09-10 16:29:02,210 Total inference time: 14.9438 seconds
2024-09-10 16:29:02,210 Inference time as percentage of total time: 29.66%
2024-09-10 16:29:02,315 Total time: 50.4910 seconds
2024-09-10 16:29:02,315 Total inference time: 14.9438 seconds
2024-09-10 16:29:02,315 Inference time as percentage of total time: 29.60%
2024-09-10 16:29:02,421 Total time: 50.5965 seconds
2024-09-10 16:29:02,421 Total inference time: 14.9438 seconds
2024-09-10 16:29:02,421 Inference time as percentage of total time: 29.54%
2024-09-10 16:29:02,526 Total time: 50.7021 seconds
2024-09-10 16:29:02,526 Total inference time: 14.9438 seconds
2024-09-10 16:29:02,527 Inference time as percentage of total time: 29.47%
2024-09-10 16:29:02,632 Total time: 50.8078 seconds
2024-09-10 16:29:02,632 Total inference time: 14.9438 seconds
2024-09-10 16:29:02,632 Inference time as percentage of total time: 29.41%
2024-09-10 16:29:02,735 Total time: 50.9110 seconds
2024-09-10 16:29:02,735 Total inference time: 14.9438 seconds
2024-09-10 16:29:02,736 Inference time as percentage of total time: 29.35%
2024-09-10 16:29:02,841 Total time: 51.0165 seconds
2024-09-10 16:29:02,841 Total inference time: 14.9438 seconds
2024-09-10 16:29:02,841 Inference time as percentage of total time: 29.29%
2024-09-10 16:29:02,946 Total time: 51.1220 seconds
2024-09-10 16:29:02,946 Total inference time: 14.9438 seconds
2024-09-10 16:29:02,946 Inference time as percentage of total time: 29.23%
2024-09-10 16:29:03,048 Total time: 51.2235 seconds
2024-09-10 16:29:03,048 Total inference time: 14.9438 seconds
2024-09-10 16:29:03,048 Inference time as percentage of total time: 29.17%
2024-09-10 16:29:03,151 Total time: 51.3266 seconds
2024-09-10 16:29:03,151 Total inference time: 14.9438 seconds
2024-09-10 16:29:03,151 Inference time as percentage of total time: 29.12%
2024-09-10 16:29:03,252 Total time: 51.4284 seconds
2024-09-10 16:29:03,253 Total inference time: 14.9438 seconds
2024-09-10 16:29:03,253 Inference time as percentage of total time: 29.06%
2024-09-10 16:29:03,358 Total time: 51.5340 seconds
2024-09-10 16:29:03,358 Total inference time: 14.9438 seconds
2024-09-10 16:29:03,358 Inference time as percentage of total time: 29.00%
2024-09-10 16:29:03,463 Total time: 51.6389 seconds
2024-09-10 16:29:03,463 Total inference time: 14.9438 seconds
2024-09-10 16:29:03,463 Inference time as percentage of total time: 28.94%
2024-09-10 16:29:03,567 Total time: 51.7433 seconds
2024-09-10 16:29:03,568 Total inference time: 14.9438 seconds
2024-09-10 16:29:03,568 Inference time as percentage of total time: 28.88%
2024-09-10 16:29:03,670 Total time: 51.8463 seconds
2024-09-10 16:29:03,671 Total inference time: 14.9438 seconds
2024-09-10 16:29:03,671 Inference time as percentage of total time: 28.82%
2024-09-10 16:29:03,772 Total time: 51.9484 seconds
2024-09-10 16:29:03,773 Total inference time: 14.9438 seconds
2024-09-10 16:29:03,773 Inference time as percentage of total time: 28.77%
2024-09-10 16:29:03,875 Total time: 52.0513 seconds
2024-09-10 16:29:03,875 Total inference time: 14.9438 seconds
2024-09-10 16:29:03,876 Inference time as percentage of total time: 28.71%
2024-09-10 16:29:03,981 Total time: 52.1570 seconds
2024-09-10 16:29:03,981 Total inference time: 14.9438 seconds
2024-09-10 16:29:03,981 Inference time as percentage of total time: 28.65%
2024-09-10 16:29:04,087 Total time: 52.2626 seconds
2024-09-10 16:29:04,087 Total inference time: 14.9438 seconds
2024-09-10 16:29:04,087 Inference time as percentage of total time: 28.59%
2024-09-10 16:29:04,190 Total time: 52.3666 seconds
2024-09-10 16:29:04,191 Total inference time: 14.9438 seconds
2024-09-10 16:29:04,191 Inference time as percentage of total time: 28.54%
2024-09-10 16:29:04,296 Total time: 52.4723 seconds
2024-09-10 16:29:04,296 Total inference time: 14.9438 seconds
2024-09-10 16:29:04,297 Inference time as percentage of total time: 28.48%
2024-09-10 16:29:04,401 Total time: 52.5766 seconds
2024-09-10 16:29:04,401 Total inference time: 14.9438 seconds
2024-09-10 16:29:04,401 Inference time as percentage of total time: 28.42%
2024-09-10 16:29:04,507 Total time: 52.6826 seconds
2024-09-10 16:29:04,507 Total inference time: 14.9438 seconds
2024-09-10 16:29:04,507 Inference time as percentage of total time: 28.37%
2024-09-10 16:29:04,612 Total time: 52.7884 seconds
2024-09-10 16:29:04,613 Total inference time: 14.9438 seconds
2024-09-10 16:29:04,613 Inference time as percentage of total time: 28.31%
2024-09-10 16:29:04,718 Total time: 52.8942 seconds
2024-09-10 16:29:04,718 Total inference time: 14.9438 seconds
2024-09-10 16:29:04,719 Inference time as percentage of total time: 28.25%
2024-09-10 16:29:04,824 Total time: 53.0000 seconds
2024-09-10 16:29:04,824 Total inference time: 14.9438 seconds
2024-09-10 16:29:04,824 Inference time as percentage of total time: 28.20%
2024-09-10 16:29:04,930 Total time: 53.1058 seconds
2024-09-10 16:29:04,930 Total inference time: 14.9438 seconds
2024-09-10 16:29:04,930 Inference time as percentage of total time: 28.14%
2024-09-10 16:29:05,034 Total time: 53.2099 seconds
2024-09-10 16:29:05,034 Total inference time: 14.9438 seconds
2024-09-10 16:29:05,034 Inference time as percentage of total time: 28.08%
2024-09-10 16:29:05,139 Total time: 53.3151 seconds
2024-09-10 16:29:05,139 Total inference time: 14.9438 seconds
2024-09-10 16:29:05,139 Inference time as percentage of total time: 28.03%
2024-09-10 16:29:05,243 Total time: 53.4188 seconds
2024-09-10 16:29:05,243 Total inference time: 14.9438 seconds
2024-09-10 16:29:05,243 Inference time as percentage of total time: 27.97%
2024-09-10 16:29:05,348 Total time: 53.5245 seconds
2024-09-10 16:29:05,349 Total inference time: 14.9438 seconds
2024-09-10 16:29:05,349 Inference time as percentage of total time: 27.92%
2024-09-10 16:29:05,454 Total time: 53.6302 seconds
2024-09-10 16:29:05,454 Total inference time: 14.9438 seconds
2024-09-10 16:29:05,454 Inference time as percentage of total time: 27.86%
2024-09-10 16:29:05,559 Total time: 53.7348 seconds
2024-09-10 16:29:05,559 Total inference time: 14.9438 seconds
2024-09-10 16:29:05,559 Inference time as percentage of total time: 27.81%
2024-09-10 16:29:05,661 Total time: 53.8367 seconds
2024-09-10 16:29:05,661 Total inference time: 14.9438 seconds
2024-09-10 16:29:05,661 Inference time as percentage of total time: 27.76%
2024-09-10 16:29:05,766 Total time: 53.9421 seconds
2024-09-10 16:29:05,766 Total inference time: 14.9438 seconds
2024-09-10 16:29:05,766 Inference time as percentage of total time: 27.70%
2024-09-10 16:29:05,867 Total time: 54.0433 seconds
2024-09-10 16:29:05,868 Total inference time: 14.9438 seconds
2024-09-10 16:29:05,868 Inference time as percentage of total time: 27.65%
2024-09-10 16:29:05,972 Total time: 54.1484 seconds
2024-09-10 16:29:05,973 Total inference time: 14.9438 seconds
2024-09-10 16:29:05,973 Inference time as percentage of total time: 27.60%
2024-09-10 16:29:06,078 Total time: 54.2543 seconds
2024-09-10 16:29:06,078 Total inference time: 14.9438 seconds
2024-09-10 16:29:06,079 Inference time as percentage of total time: 27.54%
2024-09-10 16:29:06,181 Total time: 54.3569 seconds
2024-09-10 16:29:06,181 Total inference time: 14.9438 seconds
2024-09-10 16:29:06,181 Inference time as percentage of total time: 27.49%
2024-09-10 16:29:06,286 Total time: 54.4627 seconds
2024-09-10 16:29:06,287 Total inference time: 14.9438 seconds
2024-09-10 16:29:06,287 Inference time as percentage of total time: 27.44%
2024-09-10 16:29:06,392 Total time: 54.5682 seconds
2024-09-10 16:29:06,392 Total inference time: 14.9438 seconds
2024-09-10 16:29:06,392 Inference time as percentage of total time: 27.39%
2024-09-10 16:29:06,498 Total time: 54.6739 seconds
2024-09-10 16:29:06,498 Total inference time: 14.9438 seconds
2024-09-10 16:29:06,498 Inference time as percentage of total time: 27.33%
2024-09-10 16:29:06,604 Total time: 54.7798 seconds
2024-09-10 16:29:06,604 Total inference time: 14.9438 seconds
2024-09-10 16:29:06,604 Inference time as percentage of total time: 27.28%
2024-09-10 16:29:06,709 Total time: 54.8856 seconds
2024-09-10 16:29:06,710 Total inference time: 14.9438 seconds
2024-09-10 16:29:06,710 Inference time as percentage of total time: 27.23%
2024-09-10 16:29:06,815 Total time: 54.9916 seconds
2024-09-10 16:29:06,816 Total inference time: 14.9438 seconds
2024-09-10 16:29:06,816 Inference time as percentage of total time: 27.17%
2024-09-10 16:29:06,921 Total time: 55.0974 seconds
2024-09-10 16:29:06,922 Total inference time: 14.9438 seconds
2024-09-10 16:29:06,922 Inference time as percentage of total time: 27.12%
2024-09-10 16:29:07,027 Total time: 55.2036 seconds
2024-09-10 16:29:07,028 Total inference time: 14.9438 seconds
2024-09-10 16:29:07,028 Inference time as percentage of total time: 27.07%
2024-09-10 16:29:07,133 Total time: 55.3096 seconds
2024-09-10 16:29:07,134 Total inference time: 14.9438 seconds
2024-09-10 16:29:07,134 Inference time as percentage of total time: 27.02%
2024-09-10 16:29:07,239 Total time: 55.4150 seconds
2024-09-10 16:29:07,239 Total inference time: 14.9438 seconds
2024-09-10 16:29:07,239 Inference time as percentage of total time: 26.97%
2024-09-10 16:29:07,342 Total time: 55.5188 seconds
2024-09-10 16:29:07,343 Total inference time: 14.9438 seconds
2024-09-10 16:29:07,343 Inference time as percentage of total time: 26.92%
2024-09-10 16:29:07,448 Total time: 55.6246 seconds
2024-09-10 16:29:07,449 Total inference time: 14.9438 seconds
2024-09-10 16:29:07,449 Inference time as percentage of total time: 26.87%
2024-09-10 16:29:07,554 Total time: 55.7305 seconds
2024-09-10 16:29:07,554 Total inference time: 14.9438 seconds
2024-09-10 16:29:07,555 Inference time as percentage of total time: 26.81%
2024-09-10 16:29:07,659 Total time: 55.8354 seconds
2024-09-10 16:29:07,659 Total inference time: 14.9438 seconds
2024-09-10 16:29:07,660 Inference time as percentage of total time: 26.76%
2024-09-10 16:29:07,763 Total time: 55.9395 seconds
2024-09-10 16:29:07,763 Total inference time: 14.9438 seconds
2024-09-10 16:29:07,764 Inference time as percentage of total time: 26.71%
2024-09-10 16:29:07,865 Total time: 56.0415 seconds
2024-09-10 16:29:07,865 Total inference time: 14.9438 seconds
2024-09-10 16:29:07,866 Inference time as percentage of total time: 26.67%
2024-09-10 16:29:07,967 Total time: 56.1437 seconds
2024-09-10 16:29:07,968 Total inference time: 14.9438 seconds
2024-09-10 16:29:07,968 Inference time as percentage of total time: 26.62%
2024-09-10 16:29:08,072 Total time: 56.2484 seconds
2024-09-10 16:29:08,072 Total inference time: 14.9438 seconds
2024-09-10 16:29:08,073 Inference time as percentage of total time: 26.57%
