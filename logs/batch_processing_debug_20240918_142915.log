2024-09-18 14:29:15,174 Using device: cuda
2024-09-18 14:29:15,174 Monitoring status set to True
2024-09-18 14:29:30,243 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.122.143:5000
2024-09-18 14:29:30,243 [33mPress CTRL+C to quit[0m
2024-09-18 14:29:30,615 127.0.0.1 - - [18/Sep/2024 14:29:30] "GET /health HTTP/1.1" 200 -
2024-09-18 14:29:43,692 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:29:43,693 127.0.0.1 - - [18/Sep/2024 14:29:43] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:29:45,587 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:29:45,588 127.0.0.1 - - [18/Sep/2024 14:29:45] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:29:47,468 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:29:47,468 127.0.0.1 - - [18/Sep/2024 14:29:47] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:29:49,314 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:29:49,315 127.0.0.1 - - [18/Sep/2024 14:29:49] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:29:51,165 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:29:51,166 127.0.0.1 - - [18/Sep/2024 14:29:51] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:29:53,011 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:29:53,011 127.0.0.1 - - [18/Sep/2024 14:29:53] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:29:54,857 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:29:54,858 127.0.0.1 - - [18/Sep/2024 14:29:54] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:29:56,704 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:29:56,705 127.0.0.1 - - [18/Sep/2024 14:29:56] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:29:58,549 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:29:58,549 127.0.0.1 - - [18/Sep/2024 14:29:58] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:00,413 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:00,413 127.0.0.1 - - [18/Sep/2024 14:30:00] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:01,421 127.0.0.1 - - [18/Sep/2024 14:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:02,292 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:02,293 127.0.0.1 - - [18/Sep/2024 14:30:02] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:03,301 127.0.0.1 - - [18/Sep/2024 14:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:04,161 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:04,161 127.0.0.1 - - [18/Sep/2024 14:30:04] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:05,168 127.0.0.1 - - [18/Sep/2024 14:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:06,005 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:06,005 127.0.0.1 - - [18/Sep/2024 14:30:06] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:07,012 127.0.0.1 - - [18/Sep/2024 14:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:07,858 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:07,858 127.0.0.1 - - [18/Sep/2024 14:30:07] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:08,865 127.0.0.1 - - [18/Sep/2024 14:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:09,709 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:09,710 127.0.0.1 - - [18/Sep/2024 14:30:09] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:10,718 127.0.0.1 - - [18/Sep/2024 14:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:11,570 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:11,571 127.0.0.1 - - [18/Sep/2024 14:30:11] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:12,578 127.0.0.1 - - [18/Sep/2024 14:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:13,428 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:13,428 127.0.0.1 - - [18/Sep/2024 14:30:13] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:14,435 127.0.0.1 - - [18/Sep/2024 14:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:15,298 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:15,298 127.0.0.1 - - [18/Sep/2024 14:30:15] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:16,307 127.0.0.1 - - [18/Sep/2024 14:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:17,153 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:17,153 127.0.0.1 - - [18/Sep/2024 14:30:17] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:18,160 127.0.0.1 - - [18/Sep/2024 14:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:18,998 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:18,999 127.0.0.1 - - [18/Sep/2024 14:30:18] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:20,008 127.0.0.1 - - [18/Sep/2024 14:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:20,009 127.0.0.1 - - [18/Sep/2024 14:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:20,843 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:20,844 127.0.0.1 - - [18/Sep/2024 14:30:20] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:21,853 127.0.0.1 - - [18/Sep/2024 14:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:21,855 127.0.0.1 - - [18/Sep/2024 14:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:22,752 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:22,752 127.0.0.1 - - [18/Sep/2024 14:30:22] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:23,761 127.0.0.1 - - [18/Sep/2024 14:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:23,763 127.0.0.1 - - [18/Sep/2024 14:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:24,635 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:24,636 127.0.0.1 - - [18/Sep/2024 14:30:24] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:25,644 127.0.0.1 - - [18/Sep/2024 14:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:25,646 127.0.0.1 - - [18/Sep/2024 14:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:26,500 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:26,500 127.0.0.1 - - [18/Sep/2024 14:30:26] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:27,509 127.0.0.1 - - [18/Sep/2024 14:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:27,510 127.0.0.1 - - [18/Sep/2024 14:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:28,360 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:28,360 127.0.0.1 - - [18/Sep/2024 14:30:28] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:29,368 127.0.0.1 - - [18/Sep/2024 14:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:29,371 127.0.0.1 - - [18/Sep/2024 14:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:30,202 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:30,203 127.0.0.1 - - [18/Sep/2024 14:30:30] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:31,213 127.0.0.1 - - [18/Sep/2024 14:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:31,213 127.0.0.1 - - [18/Sep/2024 14:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:32,093 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:32,093 127.0.0.1 - - [18/Sep/2024 14:30:32] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:33,103 127.0.0.1 - - [18/Sep/2024 14:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:33,103 127.0.0.1 - - [18/Sep/2024 14:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:33,990 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:33,990 127.0.0.1 - - [18/Sep/2024 14:30:33] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:34,998 127.0.0.1 - - [18/Sep/2024 14:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:35,001 127.0.0.1 - - [18/Sep/2024 14:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:35,917 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:35,917 127.0.0.1 - - [18/Sep/2024 14:30:35] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:36,926 127.0.0.1 - - [18/Sep/2024 14:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:36,927 127.0.0.1 - - [18/Sep/2024 14:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:37,805 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:37,805 127.0.0.1 - - [18/Sep/2024 14:30:37] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:38,816 127.0.0.1 - - [18/Sep/2024 14:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:38,817 127.0.0.1 - - [18/Sep/2024 14:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:38,818 127.0.0.1 - - [18/Sep/2024 14:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:39,856 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:39,857 127.0.0.1 - - [18/Sep/2024 14:30:39] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:40,867 127.0.0.1 - - [18/Sep/2024 14:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:40,869 127.0.0.1 - - [18/Sep/2024 14:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:40,871 127.0.0.1 - - [18/Sep/2024 14:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:41,823 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:41,824 127.0.0.1 - - [18/Sep/2024 14:30:41] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:42,832 127.0.0.1 - - [18/Sep/2024 14:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:42,835 127.0.0.1 - - [18/Sep/2024 14:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:42,836 127.0.0.1 - - [18/Sep/2024 14:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:43,785 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:43,785 127.0.0.1 - - [18/Sep/2024 14:30:43] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:44,794 127.0.0.1 - - [18/Sep/2024 14:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:44,797 127.0.0.1 - - [18/Sep/2024 14:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:44,798 127.0.0.1 - - [18/Sep/2024 14:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:45,722 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:45,723 127.0.0.1 - - [18/Sep/2024 14:30:45] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:46,732 127.0.0.1 - - [18/Sep/2024 14:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:46,734 127.0.0.1 - - [18/Sep/2024 14:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:46,735 127.0.0.1 - - [18/Sep/2024 14:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:47,593 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:47,594 127.0.0.1 - - [18/Sep/2024 14:30:47] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:48,604 127.0.0.1 - - [18/Sep/2024 14:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:48,606 127.0.0.1 - - [18/Sep/2024 14:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:48,607 127.0.0.1 - - [18/Sep/2024 14:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:49,574 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:49,575 127.0.0.1 - - [18/Sep/2024 14:30:49] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:50,585 127.0.0.1 - - [18/Sep/2024 14:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:50,586 127.0.0.1 - - [18/Sep/2024 14:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:50,587 127.0.0.1 - - [18/Sep/2024 14:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:51,481 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:51,482 127.0.0.1 - - [18/Sep/2024 14:30:51] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:52,491 127.0.0.1 - - [18/Sep/2024 14:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:52,492 127.0.0.1 - - [18/Sep/2024 14:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:52,494 127.0.0.1 - - [18/Sep/2024 14:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:53,420 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:53,420 127.0.0.1 - - [18/Sep/2024 14:30:53] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:54,430 127.0.0.1 - - [18/Sep/2024 14:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:54,431 127.0.0.1 - - [18/Sep/2024 14:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:54,434 127.0.0.1 - - [18/Sep/2024 14:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:55,328 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:55,329 127.0.0.1 - - [18/Sep/2024 14:30:55] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:56,337 127.0.0.1 - - [18/Sep/2024 14:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:56,339 127.0.0.1 - - [18/Sep/2024 14:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:56,340 127.0.0.1 - - [18/Sep/2024 14:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:57,263 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:57,264 127.0.0.1 - - [18/Sep/2024 14:30:57] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:30:58,274 127.0.0.1 - - [18/Sep/2024 14:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:58,276 127.0.0.1 - - [18/Sep/2024 14:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:58,277 127.0.0.1 - - [18/Sep/2024 14:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:58,278 127.0.0.1 - - [18/Sep/2024 14:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:30:59,362 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:30:59,363 127.0.0.1 - - [18/Sep/2024 14:30:59] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:00,373 127.0.0.1 - - [18/Sep/2024 14:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:00,376 127.0.0.1 - - [18/Sep/2024 14:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:00,377 127.0.0.1 - - [18/Sep/2024 14:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:00,378 127.0.0.1 - - [18/Sep/2024 14:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:01,226 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:01,226 127.0.0.1 - - [18/Sep/2024 14:31:01] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:02,237 127.0.0.1 - - [18/Sep/2024 14:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:02,240 127.0.0.1 - - [18/Sep/2024 14:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:02,241 127.0.0.1 - - [18/Sep/2024 14:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:02,242 127.0.0.1 - - [18/Sep/2024 14:31:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:03,434 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:03,434 127.0.0.1 - - [18/Sep/2024 14:31:03] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:04,444 127.0.0.1 - - [18/Sep/2024 14:31:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:04,448 127.0.0.1 - - [18/Sep/2024 14:31:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:04,449 127.0.0.1 - - [18/Sep/2024 14:31:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:04,450 127.0.0.1 - - [18/Sep/2024 14:31:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:05,415 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:05,416 127.0.0.1 - - [18/Sep/2024 14:31:05] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:06,427 127.0.0.1 - - [18/Sep/2024 14:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:06,429 127.0.0.1 - - [18/Sep/2024 14:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:06,430 127.0.0.1 - - [18/Sep/2024 14:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:06,430 127.0.0.1 - - [18/Sep/2024 14:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:07,389 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:07,390 127.0.0.1 - - [18/Sep/2024 14:31:07] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:08,402 127.0.0.1 - - [18/Sep/2024 14:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:08,403 127.0.0.1 - - [18/Sep/2024 14:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:08,404 127.0.0.1 - - [18/Sep/2024 14:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:08,405 127.0.0.1 - - [18/Sep/2024 14:31:08] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:09,359 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:09,360 127.0.0.1 - - [18/Sep/2024 14:31:09] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:10,372 127.0.0.1 - - [18/Sep/2024 14:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:10,374 127.0.0.1 - - [18/Sep/2024 14:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:10,374 127.0.0.1 - - [18/Sep/2024 14:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:10,375 127.0.0.1 - - [18/Sep/2024 14:31:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:11,458 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:11,458 127.0.0.1 - - [18/Sep/2024 14:31:11] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:12,468 127.0.0.1 - - [18/Sep/2024 14:31:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:12,470 127.0.0.1 - - [18/Sep/2024 14:31:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:12,472 127.0.0.1 - - [18/Sep/2024 14:31:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:12,473 127.0.0.1 - - [18/Sep/2024 14:31:12] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:13,363 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:13,363 127.0.0.1 - - [18/Sep/2024 14:31:13] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:14,375 127.0.0.1 - - [18/Sep/2024 14:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:14,377 127.0.0.1 - - [18/Sep/2024 14:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:14,378 127.0.0.1 - - [18/Sep/2024 14:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:14,378 127.0.0.1 - - [18/Sep/2024 14:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:15,273 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:15,273 127.0.0.1 - - [18/Sep/2024 14:31:15] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:16,281 127.0.0.1 - - [18/Sep/2024 14:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:16,282 127.0.0.1 - - [18/Sep/2024 14:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:16,285 127.0.0.1 - - [18/Sep/2024 14:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:16,287 127.0.0.1 - - [18/Sep/2024 14:31:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:17,254 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:17,254 127.0.0.1 - - [18/Sep/2024 14:31:17] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:18,268 127.0.0.1 - - [18/Sep/2024 14:31:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:18,271 127.0.0.1 - - [18/Sep/2024 14:31:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:18,273 127.0.0.1 - - [18/Sep/2024 14:31:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:18,274 127.0.0.1 - - [18/Sep/2024 14:31:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:18,274 127.0.0.1 - - [18/Sep/2024 14:31:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:18,275 127.0.0.1 - - [18/Sep/2024 14:31:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:19,283 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:19,283 127.0.0.1 - - [18/Sep/2024 14:31:19] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:20,293 127.0.0.1 - - [18/Sep/2024 14:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:20,297 127.0.0.1 - - [18/Sep/2024 14:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:20,300 127.0.0.1 - - [18/Sep/2024 14:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:20,302 127.0.0.1 - - [18/Sep/2024 14:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:20,303 127.0.0.1 - - [18/Sep/2024 14:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:20,305 127.0.0.1 - - [18/Sep/2024 14:31:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:21,279 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:21,280 127.0.0.1 - - [18/Sep/2024 14:31:21] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:22,292 127.0.0.1 - - [18/Sep/2024 14:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:22,294 127.0.0.1 - - [18/Sep/2024 14:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:22,296 127.0.0.1 - - [18/Sep/2024 14:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:22,298 127.0.0.1 - - [18/Sep/2024 14:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:22,299 127.0.0.1 - - [18/Sep/2024 14:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:22,300 127.0.0.1 - - [18/Sep/2024 14:31:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:23,229 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:23,230 127.0.0.1 - - [18/Sep/2024 14:31:23] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:24,241 127.0.0.1 - - [18/Sep/2024 14:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:24,245 127.0.0.1 - - [18/Sep/2024 14:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:24,248 127.0.0.1 - - [18/Sep/2024 14:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:24,249 127.0.0.1 - - [18/Sep/2024 14:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:24,250 127.0.0.1 - - [18/Sep/2024 14:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:24,251 127.0.0.1 - - [18/Sep/2024 14:31:24] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:25,258 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:25,259 127.0.0.1 - - [18/Sep/2024 14:31:25] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:26,273 127.0.0.1 - - [18/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:26,275 127.0.0.1 - - [18/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:26,276 127.0.0.1 - - [18/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:26,277 127.0.0.1 - - [18/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:26,278 127.0.0.1 - - [18/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:26,279 127.0.0.1 - - [18/Sep/2024 14:31:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:27,348 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:27,348 127.0.0.1 - - [18/Sep/2024 14:31:27] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:28,362 127.0.0.1 - - [18/Sep/2024 14:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:28,364 127.0.0.1 - - [18/Sep/2024 14:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:28,366 127.0.0.1 - - [18/Sep/2024 14:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:28,367 127.0.0.1 - - [18/Sep/2024 14:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:28,368 127.0.0.1 - - [18/Sep/2024 14:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:28,369 127.0.0.1 - - [18/Sep/2024 14:31:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:29,362 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:29,363 127.0.0.1 - - [18/Sep/2024 14:31:29] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:30,373 127.0.0.1 - - [18/Sep/2024 14:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:30,377 127.0.0.1 - - [18/Sep/2024 14:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:30,380 127.0.0.1 - - [18/Sep/2024 14:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:30,381 127.0.0.1 - - [18/Sep/2024 14:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:30,381 127.0.0.1 - - [18/Sep/2024 14:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:30,382 127.0.0.1 - - [18/Sep/2024 14:31:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:31,498 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:31,499 127.0.0.1 - - [18/Sep/2024 14:31:31] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:32,510 127.0.0.1 - - [18/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:32,511 127.0.0.1 - - [18/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:32,512 127.0.0.1 - - [18/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:32,516 127.0.0.1 - - [18/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:32,517 127.0.0.1 - - [18/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:32,518 127.0.0.1 - - [18/Sep/2024 14:31:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:33,582 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:33,582 127.0.0.1 - - [18/Sep/2024 14:31:33] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:34,597 127.0.0.1 - - [18/Sep/2024 14:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:34,598 127.0.0.1 - - [18/Sep/2024 14:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:34,599 127.0.0.1 - - [18/Sep/2024 14:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:34,600 127.0.0.1 - - [18/Sep/2024 14:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:34,601 127.0.0.1 - - [18/Sep/2024 14:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:34,602 127.0.0.1 - - [18/Sep/2024 14:31:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:35,632 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:35,633 127.0.0.1 - - [18/Sep/2024 14:31:35] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:36,646 127.0.0.1 - - [18/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:36,648 127.0.0.1 - - [18/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:36,650 127.0.0.1 - - [18/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:36,651 127.0.0.1 - - [18/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:36,652 127.0.0.1 - - [18/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:36,653 127.0.0.1 - - [18/Sep/2024 14:31:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:37,646 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:37,647 127.0.0.1 - - [18/Sep/2024 14:31:37] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:38,661 127.0.0.1 - - [18/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:38,663 127.0.0.1 - - [18/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:38,664 127.0.0.1 - - [18/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:38,666 127.0.0.1 - - [18/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:38,667 127.0.0.1 - - [18/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:38,668 127.0.0.1 - - [18/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:38,668 127.0.0.1 - - [18/Sep/2024 14:31:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:39,673 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:39,674 127.0.0.1 - - [18/Sep/2024 14:31:39] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:40,687 127.0.0.1 - - [18/Sep/2024 14:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:40,691 127.0.0.1 - - [18/Sep/2024 14:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:40,692 127.0.0.1 - - [18/Sep/2024 14:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:40,694 127.0.0.1 - - [18/Sep/2024 14:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:40,695 127.0.0.1 - - [18/Sep/2024 14:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:40,696 127.0.0.1 - - [18/Sep/2024 14:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:40,697 127.0.0.1 - - [18/Sep/2024 14:31:40] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:41,842 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:41,842 127.0.0.1 - - [18/Sep/2024 14:31:41] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:42,858 127.0.0.1 - - [18/Sep/2024 14:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:42,861 127.0.0.1 - - [18/Sep/2024 14:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:42,862 127.0.0.1 - - [18/Sep/2024 14:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:42,863 127.0.0.1 - - [18/Sep/2024 14:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:42,864 127.0.0.1 - - [18/Sep/2024 14:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:42,865 127.0.0.1 - - [18/Sep/2024 14:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:42,866 127.0.0.1 - - [18/Sep/2024 14:31:42] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:44,138 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:44,139 127.0.0.1 - - [18/Sep/2024 14:31:44] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:45,152 127.0.0.1 - - [18/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:45,156 127.0.0.1 - - [18/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:45,158 127.0.0.1 - - [18/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:45,159 127.0.0.1 - - [18/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:45,160 127.0.0.1 - - [18/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:45,161 127.0.0.1 - - [18/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:45,162 127.0.0.1 - - [18/Sep/2024 14:31:45] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:46,298 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:46,298 127.0.0.1 - - [18/Sep/2024 14:31:46] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:47,313 127.0.0.1 - - [18/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:47,317 127.0.0.1 - - [18/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:47,318 127.0.0.1 - - [18/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:47,319 127.0.0.1 - - [18/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:47,319 127.0.0.1 - - [18/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:47,320 127.0.0.1 - - [18/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:47,321 127.0.0.1 - - [18/Sep/2024 14:31:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:48,520 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:48,521 127.0.0.1 - - [18/Sep/2024 14:31:48] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:49,536 127.0.0.1 - - [18/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:49,538 127.0.0.1 - - [18/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:49,539 127.0.0.1 - - [18/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:49,540 127.0.0.1 - - [18/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:49,542 127.0.0.1 - - [18/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:49,543 127.0.0.1 - - [18/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:49,543 127.0.0.1 - - [18/Sep/2024 14:31:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:50,682 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:50,683 127.0.0.1 - - [18/Sep/2024 14:31:50] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:51,696 127.0.0.1 - - [18/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:51,699 127.0.0.1 - - [18/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:51,702 127.0.0.1 - - [18/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:51,703 127.0.0.1 - - [18/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:51,704 127.0.0.1 - - [18/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:51,705 127.0.0.1 - - [18/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:51,706 127.0.0.1 - - [18/Sep/2024 14:31:51] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:53,102 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:53,103 127.0.0.1 - - [18/Sep/2024 14:31:53] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:54,118 127.0.0.1 - - [18/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:54,121 127.0.0.1 - - [18/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:54,122 127.0.0.1 - - [18/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:54,123 127.0.0.1 - - [18/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:54,124 127.0.0.1 - - [18/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:54,125 127.0.0.1 - - [18/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:54,126 127.0.0.1 - - [18/Sep/2024 14:31:54] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:55,278 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:55,278 127.0.0.1 - - [18/Sep/2024 14:31:55] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:56,291 127.0.0.1 - - [18/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:56,297 127.0.0.1 - - [18/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:56,298 127.0.0.1 - - [18/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:56,299 127.0.0.1 - - [18/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:56,299 127.0.0.1 - - [18/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:56,300 127.0.0.1 - - [18/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:56,301 127.0.0.1 - - [18/Sep/2024 14:31:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:57,366 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:57,366 127.0.0.1 - - [18/Sep/2024 14:31:57] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:31:58,380 127.0.0.1 - - [18/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:58,384 127.0.0.1 - - [18/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:58,385 127.0.0.1 - - [18/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:58,386 127.0.0.1 - - [18/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:58,387 127.0.0.1 - - [18/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:58,387 127.0.0.1 - - [18/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:58,389 127.0.0.1 - - [18/Sep/2024 14:31:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:31:59,556 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:31:59,556 127.0.0.1 - - [18/Sep/2024 14:31:59] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:00,573 127.0.0.1 - - [18/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:00,577 127.0.0.1 - - [18/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:00,579 127.0.0.1 - - [18/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:00,581 127.0.0.1 - - [18/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:00,582 127.0.0.1 - - [18/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:00,582 127.0.0.1 - - [18/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:00,583 127.0.0.1 - - [18/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:00,584 127.0.0.1 - - [18/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:00,584 127.0.0.1 - - [18/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:00,586 127.0.0.1 - - [18/Sep/2024 14:32:00] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:01,936 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:01,937 127.0.0.1 - - [18/Sep/2024 14:32:01] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:02,955 127.0.0.1 - - [18/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:02,958 127.0.0.1 - - [18/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:02,959 127.0.0.1 - - [18/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:02,960 127.0.0.1 - - [18/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:02,962 127.0.0.1 - - [18/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:02,963 127.0.0.1 - - [18/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:02,964 127.0.0.1 - - [18/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:02,964 127.0.0.1 - - [18/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:02,965 127.0.0.1 - - [18/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:02,966 127.0.0.1 - - [18/Sep/2024 14:32:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:04,325 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:04,325 127.0.0.1 - - [18/Sep/2024 14:32:04] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:05,342 127.0.0.1 - - [18/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:05,347 127.0.0.1 - - [18/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:05,348 127.0.0.1 - - [18/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:05,349 127.0.0.1 - - [18/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:05,350 127.0.0.1 - - [18/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:05,351 127.0.0.1 - - [18/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:05,352 127.0.0.1 - - [18/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:05,353 127.0.0.1 - - [18/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:05,354 127.0.0.1 - - [18/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:05,355 127.0.0.1 - - [18/Sep/2024 14:32:05] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:06,713 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:06,714 127.0.0.1 - - [18/Sep/2024 14:32:06] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:07,730 127.0.0.1 - - [18/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:07,734 127.0.0.1 - - [18/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:07,738 127.0.0.1 - - [18/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:07,738 127.0.0.1 - - [18/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:07,739 127.0.0.1 - - [18/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:07,740 127.0.0.1 - - [18/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:07,741 127.0.0.1 - - [18/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:07,742 127.0.0.1 - - [18/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:07,743 127.0.0.1 - - [18/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:07,744 127.0.0.1 - - [18/Sep/2024 14:32:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:09,087 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:09,088 127.0.0.1 - - [18/Sep/2024 14:32:09] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:10,103 127.0.0.1 - - [18/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:10,109 127.0.0.1 - - [18/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:10,111 127.0.0.1 - - [18/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:10,113 127.0.0.1 - - [18/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:10,114 127.0.0.1 - - [18/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:10,115 127.0.0.1 - - [18/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:10,116 127.0.0.1 - - [18/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:10,117 127.0.0.1 - - [18/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:10,118 127.0.0.1 - - [18/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:10,118 127.0.0.1 - - [18/Sep/2024 14:32:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:12,017 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:12,018 127.0.0.1 - - [18/Sep/2024 14:32:12] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:13,037 127.0.0.1 - - [18/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:13,039 127.0.0.1 - - [18/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:13,041 127.0.0.1 - - [18/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:13,042 127.0.0.1 - - [18/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:13,043 127.0.0.1 - - [18/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:13,044 127.0.0.1 - - [18/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:13,045 127.0.0.1 - - [18/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:13,046 127.0.0.1 - - [18/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:13,046 127.0.0.1 - - [18/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:13,047 127.0.0.1 - - [18/Sep/2024 14:32:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:14,612 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:14,613 127.0.0.1 - - [18/Sep/2024 14:32:14] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:15,631 127.0.0.1 - - [18/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:15,635 127.0.0.1 - - [18/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:15,636 127.0.0.1 - - [18/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:15,637 127.0.0.1 - - [18/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:15,638 127.0.0.1 - - [18/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:15,638 127.0.0.1 - - [18/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:15,639 127.0.0.1 - - [18/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:15,640 127.0.0.1 - - [18/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:15,641 127.0.0.1 - - [18/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:15,642 127.0.0.1 - - [18/Sep/2024 14:32:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:16,994 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:16,994 127.0.0.1 - - [18/Sep/2024 14:32:16] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:18,011 127.0.0.1 - - [18/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:18,016 127.0.0.1 - - [18/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:18,017 127.0.0.1 - - [18/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:18,018 127.0.0.1 - - [18/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:18,019 127.0.0.1 - - [18/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:18,019 127.0.0.1 - - [18/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:18,021 127.0.0.1 - - [18/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:18,022 127.0.0.1 - - [18/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:18,023 127.0.0.1 - - [18/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:18,024 127.0.0.1 - - [18/Sep/2024 14:32:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:19,377 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:19,378 127.0.0.1 - - [18/Sep/2024 14:32:19] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:20,399 127.0.0.1 - - [18/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:20,400 127.0.0.1 - - [18/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:20,401 127.0.0.1 - - [18/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:20,402 127.0.0.1 - - [18/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:20,403 127.0.0.1 - - [18/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:20,403 127.0.0.1 - - [18/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:20,404 127.0.0.1 - - [18/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:20,405 127.0.0.1 - - [18/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:20,406 127.0.0.1 - - [18/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:20,407 127.0.0.1 - - [18/Sep/2024 14:32:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:21,768 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:21,769 127.0.0.1 - - [18/Sep/2024 14:32:21] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:22,789 127.0.0.1 - - [18/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:22,790 127.0.0.1 - - [18/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:22,791 127.0.0.1 - - [18/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:22,792 127.0.0.1 - - [18/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:22,793 127.0.0.1 - - [18/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:22,793 127.0.0.1 - - [18/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:22,794 127.0.0.1 - - [18/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:22,796 127.0.0.1 - - [18/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:22,796 127.0.0.1 - - [18/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:22,797 127.0.0.1 - - [18/Sep/2024 14:32:22] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:24,292 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:24,292 127.0.0.1 - - [18/Sep/2024 14:32:24] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:25,312 127.0.0.1 - - [18/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:25,315 127.0.0.1 - - [18/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:25,317 127.0.0.1 - - [18/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:25,318 127.0.0.1 - - [18/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:25,319 127.0.0.1 - - [18/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:25,319 127.0.0.1 - - [18/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:25,320 127.0.0.1 - - [18/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:25,321 127.0.0.1 - - [18/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:25,322 127.0.0.1 - - [18/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:25,323 127.0.0.1 - - [18/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:25,324 127.0.0.1 - - [18/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:25,326 127.0.0.1 - - [18/Sep/2024 14:32:25] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:27,737 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:27,738 127.0.0.1 - - [18/Sep/2024 14:32:27] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:28,758 127.0.0.1 - - [18/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:28,762 127.0.0.1 - - [18/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:28,763 127.0.0.1 - - [18/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:28,764 127.0.0.1 - - [18/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:28,765 127.0.0.1 - - [18/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:28,766 127.0.0.1 - - [18/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:28,767 127.0.0.1 - - [18/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:28,768 127.0.0.1 - - [18/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:28,769 127.0.0.1 - - [18/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:28,770 127.0.0.1 - - [18/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:28,771 127.0.0.1 - - [18/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:28,772 127.0.0.1 - - [18/Sep/2024 14:32:28] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:30,537 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:30,538 127.0.0.1 - - [18/Sep/2024 14:32:30] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:31,558 127.0.0.1 - - [18/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:31,560 127.0.0.1 - - [18/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:31,562 127.0.0.1 - - [18/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:31,564 127.0.0.1 - - [18/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:31,565 127.0.0.1 - - [18/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:31,565 127.0.0.1 - - [18/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:31,566 127.0.0.1 - - [18/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:31,567 127.0.0.1 - - [18/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:31,568 127.0.0.1 - - [18/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:31,569 127.0.0.1 - - [18/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:31,570 127.0.0.1 - - [18/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:31,571 127.0.0.1 - - [18/Sep/2024 14:32:31] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:33,031 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:33,031 127.0.0.1 - - [18/Sep/2024 14:32:33] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:34,051 127.0.0.1 - - [18/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:34,055 127.0.0.1 - - [18/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:34,056 127.0.0.1 - - [18/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:34,057 127.0.0.1 - - [18/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:34,057 127.0.0.1 - - [18/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:34,058 127.0.0.1 - - [18/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:34,059 127.0.0.1 - - [18/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:34,060 127.0.0.1 - - [18/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:34,061 127.0.0.1 - - [18/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:34,062 127.0.0.1 - - [18/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:34,062 127.0.0.1 - - [18/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:34,063 127.0.0.1 - - [18/Sep/2024 14:32:34] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:35,548 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:35,549 127.0.0.1 - - [18/Sep/2024 14:32:35] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:36,570 127.0.0.1 - - [18/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:36,573 127.0.0.1 - - [18/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:36,574 127.0.0.1 - - [18/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:36,575 127.0.0.1 - - [18/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:36,575 127.0.0.1 - - [18/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:36,576 127.0.0.1 - - [18/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:36,578 127.0.0.1 - - [18/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:36,578 127.0.0.1 - - [18/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:36,579 127.0.0.1 - - [18/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:36,580 127.0.0.1 - - [18/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:36,581 127.0.0.1 - - [18/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:36,582 127.0.0.1 - - [18/Sep/2024 14:32:36] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:37,944 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:37,945 127.0.0.1 - - [18/Sep/2024 14:32:37] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:38,969 127.0.0.1 - - [18/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:38,969 127.0.0.1 - - [18/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:38,970 127.0.0.1 - - [18/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:38,972 127.0.0.1 - - [18/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:38,972 127.0.0.1 - - [18/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:38,974 127.0.0.1 - - [18/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:38,974 127.0.0.1 - - [18/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:38,975 127.0.0.1 - - [18/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:38,976 127.0.0.1 - - [18/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:38,977 127.0.0.1 - - [18/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:38,978 127.0.0.1 - - [18/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:38,980 127.0.0.1 - - [18/Sep/2024 14:32:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:40,530 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:40,530 127.0.0.1 - - [18/Sep/2024 14:32:40] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:41,545 127.0.0.1 - - [18/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:41,550 127.0.0.1 - - [18/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:41,554 127.0.0.1 - - [18/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:41,555 127.0.0.1 - - [18/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:41,557 127.0.0.1 - - [18/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:41,558 127.0.0.1 - - [18/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:41,559 127.0.0.1 - - [18/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:41,560 127.0.0.1 - - [18/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:41,561 127.0.0.1 - - [18/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:41,563 127.0.0.1 - - [18/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:41,564 127.0.0.1 - - [18/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:41,564 127.0.0.1 - - [18/Sep/2024 14:32:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:43,374 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:43,375 127.0.0.1 - - [18/Sep/2024 14:32:43] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:44,394 127.0.0.1 - - [18/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:44,397 127.0.0.1 - - [18/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:44,399 127.0.0.1 - - [18/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:44,399 127.0.0.1 - - [18/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:44,401 127.0.0.1 - - [18/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:44,401 127.0.0.1 - - [18/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:44,402 127.0.0.1 - - [18/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:44,403 127.0.0.1 - - [18/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:44,404 127.0.0.1 - - [18/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:44,405 127.0.0.1 - - [18/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:44,406 127.0.0.1 - - [18/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:44,407 127.0.0.1 - - [18/Sep/2024 14:32:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:45,989 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:45,989 127.0.0.1 - - [18/Sep/2024 14:32:45] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:47,012 127.0.0.1 - - [18/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:47,013 127.0.0.1 - - [18/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:47,014 127.0.0.1 - - [18/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:47,015 127.0.0.1 - - [18/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:47,016 127.0.0.1 - - [18/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:47,017 127.0.0.1 - - [18/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:47,018 127.0.0.1 - - [18/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:47,019 127.0.0.1 - - [18/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:47,020 127.0.0.1 - - [18/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:47,021 127.0.0.1 - - [18/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:47,022 127.0.0.1 - - [18/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:47,023 127.0.0.1 - - [18/Sep/2024 14:32:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:48,697 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:48,698 127.0.0.1 - - [18/Sep/2024 14:32:48] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:49,718 127.0.0.1 - - [18/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:49,720 127.0.0.1 - - [18/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:49,723 127.0.0.1 - - [18/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:49,724 127.0.0.1 - - [18/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:49,725 127.0.0.1 - - [18/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:49,726 127.0.0.1 - - [18/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:49,728 127.0.0.1 - - [18/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:49,728 127.0.0.1 - - [18/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:49,730 127.0.0.1 - - [18/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:49,730 127.0.0.1 - - [18/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:49,731 127.0.0.1 - - [18/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:49,733 127.0.0.1 - - [18/Sep/2024 14:32:49] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:51,849 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:51,850 127.0.0.1 - - [18/Sep/2024 14:32:51] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:52,874 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,876 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,878 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,879 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,880 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,880 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,882 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,882 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,883 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,884 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,885 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,886 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,887 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,888 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:52,889 127.0.0.1 - - [18/Sep/2024 14:32:52] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:54,621 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:54,622 127.0.0.1 - - [18/Sep/2024 14:32:54] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:55,646 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,649 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,650 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,651 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,652 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,653 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,653 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,654 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,655 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,656 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,657 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,658 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,659 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,660 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:55,661 127.0.0.1 - - [18/Sep/2024 14:32:55] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:57,667 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:32:57,668 127.0.0.1 - - [18/Sep/2024 14:32:57] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:32:58,691 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,694 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,695 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,696 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,697 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,698 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,699 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,700 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,701 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,701 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,702 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,704 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,705 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,706 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:32:58,706 127.0.0.1 - - [18/Sep/2024 14:32:58] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:00,716 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:00,717 127.0.0.1 - - [18/Sep/2024 14:33:00] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:01,740 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,744 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,745 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,746 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,747 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,748 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,749 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,750 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,751 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,751 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,752 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,754 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,755 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,755 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:01,756 127.0.0.1 - - [18/Sep/2024 14:33:01] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:03,556 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:03,557 127.0.0.1 - - [18/Sep/2024 14:33:03] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:04,581 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,583 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,584 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,586 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,587 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,588 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,589 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,589 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,590 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,591 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,592 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,593 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,595 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,596 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:04,597 127.0.0.1 - - [18/Sep/2024 14:33:04] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:06,302 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:06,302 127.0.0.1 - - [18/Sep/2024 14:33:06] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:07,319 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,329 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,330 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,332 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,332 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,333 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,334 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,335 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,337 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,337 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,338 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,339 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,340 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,341 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:07,342 127.0.0.1 - - [18/Sep/2024 14:33:07] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:09,116 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:09,117 127.0.0.1 - - [18/Sep/2024 14:33:09] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:10,142 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,143 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,144 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,145 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,146 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,147 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,148 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,149 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,150 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,150 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,152 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,152 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,153 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,154 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:10,155 127.0.0.1 - - [18/Sep/2024 14:33:10] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:12,595 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:12,596 127.0.0.1 - - [18/Sep/2024 14:33:12] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:13,619 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,622 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,623 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,624 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,625 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,626 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,626 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,627 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,628 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,629 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,630 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,631 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,632 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,632 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:13,633 127.0.0.1 - - [18/Sep/2024 14:33:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:14,905 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:14,906 127.0.0.1 - - [18/Sep/2024 14:33:14] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:15,927 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,931 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,932 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,934 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,936 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,937 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,938 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,938 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,939 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,940 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,941 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,942 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,943 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,944 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:15,945 127.0.0.1 - - [18/Sep/2024 14:33:15] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:17,667 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:17,668 127.0.0.1 - - [18/Sep/2024 14:33:17] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:18,692 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,695 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,696 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,696 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,697 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,698 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,698 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,699 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,700 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,701 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,702 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,704 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,705 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,705 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:18,706 127.0.0.1 - - [18/Sep/2024 14:33:18] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:20,177 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:20,177 127.0.0.1 - - [18/Sep/2024 14:33:20] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:21,219 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,220 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,220 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,221 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,222 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,223 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,224 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,225 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,226 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,227 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,228 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,229 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,230 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,231 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,232 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,232 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,233 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:21,234 127.0.0.1 - - [18/Sep/2024 14:33:21] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:22,908 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:22,909 127.0.0.1 - - [18/Sep/2024 14:33:22] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:23,936 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,940 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,941 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,941 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,943 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,944 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,944 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,945 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,946 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,946 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,947 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,948 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,948 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,949 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,950 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,951 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,952 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:23,952 127.0.0.1 - - [18/Sep/2024 14:33:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:25,502 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:25,502 127.0.0.1 - - [18/Sep/2024 14:33:25] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:26,529 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,533 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,534 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,535 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,537 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,537 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,538 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,539 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,540 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,541 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,542 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,543 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,543 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,544 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,545 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,546 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,548 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:26,548 127.0.0.1 - - [18/Sep/2024 14:33:26] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:29,018 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:29,019 127.0.0.1 - - [18/Sep/2024 14:33:29] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:30,047 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,049 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,051 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,052 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,052 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,053 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,054 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,055 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,056 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,057 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,057 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,058 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,059 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,059 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,061 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,062 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,063 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:30,064 127.0.0.1 - - [18/Sep/2024 14:33:30] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:31,945 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:31,945 127.0.0.1 - - [18/Sep/2024 14:33:31] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:32,973 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,976 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,978 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,979 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,980 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,980 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,981 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,983 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,983 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,984 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,985 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,986 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,987 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,988 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,989 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,989 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,990 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:32,991 127.0.0.1 - - [18/Sep/2024 14:33:32] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:34,827 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:34,827 127.0.0.1 - - [18/Sep/2024 14:33:34] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:35,851 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,858 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,859 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,860 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,861 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,862 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,862 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,864 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,865 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,865 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,866 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,867 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,868 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,869 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,870 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,871 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,872 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:35,872 127.0.0.1 - - [18/Sep/2024 14:33:35] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:37,694 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:37,694 127.0.0.1 - - [18/Sep/2024 14:33:37] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:38,723 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,724 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,726 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,727 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,728 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,729 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,730 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,730 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,732 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,733 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,734 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,735 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,735 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,736 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,737 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,738 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,740 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:38,741 127.0.0.1 - - [18/Sep/2024 14:33:38] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:40,441 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:40,442 127.0.0.1 - - [18/Sep/2024 14:33:40] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:41,469 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,472 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,473 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,474 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,475 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,476 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,477 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,478 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,479 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,480 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,480 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,482 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,483 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,483 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,484 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,485 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,486 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:41,487 127.0.0.1 - - [18/Sep/2024 14:33:41] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:43,508 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:43,509 127.0.0.1 - - [18/Sep/2024 14:33:43] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:44,536 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,540 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,541 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,541 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,542 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,543 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,544 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,545 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,546 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,547 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,548 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,549 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,550 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,551 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,552 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,553 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,554 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:44,554 127.0.0.1 - - [18/Sep/2024 14:33:44] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:46,306 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:46,307 127.0.0.1 - - [18/Sep/2024 14:33:46] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:47,334 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,337 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,338 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,339 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,339 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,341 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,341 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,343 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,343 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,344 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,346 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,347 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,347 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,348 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,349 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,350 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,351 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:47,352 127.0.0.1 - - [18/Sep/2024 14:33:47] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:49,504 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:49,504 127.0.0.1 - - [18/Sep/2024 14:33:49] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:50,531 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,539 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,540 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,542 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,543 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,544 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,544 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,545 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,546 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,547 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,548 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,549 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,550 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,551 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,552 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,553 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,554 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,554 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,555 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,556 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,557 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:50,558 127.0.0.1 - - [18/Sep/2024 14:33:50] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:52,687 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:52,688 127.0.0.1 - - [18/Sep/2024 14:33:52] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:53,720 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,722 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,724 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,725 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,726 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,727 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,729 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,729 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,730 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,731 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,732 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,733 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,734 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,735 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,736 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,737 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,738 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,739 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,740 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,740 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,741 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:53,742 127.0.0.1 - - [18/Sep/2024 14:33:53] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:55,942 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:55,943 127.0.0.1 - - [18/Sep/2024 14:33:55] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:56,973 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,979 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,980 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,981 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,982 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,983 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,984 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,986 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,986 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,987 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,988 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,989 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,990 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,991 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,992 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,993 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,993 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,995 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,996 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,996 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,997 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:56,998 127.0.0.1 - - [18/Sep/2024 14:33:56] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:58,936 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:33:58,937 127.0.0.1 - - [18/Sep/2024 14:33:58] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:33:59,970 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,974 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,975 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,976 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,977 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,978 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,978 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,980 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,981 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,981 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,982 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,983 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,984 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,985 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,986 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,987 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,987 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,989 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,990 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,990 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,991 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:33:59,992 127.0.0.1 - - [18/Sep/2024 14:33:59] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:01,857 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:34:01,857 127.0.0.1 - - [18/Sep/2024 14:34:01] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:34:02,884 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,893 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,894 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,895 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,896 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,898 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,899 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,899 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,900 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,901 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,902 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,903 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,904 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,905 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,906 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,907 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,908 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,909 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,911 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,911 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,912 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:02,913 127.0.0.1 - - [18/Sep/2024 14:34:02] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:05,435 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:34:05,436 127.0.0.1 - - [18/Sep/2024 14:34:05] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:34:06,469 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,471 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,473 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,475 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,476 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,477 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,477 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,478 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,479 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,480 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,481 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,483 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,484 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,485 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,486 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,487 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,487 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,488 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,489 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,490 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,491 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:06,492 127.0.0.1 - - [18/Sep/2024 14:34:06] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:08,611 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:34:08,611 127.0.0.1 - - [18/Sep/2024 14:34:08] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:34:09,642 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,647 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,648 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,649 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,650 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,651 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,652 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,653 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,654 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,654 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,655 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,656 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,658 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,659 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,660 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,661 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,661 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,662 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,663 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,664 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,665 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:09,665 127.0.0.1 - - [18/Sep/2024 14:34:09] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:12,452 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:34:12,453 127.0.0.1 - - [18/Sep/2024 14:34:12] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:34:13,483 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,486 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,488 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,488 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,490 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,491 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,492 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,493 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,494 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,495 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,496 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,497 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,498 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,499 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,500 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,501 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,502 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,503 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,504 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,505 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,506 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:13,506 127.0.0.1 - - [18/Sep/2024 14:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:15,346 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:34:15,346 127.0.0.1 - - [18/Sep/2024 14:34:15] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:34:16,376 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,380 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,382 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,383 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,384 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,385 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,386 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,387 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,388 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,389 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,390 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,391 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,392 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,393 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,394 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,395 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,396 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,397 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,397 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,398 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,399 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:16,400 127.0.0.1 - - [18/Sep/2024 14:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:19,550 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:34:19,551 127.0.0.1 - - [18/Sep/2024 14:34:19] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:34:20,579 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,586 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,587 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,589 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,590 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,591 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,592 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,593 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,594 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,595 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,596 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,598 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,598 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,599 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,600 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,601 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,602 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,603 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,604 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,605 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,606 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:20,607 127.0.0.1 - - [18/Sep/2024 14:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:22,371 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:34:22,371 127.0.0.1 - - [18/Sep/2024 14:34:22] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:34:23,408 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,412 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,414 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,416 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,416 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,417 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,418 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,419 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,420 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,420 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,421 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,422 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,423 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,424 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,425 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,426 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,427 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,429 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,429 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,430 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,431 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,432 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,433 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,434 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,435 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,436 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,437 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:23,438 127.0.0.1 - - [18/Sep/2024 14:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:26,016 Exception on /inference [POST]
Traceback (most recent call last):
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/amartinezi/sincere/venv/lib64/python3.9/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 284, in inference
    completed_inference_ids, error = process_batch(model_alias, batch_size)
  File "/home/amartinezi/sincere/profiling_batch_flask.py", line 141, in process_batch
    print(f"Processed batch: {list(responses.keys())} with model {model_alias} in {elapsed_time:.4f} seconds")
UnboundLocalError: local variable 'elapsed_time' referenced before assignment
2024-09-18 14:34:26,016 127.0.0.1 - - [18/Sep/2024 14:34:26] "[35m[1mPOST /inference HTTP/1.1[0m" 500 -
2024-09-18 14:34:27,051 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,058 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,060 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,061 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,062 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,063 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,064 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,064 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,065 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,066 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,067 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,068 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,069 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,069 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,071 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,072 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,072 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,074 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,075 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,076 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,077 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,078 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,079 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,079 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,080 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,081 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,082 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-18 14:34:27,083 127.0.0.1 - - [18/Sep/2024 14:34:27] "POST /inference HTTP/1.1" 200 -
