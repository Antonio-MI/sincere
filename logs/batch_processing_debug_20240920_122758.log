2024-09-20 12:27:58,492 Using device: cuda
2024-09-20 12:27:58,493 Scheduling mode set as BestBatch+SLA
2024-09-20 12:27:58,496 Monitoring status set to True
2024-09-20 12:28:13,567 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.122.143:5000
2024-09-20 12:28:13,568 [33mPress CTRL+C to quit[0m
2024-09-20 12:29:01,940 Request with ID 0e28c35f for model gemma-7b received
2024-09-20 12:29:01,940 Adjusted batch time limit for gemma-7b: 5.0000 seconds
2024-09-20 12:29:01,941 127.0.0.1 - - [20/Sep/2024 12:29:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:02,092 Request with ID 7a657e43 for model llama3-8b received
2024-09-20 12:29:02,092 Adjusted batch time limit for llama3-8b: 5.0000 seconds
2024-09-20 12:29:02,092 127.0.0.1 - - [20/Sep/2024 12:29:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:02,102 Request with ID f3b3897c for model llama3-8b received
2024-09-20 12:29:02,103 127.0.0.1 - - [20/Sep/2024 12:29:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:02,197 Request with ID 772d8baa for model granite-7b received
2024-09-20 12:29:02,197 Adjusted batch time limit for granite-7b: 5.0000 seconds
2024-09-20 12:29:02,197 127.0.0.1 - - [20/Sep/2024 12:29:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:02,551 Request with ID 646a48f7 for model llama3-8b received
2024-09-20 12:29:02,552 Request with ID 8c62b643 for model gemma-7b received
2024-09-20 12:29:02,553 127.0.0.1 - - [20/Sep/2024 12:29:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:02,553 127.0.0.1 - - [20/Sep/2024 12:29:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:02,588 Request with ID 07a9a30e for model granite-7b received
2024-09-20 12:29:02,589 127.0.0.1 - - [20/Sep/2024 12:29:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:02,591 Request with ID d8fcfcec for model llama3-8b received
2024-09-20 12:29:02,592 127.0.0.1 - - [20/Sep/2024 12:29:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:02,609 Request with ID 4dd0c3a4 for model gemma-7b received
2024-09-20 12:29:02,609 127.0.0.1 - - [20/Sep/2024 12:29:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:02,619 Request with ID 3b488d6a for model gemma-7b received
2024-09-20 12:29:02,619 127.0.0.1 - - [20/Sep/2024 12:29:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:03,031 Request with ID bbaa5dd1 for model granite-7b received
2024-09-20 12:29:03,031 127.0.0.1 - - [20/Sep/2024 12:29:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:03,126 Request with ID 0f86a56d for model llama3-8b received
2024-09-20 12:29:03,127 127.0.0.1 - - [20/Sep/2024 12:29:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:03,127 Request with ID ebc40d6a for model llama3-8b received
2024-09-20 12:29:03,128 127.0.0.1 - - [20/Sep/2024 12:29:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:03,295 Request with ID fc040798 for model gemma-7b received
2024-09-20 12:29:03,295 127.0.0.1 - - [20/Sep/2024 12:29:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:03,411 Request with ID c33b2c8d for model granite-7b received
2024-09-20 12:29:03,411 127.0.0.1 - - [20/Sep/2024 12:29:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:03,654 Request with ID 7e646c97 for model gemma-7b received
2024-09-20 12:29:03,654 127.0.0.1 - - [20/Sep/2024 12:29:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:03,796 Request with ID 52a3c729 for model llama3-8b received
2024-09-20 12:29:03,797 127.0.0.1 - - [20/Sep/2024 12:29:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:03,877 Request with ID 6071fce6 for model llama3-8b received
2024-09-20 12:29:03,878 127.0.0.1 - - [20/Sep/2024 12:29:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:04,028 Request with ID 80b18c16 for model gemma-7b received
2024-09-20 12:29:04,029 127.0.0.1 - - [20/Sep/2024 12:29:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:04,292 Request with ID 4815ac18 for model gemma-7b received
2024-09-20 12:29:04,292 127.0.0.1 - - [20/Sep/2024 12:29:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:04,378 Request with ID 83723bec for model granite-7b received
2024-09-20 12:29:04,378 127.0.0.1 - - [20/Sep/2024 12:29:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:04,419 Request with ID 7289adde for model llama3-8b received
2024-09-20 12:29:04,419 127.0.0.1 - - [20/Sep/2024 12:29:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:04,510 Request with ID 4e6a037c for model llama3-8b received
2024-09-20 12:29:04,511 127.0.0.1 - - [20/Sep/2024 12:29:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:04,543 Request with ID 67844a21 for model llama3-8b received
2024-09-20 12:29:04,544 127.0.0.1 - - [20/Sep/2024 12:29:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:04,551 Request with ID 4b84cd2d for model gemma-7b received
2024-09-20 12:29:04,552 127.0.0.1 - - [20/Sep/2024 12:29:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:04,588 Request with ID fc59ce68 for model gemma-7b received
2024-09-20 12:29:04,588 127.0.0.1 - - [20/Sep/2024 12:29:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:04,715 Request with ID 8226fa80 for model llama3-8b received
2024-09-20 12:29:04,715 127.0.0.1 - - [20/Sep/2024 12:29:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:04,722 Request with ID 4fed1811 for model llama3-8b received
2024-09-20 12:29:04,723 127.0.0.1 - - [20/Sep/2024 12:29:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:04,915 Request with ID af96205c for model gemma-7b received
2024-09-20 12:29:04,916 127.0.0.1 - - [20/Sep/2024 12:29:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:04,922 Request with ID 0fa02a73 for model llama3-8b received
2024-09-20 12:29:04,923 127.0.0.1 - - [20/Sep/2024 12:29:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:05,015 Request with ID a1c1bddf for model llama3-8b received
2024-09-20 12:29:05,016 127.0.0.1 - - [20/Sep/2024 12:29:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:05,029 Request with ID 3990a26f for model llama3-8b received
2024-09-20 12:29:05,030 127.0.0.1 - - [20/Sep/2024 12:29:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:05,159 Request with ID 01a3818e for model llama3-8b received
2024-09-20 12:29:05,160 127.0.0.1 - - [20/Sep/2024 12:29:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:05,229 Request with ID 2761620e for model llama3-8b received
2024-09-20 12:29:05,230 127.0.0.1 - - [20/Sep/2024 12:29:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:05,243 Request with ID 9c43635c for model gemma-7b received
2024-09-20 12:29:05,243 127.0.0.1 - - [20/Sep/2024 12:29:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:05,472 Request with ID 28921a78 for model llama3-8b received
2024-09-20 12:29:05,473 127.0.0.1 - - [20/Sep/2024 12:29:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:05,592 Request with ID 84e89b42 for model llama3-8b received
2024-09-20 12:29:05,593 127.0.0.1 - - [20/Sep/2024 12:29:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:05,619 Request with ID 601d1947 for model llama3-8b received
2024-09-20 12:29:05,619 127.0.0.1 - - [20/Sep/2024 12:29:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:05,740 Request with ID b2304eff for model llama3-8b received
2024-09-20 12:29:05,740 127.0.0.1 - - [20/Sep/2024 12:29:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:05,907 Request with ID 32c278bb for model llama3-8b received
2024-09-20 12:29:05,907 127.0.0.1 - - [20/Sep/2024 12:29:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:05,927 Request with ID 236b04c9 for model llama3-8b received
2024-09-20 12:29:05,928 127.0.0.1 - - [20/Sep/2024 12:29:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:06,095 Request with ID 41b5dab5 for model gemma-7b received
2024-09-20 12:29:06,096 127.0.0.1 - - [20/Sep/2024 12:29:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:06,108 Request with ID 80daae78 for model llama3-8b received
2024-09-20 12:29:06,108 127.0.0.1 - - [20/Sep/2024 12:29:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:06,110 Request with ID 31aaeae7 for model llama3-8b received
2024-09-20 12:29:06,111 Request with ID bce3da51 for model llama3-8b received
2024-09-20 12:29:06,111 127.0.0.1 - - [20/Sep/2024 12:29:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:06,112 127.0.0.1 - - [20/Sep/2024 12:29:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:06,178 Request with ID aa991ed4 for model gemma-7b received
2024-09-20 12:29:06,178 127.0.0.1 - - [20/Sep/2024 12:29:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:06,466 Request with ID 6ce7bab4 for model llama3-8b received
2024-09-20 12:29:06,467 127.0.0.1 - - [20/Sep/2024 12:29:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:06,519 Request with ID f27afcb5 for model llama3-8b received
2024-09-20 12:29:06,519 127.0.0.1 - - [20/Sep/2024 12:29:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:06,849 Request with ID ba1fe16e for model gemma-7b received
2024-09-20 12:29:06,850 127.0.0.1 - - [20/Sep/2024 12:29:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:06,853 Request with ID 27f08389 for model llama3-8b received
2024-09-20 12:29:06,853 127.0.0.1 - - [20/Sep/2024 12:29:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:06,907 Request with ID af413ebe for model gemma-7b received
2024-09-20 12:29:06,908 127.0.0.1 - - [20/Sep/2024 12:29:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:07,149 Request with ID 66fd3474 for model gemma-7b received
2024-09-20 12:29:07,150 127.0.0.1 - - [20/Sep/2024 12:29:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:07,218 Request with ID 74098a1c for model llama3-8b received
2024-09-20 12:29:07,219 127.0.0.1 - - [20/Sep/2024 12:29:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:07,311 Request with ID d9759216 for model gemma-7b received
2024-09-20 12:29:07,312 127.0.0.1 - - [20/Sep/2024 12:29:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:07,339 Request with ID fa14919c for model gemma-7b received
2024-09-20 12:29:07,340 127.0.0.1 - - [20/Sep/2024 12:29:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:07,442 Request with ID 831f5f45 for model gemma-7b received
2024-09-20 12:29:07,443 127.0.0.1 - - [20/Sep/2024 12:29:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:07,613 Request with ID e474d199 for model gemma-7b received
2024-09-20 12:29:07,614 127.0.0.1 - - [20/Sep/2024 12:29:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:07,686 Request with ID ac131a1a for model llama3-8b received
2024-09-20 12:29:07,687 127.0.0.1 - - [20/Sep/2024 12:29:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:07,801 Request with ID 7849cd63 for model llama3-8b received
2024-09-20 12:29:07,802 127.0.0.1 - - [20/Sep/2024 12:29:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:07,828 Request with ID bd4166d6 for model gemma-7b received
2024-09-20 12:29:07,828 127.0.0.1 - - [20/Sep/2024 12:29:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:07,947 Request with ID dbe5c838 for model llama3-8b received
2024-09-20 12:29:07,947 127.0.0.1 - - [20/Sep/2024 12:29:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:08,130 Request with ID 180481a4 for model gemma-7b received
2024-09-20 12:29:08,130 127.0.0.1 - - [20/Sep/2024 12:29:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:08,144 Request with ID ce76a7d8 for model llama3-8b received
2024-09-20 12:29:08,144 127.0.0.1 - - [20/Sep/2024 12:29:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:08,175 Request with ID 2e1738b3 for model gemma-7b received
2024-09-20 12:29:08,175 127.0.0.1 - - [20/Sep/2024 12:29:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:08,580 Request with ID c9639e7a for model gemma-7b received
2024-09-20 12:29:08,581 127.0.0.1 - - [20/Sep/2024 12:29:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:08,590 Request with ID 03e51591 for model llama3-8b received
2024-09-20 12:29:08,591 127.0.0.1 - - [20/Sep/2024 12:29:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:08,693 Request with ID 80b91f1e for model gemma-7b received
2024-09-20 12:29:08,694 127.0.0.1 - - [20/Sep/2024 12:29:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:08,815 Request with ID 5b443b98 for model llama3-8b received
2024-09-20 12:29:08,815 127.0.0.1 - - [20/Sep/2024 12:29:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:08,868 Request with ID d7f00130 for model llama3-8b received
2024-09-20 12:29:08,869 127.0.0.1 - - [20/Sep/2024 12:29:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:08,877 Request with ID 999ee0a5 for model llama3-8b received
2024-09-20 12:29:08,878 127.0.0.1 - - [20/Sep/2024 12:29:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:08,974 Request with ID 91f6496d for model llama3-8b received
2024-09-20 12:29:08,975 Request with ID ddea1c66 for model gemma-7b received
2024-09-20 12:29:08,976 127.0.0.1 - - [20/Sep/2024 12:29:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:08,976 127.0.0.1 - - [20/Sep/2024 12:29:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:09,042 Request with ID 2571b401 for model gemma-7b received
2024-09-20 12:29:09,043 127.0.0.1 - - [20/Sep/2024 12:29:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:09,168 Request with ID 5ed13928 for model gemma-7b received
2024-09-20 12:29:09,169 127.0.0.1 - - [20/Sep/2024 12:29:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:09,308 Request with ID 7ceaa207 for model llama3-8b received
2024-09-20 12:29:09,309 127.0.0.1 - - [20/Sep/2024 12:29:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:09,438 Request with ID 0abf60c7 for model llama3-8b received
2024-09-20 12:29:09,438 127.0.0.1 - - [20/Sep/2024 12:29:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:09,447 Request with ID f0ea8d1a for model gemma-7b received
2024-09-20 12:29:09,447 127.0.0.1 - - [20/Sep/2024 12:29:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:09,477 Request with ID 2c2bbfc3 for model llama3-8b received
2024-09-20 12:29:09,477 127.0.0.1 - - [20/Sep/2024 12:29:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:09,547 Request with ID 39188aa0 for model llama3-8b received
2024-09-20 12:29:09,547 127.0.0.1 - - [20/Sep/2024 12:29:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:09,707 Request with ID 48540273 for model llama3-8b received
2024-09-20 12:29:09,707 127.0.0.1 - - [20/Sep/2024 12:29:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:09,819 Request with ID a6734e4d for model gemma-7b received
2024-09-20 12:29:09,819 127.0.0.1 - - [20/Sep/2024 12:29:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:09,949 Request with ID 090730b9 for model llama3-8b received
2024-09-20 12:29:09,949 127.0.0.1 - - [20/Sep/2024 12:29:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:10,098 Request with ID cd0dc97b for model llama3-8b received
2024-09-20 12:29:10,099 127.0.0.1 - - [20/Sep/2024 12:29:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:10,163 Request with ID ac0f8204 for model llama3-8b received
2024-09-20 12:29:10,163 127.0.0.1 - - [20/Sep/2024 12:29:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:10,210 Request with ID fccfd1f4 for model llama3-8b received
2024-09-20 12:29:10,210 127.0.0.1 - - [20/Sep/2024 12:29:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:10,251 Request with ID 933ab923 for model llama3-8b received
2024-09-20 12:29:10,251 127.0.0.1 - - [20/Sep/2024 12:29:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:10,585 Request with ID a7fd3132 for model granite-7b received
2024-09-20 12:29:10,586 127.0.0.1 - - [20/Sep/2024 12:29:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:10,624 Request with ID d6e9dba0 for model gemma-7b received
2024-09-20 12:29:10,624 127.0.0.1 - - [20/Sep/2024 12:29:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:10,690 Request with ID 4e4ab992 for model llama3-8b received
2024-09-20 12:29:10,691 127.0.0.1 - - [20/Sep/2024 12:29:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:10,968 Request with ID 5d7f33c8 for model llama3-8b received
2024-09-20 12:29:10,968 127.0.0.1 - - [20/Sep/2024 12:29:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:10,976 Request with ID e7d59b25 for model llama3-8b received
2024-09-20 12:29:10,976 127.0.0.1 - - [20/Sep/2024 12:29:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:11,439 Request with ID 2d8becf1 for model gemma-7b received
2024-09-20 12:29:11,440 127.0.0.1 - - [20/Sep/2024 12:29:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:11,478 Request with ID c58bca53 for model gemma-7b received
2024-09-20 12:29:11,479 127.0.0.1 - - [20/Sep/2024 12:29:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:11,514 Request with ID 1beb68e6 for model llama3-8b received
2024-09-20 12:29:11,515 127.0.0.1 - - [20/Sep/2024 12:29:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:11,719 Request with ID 27e009d7 for model granite-7b received
2024-09-20 12:29:11,720 127.0.0.1 - - [20/Sep/2024 12:29:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:11,721 Request with ID 2eda34ff for model llama3-8b received
2024-09-20 12:29:11,721 127.0.0.1 - - [20/Sep/2024 12:29:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:11,826 Request with ID b11abd9b for model granite-7b received
2024-09-20 12:29:11,827 127.0.0.1 - - [20/Sep/2024 12:29:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,045 Request with ID 05c4ff31 for model gemma-7b received
2024-09-20 12:29:12,046 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,054 Request with ID a6a56aa1 for model granite-7b received
2024-09-20 12:29:12,055 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,120 Request with ID 41906623 for model llama3-8b received
2024-09-20 12:29:12,120 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,304 Request with ID 1a3a75db for model granite-7b received
2024-09-20 12:29:12,304 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,341 Request with ID 0adf4b69 for model gemma-7b received
2024-09-20 12:29:12,342 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,441 Request with ID 8896b86f for model llama3-8b received
2024-09-20 12:29:12,442 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,465 Request with ID 6e9900e2 for model llama3-8b received
2024-09-20 12:29:12,465 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,480 Request with ID c80f2fc9 for model llama3-8b received
2024-09-20 12:29:12,481 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,608 Request with ID 8449f80d for model llama3-8b received
2024-09-20 12:29:12,609 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,641 Request with ID 68c0f93c for model granite-7b received
2024-09-20 12:29:12,641 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,644 Request with ID 1190aa5a for model granite-7b received
2024-09-20 12:29:12,644 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,702 Request with ID eaec1439 for model llama3-8b received
2024-09-20 12:29:12,703 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,722 Request with ID 508551e4 for model llama3-8b received
2024-09-20 12:29:12,723 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,751 Request with ID 1960e71a for model llama3-8b received
2024-09-20 12:29:12,752 127.0.0.1 - - [20/Sep/2024 12:29:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:12,861 Request with ID d6692afc for model llama3-8b received
2024-09-20 12:29:12,862 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:29:12,862 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:29:12,862 Next: call load_model for llama3-8b
2024-09-20 12:29:13,114 Request with ID 5a6040a9 for model llama3-8b received
2024-09-20 12:29:13,115 127.0.0.1 - - [20/Sep/2024 12:29:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:13,129 Request with ID 82457c21 for model gemma-7b received
2024-09-20 12:29:13,130 127.0.0.1 - - [20/Sep/2024 12:29:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:13,346 Request with ID 0eeb559a for model granite-7b received
2024-09-20 12:29:13,348 127.0.0.1 - - [20/Sep/2024 12:29:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:13,354 Request with ID a6d8a38a for model llama3-8b received
2024-09-20 12:29:13,367 Request with ID 819bdd4f for model gemma-7b received
2024-09-20 12:29:13,368 127.0.0.1 - - [20/Sep/2024 12:29:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:13,372 Request with ID 037712cb for model gemma-7b received
2024-09-20 12:29:13,373 127.0.0.1 - - [20/Sep/2024 12:29:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:13,380 127.0.0.1 - - [20/Sep/2024 12:29:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:13,520 Request with ID 8d97ae25 for model llama3-8b received
2024-09-20 12:29:13,527 127.0.0.1 - - [20/Sep/2024 12:29:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:13,588 Request with ID f28a896a for model llama3-8b received
2024-09-20 12:29:13,596 127.0.0.1 - - [20/Sep/2024 12:29:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:13,881 Request with ID cef1143e for model llama3-8b received
2024-09-20 12:29:13,892 127.0.0.1 - - [20/Sep/2024 12:29:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:13,975 Request with ID 7910613b for model llama3-8b received
2024-09-20 12:29:13,976 127.0.0.1 - - [20/Sep/2024 12:29:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:14,069 Request with ID caabe651 for model llama3-8b received
2024-09-20 12:29:14,072 127.0.0.1 - - [20/Sep/2024 12:29:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:14,100 Request with ID 5b4a9f93 for model llama3-8b received
2024-09-20 12:29:14,103 127.0.0.1 - - [20/Sep/2024 12:29:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:14,320 Request with ID de425da8 for model llama3-8b received
2024-09-20 12:29:14,320 127.0.0.1 - - [20/Sep/2024 12:29:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:14,322 Request with ID 54ff204f for model gemma-7b received
2024-09-20 12:29:14,324 Request with ID e64c553a for model llama3-8b received
2024-09-20 12:29:14,325 127.0.0.1 - - [20/Sep/2024 12:29:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:14,325 127.0.0.1 - - [20/Sep/2024 12:29:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:14,327 Request with ID e3ee76f9 for model gemma-7b received
2024-09-20 12:29:14,328 127.0.0.1 - - [20/Sep/2024 12:29:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:14,419 Request with ID 7ad5b22f for model gemma-7b received
2024-09-20 12:29:14,419 127.0.0.1 - - [20/Sep/2024 12:29:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:14,488 Request with ID 3e58505e for model llama3-8b received
2024-09-20 12:29:14,489 127.0.0.1 - - [20/Sep/2024 12:29:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:14,590 Request with ID 14603d11 for model granite-7b received
2024-09-20 12:29:14,590 127.0.0.1 - - [20/Sep/2024 12:29:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:14,645 Request with ID 20f47832 for model gemma-7b received
2024-09-20 12:29:14,646 127.0.0.1 - - [20/Sep/2024 12:29:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:14,790 Request with ID a257db17 for model llama3-8b received
2024-09-20 12:29:14,791 127.0.0.1 - - [20/Sep/2024 12:29:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:14,837 Request with ID 77e100c3 for model gemma-7b received
2024-09-20 12:29:14,838 127.0.0.1 - - [20/Sep/2024 12:29:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:15,104 Request with ID 142aad71 for model gemma-7b received
2024-09-20 12:29:15,104 127.0.0.1 - - [20/Sep/2024 12:29:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:15,220 Request with ID 57d5237b for model gemma-7b received
2024-09-20 12:29:15,220 127.0.0.1 - - [20/Sep/2024 12:29:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:15,298 Request with ID 75f3b99f for model llama3-8b received
2024-09-20 12:29:15,299 127.0.0.1 - - [20/Sep/2024 12:29:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:15,337 Request with ID 7871ac90 for model granite-7b received
2024-09-20 12:29:15,338 127.0.0.1 - - [20/Sep/2024 12:29:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:15,344 Request with ID 9982fb9f for model gemma-7b received
2024-09-20 12:29:15,345 127.0.0.1 - - [20/Sep/2024 12:29:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:15,661 Request with ID 022185ff for model llama3-8b received
2024-09-20 12:29:15,661 127.0.0.1 - - [20/Sep/2024 12:29:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:15,670 Request with ID 3715dcaf for model gemma-7b received
2024-09-20 12:29:15,670 127.0.0.1 - - [20/Sep/2024 12:29:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:15,785 Request with ID fab259e7 for model llama3-8b received
2024-09-20 12:29:15,785 127.0.0.1 - - [20/Sep/2024 12:29:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:15,794 Request with ID 1340c27f for model llama3-8b received
2024-09-20 12:29:15,795 127.0.0.1 - - [20/Sep/2024 12:29:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:16,348 Request with ID 8dfdcc68 for model llama3-8b received
2024-09-20 12:29:16,349 127.0.0.1 - - [20/Sep/2024 12:29:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:16,569 Request with ID 841f4303 for model llama3-8b received
2024-09-20 12:29:16,569 127.0.0.1 - - [20/Sep/2024 12:29:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:16,917 Request with ID 0bc916f2 for model llama3-8b received
2024-09-20 12:29:16,918 127.0.0.1 - - [20/Sep/2024 12:29:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:16,928 Request with ID bf78f55d for model llama3-8b received
2024-09-20 12:29:16,928 127.0.0.1 - - [20/Sep/2024 12:29:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:16,955 Request with ID 23f2d0a7 for model llama3-8b received
2024-09-20 12:29:16,956 127.0.0.1 - - [20/Sep/2024 12:29:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:17,080 Request with ID 38718063 for model llama3-8b received
2024-09-20 12:29:17,081 127.0.0.1 - - [20/Sep/2024 12:29:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:17,108 Request with ID 4be4a2b1 for model llama3-8b received
2024-09-20 12:29:17,108 127.0.0.1 - - [20/Sep/2024 12:29:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:17,322 Request with ID f611898d for model llama3-8b received
2024-09-20 12:29:17,322 127.0.0.1 - - [20/Sep/2024 12:29:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:17,750 Request with ID 4a7d32a6 for model gemma-7b received
2024-09-20 12:29:17,751 127.0.0.1 - - [20/Sep/2024 12:29:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:17,877 Request with ID 7d99d0b5 for model llama3-8b received
2024-09-20 12:29:17,878 127.0.0.1 - - [20/Sep/2024 12:29:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:17,959 Request with ID eff3ed74 for model gemma-7b received
2024-09-20 12:29:18,089 127.0.0.1 - - [20/Sep/2024 12:29:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:18,091 Request with ID b8c38a37 for model granite-7b received
2024-09-20 12:29:18,091 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:29:18,092 Dynamic batch size condition met for model granite-7b
2024-09-20 12:29:18,093 Request with ID b2b7228d for model llama3-8b received
2024-09-20 12:29:18,094 127.0.0.1 - - [20/Sep/2024 12:29:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:18,213 Request with ID 957a21be for model llama3-8b received
2024-09-20 12:29:18,214 127.0.0.1 - - [20/Sep/2024 12:29:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:18,351 Request with ID 8ea2f292 for model gemma-7b received
2024-09-20 12:29:18,352 127.0.0.1 - - [20/Sep/2024 12:29:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:18,404 Request with ID 520c82e7 for model gemma-7b received
2024-09-20 12:29:18,405 127.0.0.1 - - [20/Sep/2024 12:29:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:18,609 Request with ID 3b01cb23 for model llama3-8b received
2024-09-20 12:29:18,610 127.0.0.1 - - [20/Sep/2024 12:29:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:18,774 Request with ID 53f8b46b for model llama3-8b received
2024-09-20 12:29:18,774 127.0.0.1 - - [20/Sep/2024 12:29:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:18,778 Request with ID d424d479 for model granite-7b received
2024-09-20 12:29:18,779 127.0.0.1 - - [20/Sep/2024 12:29:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:19,040 Request with ID d7797ae0 for model gemma-7b received
2024-09-20 12:29:19,041 127.0.0.1 - - [20/Sep/2024 12:29:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:19,160 Request with ID 5635c781 for model llama3-8b received
2024-09-20 12:29:19,161 127.0.0.1 - - [20/Sep/2024 12:29:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:19,281 Request with ID 52e72ae9 for model llama3-8b received
2024-09-20 12:29:19,282 127.0.0.1 - - [20/Sep/2024 12:29:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:19,331 Request with ID 70853e31 for model granite-7b received
2024-09-20 12:29:19,331 127.0.0.1 - - [20/Sep/2024 12:29:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:19,365 Request with ID e015c2fc for model gemma-7b received
2024-09-20 12:29:19,365 127.0.0.1 - - [20/Sep/2024 12:29:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:19,378 Request with ID 6ddc7638 for model gemma-7b received
2024-09-20 12:29:19,378 127.0.0.1 - - [20/Sep/2024 12:29:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:19,400 Request with ID 4d8ff179 for model gemma-7b received
2024-09-20 12:29:19,401 127.0.0.1 - - [20/Sep/2024 12:29:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:19,428 Request with ID bef084db for model granite-7b received
2024-09-20 12:29:19,429 127.0.0.1 - - [20/Sep/2024 12:29:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:19,798 Request with ID 236b88c9 for model llama3-8b received
2024-09-20 12:29:19,798 127.0.0.1 - - [20/Sep/2024 12:29:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:19,876 Request with ID 8e70bc95 for model llama3-8b received
2024-09-20 12:29:19,876 127.0.0.1 - - [20/Sep/2024 12:29:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:19,970 Request with ID e6ff2962 for model gemma-7b received
2024-09-20 12:29:19,970 127.0.0.1 - - [20/Sep/2024 12:29:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:19,978 Request with ID ae4156eb for model llama3-8b received
2024-09-20 12:29:19,978 127.0.0.1 - - [20/Sep/2024 12:29:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,110 Request with ID c6471457 for model llama3-8b received
2024-09-20 12:29:20,111 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,119 Request with ID 213b856b for model llama3-8b received
2024-09-20 12:29:20,119 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,124 Request with ID 63acb3fe for model gemma-7b received
2024-09-20 12:29:20,124 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,293 Request with ID 6959aef4 for model llama3-8b received
2024-09-20 12:29:20,293 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,341 Request with ID 4f17d2ac for model gemma-7b received
2024-09-20 12:29:20,341 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,521 Request with ID 42663db7 for model llama3-8b received
2024-09-20 12:29:20,522 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,586 Request with ID 5a2356fe for model gemma-7b received
2024-09-20 12:29:20,587 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,592 Request with ID 5893fad2 for model llama3-8b received
2024-09-20 12:29:20,593 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,671 Request with ID 01c789e6 for model llama3-8b received
2024-09-20 12:29:20,672 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,755 Request with ID 336c7e21 for model llama3-8b received
2024-09-20 12:29:20,756 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,941 Request with ID 17103673 for model gemma-7b received
2024-09-20 12:29:20,942 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,943 Request with ID 3c468b36 for model llama3-8b received
2024-09-20 12:29:20,944 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,958 Request with ID 04ee617e for model gemma-7b received
2024-09-20 12:29:20,959 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:20,971 Request with ID 23d6cbab for model llama3-8b received
2024-09-20 12:29:20,971 127.0.0.1 - - [20/Sep/2024 12:29:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:21,122 Request with ID 03264fca for model llama3-8b received
2024-09-20 12:29:21,123 127.0.0.1 - - [20/Sep/2024 12:29:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:21,468 Request with ID 2f5fca91 for model llama3-8b received
2024-09-20 12:29:21,469 127.0.0.1 - - [20/Sep/2024 12:29:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:21,483 Request with ID 17e9f925 for model llama3-8b received
2024-09-20 12:29:21,483 127.0.0.1 - - [20/Sep/2024 12:29:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:21,608 Request with ID 44456ed5 for model llama3-8b received
2024-09-20 12:29:21,608 127.0.0.1 - - [20/Sep/2024 12:29:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:21,706 Request with ID 52861d2d for model llama3-8b received
2024-09-20 12:29:21,707 127.0.0.1 - - [20/Sep/2024 12:29:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:21,757 Request with ID 5ed8083d for model llama3-8b received
2024-09-20 12:29:21,758 127.0.0.1 - - [20/Sep/2024 12:29:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:21,838 Request with ID 15c16a12 for model gemma-7b received
2024-09-20 12:29:21,839 127.0.0.1 - - [20/Sep/2024 12:29:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:21,937 Request with ID f910628e for model llama3-8b received
2024-09-20 12:29:21,938 127.0.0.1 - - [20/Sep/2024 12:29:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:21,953 Request with ID 59c626ea for model llama3-8b received
2024-09-20 12:29:21,954 127.0.0.1 - - [20/Sep/2024 12:29:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:21,961 Request with ID c94c46e7 for model llama3-8b received
2024-09-20 12:29:21,961 127.0.0.1 - - [20/Sep/2024 12:29:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,032 Request with ID 7e40d0cb for model gemma-7b received
2024-09-20 12:29:22,032 Moving batch for gemma-7b from incoming to running due to dynamic batch size 64
2024-09-20 12:29:22,033 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:29:22,120 Request with ID c0f48b1e for model llama3-8b received
2024-09-20 12:29:22,120 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,182 Request with ID 8513654b for model llama3-8b received
2024-09-20 12:29:22,183 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,304 Request with ID 0055e9eb for model gemma-7b received
2024-09-20 12:29:22,305 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,348 Request with ID 387c6810 for model llama3-8b received
2024-09-20 12:29:22,349 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,461 Request with ID 323d2456 for model llama3-8b received
2024-09-20 12:29:22,461 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,486 Request with ID 77be1447 for model gemma-7b received
2024-09-20 12:29:22,486 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,530 Request with ID 63c4f229 for model llama3-8b received
2024-09-20 12:29:22,531 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,608 Request with ID 3cf56d02 for model gemma-7b received
2024-09-20 12:29:22,609 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,655 Request with ID c1c8f85a for model gemma-7b received
2024-09-20 12:29:22,655 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,696 Request with ID a3a9b8c2 for model llama3-8b received
2024-09-20 12:29:22,696 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,705 Request with ID 6466a80a for model llama3-8b received
2024-09-20 12:29:22,705 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,712 Request with ID 9f849953 for model llama3-8b received
2024-09-20 12:29:22,712 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,721 Request with ID 9517404b for model gemma-7b received
2024-09-20 12:29:22,722 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,747 Request with ID 16fcc8c0 for model llama3-8b received
2024-09-20 12:29:22,748 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,775 Request with ID 90b427b8 for model gemma-7b received
2024-09-20 12:29:22,775 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,840 Request with ID 819d7045 for model granite-7b received
2024-09-20 12:29:22,840 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:22,857 Request with ID d9e14f33 for model llama3-8b received
2024-09-20 12:29:22,857 127.0.0.1 - - [20/Sep/2024 12:29:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:23,085 Request with ID d2a233c2 for model granite-7b received
2024-09-20 12:29:23,085 127.0.0.1 - - [20/Sep/2024 12:29:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:23,290 Request with ID f889a5a3 for model gemma-7b received
2024-09-20 12:29:23,290 127.0.0.1 - - [20/Sep/2024 12:29:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:23,321 Request with ID 4d357cda for model gemma-7b received
2024-09-20 12:29:23,322 127.0.0.1 - - [20/Sep/2024 12:29:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:23,407 Request with ID 88cee805 for model gemma-7b received
2024-09-20 12:29:23,407 127.0.0.1 - - [20/Sep/2024 12:29:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:23,448 Request with ID c861b60b for model llama3-8b received
2024-09-20 12:29:23,449 127.0.0.1 - - [20/Sep/2024 12:29:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:23,541 Request with ID 33260f0f for model gemma-7b received
2024-09-20 12:29:23,542 127.0.0.1 - - [20/Sep/2024 12:29:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:23,648 Request with ID 70ca1439 for model granite-7b received
2024-09-20 12:29:23,648 127.0.0.1 - - [20/Sep/2024 12:29:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:23,726 Request with ID c43fcb7b for model llama3-8b received
2024-09-20 12:29:23,726 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:29:23,726 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:29:23,817 Request with ID fab50438 for model llama3-8b received
2024-09-20 12:29:23,818 127.0.0.1 - - [20/Sep/2024 12:29:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:23,963 Request with ID ceaa43e6 for model llama3-8b received
2024-09-20 12:29:23,964 127.0.0.1 - - [20/Sep/2024 12:29:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:23,965 Request with ID 64583d96 for model granite-7b received
2024-09-20 12:29:23,966 127.0.0.1 - - [20/Sep/2024 12:29:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:23,979 Request with ID f9690c03 for model gemma-7b received
2024-09-20 12:29:23,980 127.0.0.1 - - [20/Sep/2024 12:29:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:23,999 Request with ID d7931b5a for model granite-7b received
2024-09-20 12:29:23,999 127.0.0.1 - - [20/Sep/2024 12:29:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:24,187 Request with ID 17b2c289 for model granite-7b received
2024-09-20 12:29:24,187 127.0.0.1 - - [20/Sep/2024 12:29:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:24,308 Request with ID ef3fac16 for model gemma-7b received
2024-09-20 12:29:24,308 127.0.0.1 - - [20/Sep/2024 12:29:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:24,361 Request with ID ceda37ca for model llama3-8b received
2024-09-20 12:29:24,362 Request with ID e2f7b846 for model gemma-7b received
2024-09-20 12:29:24,362 127.0.0.1 - - [20/Sep/2024 12:29:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:24,363 127.0.0.1 - - [20/Sep/2024 12:29:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:24,381 Request with ID 59b3e9ea for model llama3-8b received
2024-09-20 12:29:24,381 127.0.0.1 - - [20/Sep/2024 12:29:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:24,510 Request with ID ac99e008 for model llama3-8b received
2024-09-20 12:29:24,511 127.0.0.1 - - [20/Sep/2024 12:29:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:24,695 Request with ID 7b8ea84b for model gemma-7b received
2024-09-20 12:29:24,695 127.0.0.1 - - [20/Sep/2024 12:29:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:24,736 Request with ID 3ce83a4d for model gemma-7b received
2024-09-20 12:29:24,736 127.0.0.1 - - [20/Sep/2024 12:29:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:24,871 Request with ID 3251e5f7 for model llama3-8b received
2024-09-20 12:29:24,871 127.0.0.1 - - [20/Sep/2024 12:29:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:25,020 Request with ID 90b4d0e6 for model llama3-8b received
2024-09-20 12:29:25,021 127.0.0.1 - - [20/Sep/2024 12:29:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:25,037 Request with ID 19dbde37 for model llama3-8b received
2024-09-20 12:29:25,038 127.0.0.1 - - [20/Sep/2024 12:29:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:25,086 Request with ID 5b070512 for model gemma-7b received
2024-09-20 12:29:25,086 127.0.0.1 - - [20/Sep/2024 12:29:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:25,092 Request with ID fc1329a0 for model llama3-8b received
2024-09-20 12:29:25,093 127.0.0.1 - - [20/Sep/2024 12:29:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:25,102 Request with ID 693236fb for model llama3-8b received
2024-09-20 12:29:25,103 127.0.0.1 - - [20/Sep/2024 12:29:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:25,248 Request with ID ab2b89b5 for model llama3-8b received
2024-09-20 12:29:25,249 127.0.0.1 - - [20/Sep/2024 12:29:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:25,343 Request with ID daf2b7d5 for model llama3-8b received
2024-09-20 12:29:25,344 127.0.0.1 - - [20/Sep/2024 12:29:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:25,523 Request with ID adcef5c6 for model llama3-8b received
2024-09-20 12:29:25,524 127.0.0.1 - - [20/Sep/2024 12:29:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:25,796 Request with ID d21239cb for model gemma-7b received
2024-09-20 12:29:25,797 127.0.0.1 - - [20/Sep/2024 12:29:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:25,845 Request with ID d402730b for model llama3-8b received
2024-09-20 12:29:25,845 127.0.0.1 - - [20/Sep/2024 12:29:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:25,850 Request with ID ef94c3cb for model gemma-7b received
2024-09-20 12:29:25,850 127.0.0.1 - - [20/Sep/2024 12:29:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:26,012 Request with ID 790395af for model gemma-7b received
2024-09-20 12:29:26,012 127.0.0.1 - - [20/Sep/2024 12:29:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:26,031 Request with ID 3bbe463b for model gemma-7b received
2024-09-20 12:29:26,031 127.0.0.1 - - [20/Sep/2024 12:29:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:26,134 Request with ID a5ccbcc6 for model gemma-7b received
2024-09-20 12:29:26,134 127.0.0.1 - - [20/Sep/2024 12:29:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:26,224 Request with ID 533c0068 for model llama3-8b received
2024-09-20 12:29:26,224 127.0.0.1 - - [20/Sep/2024 12:29:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:26,272 Request with ID eab11a89 for model llama3-8b received
2024-09-20 12:29:26,273 127.0.0.1 - - [20/Sep/2024 12:29:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:26,345 Request with ID 3935518c for model gemma-7b received
2024-09-20 12:29:26,346 127.0.0.1 - - [20/Sep/2024 12:29:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:26,424 Request with ID 4f80f1b3 for model llama3-8b received
2024-09-20 12:29:26,425 127.0.0.1 - - [20/Sep/2024 12:29:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:26,524 Request with ID cba37426 for model llama3-8b received
2024-09-20 12:29:26,525 127.0.0.1 - - [20/Sep/2024 12:29:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:26,565 Request with ID cf5ad4e0 for model gemma-7b received
2024-09-20 12:29:26,566 127.0.0.1 - - [20/Sep/2024 12:29:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:26,582 Request with ID 8ab88def for model llama3-8b received
2024-09-20 12:29:26,583 127.0.0.1 - - [20/Sep/2024 12:29:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:26,662 Request with ID 8c8a8467 for model llama3-8b received
2024-09-20 12:29:26,663 127.0.0.1 - - [20/Sep/2024 12:29:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:27,269 Request with ID 95358682 for model llama3-8b received
2024-09-20 12:29:27,270 127.0.0.1 - - [20/Sep/2024 12:29:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:27,421 Request with ID f7689a74 for model gemma-7b received
2024-09-20 12:29:27,422 127.0.0.1 - - [20/Sep/2024 12:29:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:27,549 Request with ID 5774af2e for model llama3-8b received
2024-09-20 12:29:27,549 127.0.0.1 - - [20/Sep/2024 12:29:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:27,592 Request with ID f8396b57 for model gemma-7b received
2024-09-20 12:29:27,592 127.0.0.1 - - [20/Sep/2024 12:29:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:27,781 Request with ID 2783d3db for model llama3-8b received
2024-09-20 12:29:27,781 127.0.0.1 - - [20/Sep/2024 12:29:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:27,798 Request with ID 9ce059c8 for model llama3-8b received
2024-09-20 12:29:27,798 127.0.0.1 - - [20/Sep/2024 12:29:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:27,949 Request with ID d3a96ef5 for model llama3-8b received
2024-09-20 12:29:27,949 127.0.0.1 - - [20/Sep/2024 12:29:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:28,034 Request with ID 7059025d for model gemma-7b received
2024-09-20 12:29:28,034 127.0.0.1 - - [20/Sep/2024 12:29:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:28,077 Request with ID 0bcc224f for model llama3-8b received
2024-09-20 12:29:28,078 127.0.0.1 - - [20/Sep/2024 12:29:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:28,121 Request with ID 019671aa for model llama3-8b received
2024-09-20 12:29:28,121 127.0.0.1 - - [20/Sep/2024 12:29:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:28,156 Request with ID c3a92cbb for model gemma-7b received
2024-09-20 12:29:28,156 127.0.0.1 - - [20/Sep/2024 12:29:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:28,247 Request with ID b1d2f5e6 for model gemma-7b received
2024-09-20 12:29:28,248 127.0.0.1 - - [20/Sep/2024 12:29:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:28,379 Request with ID 0cceed4c for model llama3-8b received
2024-09-20 12:29:28,379 127.0.0.1 - - [20/Sep/2024 12:29:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:28,536 Request with ID ea731283 for model llama3-8b received
2024-09-20 12:29:28,536 127.0.0.1 - - [20/Sep/2024 12:29:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:28,686 Request with ID 546528ec for model llama3-8b received
2024-09-20 12:29:28,686 127.0.0.1 - - [20/Sep/2024 12:29:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:28,822 Request with ID 1b21d444 for model gemma-7b received
2024-09-20 12:29:28,822 127.0.0.1 - - [20/Sep/2024 12:29:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:28,850 Request with ID 34e7058a for model gemma-7b received
2024-09-20 12:29:28,851 127.0.0.1 - - [20/Sep/2024 12:29:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:29,034 Request with ID a9e1b346 for model gemma-7b received
2024-09-20 12:29:29,034 127.0.0.1 - - [20/Sep/2024 12:29:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:29,060 Request with ID a95bf7f0 for model gemma-7b received
2024-09-20 12:29:29,060 127.0.0.1 - - [20/Sep/2024 12:29:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:29,067 Request with ID c1ee7fc3 for model llama3-8b received
2024-09-20 12:29:29,067 Request with ID c0d7190d for model gemma-7b received
2024-09-20 12:29:29,068 127.0.0.1 - - [20/Sep/2024 12:29:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:29,068 127.0.0.1 - - [20/Sep/2024 12:29:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:29,122 Request with ID 283e86ea for model llama3-8b received
2024-09-20 12:29:29,123 127.0.0.1 - - [20/Sep/2024 12:29:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:29,166 Request with ID d4bb6b95 for model llama3-8b received
2024-09-20 12:29:29,167 127.0.0.1 - - [20/Sep/2024 12:29:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:29,228 Request with ID a70e065a for model granite-7b received
2024-09-20 12:29:29,228 127.0.0.1 - - [20/Sep/2024 12:29:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:29,474 Request with ID 0624e82c for model gemma-7b received
2024-09-20 12:29:29,474 127.0.0.1 - - [20/Sep/2024 12:29:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:29,545 Request with ID 9d0a6daa for model granite-7b received
2024-09-20 12:29:29,545 127.0.0.1 - - [20/Sep/2024 12:29:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:29,583 Request with ID 8413c474 for model llama3-8b received
2024-09-20 12:29:29,583 127.0.0.1 - - [20/Sep/2024 12:29:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:29,686 Request with ID 6f3ea936 for model llama3-8b received
2024-09-20 12:29:29,687 127.0.0.1 - - [20/Sep/2024 12:29:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:30,058 Request with ID 2e585057 for model llama3-8b received
2024-09-20 12:29:30,059 127.0.0.1 - - [20/Sep/2024 12:29:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:30,256 Request with ID 00024640 for model llama3-8b received
2024-09-20 12:29:30,257 127.0.0.1 - - [20/Sep/2024 12:29:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:30,327 Request with ID abc7e12a for model gemma-7b received
2024-09-20 12:29:30,328 127.0.0.1 - - [20/Sep/2024 12:29:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:30,379 Request with ID 1533290c for model llama3-8b received
2024-09-20 12:29:30,379 127.0.0.1 - - [20/Sep/2024 12:29:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:30,403 Request with ID 0e30c0b8 for model gemma-7b received
2024-09-20 12:29:30,403 127.0.0.1 - - [20/Sep/2024 12:29:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:30,586 Request with ID 0819540b for model gemma-7b received
2024-09-20 12:29:30,586 127.0.0.1 - - [20/Sep/2024 12:29:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:30,712 Request with ID 7256e78c for model llama3-8b received
2024-09-20 12:29:30,713 127.0.0.1 - - [20/Sep/2024 12:29:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:30,779 Request with ID 74a4a440 for model llama3-8b received
2024-09-20 12:29:30,780 127.0.0.1 - - [20/Sep/2024 12:29:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:30,791 Request with ID edf140cd for model llama3-8b received
2024-09-20 12:29:30,792 127.0.0.1 - - [20/Sep/2024 12:29:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:30,839 Request with ID 64cbd69f for model llama3-8b received
2024-09-20 12:29:30,840 127.0.0.1 - - [20/Sep/2024 12:29:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:30,917 Request with ID 982282b3 for model llama3-8b received
2024-09-20 12:29:30,918 127.0.0.1 - - [20/Sep/2024 12:29:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:31,103 Request with ID 8fea652e for model llama3-8b received
2024-09-20 12:29:31,103 127.0.0.1 - - [20/Sep/2024 12:29:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:31,134 Request with ID 8a7912d9 for model llama3-8b received
2024-09-20 12:29:31,135 127.0.0.1 - - [20/Sep/2024 12:29:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:31,137 Request with ID 36af71c5 for model granite-7b received
2024-09-20 12:29:31,137 127.0.0.1 - - [20/Sep/2024 12:29:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:31,167 Request with ID ade09e19 for model llama3-8b received
2024-09-20 12:29:31,167 127.0.0.1 - - [20/Sep/2024 12:29:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:31,347 Request with ID 5bf3f839 for model llama3-8b received
2024-09-20 12:29:31,347 127.0.0.1 - - [20/Sep/2024 12:29:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:31,362 Request with ID cb859337 for model gemma-7b received
2024-09-20 12:29:31,363 127.0.0.1 - - [20/Sep/2024 12:29:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:31,592 Request with ID 1d8fbe39 for model llama3-8b received
2024-09-20 12:29:31,593 127.0.0.1 - - [20/Sep/2024 12:29:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:31,727 Request with ID ff66236b for model gemma-7b received
2024-09-20 12:29:31,727 127.0.0.1 - - [20/Sep/2024 12:29:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:31,940 Request with ID 5ae2e0a1 for model llama3-8b received
2024-09-20 12:29:31,941 127.0.0.1 - - [20/Sep/2024 12:29:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:32,166 Request with ID 621ef528 for model gemma-7b received
2024-09-20 12:29:32,166 127.0.0.1 - - [20/Sep/2024 12:29:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:32,340 Request with ID 1b2c4ee0 for model llama3-8b received
2024-09-20 12:29:32,341 127.0.0.1 - - [20/Sep/2024 12:29:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:32,373 Request with ID 6089e1af for model llama3-8b received
2024-09-20 12:29:32,374 127.0.0.1 - - [20/Sep/2024 12:29:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:32,456 Request with ID 60b33cbb for model gemma-7b received
2024-09-20 12:29:32,457 127.0.0.1 - - [20/Sep/2024 12:29:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:32,755 Request with ID f80bef62 for model gemma-7b received
2024-09-20 12:29:32,755 127.0.0.1 - - [20/Sep/2024 12:29:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:32,960 Request with ID 07ed7dc8 for model llama3-8b received
2024-09-20 12:29:32,961 127.0.0.1 - - [20/Sep/2024 12:29:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:33,244 Request with ID ad9c75fb for model llama3-8b received
2024-09-20 12:29:33,245 127.0.0.1 - - [20/Sep/2024 12:29:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:33,246 Request with ID 15455a7a for model llama3-8b received
2024-09-20 12:29:33,247 127.0.0.1 - - [20/Sep/2024 12:29:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:33,278 Request with ID 8c612dc1 for model llama3-8b received
2024-09-20 12:29:33,279 127.0.0.1 - - [20/Sep/2024 12:29:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:33,398 Request with ID fe3fee4f for model granite-7b received
2024-09-20 12:29:33,399 127.0.0.1 - - [20/Sep/2024 12:29:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:33,646 Request with ID 7a07c992 for model llama3-8b received
2024-09-20 12:29:33,646 127.0.0.1 - - [20/Sep/2024 12:29:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:33,679 Request with ID 675f60b7 for model llama3-8b received
2024-09-20 12:29:33,679 127.0.0.1 - - [20/Sep/2024 12:29:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:33,860 Request with ID 0d84575c for model gemma-7b received
2024-09-20 12:29:33,860 127.0.0.1 - - [20/Sep/2024 12:29:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:33,875 Request with ID 0faa21bf for model llama3-8b received
2024-09-20 12:29:33,876 127.0.0.1 - - [20/Sep/2024 12:29:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:34,088 Request with ID dbd3e1a3 for model gemma-7b received
2024-09-20 12:29:34,088 127.0.0.1 - - [20/Sep/2024 12:29:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:34,188 Request with ID 76d7b6e0 for model llama3-8b received
2024-09-20 12:29:34,189 127.0.0.1 - - [20/Sep/2024 12:29:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:34,372 Request with ID bdff36cc for model llama3-8b received
2024-09-20 12:29:34,372 127.0.0.1 - - [20/Sep/2024 12:29:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:34,377 Request with ID 30fa408a for model llama3-8b received
2024-09-20 12:29:34,377 127.0.0.1 - - [20/Sep/2024 12:29:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:34,386 Request with ID e722bb9e for model gemma-7b received
2024-09-20 12:29:34,386 127.0.0.1 - - [20/Sep/2024 12:29:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:34,438 Request with ID db2238f0 for model llama3-8b received
2024-09-20 12:29:34,439 127.0.0.1 - - [20/Sep/2024 12:29:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:34,687 Request with ID 78c2d623 for model gemma-7b received
2024-09-20 12:29:34,688 127.0.0.1 - - [20/Sep/2024 12:29:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:34,771 Request with ID 954534b3 for model gemma-7b received
2024-09-20 12:29:34,772 127.0.0.1 - - [20/Sep/2024 12:29:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:34,948 Loaded model llama3-8b
2024-09-20 12:29:34,951 Batch processing started for model llama3-8b
2024-09-20 12:29:35,082 Request with ID 1d5345da for model llama3-8b received
2024-09-20 12:29:35,082 127.0.0.1 - - [20/Sep/2024 12:29:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:35,111 Request with ID 4169a795 for model gemma-7b received
2024-09-20 12:29:35,112 127.0.0.1 - - [20/Sep/2024 12:29:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:35,205 Request with ID f0b0d4d8 for model gemma-7b received
2024-09-20 12:29:35,206 127.0.0.1 - - [20/Sep/2024 12:29:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:35,301 Request with ID 677117df for model gemma-7b received
2024-09-20 12:29:35,301 127.0.0.1 - - [20/Sep/2024 12:29:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:35,345 Request with ID c3407234 for model llama3-8b received
2024-09-20 12:29:35,345 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:29:35,346 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:29:35,462 Request with ID e0f4e93f for model llama3-8b received
2024-09-20 12:29:35,463 127.0.0.1 - - [20/Sep/2024 12:29:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:35,469 Request with ID bf01b650 for model granite-7b received
2024-09-20 12:29:35,470 127.0.0.1 - - [20/Sep/2024 12:29:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:35,816 Request with ID f7e54c5f for model llama3-8b received
2024-09-20 12:29:35,816 127.0.0.1 - - [20/Sep/2024 12:29:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:35,861 Request with ID 3b40c383 for model llama3-8b received
2024-09-20 12:29:35,862 127.0.0.1 - - [20/Sep/2024 12:29:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:35,922 Request with ID ee46a396 for model llama3-8b received
2024-09-20 12:29:35,922 127.0.0.1 - - [20/Sep/2024 12:29:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:36,130 Request with ID 6a1dd4b1 for model llama3-8b received
2024-09-20 12:29:36,130 127.0.0.1 - - [20/Sep/2024 12:29:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:36,274 Request with ID 3909786c for model llama3-8b received
2024-09-20 12:29:36,275 127.0.0.1 - - [20/Sep/2024 12:29:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:36,466 Request with ID eab960ba for model llama3-8b received
2024-09-20 12:29:36,466 127.0.0.1 - - [20/Sep/2024 12:29:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:36,587 Request with ID 0caaed23 for model llama3-8b received
2024-09-20 12:29:36,588 127.0.0.1 - - [20/Sep/2024 12:29:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:36,591 Request with ID b74e4cb9 for model llama3-8b received
2024-09-20 12:29:36,592 127.0.0.1 - - [20/Sep/2024 12:29:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:37,328 Request with ID 3dbf7ff8 for model llama3-8b received
2024-09-20 12:29:37,328 127.0.0.1 - - [20/Sep/2024 12:29:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:37,576 Request with ID c46dc724 for model llama3-8b received
2024-09-20 12:29:37,577 127.0.0.1 - - [20/Sep/2024 12:29:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:37,612 Request with ID 42b06005 for model llama3-8b received
2024-09-20 12:29:37,613 127.0.0.1 - - [20/Sep/2024 12:29:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:37,774 Request with ID d066c64a for model granite-7b received
2024-09-20 12:29:37,774 127.0.0.1 - - [20/Sep/2024 12:29:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:37,835 Request with ID 82b5d0d4 for model llama3-8b received
2024-09-20 12:29:37,836 127.0.0.1 - - [20/Sep/2024 12:29:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:37,840 Request with ID 7098208b for model gemma-7b received
2024-09-20 12:29:37,840 127.0.0.1 - - [20/Sep/2024 12:29:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:37,925 Request with ID b15ff23a for model llama3-8b received
2024-09-20 12:29:37,925 127.0.0.1 - - [20/Sep/2024 12:29:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:38,003 Request with ID e26c0730 for model llama3-8b received
2024-09-20 12:29:38,004 127.0.0.1 - - [20/Sep/2024 12:29:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:38,089 Request with ID 45c56fcb for model llama3-8b received
2024-09-20 12:29:38,090 127.0.0.1 - - [20/Sep/2024 12:29:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:38,224 Request with ID c7b8ca8f for model llama3-8b received
2024-09-20 12:29:38,225 127.0.0.1 - - [20/Sep/2024 12:29:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:38,437 Request with ID ab1f9a9d for model llama3-8b received
2024-09-20 12:29:38,437 127.0.0.1 - - [20/Sep/2024 12:29:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:38,903 Request with ID c9e9f7eb for model llama3-8b received
2024-09-20 12:29:38,903 127.0.0.1 - - [20/Sep/2024 12:29:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:38,980 Request with ID 637fb345 for model llama3-8b received
2024-09-20 12:29:38,981 127.0.0.1 - - [20/Sep/2024 12:29:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:39,601 Request with ID add06a81 for model llama3-8b received
2024-09-20 12:29:39,602 127.0.0.1 - - [20/Sep/2024 12:29:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:39,654 Request with ID c5a781b3 for model llama3-8b received
2024-09-20 12:29:39,654 127.0.0.1 - - [20/Sep/2024 12:29:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:39,743 Request with ID c1a16ed6 for model llama3-8b received
2024-09-20 12:29:39,743 127.0.0.1 - - [20/Sep/2024 12:29:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:39,892 Request with ID 34821361 for model gemma-7b received
2024-09-20 12:29:39,893 127.0.0.1 - - [20/Sep/2024 12:29:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:39,967 Request with ID 726a6034 for model llama3-8b received
2024-09-20 12:29:39,968 127.0.0.1 - - [20/Sep/2024 12:29:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:40,003 Request with ID 7146dbfc for model gemma-7b received
2024-09-20 12:29:40,004 127.0.0.1 - - [20/Sep/2024 12:29:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:40,031 Request with ID ba3d0c30 for model granite-7b received
2024-09-20 12:29:40,031 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:29:40,032 Dynamic batch size condition met for model granite-7b
2024-09-20 12:29:40,474 Request with ID 4907620a for model gemma-7b received
2024-09-20 12:29:40,474 127.0.0.1 - - [20/Sep/2024 12:29:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:40,589 Request with ID b5e22d6b for model llama3-8b received
2024-09-20 12:29:40,589 127.0.0.1 - - [20/Sep/2024 12:29:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:40,621 Request with ID 0510fadd for model llama3-8b received
2024-09-20 12:29:40,623 127.0.0.1 - - [20/Sep/2024 12:29:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:40,839 Request with ID b0f25d44 for model llama3-8b received
2024-09-20 12:29:40,839 127.0.0.1 - - [20/Sep/2024 12:29:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:41,294 Request with ID 9374eae8 for model gemma-7b received
2024-09-20 12:29:41,294 127.0.0.1 - - [20/Sep/2024 12:29:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:41,581 Request with ID ede3f2cf for model llama3-8b received
2024-09-20 12:29:41,582 127.0.0.1 - - [20/Sep/2024 12:29:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:41,654 Request with ID 86152909 for model gemma-7b received
2024-09-20 12:29:41,654 127.0.0.1 - - [20/Sep/2024 12:29:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:41,657 Request with ID 057e0f91 for model gemma-7b received
2024-09-20 12:29:41,658 127.0.0.1 - - [20/Sep/2024 12:29:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:41,665 Request with ID 2dac514e for model llama3-8b received
2024-09-20 12:29:41,665 127.0.0.1 - - [20/Sep/2024 12:29:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:41,931 Request with ID 55fb676a for model llama3-8b received
2024-09-20 12:29:41,932 127.0.0.1 - - [20/Sep/2024 12:29:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:41,962 Request with ID ece18b11 for model llama3-8b received
2024-09-20 12:29:41,963 127.0.0.1 - - [20/Sep/2024 12:29:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:41,980 Request with ID 8d7c4573 for model llama3-8b received
2024-09-20 12:29:41,981 127.0.0.1 - - [20/Sep/2024 12:29:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:42,080 Request with ID 4906a5a9 for model llama3-8b received
2024-09-20 12:29:42,081 127.0.0.1 - - [20/Sep/2024 12:29:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:42,172 Request with ID 9669aade for model llama3-8b received
2024-09-20 12:29:42,172 127.0.0.1 - - [20/Sep/2024 12:29:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:42,235 Request with ID 04da3193 for model gemma-7b received
2024-09-20 12:29:42,235 127.0.0.1 - - [20/Sep/2024 12:29:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:42,249 Request with ID 99d75d86 for model llama3-8b received
2024-09-20 12:29:42,250 127.0.0.1 - - [20/Sep/2024 12:29:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:42,450 Request with ID b9294182 for model gemma-7b received
2024-09-20 12:29:42,450 127.0.0.1 - - [20/Sep/2024 12:29:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:42,720 Request with ID 6ddc4cf7 for model granite-7b received
2024-09-20 12:29:42,721 127.0.0.1 - - [20/Sep/2024 12:29:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:42,774 Request with ID e01bf875 for model granite-7b received
2024-09-20 12:29:42,774 127.0.0.1 - - [20/Sep/2024 12:29:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:42,895 Request with ID 077ff70f for model llama3-8b received
2024-09-20 12:29:42,896 127.0.0.1 - - [20/Sep/2024 12:29:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:42,904 Request with ID 7a26edf2 for model llama3-8b received
2024-09-20 12:29:42,905 127.0.0.1 - - [20/Sep/2024 12:29:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:42,913 Request with ID 568a98be for model granite-7b received
2024-09-20 12:29:42,913 127.0.0.1 - - [20/Sep/2024 12:29:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:43,130 Request with ID ce4964a0 for model llama3-8b received
2024-09-20 12:29:43,130 127.0.0.1 - - [20/Sep/2024 12:29:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:43,305 Request with ID 4562f8d5 for model llama3-8b received
2024-09-20 12:29:43,306 127.0.0.1 - - [20/Sep/2024 12:29:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:43,385 Request with ID 8156a541 for model gemma-7b received
2024-09-20 12:29:43,386 127.0.0.1 - - [20/Sep/2024 12:29:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:43,599 Request with ID 2bc575c4 for model llama3-8b received
2024-09-20 12:29:43,600 127.0.0.1 - - [20/Sep/2024 12:29:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:43,802 Request with ID 62bdeb28 for model gemma-7b received
2024-09-20 12:29:43,803 127.0.0.1 - - [20/Sep/2024 12:29:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:43,830 Request with ID 5ef7bae4 for model llama3-8b received
2024-09-20 12:29:43,831 127.0.0.1 - - [20/Sep/2024 12:29:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:43,929 Request with ID 1301e3d0 for model gemma-7b received
2024-09-20 12:29:43,930 127.0.0.1 - - [20/Sep/2024 12:29:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:44,144 Request with ID 76c44514 for model llama3-8b received
2024-09-20 12:29:44,144 127.0.0.1 - - [20/Sep/2024 12:29:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:44,358 Request with ID 6719156f for model gemma-7b received
2024-09-20 12:29:44,359 127.0.0.1 - - [20/Sep/2024 12:29:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:44,400 Request with ID bceb8d3d for model gemma-7b received
2024-09-20 12:29:44,400 Moving batch for gemma-7b from incoming to running due to dynamic batch size 64
2024-09-20 12:29:44,400 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:29:44,575 Processed batch: ['7a657e43', 'f3b3897c', '646a48f7', 'd8fcfcec', '0f86a56d', 'ebc40d6a', '52a3c729', '6071fce6', '7289adde', '4e6a037c', '67844a21', '8226fa80', '4fed1811', '0fa02a73', 'a1c1bddf', '3990a26f', '01a3818e', '2761620e', '28921a78', '84e89b42', '601d1947', 'b2304eff', '32c278bb', '236b04c9', '80daae78', '31aaeae7', 'bce3da51', '6ce7bab4', 'f27afcb5', '27f08389', '74098a1c', 'ac131a1a', '7849cd63', 'dbe5c838', 'ce76a7d8', '03e51591', '5b443b98', 'd7f00130', '999ee0a5', '91f6496d', '7ceaa207', '0abf60c7', '2c2bbfc3', '39188aa0', '48540273', '090730b9', 'cd0dc97b', 'ac0f8204', 'fccfd1f4', '933ab923', '4e4ab992', '5d7f33c8', 'e7d59b25', '1beb68e6', '2eda34ff', '41906623', '8896b86f', '6e9900e2', 'c80f2fc9', '8449f80d', 'eaec1439', '508551e4', '1960e71a', 'd6692afc'] with model llama3-8b in 9.6234 seconds
2024-09-20 12:29:44,575 Saving sys info
2024-09-20 12:29:44,576 Request with ID ed0ecf4e for model llama3-8b received
2024-09-20 12:29:44,577 127.0.0.1 - - [20/Sep/2024 12:29:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:44,579 Request with ID e7af57cf for model granite-7b received
2024-09-20 12:29:44,579 127.0.0.1 - - [20/Sep/2024 12:29:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:44,615 Request with ID 3e7663b4 for model llama3-8b received
2024-09-20 12:29:44,615 127.0.0.1 - - [20/Sep/2024 12:29:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:44,645 Latency for request 7a657e43 with model llama3-8b: 42.4820 seconds
2024-09-20 12:29:44,645 Saving results with gpu monitoring
2024-09-20 12:29:44,649 Request with ID beb38004 for model granite-7b received
2024-09-20 12:29:44,649 127.0.0.1 - - [20/Sep/2024 12:29:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:44,652 Latency for request f3b3897c with model llama3-8b: 42.4720 seconds
2024-09-20 12:29:44,652 Saving results with gpu monitoring
2024-09-20 12:29:44,654 Latency for request 646a48f7 with model llama3-8b: 42.0230 seconds
2024-09-20 12:29:44,654 Saving results with gpu monitoring
2024-09-20 12:29:44,656 Latency for request d8fcfcec with model llama3-8b: 41.9830 seconds
2024-09-20 12:29:44,656 Saving results with gpu monitoring
2024-09-20 12:29:44,658 Latency for request 0f86a56d with model llama3-8b: 41.4490 seconds
2024-09-20 12:29:44,658 Saving results with gpu monitoring
2024-09-20 12:29:44,660 Latency for request ebc40d6a with model llama3-8b: 41.4470 seconds
2024-09-20 12:29:44,660 Saving results with gpu monitoring
2024-09-20 12:29:44,663 Latency for request 52a3c729 with model llama3-8b: 40.7780 seconds
2024-09-20 12:29:44,663 Saving results with gpu monitoring
2024-09-20 12:29:44,665 Latency for request 6071fce6 with model llama3-8b: 40.6970 seconds
2024-09-20 12:29:44,665 Saving results with gpu monitoring
2024-09-20 12:29:44,667 Latency for request 7289adde with model llama3-8b: 40.1550 seconds
2024-09-20 12:29:44,667 Saving results with gpu monitoring
2024-09-20 12:29:44,669 Latency for request 4e6a037c with model llama3-8b: 40.0640 seconds
2024-09-20 12:29:44,669 Saving results with gpu monitoring
2024-09-20 12:29:44,671 Latency for request 67844a21 with model llama3-8b: 40.0310 seconds
2024-09-20 12:29:44,671 Saving results with gpu monitoring
2024-09-20 12:29:44,673 Latency for request 8226fa80 with model llama3-8b: 39.8600 seconds
2024-09-20 12:29:44,673 Saving results with gpu monitoring
2024-09-20 12:29:44,675 Latency for request 4fed1811 with model llama3-8b: 39.8520 seconds
2024-09-20 12:29:44,675 Saving results with gpu monitoring
2024-09-20 12:29:44,677 Latency for request 0fa02a73 with model llama3-8b: 39.6530 seconds
2024-09-20 12:29:44,677 Saving results with gpu monitoring
2024-09-20 12:29:44,679 Latency for request a1c1bddf with model llama3-8b: 39.5590 seconds
2024-09-20 12:29:44,679 Saving results with gpu monitoring
2024-09-20 12:29:44,681 Latency for request 3990a26f with model llama3-8b: 39.5450 seconds
2024-09-20 12:29:44,681 Saving results with gpu monitoring
2024-09-20 12:29:44,683 Latency for request 01a3818e with model llama3-8b: 39.4150 seconds
2024-09-20 12:29:44,683 Saving results with gpu monitoring
2024-09-20 12:29:44,685 Latency for request 2761620e with model llama3-8b: 39.3450 seconds
2024-09-20 12:29:44,685 Saving results with gpu monitoring
2024-09-20 12:29:44,687 Latency for request 28921a78 with model llama3-8b: 39.1020 seconds
2024-09-20 12:29:44,687 Saving results with gpu monitoring
2024-09-20 12:29:44,689 Latency for request 84e89b42 with model llama3-8b: 38.9820 seconds
2024-09-20 12:29:44,689 Saving results with gpu monitoring
2024-09-20 12:29:44,691 Latency for request 601d1947 with model llama3-8b: 38.9560 seconds
2024-09-20 12:29:44,691 Saving results with gpu monitoring
2024-09-20 12:29:44,693 Latency for request b2304eff with model llama3-8b: 38.8350 seconds
2024-09-20 12:29:44,693 Saving results with gpu monitoring
2024-09-20 12:29:44,695 Latency for request 32c278bb with model llama3-8b: 38.6680 seconds
2024-09-20 12:29:44,695 Saving results with gpu monitoring
2024-09-20 12:29:44,697 Latency for request 236b04c9 with model llama3-8b: 38.6470 seconds
2024-09-20 12:29:44,697 Saving results with gpu monitoring
2024-09-20 12:29:44,699 Latency for request 80daae78 with model llama3-8b: 38.4670 seconds
2024-09-20 12:29:44,699 Saving results with gpu monitoring
2024-09-20 12:29:44,701 Latency for request 31aaeae7 with model llama3-8b: 38.4650 seconds
2024-09-20 12:29:44,701 Saving results with gpu monitoring
2024-09-20 12:29:44,703 Latency for request bce3da51 with model llama3-8b: 38.4640 seconds
2024-09-20 12:29:44,703 Saving results with gpu monitoring
2024-09-20 12:29:44,705 Latency for request 6ce7bab4 with model llama3-8b: 38.1090 seconds
2024-09-20 12:29:44,705 Saving results with gpu monitoring
2024-09-20 12:29:44,707 Latency for request f27afcb5 with model llama3-8b: 38.0560 seconds
2024-09-20 12:29:44,707 Saving results with gpu monitoring
2024-09-20 12:29:44,709 Latency for request 27f08389 with model llama3-8b: 37.7220 seconds
2024-09-20 12:29:44,709 Saving results with gpu monitoring
2024-09-20 12:29:44,711 Latency for request 74098a1c with model llama3-8b: 37.3560 seconds
2024-09-20 12:29:44,711 Saving results with gpu monitoring
2024-09-20 12:29:44,713 Latency for request ac131a1a with model llama3-8b: 36.8880 seconds
2024-09-20 12:29:44,713 Saving results with gpu monitoring
2024-09-20 12:29:44,715 Latency for request 7849cd63 with model llama3-8b: 36.7730 seconds
2024-09-20 12:29:44,715 Saving results with gpu monitoring
2024-09-20 12:29:44,717 Latency for request dbe5c838 with model llama3-8b: 36.6280 seconds
2024-09-20 12:29:44,717 Saving results with gpu monitoring
2024-09-20 12:29:44,719 Latency for request ce76a7d8 with model llama3-8b: 36.4310 seconds
2024-09-20 12:29:44,719 Saving results with gpu monitoring
2024-09-20 12:29:44,721 Latency for request 03e51591 with model llama3-8b: 35.9850 seconds
2024-09-20 12:29:44,721 Saving results with gpu monitoring
2024-09-20 12:29:44,723 Latency for request 5b443b98 with model llama3-8b: 35.7590 seconds
2024-09-20 12:29:44,723 Saving results with gpu monitoring
2024-09-20 12:29:44,725 Latency for request d7f00130 with model llama3-8b: 35.7060 seconds
2024-09-20 12:29:44,725 Saving results with gpu monitoring
2024-09-20 12:29:44,727 Latency for request 999ee0a5 with model llama3-8b: 35.6970 seconds
2024-09-20 12:29:44,727 Saving results with gpu monitoring
2024-09-20 12:29:44,729 Latency for request 91f6496d with model llama3-8b: 35.6010 seconds
2024-09-20 12:29:44,729 Saving results with gpu monitoring
2024-09-20 12:29:44,731 Latency for request 7ceaa207 with model llama3-8b: 35.2660 seconds
2024-09-20 12:29:44,731 Saving results with gpu monitoring
2024-09-20 12:29:44,733 Latency for request 0abf60c7 with model llama3-8b: 35.1370 seconds
2024-09-20 12:29:44,733 Saving results with gpu monitoring
2024-09-20 12:29:44,735 Latency for request 2c2bbfc3 with model llama3-8b: 35.0980 seconds
2024-09-20 12:29:44,735 Saving results with gpu monitoring
2024-09-20 12:29:44,737 Latency for request 39188aa0 with model llama3-8b: 35.0280 seconds
2024-09-20 12:29:44,737 Saving results with gpu monitoring
2024-09-20 12:29:44,739 Latency for request 48540273 with model llama3-8b: 34.8680 seconds
2024-09-20 12:29:44,739 Saving results with gpu monitoring
2024-09-20 12:29:44,741 Latency for request 090730b9 with model llama3-8b: 34.6260 seconds
2024-09-20 12:29:44,741 Saving results with gpu monitoring
2024-09-20 12:29:44,743 Latency for request cd0dc97b with model llama3-8b: 34.4760 seconds
2024-09-20 12:29:44,743 Saving results with gpu monitoring
2024-09-20 12:29:44,745 Latency for request ac0f8204 with model llama3-8b: 34.4120 seconds
2024-09-20 12:29:44,745 Saving results with gpu monitoring
2024-09-20 12:29:44,747 Latency for request fccfd1f4 with model llama3-8b: 34.3650 seconds
2024-09-20 12:29:44,747 Saving results with gpu monitoring
2024-09-20 12:29:44,749 Latency for request 933ab923 with model llama3-8b: 34.3230 seconds
2024-09-20 12:29:44,749 Saving results with gpu monitoring
2024-09-20 12:29:44,751 Latency for request 4e4ab992 with model llama3-8b: 33.8840 seconds
2024-09-20 12:29:44,751 Saving results with gpu monitoring
2024-09-20 12:29:44,753 Latency for request 5d7f33c8 with model llama3-8b: 33.6070 seconds
2024-09-20 12:29:44,753 Saving results with gpu monitoring
2024-09-20 12:29:44,755 Latency for request e7d59b25 with model llama3-8b: 33.5990 seconds
2024-09-20 12:29:44,755 Saving results with gpu monitoring
2024-09-20 12:29:44,757 Latency for request 1beb68e6 with model llama3-8b: 33.0600 seconds
2024-09-20 12:29:44,757 Saving results with gpu monitoring
2024-09-20 12:29:44,759 Latency for request 2eda34ff with model llama3-8b: 32.8540 seconds
2024-09-20 12:29:44,759 Saving results with gpu monitoring
2024-09-20 12:29:44,761 Latency for request 41906623 with model llama3-8b: 32.4550 seconds
2024-09-20 12:29:44,761 Saving results with gpu monitoring
2024-09-20 12:29:44,763 Latency for request 8896b86f with model llama3-8b: 32.1330 seconds
2024-09-20 12:29:44,763 Saving results with gpu monitoring
2024-09-20 12:29:44,765 Latency for request 6e9900e2 with model llama3-8b: 32.1100 seconds
2024-09-20 12:29:44,765 Saving results with gpu monitoring
2024-09-20 12:29:44,767 Latency for request c80f2fc9 with model llama3-8b: 32.0940 seconds
2024-09-20 12:29:44,767 Saving results with gpu monitoring
2024-09-20 12:29:44,769 Latency for request 8449f80d with model llama3-8b: 31.9660 seconds
2024-09-20 12:29:44,769 Saving results with gpu monitoring
2024-09-20 12:29:44,771 Latency for request eaec1439 with model llama3-8b: 31.8720 seconds
2024-09-20 12:29:44,771 Saving results with gpu monitoring
2024-09-20 12:29:44,773 Latency for request 508551e4 with model llama3-8b: 31.8520 seconds
2024-09-20 12:29:44,773 Saving results with gpu monitoring
2024-09-20 12:29:44,775 Latency for request 1960e71a with model llama3-8b: 31.8230 seconds
2024-09-20 12:29:44,775 Saving results with gpu monitoring
2024-09-20 12:29:44,777 Latency for request d6692afc with model llama3-8b: 31.7130 seconds
2024-09-20 12:29:44,777 Saving results with gpu monitoring
2024-09-20 12:29:44,779 127.0.0.1 - - [20/Sep/2024 12:29:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:44,780 Next: call load_model for granite-7b
2024-09-20 12:29:44,875 Unloaded previous model
2024-09-20 12:29:44,879 Request with ID 0ee5c476 for model gemma-7b received
2024-09-20 12:29:44,880 127.0.0.1 - - [20/Sep/2024 12:29:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:44,976 Request with ID def62866 for model llama3-8b received
2024-09-20 12:29:44,976 Adjusted batch time limit for llama3-8b: 5.0000 seconds
2024-09-20 12:29:44,986 127.0.0.1 - - [20/Sep/2024 12:29:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:45,221 Request with ID d4c5870a for model llama3-8b received
2024-09-20 12:29:45,221 127.0.0.1 - - [20/Sep/2024 12:29:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:45,500 Request with ID cb7b7b99 for model llama3-8b received
2024-09-20 12:29:45,500 127.0.0.1 - - [20/Sep/2024 12:29:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:45,523 Request with ID 5328c32a for model granite-7b received
2024-09-20 12:29:45,523 127.0.0.1 - - [20/Sep/2024 12:29:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:45,565 Request with ID 834bfc26 for model llama3-8b received
2024-09-20 12:29:45,571 127.0.0.1 - - [20/Sep/2024 12:29:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:45,652 Request with ID a619c280 for model gemma-7b received
2024-09-20 12:29:45,656 127.0.0.1 - - [20/Sep/2024 12:29:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:45,817 Request with ID 345097e9 for model llama3-8b received
2024-09-20 12:29:45,820 127.0.0.1 - - [20/Sep/2024 12:29:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:45,836 Request with ID 6519ab61 for model gemma-7b received
2024-09-20 12:29:45,840 127.0.0.1 - - [20/Sep/2024 12:29:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,011 Request with ID e1583913 for model granite-7b received
2024-09-20 12:29:46,017 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,161 Request with ID 3978e8e2 for model llama3-8b received
2024-09-20 12:29:46,162 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,166 Request with ID 96d878f5 for model llama3-8b received
2024-09-20 12:29:46,166 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,168 Request with ID f9c962a3 for model llama3-8b received
2024-09-20 12:29:46,168 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,302 Request with ID 6a79e17c for model llama3-8b received
2024-09-20 12:29:46,302 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,382 Request with ID 9e76851e for model gemma-7b received
2024-09-20 12:29:46,383 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,392 Request with ID 753829ed for model gemma-7b received
2024-09-20 12:29:46,392 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,406 Request with ID 217bd3c0 for model llama3-8b received
2024-09-20 12:29:46,407 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,464 Request with ID 14965229 for model gemma-7b received
2024-09-20 12:29:46,465 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,497 Request with ID e39128c2 for model gemma-7b received
2024-09-20 12:29:46,497 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,539 Request with ID 60467e45 for model gemma-7b received
2024-09-20 12:29:46,539 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,565 Request with ID fc2999a9 for model llama3-8b received
2024-09-20 12:29:46,566 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,691 Request with ID 7fa01530 for model llama3-8b received
2024-09-20 12:29:46,692 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,756 Request with ID d24d656a for model gemma-7b received
2024-09-20 12:29:46,757 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,779 Request with ID 6de5c6c5 for model llama3-8b received
2024-09-20 12:29:46,780 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:46,968 Request with ID b6747e53 for model granite-7b received
2024-09-20 12:29:46,969 127.0.0.1 - - [20/Sep/2024 12:29:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:47,129 Request with ID cbe75c2b for model granite-7b received
2024-09-20 12:29:47,130 127.0.0.1 - - [20/Sep/2024 12:29:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:47,384 Request with ID 41f15490 for model llama3-8b received
2024-09-20 12:29:47,385 127.0.0.1 - - [20/Sep/2024 12:29:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:47,398 Request with ID 32d27a84 for model gemma-7b received
2024-09-20 12:29:47,398 127.0.0.1 - - [20/Sep/2024 12:29:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:47,483 Request with ID 4c3f9844 for model gemma-7b received
2024-09-20 12:29:47,483 127.0.0.1 - - [20/Sep/2024 12:29:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:47,591 Request with ID 39d3d799 for model llama3-8b received
2024-09-20 12:29:47,591 127.0.0.1 - - [20/Sep/2024 12:29:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:47,649 Request with ID c6ee1178 for model llama3-8b received
2024-09-20 12:29:47,649 127.0.0.1 - - [20/Sep/2024 12:29:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:47,651 Request with ID 1af8642b for model llama3-8b received
2024-09-20 12:29:47,651 127.0.0.1 - - [20/Sep/2024 12:29:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:47,703 Request with ID 5833861f for model llama3-8b received
2024-09-20 12:29:47,703 127.0.0.1 - - [20/Sep/2024 12:29:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:47,812 Request with ID d0b3bcff for model llama3-8b received
2024-09-20 12:29:47,813 127.0.0.1 - - [20/Sep/2024 12:29:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:47,965 Request with ID 72eff8e2 for model llama3-8b received
2024-09-20 12:29:47,966 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:29:47,966 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:29:48,105 Request with ID 82c37b35 for model gemma-7b received
2024-09-20 12:29:48,105 127.0.0.1 - - [20/Sep/2024 12:29:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:48,539 Request with ID 64747559 for model granite-7b received
2024-09-20 12:29:48,540 127.0.0.1 - - [20/Sep/2024 12:29:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:48,605 Request with ID 78d13aef for model llama3-8b received
2024-09-20 12:29:48,606 127.0.0.1 - - [20/Sep/2024 12:29:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:48,690 Request with ID 26608c9c for model llama3-8b received
2024-09-20 12:29:48,691 127.0.0.1 - - [20/Sep/2024 12:29:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:48,697 Request with ID f3f567c7 for model gemma-7b received
2024-09-20 12:29:48,698 127.0.0.1 - - [20/Sep/2024 12:29:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:48,701 Request with ID d13939a2 for model gemma-7b received
2024-09-20 12:29:48,701 127.0.0.1 - - [20/Sep/2024 12:29:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:48,742 Request with ID feb7f1b5 for model llama3-8b received
2024-09-20 12:29:48,743 127.0.0.1 - - [20/Sep/2024 12:29:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:48,905 Request with ID 1e264daf for model gemma-7b received
2024-09-20 12:29:48,905 127.0.0.1 - - [20/Sep/2024 12:29:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:48,917 Request with ID 520b516f for model gemma-7b received
2024-09-20 12:29:48,917 127.0.0.1 - - [20/Sep/2024 12:29:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:49,146 Request with ID 730c3d3f for model llama3-8b received
2024-09-20 12:29:49,147 127.0.0.1 - - [20/Sep/2024 12:29:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:49,152 Request with ID 555772ce for model gemma-7b received
2024-09-20 12:29:49,152 127.0.0.1 - - [20/Sep/2024 12:29:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:49,428 Request with ID a8d99ad5 for model llama3-8b received
2024-09-20 12:29:49,429 127.0.0.1 - - [20/Sep/2024 12:29:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:49,600 Request with ID cdc12c8a for model llama3-8b received
2024-09-20 12:29:49,601 127.0.0.1 - - [20/Sep/2024 12:29:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:49,603 Request with ID a6f8394f for model llama3-8b received
2024-09-20 12:29:49,603 127.0.0.1 - - [20/Sep/2024 12:29:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:49,683 Request with ID 274b0511 for model llama3-8b received
2024-09-20 12:29:49,684 127.0.0.1 - - [20/Sep/2024 12:29:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:49,788 Request with ID 266c5f9e for model gemma-7b received
2024-09-20 12:29:49,789 127.0.0.1 - - [20/Sep/2024 12:29:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:49,848 Request with ID d910f275 for model llama3-8b received
2024-09-20 12:29:49,848 127.0.0.1 - - [20/Sep/2024 12:29:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:49,915 Request with ID 5ecb3d15 for model gemma-7b received
2024-09-20 12:29:49,916 127.0.0.1 - - [20/Sep/2024 12:29:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:50,289 Request with ID dd3c56dd for model gemma-7b received
2024-09-20 12:29:50,290 127.0.0.1 - - [20/Sep/2024 12:29:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:50,448 Request with ID 07f7f268 for model granite-7b received
2024-09-20 12:29:50,449 127.0.0.1 - - [20/Sep/2024 12:29:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:50,466 Request with ID 17c6ba4f for model llama3-8b received
2024-09-20 12:29:50,467 127.0.0.1 - - [20/Sep/2024 12:29:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:50,493 Request with ID 983d1c63 for model llama3-8b received
2024-09-20 12:29:50,494 127.0.0.1 - - [20/Sep/2024 12:29:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:50,600 Request with ID cafb614f for model llama3-8b received
2024-09-20 12:29:50,601 127.0.0.1 - - [20/Sep/2024 12:29:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:50,626 Request with ID 596956a8 for model gemma-7b received
2024-09-20 12:29:50,627 127.0.0.1 - - [20/Sep/2024 12:29:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:50,812 Request with ID 1e011217 for model llama3-8b received
2024-09-20 12:29:50,813 127.0.0.1 - - [20/Sep/2024 12:29:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:50,950 Request with ID 098c04a2 for model llama3-8b received
2024-09-20 12:29:50,951 127.0.0.1 - - [20/Sep/2024 12:29:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:51,084 Request with ID 45b26f65 for model granite-7b received
2024-09-20 12:29:51,085 127.0.0.1 - - [20/Sep/2024 12:29:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:51,288 Request with ID 2c5a2797 for model llama3-8b received
2024-09-20 12:29:51,289 127.0.0.1 - - [20/Sep/2024 12:29:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:51,291 Request with ID 4cab7d4f for model llama3-8b received
2024-09-20 12:29:51,292 127.0.0.1 - - [20/Sep/2024 12:29:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:51,385 Request with ID 72c56be4 for model llama3-8b received
2024-09-20 12:29:51,386 127.0.0.1 - - [20/Sep/2024 12:29:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:51,872 Request with ID e0497db7 for model llama3-8b received
2024-09-20 12:29:51,873 127.0.0.1 - - [20/Sep/2024 12:29:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:51,896 Request with ID e6f99498 for model llama3-8b received
2024-09-20 12:29:51,896 127.0.0.1 - - [20/Sep/2024 12:29:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:52,030 Request with ID bd30b7e7 for model llama3-8b received
2024-09-20 12:29:52,031 127.0.0.1 - - [20/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:52,274 Request with ID db08627a for model llama3-8b received
2024-09-20 12:29:52,274 127.0.0.1 - - [20/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:52,321 Request with ID 24895b05 for model gemma-7b received
2024-09-20 12:29:52,322 127.0.0.1 - - [20/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:52,516 Request with ID 0dc5c0d4 for model gemma-7b received
2024-09-20 12:29:52,516 127.0.0.1 - - [20/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:52,723 Request with ID 9630cbef for model llama3-8b received
2024-09-20 12:29:52,723 127.0.0.1 - - [20/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:52,810 Request with ID a7a339ce for model granite-7b received
2024-09-20 12:29:52,811 127.0.0.1 - - [20/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:52,919 Request with ID 1f7073c8 for model gemma-7b received
2024-09-20 12:29:52,920 127.0.0.1 - - [20/Sep/2024 12:29:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,116 Request with ID 6e6bca97 for model gemma-7b received
2024-09-20 12:29:53,117 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,267 Request with ID 177efa87 for model gemma-7b received
2024-09-20 12:29:53,267 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,293 Request with ID 40ff44ec for model gemma-7b received
2024-09-20 12:29:53,294 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,371 Request with ID 5cf2bff5 for model llama3-8b received
2024-09-20 12:29:53,372 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,387 Request with ID 44b5b925 for model llama3-8b received
2024-09-20 12:29:53,387 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,512 Request with ID 14e4877b for model gemma-7b received
2024-09-20 12:29:53,512 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,561 Request with ID 609d5ebc for model gemma-7b received
2024-09-20 12:29:53,561 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,639 Request with ID 39188f08 for model llama3-8b received
2024-09-20 12:29:53,640 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,729 Request with ID dbc17c21 for model llama3-8b received
2024-09-20 12:29:53,729 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,808 Request with ID 3e4f8578 for model gemma-7b received
2024-09-20 12:29:53,809 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,815 Request with ID 8ce82454 for model llama3-8b received
2024-09-20 12:29:53,815 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,819 Request with ID 75b512d5 for model gemma-7b received
2024-09-20 12:29:53,820 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,840 Request with ID eda8e3fa for model gemma-7b received
2024-09-20 12:29:53,840 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,913 Request with ID 39375623 for model llama3-8b received
2024-09-20 12:29:53,914 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,965 Request with ID 1c4ac39e for model llama3-8b received
2024-09-20 12:29:53,965 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:53,969 Request with ID 88a8c31f for model llama3-8b received
2024-09-20 12:29:53,970 127.0.0.1 - - [20/Sep/2024 12:29:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:54,172 Request with ID 35210733 for model gemma-7b received
2024-09-20 12:29:54,172 127.0.0.1 - - [20/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:54,246 Request with ID f58cf598 for model llama3-8b received
2024-09-20 12:29:54,247 127.0.0.1 - - [20/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:54,262 Request with ID 538f273c for model gemma-7b received
2024-09-20 12:29:54,262 127.0.0.1 - - [20/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:54,386 Request with ID 72289a81 for model llama3-8b received
2024-09-20 12:29:54,387 127.0.0.1 - - [20/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:54,739 Request with ID dbc8b347 for model llama3-8b received
2024-09-20 12:29:54,740 127.0.0.1 - - [20/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:54,757 Request with ID 7879f586 for model llama3-8b received
2024-09-20 12:29:54,758 127.0.0.1 - - [20/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:54,777 Request with ID bf906378 for model llama3-8b received
2024-09-20 12:29:54,778 127.0.0.1 - - [20/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:54,895 Request with ID 040cc27d for model gemma-7b received
2024-09-20 12:29:54,895 127.0.0.1 - - [20/Sep/2024 12:29:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:55,076 Request with ID 6d4ab092 for model llama3-8b received
2024-09-20 12:29:55,076 127.0.0.1 - - [20/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:55,078 Request with ID fc59367f for model llama3-8b received
2024-09-20 12:29:55,079 127.0.0.1 - - [20/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:55,332 Request with ID 3d8a18f9 for model llama3-8b received
2024-09-20 12:29:55,332 127.0.0.1 - - [20/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:55,384 Request with ID f987d62c for model llama3-8b received
2024-09-20 12:29:55,384 127.0.0.1 - - [20/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:55,428 Request with ID 18bc555e for model llama3-8b received
2024-09-20 12:29:55,429 127.0.0.1 - - [20/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:55,467 Request with ID 526b127c for model llama3-8b received
2024-09-20 12:29:55,467 127.0.0.1 - - [20/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:55,622 Request with ID d5c1d7c3 for model gemma-7b received
2024-09-20 12:29:55,622 127.0.0.1 - - [20/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:55,817 Request with ID a5236e27 for model llama3-8b received
2024-09-20 12:29:55,818 127.0.0.1 - - [20/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:55,819 Request with ID 435cadfe for model gemma-7b received
2024-09-20 12:29:55,819 127.0.0.1 - - [20/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:55,994 Request with ID b9568136 for model gemma-7b received
2024-09-20 12:29:55,994 127.0.0.1 - - [20/Sep/2024 12:29:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,100 Request with ID fb8c1cac for model llama3-8b received
2024-09-20 12:29:56,100 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,148 Request with ID cb9a5e2f for model llama3-8b received
2024-09-20 12:29:56,149 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,229 Request with ID 23502efa for model granite-7b received
2024-09-20 12:29:56,230 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,319 Request with ID 46115fdd for model llama3-8b received
2024-09-20 12:29:56,320 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,368 Request with ID 5543f76a for model llama3-8b received
2024-09-20 12:29:56,368 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,371 Request with ID 76f2c51f for model gemma-7b received
2024-09-20 12:29:56,372 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,388 Request with ID c20718c4 for model llama3-8b received
2024-09-20 12:29:56,389 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,467 Request with ID d8d92619 for model llama3-8b received
2024-09-20 12:29:56,468 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,637 Request with ID 26e0b3a3 for model llama3-8b received
2024-09-20 12:29:56,637 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,811 Request with ID 2d28f137 for model llama3-8b received
2024-09-20 12:29:56,812 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,819 Request with ID af1844d6 for model llama3-8b received
2024-09-20 12:29:56,819 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,826 Request with ID 82601b3c for model llama3-8b received
2024-09-20 12:29:56,826 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,849 Request with ID ef2c40c9 for model llama3-8b received
2024-09-20 12:29:56,849 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,880 Request with ID d8fdd5ba for model llama3-8b received
2024-09-20 12:29:56,880 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:56,959 Request with ID 969bfc6f for model llama3-8b received
2024-09-20 12:29:56,960 127.0.0.1 - - [20/Sep/2024 12:29:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:57,087 Request with ID bc378d41 for model gemma-7b received
2024-09-20 12:29:57,088 127.0.0.1 - - [20/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:57,107 Request with ID d8fbe4a0 for model llama3-8b received
2024-09-20 12:29:57,107 127.0.0.1 - - [20/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:57,233 Request with ID 1e6d9e2e for model gemma-7b received
2024-09-20 12:29:57,234 127.0.0.1 - - [20/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:57,565 Request with ID 1f81bd2b for model granite-7b received
2024-09-20 12:29:57,566 127.0.0.1 - - [20/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:57,738 Request with ID e27f0618 for model granite-7b received
2024-09-20 12:29:57,738 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:29:57,739 Dynamic batch size condition met for model granite-7b
2024-09-20 12:29:57,838 Request with ID 518cafd7 for model llama3-8b received
2024-09-20 12:29:57,839 127.0.0.1 - - [20/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:57,865 Request with ID 498774d6 for model llama3-8b received
2024-09-20 12:29:57,865 127.0.0.1 - - [20/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:57,885 Request with ID 6ced63d2 for model llama3-8b received
2024-09-20 12:29:57,885 127.0.0.1 - - [20/Sep/2024 12:29:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:58,119 Request with ID 9ea38c9e for model llama3-8b received
2024-09-20 12:29:58,120 127.0.0.1 - - [20/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:58,148 Request with ID e2d787eb for model gemma-7b received
2024-09-20 12:29:58,149 127.0.0.1 - - [20/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:58,323 Request with ID 129839bc for model llama3-8b received
2024-09-20 12:29:58,324 127.0.0.1 - - [20/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:58,341 Request with ID 93c1e30a for model llama3-8b received
2024-09-20 12:29:58,341 127.0.0.1 - - [20/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:58,360 Request with ID 526e8e47 for model llama3-8b received
2024-09-20 12:29:58,360 127.0.0.1 - - [20/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:58,426 Request with ID 67c2289f for model granite-7b received
2024-09-20 12:29:58,427 127.0.0.1 - - [20/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:58,531 Request with ID a8818bcd for model gemma-7b received
2024-09-20 12:29:58,532 127.0.0.1 - - [20/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:58,706 Request with ID 81a20373 for model gemma-7b received
2024-09-20 12:29:58,706 127.0.0.1 - - [20/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:58,726 Request with ID 30dfaa0e for model llama3-8b received
2024-09-20 12:29:58,726 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:29:58,727 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:29:58,742 Request with ID 5e471ccb for model llama3-8b received
2024-09-20 12:29:58,743 127.0.0.1 - - [20/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:58,870 Request with ID f64df894 for model gemma-7b received
2024-09-20 12:29:58,871 127.0.0.1 - - [20/Sep/2024 12:29:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,042 Request with ID 6d8f5a2a for model llama3-8b received
2024-09-20 12:29:59,043 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,131 Request with ID f38f6728 for model llama3-8b received
2024-09-20 12:29:59,131 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,162 Request with ID 7f4394cd for model llama3-8b received
2024-09-20 12:29:59,162 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,185 Request with ID 13425702 for model gemma-7b received
2024-09-20 12:29:59,185 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,230 Request with ID df06bd73 for model llama3-8b received
2024-09-20 12:29:59,230 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,411 Request with ID 0a9f5453 for model llama3-8b received
2024-09-20 12:29:59,411 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,438 Request with ID 373b5af9 for model llama3-8b received
2024-09-20 12:29:59,439 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,516 Request with ID ab80e15a for model gemma-7b received
2024-09-20 12:29:59,516 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,630 Request with ID d20fda97 for model llama3-8b received
2024-09-20 12:29:59,630 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,712 Request with ID ac058f86 for model llama3-8b received
2024-09-20 12:29:59,713 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,719 Request with ID 344eb48e for model llama3-8b received
2024-09-20 12:29:59,719 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,741 Request with ID 9ce780dc for model gemma-7b received
2024-09-20 12:29:59,742 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,796 Request with ID af7fccc9 for model llama3-8b received
2024-09-20 12:29:59,798 Request with ID 4ae28967 for model llama3-8b received
2024-09-20 12:29:59,798 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,799 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,958 Request with ID c628b9ca for model gemma-7b received
2024-09-20 12:29:59,958 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:29:59,971 Request with ID 44e2eb28 for model llama3-8b received
2024-09-20 12:29:59,971 127.0.0.1 - - [20/Sep/2024 12:29:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:00,236 Request with ID 7315a12f for model gemma-7b received
2024-09-20 12:30:00,237 127.0.0.1 - - [20/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:00,349 Request with ID 0e77e5d2 for model llama3-8b received
2024-09-20 12:30:00,350 127.0.0.1 - - [20/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:00,359 Request with ID 448657e5 for model llama3-8b received
2024-09-20 12:30:00,359 127.0.0.1 - - [20/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:00,455 Request with ID a5410700 for model llama3-8b received
2024-09-20 12:30:00,456 127.0.0.1 - - [20/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:00,459 Request with ID a081fd73 for model gemma-7b received
2024-09-20 12:30:00,459 127.0.0.1 - - [20/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:00,502 Request with ID 7203e6e3 for model gemma-7b received
2024-09-20 12:30:00,503 127.0.0.1 - - [20/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:00,531 Request with ID 5ec754e9 for model llama3-8b received
2024-09-20 12:30:00,531 127.0.0.1 - - [20/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:00,565 Request with ID 2c64a720 for model llama3-8b received
2024-09-20 12:30:00,565 127.0.0.1 - - [20/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:00,640 Request with ID 57bbf313 for model llama3-8b received
2024-09-20 12:30:00,640 127.0.0.1 - - [20/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:00,727 Request with ID cd8cf564 for model llama3-8b received
2024-09-20 12:30:00,727 127.0.0.1 - - [20/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:00,751 Request with ID ed7b8d2b for model gemma-7b received
2024-09-20 12:30:00,752 127.0.0.1 - - [20/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:00,923 Request with ID 47412c75 for model llama3-8b received
2024-09-20 12:30:00,924 127.0.0.1 - - [20/Sep/2024 12:30:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:01,001 Request with ID 1f84abe8 for model gemma-7b received
2024-09-20 12:30:01,002 127.0.0.1 - - [20/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:01,025 Request with ID a0604341 for model gemma-7b received
2024-09-20 12:30:01,026 127.0.0.1 - - [20/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:01,029 Request with ID 51be2625 for model gemma-7b received
2024-09-20 12:30:01,029 127.0.0.1 - - [20/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:01,347 Request with ID 53826610 for model llama3-8b received
2024-09-20 12:30:01,348 127.0.0.1 - - [20/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:01,582 Request with ID 415668b8 for model llama3-8b received
2024-09-20 12:30:01,583 127.0.0.1 - - [20/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:01,584 Request with ID a8767a7d for model llama3-8b received
2024-09-20 12:30:01,585 127.0.0.1 - - [20/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:01,655 Request with ID c139e932 for model llama3-8b received
2024-09-20 12:30:01,656 127.0.0.1 - - [20/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:01,695 Request with ID 2d29100c for model llama3-8b received
2024-09-20 12:30:01,695 127.0.0.1 - - [20/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:01,807 Request with ID 8891c354 for model gemma-7b received
2024-09-20 12:30:01,807 127.0.0.1 - - [20/Sep/2024 12:30:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:02,139 Request with ID 663d0cda for model llama3-8b received
2024-09-20 12:30:02,140 127.0.0.1 - - [20/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:02,153 Request with ID 3f635469 for model gemma-7b received
2024-09-20 12:30:02,154 127.0.0.1 - - [20/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:02,226 Request with ID 97b911aa for model gemma-7b received
2024-09-20 12:30:02,227 127.0.0.1 - - [20/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:02,419 Request with ID f63cb777 for model granite-7b received
2024-09-20 12:30:02,419 127.0.0.1 - - [20/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:02,513 Request with ID 8fd24c7c for model llama3-8b received
2024-09-20 12:30:02,513 127.0.0.1 - - [20/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:02,576 Request with ID 29f02642 for model llama3-8b received
2024-09-20 12:30:02,576 127.0.0.1 - - [20/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:02,718 Request with ID 188b5c69 for model llama3-8b received
2024-09-20 12:30:02,719 127.0.0.1 - - [20/Sep/2024 12:30:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:03,124 Loaded model granite-7b
2024-09-20 12:30:03,127 Batch processing started for model granite-7b
2024-09-20 12:30:03,132 Request with ID e05eea92 for model gemma-7b received
2024-09-20 12:30:03,133 127.0.0.1 - - [20/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:03,140 Request with ID 86517b15 for model gemma-7b received
2024-09-20 12:30:03,140 127.0.0.1 - - [20/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:03,151 Request with ID cac524b3 for model granite-7b received
2024-09-20 12:30:03,152 127.0.0.1 - - [20/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:03,225 Request with ID f4f7d7ff for model gemma-7b received
2024-09-20 12:30:03,226 127.0.0.1 - - [20/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:03,253 Request with ID 14f32fc1 for model gemma-7b received
2024-09-20 12:30:03,253 127.0.0.1 - - [20/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:03,353 Request with ID f3b5278e for model llama3-8b received
2024-09-20 12:30:03,354 127.0.0.1 - - [20/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:03,483 Request with ID 39bd3bb5 for model llama3-8b received
2024-09-20 12:30:03,484 127.0.0.1 - - [20/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:03,544 Request with ID b8e78810 for model gemma-7b received
2024-09-20 12:30:03,544 Moving batch for gemma-7b from incoming to running due to dynamic batch size 64
2024-09-20 12:30:03,545 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:30:03,621 Request with ID fdf9f182 for model gemma-7b received
2024-09-20 12:30:03,621 127.0.0.1 - - [20/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:03,672 Request with ID 9f977f87 for model gemma-7b received
2024-09-20 12:30:03,672 127.0.0.1 - - [20/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:03,686 Request with ID ec63ec41 for model gemma-7b received
2024-09-20 12:30:03,687 127.0.0.1 - - [20/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:03,832 Request with ID b2c5d729 for model llama3-8b received
2024-09-20 12:30:03,833 127.0.0.1 - - [20/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:03,857 Request with ID 55086d75 for model gemma-7b received
2024-09-20 12:30:03,858 127.0.0.1 - - [20/Sep/2024 12:30:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:04,233 Request with ID 01d545a2 for model llama3-8b received
2024-09-20 12:30:04,233 127.0.0.1 - - [20/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:04,301 Request with ID f9bf6280 for model llama3-8b received
2024-09-20 12:30:04,302 127.0.0.1 - - [20/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:04,363 Request with ID aed63d79 for model granite-7b received
2024-09-20 12:30:04,364 127.0.0.1 - - [20/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:04,431 Request with ID 1e7950f9 for model llama3-8b received
2024-09-20 12:30:04,432 127.0.0.1 - - [20/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:04,459 Request with ID e2cd2522 for model llama3-8b received
2024-09-20 12:30:04,460 127.0.0.1 - - [20/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:04,508 Request with ID 1d7b664b for model llama3-8b received
2024-09-20 12:30:04,508 127.0.0.1 - - [20/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:04,560 Request with ID 3c30046c for model gemma-7b received
2024-09-20 12:30:04,560 127.0.0.1 - - [20/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:04,670 Request with ID 6e919278 for model llama3-8b received
2024-09-20 12:30:04,670 127.0.0.1 - - [20/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:04,729 Request with ID ba7328a7 for model gemma-7b received
2024-09-20 12:30:04,729 127.0.0.1 - - [20/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:04,997 Request with ID 037aa8e9 for model llama3-8b received
2024-09-20 12:30:04,998 127.0.0.1 - - [20/Sep/2024 12:30:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,067 Request with ID f37c185f for model llama3-8b received
2024-09-20 12:30:05,068 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,171 Request with ID d4eea060 for model llama3-8b received
2024-09-20 12:30:05,171 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,232 Request with ID 0257a302 for model llama3-8b received
2024-09-20 12:30:05,232 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,292 Request with ID e9a130e8 for model granite-7b received
2024-09-20 12:30:05,292 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,300 Request with ID 4ac73c80 for model llama3-8b received
2024-09-20 12:30:05,301 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,465 Request with ID b6598cb6 for model llama3-8b received
2024-09-20 12:30:05,465 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,515 Request with ID 2f38148a for model gemma-7b received
2024-09-20 12:30:05,515 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,559 Request with ID 3c09ff9c for model llama3-8b received
2024-09-20 12:30:05,559 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,714 Request with ID 2d0d2b62 for model gemma-7b received
2024-09-20 12:30:05,715 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,724 Request with ID 2bfb131d for model llama3-8b received
2024-09-20 12:30:05,724 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,757 Request with ID cf64a644 for model granite-7b received
2024-09-20 12:30:05,757 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,832 Request with ID 73e69396 for model llama3-8b received
2024-09-20 12:30:05,832 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,858 Request with ID 7d7d8e95 for model gemma-7b received
2024-09-20 12:30:05,859 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,927 Processed batch: ['d424d479', '70853e31', 'bef084db', '819d7045', 'd2a233c2', '70ca1439', '64583d96', 'd7931b5a', '17b2c289', 'a70e065a', '9d0a6daa', '36af71c5', 'fe3fee4f', 'bf01b650', 'd066c64a', 'ba3d0c30'] with model granite-7b in 2.7997 seconds
2024-09-20 12:30:05,927 Saving sys info
2024-09-20 12:30:05,955 Request with ID 8f9f737b for model granite-7b received
2024-09-20 12:30:05,956 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,963 Latency for request d424d479 with model granite-7b: 47.1490 seconds
2024-09-20 12:30:05,964 Saving results with gpu monitoring
2024-09-20 12:30:05,967 Latency for request 70853e31 with model granite-7b: 46.5970 seconds
2024-09-20 12:30:05,967 Saving results with gpu monitoring
2024-09-20 12:30:05,969 Latency for request bef084db with model granite-7b: 46.4990 seconds
2024-09-20 12:30:05,969 Saving results with gpu monitoring
2024-09-20 12:30:05,971 Latency for request 819d7045 with model granite-7b: 43.0880 seconds
2024-09-20 12:30:05,971 Saving results with gpu monitoring
2024-09-20 12:30:05,973 Latency for request d2a233c2 with model granite-7b: 42.8420 seconds
2024-09-20 12:30:05,973 Saving results with gpu monitoring
2024-09-20 12:30:05,975 Latency for request 70ca1439 with model granite-7b: 42.2790 seconds
2024-09-20 12:30:05,975 Saving results with gpu monitoring
2024-09-20 12:30:05,977 Latency for request 64583d96 with model granite-7b: 41.9620 seconds
2024-09-20 12:30:05,977 Saving results with gpu monitoring
2024-09-20 12:30:05,979 Latency for request d7931b5a with model granite-7b: 41.9280 seconds
2024-09-20 12:30:05,979 Saving results with gpu monitoring
2024-09-20 12:30:05,981 Latency for request 17b2c289 with model granite-7b: 41.7400 seconds
2024-09-20 12:30:05,981 Saving results with gpu monitoring
2024-09-20 12:30:05,983 Latency for request a70e065a with model granite-7b: 36.7000 seconds
2024-09-20 12:30:05,983 Saving results with gpu monitoring
2024-09-20 12:30:05,985 Latency for request 9d0a6daa with model granite-7b: 36.3820 seconds
2024-09-20 12:30:05,985 Saving results with gpu monitoring
2024-09-20 12:30:05,987 Latency for request 36af71c5 with model granite-7b: 34.7900 seconds
2024-09-20 12:30:05,987 Saving results with gpu monitoring
2024-09-20 12:30:05,989 Latency for request fe3fee4f with model granite-7b: 32.5290 seconds
2024-09-20 12:30:05,989 Saving results with gpu monitoring
2024-09-20 12:30:05,991 Latency for request bf01b650 with model granite-7b: 30.4580 seconds
2024-09-20 12:30:05,991 Saving results with gpu monitoring
2024-09-20 12:30:05,993 Latency for request d066c64a with model granite-7b: 28.1540 seconds
2024-09-20 12:30:05,993 Saving results with gpu monitoring
2024-09-20 12:30:05,995 Latency for request ba3d0c30 with model granite-7b: 25.8960 seconds
2024-09-20 12:30:05,995 Saving results with gpu monitoring
2024-09-20 12:30:05,997 127.0.0.1 - - [20/Sep/2024 12:30:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:05,998 Next: call load_model for gemma-7b
2024-09-20 12:30:06,083 Unloaded previous model
2024-09-20 12:30:06,625 Request with ID 65303b33 for model granite-7b received
2024-09-20 12:30:06,626 Adjusted batch time limit for granite-7b: 5.0000 seconds
2024-09-20 12:30:06,626 127.0.0.1 - - [20/Sep/2024 12:30:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:06,636 Request with ID eadf0373 for model llama3-8b received
2024-09-20 12:30:06,636 127.0.0.1 - - [20/Sep/2024 12:30:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:06,642 Request with ID 4c8c753b for model llama3-8b received
2024-09-20 12:30:06,644 127.0.0.1 - - [20/Sep/2024 12:30:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:06,821 Request with ID fd16b620 for model llama3-8b received
2024-09-20 12:30:06,823 127.0.0.1 - - [20/Sep/2024 12:30:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:06,847 Request with ID 461442cf for model gemma-7b received
2024-09-20 12:30:06,847 127.0.0.1 - - [20/Sep/2024 12:30:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:07,091 Request with ID 7043450d for model gemma-7b received
2024-09-20 12:30:07,097 127.0.0.1 - - [20/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:07,254 Request with ID 6b44fef0 for model gemma-7b received
2024-09-20 12:30:07,258 127.0.0.1 - - [20/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:07,269 Request with ID 0544927b for model granite-7b received
2024-09-20 12:30:07,280 127.0.0.1 - - [20/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:07,744 Request with ID 5a9e41a2 for model llama3-8b received
2024-09-20 12:30:07,748 127.0.0.1 - - [20/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:07,875 Request with ID 30f77b45 for model llama3-8b received
2024-09-20 12:30:07,875 127.0.0.1 - - [20/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:07,969 Request with ID 2df9346e for model llama3-8b received
2024-09-20 12:30:07,969 127.0.0.1 - - [20/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:07,971 Request with ID 6f951fe2 for model llama3-8b received
2024-09-20 12:30:07,971 127.0.0.1 - - [20/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:07,990 Request with ID 005fe820 for model llama3-8b received
2024-09-20 12:30:07,990 127.0.0.1 - - [20/Sep/2024 12:30:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:08,022 Request with ID e021001d for model gemma-7b received
2024-09-20 12:30:08,023 127.0.0.1 - - [20/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:08,155 Request with ID 40f8848e for model llama3-8b received
2024-09-20 12:30:08,155 127.0.0.1 - - [20/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:08,222 Request with ID c1c073ff for model llama3-8b received
2024-09-20 12:30:08,223 127.0.0.1 - - [20/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:08,357 Request with ID 0e72939b for model llama3-8b received
2024-09-20 12:30:08,358 127.0.0.1 - - [20/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:08,453 Request with ID 14c47490 for model llama3-8b received
2024-09-20 12:30:08,454 127.0.0.1 - - [20/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:08,572 Request with ID 3df0192a for model llama3-8b received
2024-09-20 12:30:08,572 127.0.0.1 - - [20/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:08,784 Request with ID 419aa809 for model gemma-7b received
2024-09-20 12:30:08,785 127.0.0.1 - - [20/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:08,868 Request with ID 57f4c0f5 for model llama3-8b received
2024-09-20 12:30:08,868 127.0.0.1 - - [20/Sep/2024 12:30:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:09,351 Request with ID effc5b3f for model llama3-8b received
2024-09-20 12:30:09,352 127.0.0.1 - - [20/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:09,514 Request with ID 90ef0820 for model llama3-8b received
2024-09-20 12:30:09,514 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:30:09,514 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:30:09,612 Request with ID 53d4bd39 for model llama3-8b received
2024-09-20 12:30:09,612 127.0.0.1 - - [20/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:09,660 Request with ID bb1a1d67 for model llama3-8b received
2024-09-20 12:30:09,661 Request with ID 3dcee206 for model granite-7b received
2024-09-20 12:30:09,661 127.0.0.1 - - [20/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:09,662 127.0.0.1 - - [20/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:09,800 Request with ID 5da3eb01 for model llama3-8b received
2024-09-20 12:30:09,800 127.0.0.1 - - [20/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:09,944 Request with ID deb5fb6d for model llama3-8b received
2024-09-20 12:30:09,945 127.0.0.1 - - [20/Sep/2024 12:30:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:10,009 Request with ID d2c619b0 for model gemma-7b received
2024-09-20 12:30:10,010 127.0.0.1 - - [20/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:10,059 Request with ID 01219a06 for model llama3-8b received
2024-09-20 12:30:10,059 127.0.0.1 - - [20/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:10,279 Request with ID 5969150c for model gemma-7b received
2024-09-20 12:30:10,279 127.0.0.1 - - [20/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:10,390 Request with ID 85145c02 for model llama3-8b received
2024-09-20 12:30:10,391 Request with ID 9ce34f82 for model gemma-7b received
2024-09-20 12:30:10,392 127.0.0.1 - - [20/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:10,393 127.0.0.1 - - [20/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:10,412 Request with ID 170dd6be for model granite-7b received
2024-09-20 12:30:10,413 127.0.0.1 - - [20/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:10,502 Request with ID 9c6aebab for model llama3-8b received
2024-09-20 12:30:10,503 127.0.0.1 - - [20/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:10,513 Request with ID 9c5d79b9 for model llama3-8b received
2024-09-20 12:30:10,514 127.0.0.1 - - [20/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:10,518 Request with ID 053ff322 for model llama3-8b received
2024-09-20 12:30:10,518 127.0.0.1 - - [20/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:10,614 Request with ID 6876019a for model gemma-7b received
2024-09-20 12:30:10,615 127.0.0.1 - - [20/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:10,716 Request with ID 3c600de5 for model llama3-8b received
2024-09-20 12:30:10,717 127.0.0.1 - - [20/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:10,855 Request with ID 6d745723 for model llama3-8b received
2024-09-20 12:30:10,855 127.0.0.1 - - [20/Sep/2024 12:30:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:11,012 Request with ID 5c58d374 for model llama3-8b received
2024-09-20 12:30:11,013 127.0.0.1 - - [20/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:11,028 Request with ID 8379dfb0 for model llama3-8b received
2024-09-20 12:30:11,029 127.0.0.1 - - [20/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:11,056 Request with ID 68ea681f for model gemma-7b received
2024-09-20 12:30:11,056 127.0.0.1 - - [20/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:11,150 Request with ID d5b28163 for model llama3-8b received
2024-09-20 12:30:11,150 127.0.0.1 - - [20/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:11,423 Request with ID f4158f62 for model gemma-7b received
2024-09-20 12:30:11,424 127.0.0.1 - - [20/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:11,527 Request with ID 6c61b8db for model llama3-8b received
2024-09-20 12:30:11,527 127.0.0.1 - - [20/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:11,540 Request with ID 9d3f2cea for model llama3-8b received
2024-09-20 12:30:11,540 127.0.0.1 - - [20/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:11,680 Request with ID a8f239ad for model llama3-8b received
2024-09-20 12:30:11,681 127.0.0.1 - - [20/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:11,701 Request with ID 7a079d0d for model llama3-8b received
2024-09-20 12:30:11,701 127.0.0.1 - - [20/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:11,720 Request with ID 1ed7a3d8 for model granite-7b received
2024-09-20 12:30:11,721 127.0.0.1 - - [20/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:11,901 Request with ID b841daa2 for model llama3-8b received
2024-09-20 12:30:11,902 127.0.0.1 - - [20/Sep/2024 12:30:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:12,169 Request with ID 0652c1c8 for model llama3-8b received
2024-09-20 12:30:12,169 127.0.0.1 - - [20/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:12,194 Request with ID e25a4db7 for model llama3-8b received
2024-09-20 12:30:12,195 127.0.0.1 - - [20/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:12,217 Request with ID 91efd0f2 for model llama3-8b received
2024-09-20 12:30:12,218 127.0.0.1 - - [20/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:12,497 Request with ID f91525cb for model granite-7b received
2024-09-20 12:30:12,497 127.0.0.1 - - [20/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:12,630 Request with ID 060a904f for model llama3-8b received
2024-09-20 12:30:12,631 127.0.0.1 - - [20/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:12,782 Request with ID c02ebd01 for model granite-7b received
2024-09-20 12:30:12,783 127.0.0.1 - - [20/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:12,808 Request with ID 934fd01e for model gemma-7b received
2024-09-20 12:30:12,808 127.0.0.1 - - [20/Sep/2024 12:30:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:13,067 Request with ID 404f26df for model llama3-8b received
2024-09-20 12:30:13,068 127.0.0.1 - - [20/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:13,074 Request with ID 4b0c1f1a for model granite-7b received
2024-09-20 12:30:13,075 127.0.0.1 - - [20/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:13,080 Request with ID 2427a30f for model gemma-7b received
2024-09-20 12:30:13,080 127.0.0.1 - - [20/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:13,320 Request with ID 74953a87 for model llama3-8b received
2024-09-20 12:30:13,321 127.0.0.1 - - [20/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:13,367 Request with ID 2511a44c for model llama3-8b received
2024-09-20 12:30:13,368 127.0.0.1 - - [20/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:13,519 Request with ID 8945562e for model gemma-7b received
2024-09-20 12:30:13,520 127.0.0.1 - - [20/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:13,780 Request with ID 61a379ae for model granite-7b received
2024-09-20 12:30:13,780 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:30:13,781 Dynamic batch size condition met for model granite-7b
2024-09-20 12:30:13,954 Request with ID 6363abd2 for model gemma-7b received
2024-09-20 12:30:13,954 127.0.0.1 - - [20/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:13,992 Request with ID 5e1ccdc4 for model gemma-7b received
2024-09-20 12:30:13,993 127.0.0.1 - - [20/Sep/2024 12:30:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:14,225 Request with ID 3a596d49 for model llama3-8b received
2024-09-20 12:30:14,225 127.0.0.1 - - [20/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:14,306 Request with ID d2574f4c for model llama3-8b received
2024-09-20 12:30:14,307 127.0.0.1 - - [20/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:14,585 Request with ID 78899d6a for model llama3-8b received
2024-09-20 12:30:14,585 127.0.0.1 - - [20/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:14,741 Request with ID e398a0df for model llama3-8b received
2024-09-20 12:30:14,742 127.0.0.1 - - [20/Sep/2024 12:30:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:15,133 Request with ID 09b302d2 for model gemma-7b received
2024-09-20 12:30:15,133 127.0.0.1 - - [20/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:15,175 Request with ID df977117 for model llama3-8b received
2024-09-20 12:30:15,176 127.0.0.1 - - [20/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:15,272 Request with ID d45f5e54 for model granite-7b received
2024-09-20 12:30:15,273 127.0.0.1 - - [20/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:15,399 Request with ID ee60ed0e for model gemma-7b received
2024-09-20 12:30:15,400 127.0.0.1 - - [20/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:15,592 Request with ID ec1cc605 for model llama3-8b received
2024-09-20 12:30:15,592 127.0.0.1 - - [20/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:15,617 Request with ID ec03094e for model llama3-8b received
2024-09-20 12:30:15,618 127.0.0.1 - - [20/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:15,625 Request with ID 36cf0eff for model llama3-8b received
2024-09-20 12:30:15,626 127.0.0.1 - - [20/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:15,635 Request with ID f7bba97c for model llama3-8b received
2024-09-20 12:30:15,636 127.0.0.1 - - [20/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:15,694 Request with ID 9fe5f35d for model llama3-8b received
2024-09-20 12:30:15,694 127.0.0.1 - - [20/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:15,718 Request with ID 62cf8630 for model llama3-8b received
2024-09-20 12:30:15,719 127.0.0.1 - - [20/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:15,783 Request with ID 9433e1ac for model granite-7b received
2024-09-20 12:30:15,783 127.0.0.1 - - [20/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:15,857 Request with ID eedde451 for model gemma-7b received
2024-09-20 12:30:15,857 127.0.0.1 - - [20/Sep/2024 12:30:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:16,241 Request with ID 68896f31 for model llama3-8b received
2024-09-20 12:30:16,241 127.0.0.1 - - [20/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:16,283 Request with ID dfbe1798 for model llama3-8b received
2024-09-20 12:30:16,284 127.0.0.1 - - [20/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:16,427 Request with ID df122d78 for model llama3-8b received
2024-09-20 12:30:16,428 127.0.0.1 - - [20/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:16,451 Request with ID fb0885fc for model llama3-8b received
2024-09-20 12:30:16,451 127.0.0.1 - - [20/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:16,660 Request with ID 08aa3654 for model llama3-8b received
2024-09-20 12:30:16,660 127.0.0.1 - - [20/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:16,798 Request with ID 234b0ff1 for model granite-7b received
2024-09-20 12:30:16,799 127.0.0.1 - - [20/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:16,805 Request with ID 5fa4a435 for model gemma-7b received
2024-09-20 12:30:16,806 127.0.0.1 - - [20/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:16,856 Request with ID ebe84cd3 for model gemma-7b received
2024-09-20 12:30:16,857 127.0.0.1 - - [20/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:16,918 Request with ID 5a6499cf for model granite-7b received
2024-09-20 12:30:16,918 127.0.0.1 - - [20/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:16,978 Request with ID 5a49b466 for model gemma-7b received
2024-09-20 12:30:16,978 127.0.0.1 - - [20/Sep/2024 12:30:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:17,055 Request with ID f7fe5f50 for model llama3-8b received
2024-09-20 12:30:17,055 127.0.0.1 - - [20/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:17,088 Request with ID be4d64b8 for model gemma-7b received
2024-09-20 12:30:17,088 127.0.0.1 - - [20/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:17,337 Request with ID 67cb8459 for model llama3-8b received
2024-09-20 12:30:17,337 127.0.0.1 - - [20/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:17,398 Request with ID 63445b13 for model llama3-8b received
2024-09-20 12:30:17,398 127.0.0.1 - - [20/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:17,637 Request with ID 2b30a42b for model gemma-7b received
2024-09-20 12:30:17,637 127.0.0.1 - - [20/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:17,710 Request with ID 1920e461 for model gemma-7b received
2024-09-20 12:30:17,710 127.0.0.1 - - [20/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:17,936 Request with ID 21bee2b4 for model llama3-8b received
2024-09-20 12:30:17,937 127.0.0.1 - - [20/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:17,975 Request with ID cb665bbd for model llama3-8b received
2024-09-20 12:30:17,975 127.0.0.1 - - [20/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:17,989 Request with ID e94e2a97 for model llama3-8b received
2024-09-20 12:30:17,989 127.0.0.1 - - [20/Sep/2024 12:30:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:18,333 Request with ID 3ed1e3e7 for model llama3-8b received
2024-09-20 12:30:18,334 127.0.0.1 - - [20/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:18,348 Request with ID 6296634c for model llama3-8b received
2024-09-20 12:30:18,348 127.0.0.1 - - [20/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:18,368 Request with ID 8352baa9 for model llama3-8b received
2024-09-20 12:30:18,368 127.0.0.1 - - [20/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:18,478 Request with ID 0fb5dabd for model granite-7b received
2024-09-20 12:30:18,478 127.0.0.1 - - [20/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:18,481 Request with ID fcc17f3a for model llama3-8b received
2024-09-20 12:30:18,481 127.0.0.1 - - [20/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:18,490 Request with ID e14e5c50 for model gemma-7b received
2024-09-20 12:30:18,490 127.0.0.1 - - [20/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:18,689 Request with ID 4dd50de9 for model llama3-8b received
2024-09-20 12:30:18,690 127.0.0.1 - - [20/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:18,700 Request with ID 4362504d for model llama3-8b received
2024-09-20 12:30:18,701 127.0.0.1 - - [20/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:18,809 Request with ID 60acbfca for model llama3-8b received
2024-09-20 12:30:18,810 127.0.0.1 - - [20/Sep/2024 12:30:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:19,024 Request with ID be312783 for model gemma-7b received
2024-09-20 12:30:19,024 127.0.0.1 - - [20/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:19,150 Request with ID 472d9471 for model gemma-7b received
2024-09-20 12:30:19,150 127.0.0.1 - - [20/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:19,178 Request with ID a97256a3 for model llama3-8b received
2024-09-20 12:30:19,178 127.0.0.1 - - [20/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:19,315 Request with ID e66772b0 for model llama3-8b received
2024-09-20 12:30:19,316 127.0.0.1 - - [20/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:19,422 Request with ID 390fc5a4 for model gemma-7b received
2024-09-20 12:30:19,422 127.0.0.1 - - [20/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:19,608 Request with ID 1be5314f for model llama3-8b received
2024-09-20 12:30:19,609 127.0.0.1 - - [20/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:19,639 Request with ID f92f09d7 for model gemma-7b received
2024-09-20 12:30:19,639 127.0.0.1 - - [20/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:19,806 Request with ID 3455689b for model gemma-7b received
2024-09-20 12:30:19,807 127.0.0.1 - - [20/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:19,808 Request with ID f21fecb6 for model gemma-7b received
2024-09-20 12:30:19,809 127.0.0.1 - - [20/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:19,951 Request with ID 4d766867 for model llama3-8b received
2024-09-20 12:30:19,952 127.0.0.1 - - [20/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:19,959 Request with ID 3e201e40 for model llama3-8b received
2024-09-20 12:30:19,959 127.0.0.1 - - [20/Sep/2024 12:30:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,080 Request with ID a3ca5a49 for model gemma-7b received
2024-09-20 12:30:20,081 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,126 Request with ID f62ec30b for model granite-7b received
2024-09-20 12:30:20,126 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,163 Request with ID b62a784d for model llama3-8b received
2024-09-20 12:30:20,164 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,312 Request with ID 1da8f4de for model llama3-8b received
2024-09-20 12:30:20,312 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,343 Request with ID f240efa1 for model llama3-8b received
2024-09-20 12:30:20,343 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,428 Request with ID b5afcd94 for model llama3-8b received
2024-09-20 12:30:20,428 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:30:20,429 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:30:20,490 Request with ID 07cde9d6 for model llama3-8b received
2024-09-20 12:30:20,491 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,539 Request with ID e953209c for model llama3-8b received
2024-09-20 12:30:20,539 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,606 Request with ID 81369a57 for model granite-7b received
2024-09-20 12:30:20,607 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,743 Request with ID 5b9c52e2 for model llama3-8b received
2024-09-20 12:30:20,743 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,756 Request with ID fa1cc622 for model llama3-8b received
2024-09-20 12:30:20,757 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,934 Request with ID 7c84a835 for model llama3-8b received
2024-09-20 12:30:20,935 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,937 Request with ID d3490d9b for model llama3-8b received
2024-09-20 12:30:20,937 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,972 Request with ID 700dfbd3 for model gemma-7b received
2024-09-20 12:30:20,972 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:20,985 Request with ID ce48467d for model granite-7b received
2024-09-20 12:30:20,985 127.0.0.1 - - [20/Sep/2024 12:30:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:21,071 Request with ID 402525dc for model llama3-8b received
2024-09-20 12:30:21,072 127.0.0.1 - - [20/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:21,079 Request with ID a74d8a4f for model granite-7b received
2024-09-20 12:30:21,079 127.0.0.1 - - [20/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:21,315 Request with ID ed616b8d for model llama3-8b received
2024-09-20 12:30:21,315 127.0.0.1 - - [20/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:21,356 Request with ID 25e53c0d for model llama3-8b received
2024-09-20 12:30:21,357 127.0.0.1 - - [20/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:21,377 Request with ID 9f893362 for model llama3-8b received
2024-09-20 12:30:21,377 127.0.0.1 - - [20/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:21,562 Request with ID fac07de8 for model llama3-8b received
2024-09-20 12:30:21,563 127.0.0.1 - - [20/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:21,594 Request with ID 693253f0 for model llama3-8b received
2024-09-20 12:30:21,594 127.0.0.1 - - [20/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:21,671 Request with ID 7e104415 for model gemma-7b received
2024-09-20 12:30:21,671 127.0.0.1 - - [20/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:21,696 Request with ID 84bddc08 for model llama3-8b received
2024-09-20 12:30:21,697 127.0.0.1 - - [20/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:21,701 Request with ID 9ef68f34 for model llama3-8b received
2024-09-20 12:30:21,701 127.0.0.1 - - [20/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:21,915 Request with ID 2b5b2477 for model llama3-8b received
2024-09-20 12:30:21,916 127.0.0.1 - - [20/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:21,973 Request with ID 3706811c for model llama3-8b received
2024-09-20 12:30:21,974 127.0.0.1 - - [20/Sep/2024 12:30:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:22,198 Request with ID 2d278ec9 for model llama3-8b received
2024-09-20 12:30:22,199 127.0.0.1 - - [20/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:22,300 Request with ID f8a8a5d2 for model llama3-8b received
2024-09-20 12:30:22,300 127.0.0.1 - - [20/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:22,403 Request with ID b86099ab for model llama3-8b received
2024-09-20 12:30:22,404 127.0.0.1 - - [20/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:22,414 Request with ID 18b613e9 for model llama3-8b received
2024-09-20 12:30:22,414 127.0.0.1 - - [20/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:22,771 Request with ID 85efca65 for model llama3-8b received
2024-09-20 12:30:22,772 127.0.0.1 - - [20/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:22,865 Request with ID 1fb47166 for model llama3-8b received
2024-09-20 12:30:22,865 127.0.0.1 - - [20/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:22,967 Request with ID 9e861fd0 for model granite-7b received
2024-09-20 12:30:22,967 127.0.0.1 - - [20/Sep/2024 12:30:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,061 Request with ID c88f1372 for model gemma-7b received
2024-09-20 12:30:23,062 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,095 Request with ID 7920b026 for model gemma-7b received
2024-09-20 12:30:23,095 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,162 Request with ID d577cd02 for model llama3-8b received
2024-09-20 12:30:23,163 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,223 Request with ID d7bd6c7d for model gemma-7b received
2024-09-20 12:30:23,224 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,297 Request with ID 99f94c06 for model llama3-8b received
2024-09-20 12:30:23,298 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,302 Request with ID fd686ac0 for model granite-7b received
2024-09-20 12:30:23,303 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,316 Request with ID b9150897 for model llama3-8b received
2024-09-20 12:30:23,316 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,376 Request with ID cfe3d4ba for model llama3-8b received
2024-09-20 12:30:23,377 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,411 Request with ID 487f7ffa for model llama3-8b received
2024-09-20 12:30:23,412 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,446 Request with ID a9e6e0eb for model llama3-8b received
2024-09-20 12:30:23,446 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,661 Request with ID 623a1bf0 for model llama3-8b received
2024-09-20 12:30:23,661 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,730 Request with ID 71fc7f1c for model llama3-8b received
2024-09-20 12:30:23,730 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:23,744 Request with ID 474fcf6d for model gemma-7b received
2024-09-20 12:30:23,744 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-20 12:30:23,744 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:30:23,877 Request with ID 81acfee1 for model llama3-8b received
2024-09-20 12:30:23,878 127.0.0.1 - - [20/Sep/2024 12:30:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:24,004 Request with ID 15a58d4f for model llama3-8b received
2024-09-20 12:30:24,004 127.0.0.1 - - [20/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:24,317 Request with ID f94383e5 for model llama3-8b received
2024-09-20 12:30:24,318 Request with ID e561d43c for model granite-7b received
2024-09-20 12:30:24,318 127.0.0.1 - - [20/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:24,318 127.0.0.1 - - [20/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:24,525 Request with ID e2a5a58c for model gemma-7b received
2024-09-20 12:30:24,526 127.0.0.1 - - [20/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:24,575 Request with ID 8c5939a7 for model gemma-7b received
2024-09-20 12:30:24,576 127.0.0.1 - - [20/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:24,589 Request with ID e24d7b25 for model llama3-8b received
2024-09-20 12:30:24,589 127.0.0.1 - - [20/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:24,597 Request with ID 4b62bdb2 for model llama3-8b received
2024-09-20 12:30:24,598 127.0.0.1 - - [20/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:24,711 Request with ID 7a935d4f for model llama3-8b received
2024-09-20 12:30:24,711 127.0.0.1 - - [20/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:24,931 Request with ID d48500cc for model granite-7b received
2024-09-20 12:30:24,931 127.0.0.1 - - [20/Sep/2024 12:30:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:25,034 Request with ID e3cacfdb for model gemma-7b received
2024-09-20 12:30:25,035 127.0.0.1 - - [20/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:25,136 Request with ID f4ba7bd3 for model llama3-8b received
2024-09-20 12:30:25,136 127.0.0.1 - - [20/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:25,142 Request with ID d12a3109 for model llama3-8b received
2024-09-20 12:30:25,143 127.0.0.1 - - [20/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:25,317 Request with ID ab066145 for model gemma-7b received
2024-09-20 12:30:25,318 127.0.0.1 - - [20/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:25,385 Request with ID d8a94857 for model granite-7b received
2024-09-20 12:30:25,386 127.0.0.1 - - [20/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:25,398 Request with ID 5b6e29b2 for model gemma-7b received
2024-09-20 12:30:25,398 127.0.0.1 - - [20/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:25,463 Request with ID ad23014a for model llama3-8b received
2024-09-20 12:30:25,464 127.0.0.1 - - [20/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:25,653 Request with ID f9fa90d8 for model llama3-8b received
2024-09-20 12:30:25,653 127.0.0.1 - - [20/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:25,704 Request with ID 32bf2efd for model llama3-8b received
2024-09-20 12:30:25,705 127.0.0.1 - - [20/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:25,946 Request with ID 890c1061 for model llama3-8b received
2024-09-20 12:30:25,946 127.0.0.1 - - [20/Sep/2024 12:30:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,066 Request with ID eacb168e for model llama3-8b received
2024-09-20 12:30:26,066 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,154 Request with ID c9721961 for model llama3-8b received
2024-09-20 12:30:26,155 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,193 Request with ID 2ec94aa9 for model gemma-7b received
2024-09-20 12:30:26,194 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,197 Request with ID a6f064f6 for model llama3-8b received
2024-09-20 12:30:26,197 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,246 Request with ID 36a31428 for model gemma-7b received
2024-09-20 12:30:26,247 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,469 Request with ID c87f3068 for model granite-7b received
2024-09-20 12:30:26,470 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,575 Request with ID 34498945 for model granite-7b received
2024-09-20 12:30:26,575 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:30:26,575 Dynamic batch size condition met for model granite-7b
2024-09-20 12:30:26,625 Request with ID 0bb2dde0 for model llama3-8b received
2024-09-20 12:30:26,626 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,636 Request with ID 08ab6e66 for model llama3-8b received
2024-09-20 12:30:26,636 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,683 Request with ID 32db77fd for model llama3-8b received
2024-09-20 12:30:26,683 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,746 Request with ID 3e6270be for model gemma-7b received
2024-09-20 12:30:26,746 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,814 Request with ID c01400d0 for model llama3-8b received
2024-09-20 12:30:26,814 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,892 Request with ID 028ba814 for model gemma-7b received
2024-09-20 12:30:26,892 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,896 Request with ID 304cd9d3 for model llama3-8b received
2024-09-20 12:30:26,897 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,952 Request with ID 9f9454a4 for model gemma-7b received
2024-09-20 12:30:26,953 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:26,970 Request with ID 67ffc13a for model gemma-7b received
2024-09-20 12:30:26,970 127.0.0.1 - - [20/Sep/2024 12:30:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:27,203 Request with ID a761cab4 for model llama3-8b received
2024-09-20 12:30:27,204 127.0.0.1 - - [20/Sep/2024 12:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:27,241 Request with ID 8a2da860 for model llama3-8b received
2024-09-20 12:30:27,242 127.0.0.1 - - [20/Sep/2024 12:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:27,323 Request with ID 3a4fe6d5 for model gemma-7b received
2024-09-20 12:30:27,323 127.0.0.1 - - [20/Sep/2024 12:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:27,649 Request with ID a55d3f2c for model granite-7b received
2024-09-20 12:30:27,650 127.0.0.1 - - [20/Sep/2024 12:30:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:28,005 Request with ID a500b08b for model llama3-8b received
2024-09-20 12:30:28,006 127.0.0.1 - - [20/Sep/2024 12:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:28,023 Request with ID c842e17a for model llama3-8b received
2024-09-20 12:30:28,024 127.0.0.1 - - [20/Sep/2024 12:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:28,170 Request with ID b2be029a for model llama3-8b received
2024-09-20 12:30:28,170 127.0.0.1 - - [20/Sep/2024 12:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:28,214 Request with ID 26c85307 for model gemma-7b received
2024-09-20 12:30:28,215 127.0.0.1 - - [20/Sep/2024 12:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:28,237 Request with ID 2d80e080 for model gemma-7b received
2024-09-20 12:30:28,237 127.0.0.1 - - [20/Sep/2024 12:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:28,270 Request with ID 2b936d00 for model llama3-8b received
2024-09-20 12:30:28,270 127.0.0.1 - - [20/Sep/2024 12:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:28,351 Request with ID 78cf85af for model llama3-8b received
2024-09-20 12:30:28,351 127.0.0.1 - - [20/Sep/2024 12:30:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:29,169 Request with ID 611f7c85 for model llama3-8b received
2024-09-20 12:30:29,170 127.0.0.1 - - [20/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:29,237 Request with ID c0857f87 for model gemma-7b received
2024-09-20 12:30:29,238 127.0.0.1 - - [20/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:29,415 Request with ID 693f64bb for model llama3-8b received
2024-09-20 12:30:29,415 127.0.0.1 - - [20/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:29,416 Loaded model gemma-7b
2024-09-20 12:30:29,417 Request with ID c980db3c for model llama3-8b received
2024-09-20 12:30:29,417 127.0.0.1 - - [20/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:29,423 Batch processing started for model gemma-7b
2024-09-20 12:30:29,653 Request with ID 6b9952f5 for model llama3-8b received
2024-09-20 12:30:29,653 127.0.0.1 - - [20/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:29,896 Request with ID 871cb4c5 for model gemma-7b received
2024-09-20 12:30:29,896 127.0.0.1 - - [20/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:29,959 Request with ID ab208814 for model gemma-7b received
2024-09-20 12:30:29,959 127.0.0.1 - - [20/Sep/2024 12:30:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,119 Request with ID b2bfcc4c for model llama3-8b received
2024-09-20 12:30:30,119 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,122 Request with ID e0357d4b for model gemma-7b received
2024-09-20 12:30:30,123 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,187 Request with ID 584b85e3 for model llama3-8b received
2024-09-20 12:30:30,187 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,257 Request with ID cccae545 for model gemma-7b received
2024-09-20 12:30:30,257 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,292 Request with ID 6ae71cb3 for model llama3-8b received
2024-09-20 12:30:30,292 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:30:30,292 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:30:30,387 Request with ID 14b2385e for model llama3-8b received
2024-09-20 12:30:30,387 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,475 Request with ID ce5317b7 for model llama3-8b received
2024-09-20 12:30:30,475 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,537 Request with ID 6c94dd13 for model llama3-8b received
2024-09-20 12:30:30,538 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,685 Request with ID 93625aba for model llama3-8b received
2024-09-20 12:30:30,686 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,708 Request with ID 682ee15c for model llama3-8b received
2024-09-20 12:30:30,708 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,768 Request with ID a7d89867 for model gemma-7b received
2024-09-20 12:30:30,769 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,797 Request with ID 04db65fa for model llama3-8b received
2024-09-20 12:30:30,797 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,871 Request with ID 15248dd7 for model llama3-8b received
2024-09-20 12:30:30,871 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:30,874 Request with ID 1c01ba5c for model llama3-8b received
2024-09-20 12:30:30,874 127.0.0.1 - - [20/Sep/2024 12:30:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:31,004 Request with ID bf8e705d for model llama3-8b received
2024-09-20 12:30:31,004 127.0.0.1 - - [20/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:31,109 Request with ID 89195a6f for model llama3-8b received
2024-09-20 12:30:31,109 127.0.0.1 - - [20/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:31,142 Request with ID 243d5033 for model llama3-8b received
2024-09-20 12:30:31,142 127.0.0.1 - - [20/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:31,302 Request with ID 3c07458f for model gemma-7b received
2024-09-20 12:30:31,302 127.0.0.1 - - [20/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:31,827 Request with ID acc75922 for model granite-7b received
2024-09-20 12:30:31,827 127.0.0.1 - - [20/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:31,963 Request with ID f66057bf for model llama3-8b received
2024-09-20 12:30:31,963 127.0.0.1 - - [20/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:31,970 Request with ID 2f952f8b for model llama3-8b received
2024-09-20 12:30:31,970 127.0.0.1 - - [20/Sep/2024 12:30:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:32,119 Request with ID a112fc08 for model llama3-8b received
2024-09-20 12:30:32,120 127.0.0.1 - - [20/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:32,308 Request with ID 56653650 for model granite-7b received
2024-09-20 12:30:32,309 127.0.0.1 - - [20/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:32,362 Request with ID 20b00498 for model granite-7b received
2024-09-20 12:30:32,362 127.0.0.1 - - [20/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:32,400 Request with ID 4fd6e066 for model llama3-8b received
2024-09-20 12:30:32,400 127.0.0.1 - - [20/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:32,698 Request with ID 4a1747e2 for model granite-7b received
2024-09-20 12:30:32,698 127.0.0.1 - - [20/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:32,708 Request with ID 0fc759f4 for model gemma-7b received
2024-09-20 12:30:32,708 127.0.0.1 - - [20/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:32,717 Request with ID def1e2b5 for model llama3-8b received
2024-09-20 12:30:32,717 127.0.0.1 - - [20/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:32,842 Request with ID e4ee42ff for model llama3-8b received
2024-09-20 12:30:32,843 127.0.0.1 - - [20/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:32,955 Request with ID fb4a11a7 for model gemma-7b received
2024-09-20 12:30:32,955 127.0.0.1 - - [20/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:32,988 Request with ID ffbcb621 for model llama3-8b received
2024-09-20 12:30:32,989 127.0.0.1 - - [20/Sep/2024 12:30:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,042 Request with ID 83a2d8b1 for model granite-7b received
2024-09-20 12:30:33,042 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,132 Request with ID 25e3db65 for model llama3-8b received
2024-09-20 12:30:33,132 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,226 Request with ID b7d815aa for model llama3-8b received
2024-09-20 12:30:33,226 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,370 Request with ID 1ccf47f0 for model llama3-8b received
2024-09-20 12:30:33,371 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,441 Request with ID 838be3d0 for model llama3-8b received
2024-09-20 12:30:33,441 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,615 Request with ID 65d47afa for model granite-7b received
2024-09-20 12:30:33,616 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,731 Request with ID 7f818a01 for model gemma-7b received
2024-09-20 12:30:33,732 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,766 Request with ID aee33375 for model llama3-8b received
2024-09-20 12:30:33,767 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,785 Request with ID a10ca86c for model llama3-8b received
2024-09-20 12:30:33,785 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,837 Request with ID 8ebc4bdc for model gemma-7b received
2024-09-20 12:30:33,838 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,852 Request with ID ff143b45 for model llama3-8b received
2024-09-20 12:30:33,852 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,886 Request with ID e61a668b for model granite-7b received
2024-09-20 12:30:33,886 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:33,960 Request with ID 4a86e4ac for model gemma-7b received
2024-09-20 12:30:33,960 127.0.0.1 - - [20/Sep/2024 12:30:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:34,086 Request with ID cc590878 for model llama3-8b received
2024-09-20 12:30:34,087 Request with ID c9e0b8af for model granite-7b received
2024-09-20 12:30:34,087 127.0.0.1 - - [20/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:34,088 127.0.0.1 - - [20/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:34,356 Request with ID 93a2476a for model gemma-7b received
2024-09-20 12:30:34,356 127.0.0.1 - - [20/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:34,388 Request with ID 1b55162a for model llama3-8b received
2024-09-20 12:30:34,389 127.0.0.1 - - [20/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:34,475 Request with ID dcd4649f for model llama3-8b received
2024-09-20 12:30:34,476 127.0.0.1 - - [20/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:34,719 Request with ID 7f889c33 for model llama3-8b received
2024-09-20 12:30:34,719 127.0.0.1 - - [20/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:34,732 Request with ID 9d12c89f for model llama3-8b received
2024-09-20 12:30:34,733 127.0.0.1 - - [20/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:34,784 Request with ID 8bf87cf0 for model llama3-8b received
2024-09-20 12:30:34,784 127.0.0.1 - - [20/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:34,899 Request with ID 6e5e4645 for model gemma-7b received
2024-09-20 12:30:34,899 127.0.0.1 - - [20/Sep/2024 12:30:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:35,110 Request with ID 9dcc94d7 for model llama3-8b received
2024-09-20 12:30:35,111 127.0.0.1 - - [20/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:35,255 Request with ID 3753e5b0 for model llama3-8b received
2024-09-20 12:30:35,255 127.0.0.1 - - [20/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:35,546 Request with ID 37618a5b for model gemma-7b received
2024-09-20 12:30:35,547 127.0.0.1 - - [20/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:35,700 Request with ID 85ae5d05 for model llama3-8b received
2024-09-20 12:30:35,701 127.0.0.1 - - [20/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:35,712 Request with ID e178eae3 for model llama3-8b received
2024-09-20 12:30:35,713 127.0.0.1 - - [20/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:35,783 Request with ID 0b505ea1 for model llama3-8b received
2024-09-20 12:30:35,784 127.0.0.1 - - [20/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:35,796 Request with ID a3282e2b for model llama3-8b received
2024-09-20 12:30:35,797 Request with ID 2b38c3a5 for model llama3-8b received
2024-09-20 12:30:35,798 127.0.0.1 - - [20/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:35,798 127.0.0.1 - - [20/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:35,853 Request with ID d388051d for model llama3-8b received
2024-09-20 12:30:35,853 127.0.0.1 - - [20/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:35,982 Request with ID bb356d8d for model llama3-8b received
2024-09-20 12:30:35,983 127.0.0.1 - - [20/Sep/2024 12:30:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,047 Request with ID bd1239b2 for model llama3-8b received
2024-09-20 12:30:36,048 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,208 Request with ID 6181fe6d for model llama3-8b received
2024-09-20 12:30:36,208 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,243 Request with ID 67d0a38b for model llama3-8b received
2024-09-20 12:30:36,244 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,258 Request with ID a40f5ceb for model llama3-8b received
2024-09-20 12:30:36,258 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,264 Request with ID f208f09e for model llama3-8b received
2024-09-20 12:30:36,264 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,287 Request with ID 5998b27e for model granite-7b received
2024-09-20 12:30:36,287 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,292 Request with ID 918ba740 for model granite-7b received
2024-09-20 12:30:36,292 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,305 Request with ID 673fc77b for model llama3-8b received
2024-09-20 12:30:36,306 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,317 Request with ID 68c8df6c for model gemma-7b received
2024-09-20 12:30:36,318 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,563 Request with ID a74ef6d2 for model llama3-8b received
2024-09-20 12:30:36,564 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,862 Request with ID fc0f91d8 for model llama3-8b received
2024-09-20 12:30:36,862 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,914 Request with ID 7d618a78 for model llama3-8b received
2024-09-20 12:30:36,915 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,960 Request with ID 366040f5 for model llama3-8b received
2024-09-20 12:30:36,973 127.0.0.1 - - [20/Sep/2024 12:30:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:36,992 Processed batch: ['0ee5c476', 'a619c280', '6519ab61', '9e76851e', '753829ed', '14965229', 'e39128c2', '60467e45', 'd24d656a', '32d27a84', '4c3f9844', '82c37b35', 'f3f567c7', 'd13939a2', '1e264daf', '520b516f', '555772ce', '266c5f9e', '5ecb3d15', 'dd3c56dd', '596956a8', '24895b05', '0dc5c0d4', '1f7073c8', '6e6bca97', '177efa87', '40ff44ec', '14e4877b', '609d5ebc', '3e4f8578', '75b512d5', 'eda8e3fa', '35210733', '538f273c', '040cc27d', 'd5c1d7c3', '435cadfe', 'b9568136', '76f2c51f', 'bc378d41', '1e6d9e2e', 'e2d787eb', 'a8818bcd', '81a20373', 'f64df894', '13425702', 'ab80e15a', '9ce780dc', 'c628b9ca', '7315a12f', 'a081fd73', '7203e6e3', 'ed7b8d2b', '1f84abe8', 'a0604341', '51be2625', '8891c354', '3f635469', '97b911aa', 'e05eea92', '86517b15', 'f4f7d7ff', '14f32fc1', 'b8e78810'] with model gemma-7b in 7.5693 seconds
2024-09-20 12:30:36,992 Saving sys info
2024-09-20 12:30:37,025 Latency for request 0ee5c476 with model gemma-7b: 52.1130 seconds
2024-09-20 12:30:37,025 Saving results with gpu monitoring
2024-09-20 12:30:37,029 Latency for request a619c280 with model gemma-7b: 51.3400 seconds
2024-09-20 12:30:37,029 Saving results with gpu monitoring
2024-09-20 12:30:37,031 Latency for request 6519ab61 with model gemma-7b: 51.1560 seconds
2024-09-20 12:30:37,031 Saving results with gpu monitoring
2024-09-20 12:30:37,033 Latency for request 9e76851e with model gemma-7b: 50.6100 seconds
2024-09-20 12:30:37,033 Saving results with gpu monitoring
2024-09-20 12:30:37,035 Latency for request 753829ed with model gemma-7b: 50.6000 seconds
2024-09-20 12:30:37,035 Saving results with gpu monitoring
2024-09-20 12:30:37,037 Latency for request 14965229 with model gemma-7b: 50.5280 seconds
2024-09-20 12:30:37,037 Saving results with gpu monitoring
2024-09-20 12:30:37,039 Latency for request e39128c2 with model gemma-7b: 50.4950 seconds
2024-09-20 12:30:37,039 Saving results with gpu monitoring
2024-09-20 12:30:37,041 Latency for request 60467e45 with model gemma-7b: 50.4530 seconds
2024-09-20 12:30:37,041 Saving results with gpu monitoring
2024-09-20 12:30:37,043 Latency for request d24d656a with model gemma-7b: 50.2350 seconds
2024-09-20 12:30:37,043 Saving results with gpu monitoring
2024-09-20 12:30:37,045 Latency for request 32d27a84 with model gemma-7b: 49.5940 seconds
2024-09-20 12:30:37,045 Saving results with gpu monitoring
2024-09-20 12:30:37,047 Latency for request 4c3f9844 with model gemma-7b: 49.5090 seconds
2024-09-20 12:30:37,047 Saving results with gpu monitoring
2024-09-20 12:30:37,049 Latency for request 82c37b35 with model gemma-7b: 48.8870 seconds
2024-09-20 12:30:37,049 Saving results with gpu monitoring
2024-09-20 12:30:37,051 Latency for request f3f567c7 with model gemma-7b: 48.2950 seconds
2024-09-20 12:30:37,051 Saving results with gpu monitoring
2024-09-20 12:30:37,053 Latency for request d13939a2 with model gemma-7b: 48.2910 seconds
2024-09-20 12:30:37,053 Saving results with gpu monitoring
2024-09-20 12:30:37,055 Latency for request 1e264daf with model gemma-7b: 48.0870 seconds
2024-09-20 12:30:37,055 Saving results with gpu monitoring
2024-09-20 12:30:37,057 Latency for request 520b516f with model gemma-7b: 48.0750 seconds
2024-09-20 12:30:37,057 Saving results with gpu monitoring
2024-09-20 12:30:37,059 Latency for request 555772ce with model gemma-7b: 47.8400 seconds
2024-09-20 12:30:37,059 Saving results with gpu monitoring
2024-09-20 12:30:37,061 Latency for request 266c5f9e with model gemma-7b: 47.2040 seconds
2024-09-20 12:30:37,061 Saving results with gpu monitoring
2024-09-20 12:30:37,063 Latency for request 5ecb3d15 with model gemma-7b: 47.0770 seconds
2024-09-20 12:30:37,063 Saving results with gpu monitoring
2024-09-20 12:30:37,065 Latency for request dd3c56dd with model gemma-7b: 46.7030 seconds
2024-09-20 12:30:37,065 Saving results with gpu monitoring
2024-09-20 12:30:37,067 Latency for request 596956a8 with model gemma-7b: 46.3650 seconds
2024-09-20 12:30:37,067 Saving results with gpu monitoring
2024-09-20 12:30:37,069 Latency for request 24895b05 with model gemma-7b: 44.6710 seconds
2024-09-20 12:30:37,069 Saving results with gpu monitoring
2024-09-20 12:30:37,071 Latency for request 0dc5c0d4 with model gemma-7b: 44.4760 seconds
2024-09-20 12:30:37,071 Saving results with gpu monitoring
2024-09-20 12:30:37,073 Latency for request 1f7073c8 with model gemma-7b: 44.0730 seconds
2024-09-20 12:30:37,073 Saving results with gpu monitoring
2024-09-20 12:30:37,075 Latency for request 6e6bca97 with model gemma-7b: 43.8760 seconds
2024-09-20 12:30:37,075 Saving results with gpu monitoring
2024-09-20 12:30:37,077 Latency for request 177efa87 with model gemma-7b: 43.7250 seconds
2024-09-20 12:30:37,077 Saving results with gpu monitoring
2024-09-20 12:30:37,079 Latency for request 40ff44ec with model gemma-7b: 43.6980 seconds
2024-09-20 12:30:37,079 Saving results with gpu monitoring
2024-09-20 12:30:37,081 Latency for request 14e4877b with model gemma-7b: 43.4800 seconds
2024-09-20 12:30:37,081 Saving results with gpu monitoring
2024-09-20 12:30:37,083 Latency for request 609d5ebc with model gemma-7b: 43.4310 seconds
2024-09-20 12:30:37,083 Saving results with gpu monitoring
2024-09-20 12:30:37,085 Latency for request 3e4f8578 with model gemma-7b: 43.1840 seconds
2024-09-20 12:30:37,085 Saving results with gpu monitoring
2024-09-20 12:30:37,087 Latency for request 75b512d5 with model gemma-7b: 43.1720 seconds
2024-09-20 12:30:37,087 Saving results with gpu monitoring
2024-09-20 12:30:37,089 Latency for request eda8e3fa with model gemma-7b: 43.1520 seconds
2024-09-20 12:30:37,089 Saving results with gpu monitoring
2024-09-20 12:30:37,091 Latency for request 35210733 with model gemma-7b: 42.8200 seconds
2024-09-20 12:30:37,091 Saving results with gpu monitoring
2024-09-20 12:30:37,093 Latency for request 538f273c with model gemma-7b: 42.7300 seconds
2024-09-20 12:30:37,093 Saving results with gpu monitoring
2024-09-20 12:30:37,095 Latency for request 040cc27d with model gemma-7b: 42.0970 seconds
2024-09-20 12:30:37,095 Saving results with gpu monitoring
2024-09-20 12:30:37,097 Latency for request d5c1d7c3 with model gemma-7b: 41.3700 seconds
2024-09-20 12:30:37,097 Saving results with gpu monitoring
2024-09-20 12:30:37,099 Latency for request 435cadfe with model gemma-7b: 41.1730 seconds
2024-09-20 12:30:37,099 Saving results with gpu monitoring
2024-09-20 12:30:37,101 Latency for request b9568136 with model gemma-7b: 40.9980 seconds
2024-09-20 12:30:37,101 Saving results with gpu monitoring
2024-09-20 12:30:37,103 Latency for request 76f2c51f with model gemma-7b: 40.6210 seconds
2024-09-20 12:30:37,103 Saving results with gpu monitoring
2024-09-20 12:30:37,105 Latency for request bc378d41 with model gemma-7b: 39.9050 seconds
2024-09-20 12:30:37,105 Saving results with gpu monitoring
2024-09-20 12:30:37,107 Latency for request 1e6d9e2e with model gemma-7b: 39.7590 seconds
2024-09-20 12:30:37,107 Saving results with gpu monitoring
2024-09-20 12:30:37,109 Latency for request e2d787eb with model gemma-7b: 38.8440 seconds
2024-09-20 12:30:37,109 Saving results with gpu monitoring
2024-09-20 12:30:37,111 Latency for request a8818bcd with model gemma-7b: 38.4600 seconds
2024-09-20 12:30:37,111 Saving results with gpu monitoring
2024-09-20 12:30:37,113 Latency for request 81a20373 with model gemma-7b: 38.2860 seconds
2024-09-20 12:30:37,113 Saving results with gpu monitoring
2024-09-20 12:30:37,115 Latency for request f64df894 with model gemma-7b: 38.1220 seconds
2024-09-20 12:30:37,115 Saving results with gpu monitoring
2024-09-20 12:30:37,117 Latency for request 13425702 with model gemma-7b: 37.8070 seconds
2024-09-20 12:30:37,117 Saving results with gpu monitoring
2024-09-20 12:30:37,119 Latency for request ab80e15a with model gemma-7b: 37.4760 seconds
2024-09-20 12:30:37,119 Saving results with gpu monitoring
2024-09-20 12:30:37,121 Latency for request 9ce780dc with model gemma-7b: 37.2510 seconds
2024-09-20 12:30:37,121 Saving results with gpu monitoring
2024-09-20 12:30:37,123 Latency for request c628b9ca with model gemma-7b: 37.0340 seconds
2024-09-20 12:30:37,123 Saving results with gpu monitoring
2024-09-20 12:30:37,125 Latency for request 7315a12f with model gemma-7b: 36.7560 seconds
2024-09-20 12:30:37,125 Saving results with gpu monitoring
2024-09-20 12:30:37,127 Latency for request a081fd73 with model gemma-7b: 36.5330 seconds
2024-09-20 12:30:37,127 Saving results with gpu monitoring
2024-09-20 12:30:37,129 Latency for request 7203e6e3 with model gemma-7b: 36.4900 seconds
2024-09-20 12:30:37,129 Saving results with gpu monitoring
2024-09-20 12:30:37,131 Latency for request ed7b8d2b with model gemma-7b: 36.2410 seconds
2024-09-20 12:30:37,131 Saving results with gpu monitoring
2024-09-20 12:30:37,133 Latency for request 1f84abe8 with model gemma-7b: 35.9900 seconds
2024-09-20 12:30:37,133 Saving results with gpu monitoring
2024-09-20 12:30:37,135 Latency for request a0604341 with model gemma-7b: 35.9670 seconds
2024-09-20 12:30:37,135 Saving results with gpu monitoring
2024-09-20 12:30:37,137 Latency for request 51be2625 with model gemma-7b: 35.9630 seconds
2024-09-20 12:30:37,137 Saving results with gpu monitoring
2024-09-20 12:30:37,139 Latency for request 8891c354 with model gemma-7b: 35.1850 seconds
2024-09-20 12:30:37,139 Saving results with gpu monitoring
2024-09-20 12:30:37,141 Latency for request 3f635469 with model gemma-7b: 34.8380 seconds
2024-09-20 12:30:37,141 Saving results with gpu monitoring
2024-09-20 12:30:37,143 Latency for request 97b911aa with model gemma-7b: 34.7660 seconds
2024-09-20 12:30:37,143 Saving results with gpu monitoring
2024-09-20 12:30:37,145 Latency for request e05eea92 with model gemma-7b: 33.8600 seconds
2024-09-20 12:30:37,145 Saving results with gpu monitoring
2024-09-20 12:30:37,147 Latency for request 86517b15 with model gemma-7b: 33.8520 seconds
2024-09-20 12:30:37,147 Saving results with gpu monitoring
2024-09-20 12:30:37,149 Latency for request f4f7d7ff with model gemma-7b: 33.7670 seconds
2024-09-20 12:30:37,149 Saving results with gpu monitoring
2024-09-20 12:30:37,151 Latency for request 14f32fc1 with model gemma-7b: 33.7390 seconds
2024-09-20 12:30:37,151 Saving results with gpu monitoring
2024-09-20 12:30:37,153 Latency for request b8e78810 with model gemma-7b: 33.4480 seconds
2024-09-20 12:30:37,153 Saving results with gpu monitoring
2024-09-20 12:30:37,156 127.0.0.1 - - [20/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:37,156 Next: call load_model for llama3-8b
2024-09-20 12:30:37,276 Unloaded previous model
2024-09-20 12:30:37,491 Request with ID 41cbcbd8 for model llama3-8b received
2024-09-20 12:30:37,494 127.0.0.1 - - [20/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:37,496 Request with ID a179dd57 for model gemma-7b received
2024-09-20 12:30:37,496 Adjusted batch time limit for gemma-7b: 5.0000 seconds
2024-09-20 12:30:37,497 127.0.0.1 - - [20/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:37,713 Request with ID 8f24b7cf for model llama3-8b received
2024-09-20 12:30:37,720 127.0.0.1 - - [20/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:37,898 Request with ID 01006e54 for model gemma-7b received
2024-09-20 12:30:37,902 Moving batch for gemma-7b from incoming to running due to dynamic batch size 32
2024-09-20 12:30:37,910 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:30:37,930 Request with ID dfebf086 for model gemma-7b received
2024-09-20 12:30:37,930 127.0.0.1 - - [20/Sep/2024 12:30:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:38,122 Request with ID 2677124e for model granite-7b received
2024-09-20 12:30:38,127 Request with ID 50118672 for model llama3-8b received
2024-09-20 12:30:38,128 127.0.0.1 - - [20/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:38,134 127.0.0.1 - - [20/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:38,318 Request with ID 9d3d35d0 for model granite-7b received
2024-09-20 12:30:38,322 127.0.0.1 - - [20/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:38,504 Request with ID 4db3153d for model llama3-8b received
2024-09-20 12:30:38,504 127.0.0.1 - - [20/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:38,536 Request with ID 34cf30ed for model gemma-7b received
2024-09-20 12:30:38,542 127.0.0.1 - - [20/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:38,545 Request with ID 887a5b3a for model llama3-8b received
2024-09-20 12:30:38,548 127.0.0.1 - - [20/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:38,705 Request with ID 713063e5 for model granite-7b received
2024-09-20 12:30:38,810 127.0.0.1 - - [20/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:38,812 Request with ID 55f73226 for model llama3-8b received
2024-09-20 12:30:38,812 127.0.0.1 - - [20/Sep/2024 12:30:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,021 Request with ID bbcb0412 for model llama3-8b received
2024-09-20 12:30:39,021 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,100 Request with ID 95581208 for model gemma-7b received
2024-09-20 12:30:39,101 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,126 Request with ID 63fd9a33 for model llama3-8b received
2024-09-20 12:30:39,127 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,166 Request with ID 7a678bd0 for model llama3-8b received
2024-09-20 12:30:39,166 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,268 Request with ID eaca9402 for model gemma-7b received
2024-09-20 12:30:39,269 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,373 Request with ID e0d1a06f for model llama3-8b received
2024-09-20 12:30:39,374 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,416 Request with ID 3788eaee for model llama3-8b received
2024-09-20 12:30:39,416 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,423 Request with ID 7b1a613b for model granite-7b received
2024-09-20 12:30:39,424 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,441 Request with ID 2d3553b0 for model llama3-8b received
2024-09-20 12:30:39,441 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,469 Request with ID c41e4e17 for model llama3-8b received
2024-09-20 12:30:39,469 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,505 Request with ID a628c5eb for model gemma-7b received
2024-09-20 12:30:39,506 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,805 Request with ID 426428c0 for model granite-7b received
2024-09-20 12:30:39,805 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:30:39,806 Dynamic batch size condition met for model granite-7b
2024-09-20 12:30:39,839 Request with ID 81aed6cd for model llama3-8b received
2024-09-20 12:30:39,839 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:30:39,840 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:30:39,923 Request with ID 351b888a for model llama3-8b received
2024-09-20 12:30:39,924 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:39,946 Request with ID b657b1b1 for model llama3-8b received
2024-09-20 12:30:39,947 127.0.0.1 - - [20/Sep/2024 12:30:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:40,346 Request with ID 73e5009f for model llama3-8b received
2024-09-20 12:30:40,347 127.0.0.1 - - [20/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:40,374 Request with ID c4540a06 for model gemma-7b received
2024-09-20 12:30:40,374 127.0.0.1 - - [20/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:40,478 Request with ID 67245397 for model llama3-8b received
2024-09-20 12:30:40,478 127.0.0.1 - - [20/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:40,604 Request with ID d384e49e for model gemma-7b received
2024-09-20 12:30:40,604 127.0.0.1 - - [20/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:40,662 Request with ID 04f43ab0 for model granite-7b received
2024-09-20 12:30:40,663 127.0.0.1 - - [20/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:40,761 Request with ID cfa3dd4a for model gemma-7b received
2024-09-20 12:30:40,762 127.0.0.1 - - [20/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:40,921 Request with ID 9d51690b for model llama3-8b received
2024-09-20 12:30:40,922 127.0.0.1 - - [20/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:40,996 Request with ID 7bfb2e8e for model llama3-8b received
2024-09-20 12:30:40,997 127.0.0.1 - - [20/Sep/2024 12:30:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,014 Request with ID 9d9b644c for model llama3-8b received
2024-09-20 12:30:41,014 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,054 Request with ID 1091b76c for model llama3-8b received
2024-09-20 12:30:41,055 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,165 Request with ID 6eae66bd for model llama3-8b received
2024-09-20 12:30:41,166 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,311 Request with ID 205f238e for model llama3-8b received
2024-09-20 12:30:41,312 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,314 Request with ID ba557b3e for model llama3-8b received
2024-09-20 12:30:41,314 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,362 Request with ID 02a3b0fd for model llama3-8b received
2024-09-20 12:30:41,363 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,382 Request with ID 84b27de8 for model granite-7b received
2024-09-20 12:30:41,383 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,440 Request with ID f968fde0 for model llama3-8b received
2024-09-20 12:30:41,440 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,550 Request with ID e02c92a2 for model llama3-8b received
2024-09-20 12:30:41,551 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,568 Request with ID 53791caa for model llama3-8b received
2024-09-20 12:30:41,569 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,638 Request with ID d4e724ff for model llama3-8b received
2024-09-20 12:30:41,639 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,686 Request with ID 24f82029 for model granite-7b received
2024-09-20 12:30:41,686 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,689 Request with ID 07fbdf69 for model llama3-8b received
2024-09-20 12:30:41,690 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,742 Request with ID ef4c5940 for model gemma-7b received
2024-09-20 12:30:41,743 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:41,850 Request with ID cef27768 for model llama3-8b received
2024-09-20 12:30:41,851 127.0.0.1 - - [20/Sep/2024 12:30:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:42,062 Request with ID 3299fc5f for model gemma-7b received
2024-09-20 12:30:42,062 127.0.0.1 - - [20/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:42,135 Request with ID 890578a8 for model granite-7b received
2024-09-20 12:30:42,135 127.0.0.1 - - [20/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:42,138 Request with ID d5217772 for model gemma-7b received
2024-09-20 12:30:42,138 127.0.0.1 - - [20/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:42,254 Request with ID e99f2356 for model llama3-8b received
2024-09-20 12:30:42,255 127.0.0.1 - - [20/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:42,343 Request with ID a7bc5019 for model llama3-8b received
2024-09-20 12:30:42,344 127.0.0.1 - - [20/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:42,401 Request with ID 4d8e4904 for model gemma-7b received
2024-09-20 12:30:42,401 127.0.0.1 - - [20/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:42,628 Request with ID 977e75ea for model llama3-8b received
2024-09-20 12:30:42,628 127.0.0.1 - - [20/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:42,774 Request with ID 3660e634 for model llama3-8b received
2024-09-20 12:30:42,774 127.0.0.1 - - [20/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:42,854 Request with ID 9ca5acfb for model gemma-7b received
2024-09-20 12:30:42,854 127.0.0.1 - - [20/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:42,890 Request with ID 1e896cf3 for model llama3-8b received
2024-09-20 12:30:42,890 127.0.0.1 - - [20/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:42,914 Request with ID b297afd8 for model granite-7b received
2024-09-20 12:30:42,915 127.0.0.1 - - [20/Sep/2024 12:30:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,199 Request with ID 8b936b10 for model llama3-8b received
2024-09-20 12:30:43,200 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,367 Request with ID d32acadc for model granite-7b received
2024-09-20 12:30:43,368 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,499 Request with ID f119f0ef for model llama3-8b received
2024-09-20 12:30:43,499 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,608 Request with ID 938eca6b for model llama3-8b received
2024-09-20 12:30:43,608 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,686 Request with ID f0102a01 for model llama3-8b received
2024-09-20 12:30:43,687 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,738 Request with ID b34b4972 for model llama3-8b received
2024-09-20 12:30:43,739 Request with ID 21eb075f for model llama3-8b received
2024-09-20 12:30:43,740 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,740 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,744 Request with ID 2105500d for model gemma-7b received
2024-09-20 12:30:43,745 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,769 Request with ID 18f06937 for model gemma-7b received
2024-09-20 12:30:43,770 Request with ID e6840d61 for model gemma-7b received
2024-09-20 12:30:43,770 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,771 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,809 Request with ID a5060c5b for model llama3-8b received
2024-09-20 12:30:43,809 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,865 Request with ID fa2097e6 for model llama3-8b received
2024-09-20 12:30:43,865 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:43,902 Request with ID 7ae2490c for model llama3-8b received
2024-09-20 12:30:43,902 127.0.0.1 - - [20/Sep/2024 12:30:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:44,073 Request with ID 396975b4 for model gemma-7b received
2024-09-20 12:30:44,074 127.0.0.1 - - [20/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:44,116 Request with ID 8a535a93 for model llama3-8b received
2024-09-20 12:30:44,116 127.0.0.1 - - [20/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:44,141 Request with ID f8e57960 for model gemma-7b received
2024-09-20 12:30:44,141 127.0.0.1 - - [20/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:44,234 Request with ID 57bcf1ea for model granite-7b received
2024-09-20 12:30:44,234 127.0.0.1 - - [20/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:44,314 Request with ID 8c82f52f for model gemma-7b received
2024-09-20 12:30:44,314 127.0.0.1 - - [20/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:44,467 Request with ID 813d1e8e for model gemma-7b received
2024-09-20 12:30:44,467 127.0.0.1 - - [20/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:44,640 Request with ID 4215d51d for model gemma-7b received
2024-09-20 12:30:44,641 127.0.0.1 - - [20/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:44,694 Request with ID e47af50d for model llama3-8b received
2024-09-20 12:30:44,695 127.0.0.1 - - [20/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:44,713 Request with ID 85274a95 for model llama3-8b received
2024-09-20 12:30:44,714 127.0.0.1 - - [20/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:44,893 Request with ID 72a4d905 for model gemma-7b received
2024-09-20 12:30:44,894 127.0.0.1 - - [20/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:44,904 Request with ID 9ef76482 for model llama3-8b received
2024-09-20 12:30:44,904 127.0.0.1 - - [20/Sep/2024 12:30:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:45,037 Request with ID a7982bad for model gemma-7b received
2024-09-20 12:30:45,038 127.0.0.1 - - [20/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:45,040 Request with ID 6d4c0d6f for model gemma-7b received
2024-09-20 12:30:45,041 127.0.0.1 - - [20/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:45,085 Request with ID c8867ddd for model llama3-8b received
2024-09-20 12:30:45,085 127.0.0.1 - - [20/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:45,103 Request with ID f2330178 for model llama3-8b received
2024-09-20 12:30:45,103 127.0.0.1 - - [20/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:45,188 Request with ID fc5e2c2a for model llama3-8b received
2024-09-20 12:30:45,188 127.0.0.1 - - [20/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:45,236 Request with ID 6533998a for model gemma-7b received
2024-09-20 12:30:45,237 127.0.0.1 - - [20/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:45,475 Request with ID 7a89c3db for model granite-7b received
2024-09-20 12:30:45,476 127.0.0.1 - - [20/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:45,659 Request with ID c15cc2f2 for model llama3-8b received
2024-09-20 12:30:45,660 127.0.0.1 - - [20/Sep/2024 12:30:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:46,014 Request with ID 43306884 for model granite-7b received
2024-09-20 12:30:46,015 127.0.0.1 - - [20/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:46,098 Request with ID bd416383 for model llama3-8b received
2024-09-20 12:30:46,098 127.0.0.1 - - [20/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:46,441 Request with ID dc56d131 for model llama3-8b received
2024-09-20 12:30:46,442 127.0.0.1 - - [20/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:46,641 Request with ID 7d1a5e15 for model llama3-8b received
2024-09-20 12:30:46,642 127.0.0.1 - - [20/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:46,768 Request with ID 645af5e0 for model gemma-7b received
2024-09-20 12:30:46,769 127.0.0.1 - - [20/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:46,783 Request with ID b95d9c08 for model llama3-8b received
2024-09-20 12:30:46,783 127.0.0.1 - - [20/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:46,899 Request with ID dc39877b for model llama3-8b received
2024-09-20 12:30:46,899 127.0.0.1 - - [20/Sep/2024 12:30:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:47,012 Request with ID 551da0db for model gemma-7b received
2024-09-20 12:30:47,012 127.0.0.1 - - [20/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:47,112 Request with ID 0a016eef for model llama3-8b received
2024-09-20 12:30:47,112 127.0.0.1 - - [20/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:47,515 Request with ID c79b2f0f for model gemma-7b received
2024-09-20 12:30:47,515 127.0.0.1 - - [20/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:47,532 Request with ID a949085d for model granite-7b received
2024-09-20 12:30:47,533 127.0.0.1 - - [20/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:47,584 Request with ID 920cd38c for model gemma-7b received
2024-09-20 12:30:47,585 127.0.0.1 - - [20/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:47,683 Request with ID cca4c1e7 for model llama3-8b received
2024-09-20 12:30:47,684 127.0.0.1 - - [20/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:47,736 Request with ID 8978194c for model gemma-7b received
2024-09-20 12:30:47,736 127.0.0.1 - - [20/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:47,781 Request with ID b1c8fe57 for model llama3-8b received
2024-09-20 12:30:47,781 127.0.0.1 - - [20/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:47,899 Request with ID b21b2fad for model gemma-7b received
2024-09-20 12:30:47,900 127.0.0.1 - - [20/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:47,948 Request with ID 8cc60498 for model llama3-8b received
2024-09-20 12:30:47,949 127.0.0.1 - - [20/Sep/2024 12:30:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:48,083 Request with ID 0d929d84 for model gemma-7b received
2024-09-20 12:30:48,083 127.0.0.1 - - [20/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:48,139 Request with ID b5d5df43 for model llama3-8b received
2024-09-20 12:30:48,139 127.0.0.1 - - [20/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:48,604 Request with ID ab0dec3d for model gemma-7b received
2024-09-20 12:30:48,605 127.0.0.1 - - [20/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:48,663 Request with ID e64947ce for model granite-7b received
2024-09-20 12:30:48,663 127.0.0.1 - - [20/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:48,723 Request with ID 5dbbd443 for model gemma-7b received
2024-09-20 12:30:48,724 127.0.0.1 - - [20/Sep/2024 12:30:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:49,080 Request with ID 271be755 for model llama3-8b received
2024-09-20 12:30:49,080 127.0.0.1 - - [20/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:49,163 Request with ID 6f6f222c for model llama3-8b received
2024-09-20 12:30:49,163 127.0.0.1 - - [20/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:49,206 Request with ID 5a39aa1c for model llama3-8b received
2024-09-20 12:30:49,207 127.0.0.1 - - [20/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:49,343 Request with ID 9ddd6d27 for model gemma-7b received
2024-09-20 12:30:49,344 127.0.0.1 - - [20/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:49,453 Request with ID d3f60466 for model gemma-7b received
2024-09-20 12:30:49,454 127.0.0.1 - - [20/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:49,546 Request with ID 3c0cca34 for model granite-7b received
2024-09-20 12:30:49,547 127.0.0.1 - - [20/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:49,851 Request with ID 44cd313e for model llama3-8b received
2024-09-20 12:30:49,851 127.0.0.1 - - [20/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:49,913 Request with ID 8eb2e2c5 for model llama3-8b received
2024-09-20 12:30:49,914 127.0.0.1 - - [20/Sep/2024 12:30:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:50,038 Request with ID d064f124 for model gemma-7b received
2024-09-20 12:30:50,039 127.0.0.1 - - [20/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:50,153 Request with ID 9fd8535f for model llama3-8b received
2024-09-20 12:30:50,153 127.0.0.1 - - [20/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:50,242 Request with ID 60c7bc2f for model gemma-7b received
2024-09-20 12:30:50,242 127.0.0.1 - - [20/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:50,335 Request with ID 6494c9d2 for model gemma-7b received
2024-09-20 12:30:50,335 127.0.0.1 - - [20/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:50,348 Request with ID 1f567e97 for model gemma-7b received
2024-09-20 12:30:50,348 127.0.0.1 - - [20/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:50,643 Request with ID 9656497e for model llama3-8b received
2024-09-20 12:30:50,644 Request with ID 1b6450dc for model llama3-8b received
2024-09-20 12:30:50,644 127.0.0.1 - - [20/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:50,644 127.0.0.1 - - [20/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:50,766 Request with ID 7ca4cf5d for model granite-7b received
2024-09-20 12:30:50,767 127.0.0.1 - - [20/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:50,866 Request with ID d6dca4cb for model llama3-8b received
2024-09-20 12:30:50,867 127.0.0.1 - - [20/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:50,897 Request with ID 2410e004 for model llama3-8b received
2024-09-20 12:30:50,897 127.0.0.1 - - [20/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:50,950 Request with ID 92aafe2e for model gemma-7b received
2024-09-20 12:30:50,951 127.0.0.1 - - [20/Sep/2024 12:30:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:51,064 Request with ID b7498106 for model llama3-8b received
2024-09-20 12:30:51,064 127.0.0.1 - - [20/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:51,135 Request with ID e143e259 for model llama3-8b received
2024-09-20 12:30:51,135 127.0.0.1 - - [20/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:51,145 Request with ID d0610bd2 for model llama3-8b received
2024-09-20 12:30:51,145 127.0.0.1 - - [20/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:51,204 Request with ID e6c4f747 for model llama3-8b received
2024-09-20 12:30:51,204 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:30:51,204 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:30:51,335 Request with ID dcbf8036 for model gemma-7b received
2024-09-20 12:30:51,335 127.0.0.1 - - [20/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:51,416 Request with ID 6406b5f9 for model gemma-7b received
2024-09-20 12:30:51,416 127.0.0.1 - - [20/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:51,543 Request with ID 3133346b for model gemma-7b received
2024-09-20 12:30:51,543 127.0.0.1 - - [20/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:51,757 Request with ID 6723b679 for model llama3-8b received
2024-09-20 12:30:51,758 127.0.0.1 - - [20/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:51,760 Request with ID 3136567c for model granite-7b received
2024-09-20 12:30:51,760 127.0.0.1 - - [20/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:51,770 Request with ID dc11d249 for model granite-7b received
2024-09-20 12:30:51,771 127.0.0.1 - - [20/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:51,832 Request with ID e4785413 for model llama3-8b received
2024-09-20 12:30:51,834 127.0.0.1 - - [20/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:51,924 Request with ID 2d18a941 for model llama3-8b received
2024-09-20 12:30:51,925 127.0.0.1 - - [20/Sep/2024 12:30:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,108 Request with ID bbb4513e for model gemma-7b received
2024-09-20 12:30:52,109 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,177 Request with ID b371ebb7 for model llama3-8b received
2024-09-20 12:30:52,178 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,209 Request with ID a8d67a69 for model llama3-8b received
2024-09-20 12:30:52,209 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,217 Request with ID 0e1e2ada for model llama3-8b received
2024-09-20 12:30:52,217 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,242 Request with ID 549fb3fe for model gemma-7b received
2024-09-20 12:30:52,242 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,290 Request with ID 9b8c6b21 for model llama3-8b received
2024-09-20 12:30:52,291 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,295 Request with ID 3a22c700 for model llama3-8b received
2024-09-20 12:30:52,296 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,397 Request with ID a052f83e for model llama3-8b received
2024-09-20 12:30:52,398 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,457 Request with ID c169520d for model llama3-8b received
2024-09-20 12:30:52,459 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,465 Request with ID 83517b93 for model gemma-7b received
2024-09-20 12:30:52,465 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,525 Request with ID 97fed10f for model gemma-7b received
2024-09-20 12:30:52,526 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,598 Request with ID 652473cc for model llama3-8b received
2024-09-20 12:30:52,598 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,862 Request with ID 192f4c9c for model llama3-8b received
2024-09-20 12:30:52,863 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,863 Request with ID 4207e47c for model gemma-7b received
2024-09-20 12:30:52,864 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:52,881 Request with ID 3f53d64b for model llama3-8b received
2024-09-20 12:30:52,881 127.0.0.1 - - [20/Sep/2024 12:30:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:53,038 Request with ID b2622677 for model llama3-8b received
2024-09-20 12:30:53,038 127.0.0.1 - - [20/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:53,167 Request with ID e5963cef for model llama3-8b received
2024-09-20 12:30:53,167 127.0.0.1 - - [20/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:53,333 Request with ID af9c115c for model gemma-7b received
2024-09-20 12:30:53,333 127.0.0.1 - - [20/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:53,481 Request with ID 81d979f0 for model llama3-8b received
2024-09-20 12:30:53,482 127.0.0.1 - - [20/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:53,484 Request with ID c15e310d for model llama3-8b received
2024-09-20 12:30:53,484 127.0.0.1 - - [20/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:53,566 Request with ID 2136f6a1 for model gemma-7b received
2024-09-20 12:30:53,566 127.0.0.1 - - [20/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:53,733 Request with ID 21febf62 for model llama3-8b received
2024-09-20 12:30:53,733 127.0.0.1 - - [20/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:53,780 Request with ID fc8e6f07 for model llama3-8b received
2024-09-20 12:30:53,781 127.0.0.1 - - [20/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:53,992 Request with ID 2f25cf66 for model llama3-8b received
2024-09-20 12:30:53,993 127.0.0.1 - - [20/Sep/2024 12:30:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:54,000 Request with ID 11dd0071 for model llama3-8b received
2024-09-20 12:30:54,001 127.0.0.1 - - [20/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:54,024 Request with ID bbd61659 for model llama3-8b received
2024-09-20 12:30:54,024 127.0.0.1 - - [20/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:54,222 Request with ID f7807586 for model llama3-8b received
2024-09-20 12:30:54,223 127.0.0.1 - - [20/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:54,277 Request with ID 7beff5b2 for model llama3-8b received
2024-09-20 12:30:54,277 127.0.0.1 - - [20/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:54,334 Request with ID 408c8e2b for model llama3-8b received
2024-09-20 12:30:54,334 127.0.0.1 - - [20/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:54,468 Request with ID d0ca5eda for model gemma-7b received
2024-09-20 12:30:54,468 127.0.0.1 - - [20/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:54,477 Request with ID f251ec40 for model llama3-8b received
2024-09-20 12:30:54,477 127.0.0.1 - - [20/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:54,612 Request with ID d36262b6 for model gemma-7b received
2024-09-20 12:30:54,612 127.0.0.1 - - [20/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:54,656 Request with ID 8d657f4d for model gemma-7b received
2024-09-20 12:30:54,656 127.0.0.1 - - [20/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:54,732 Request with ID dbf5d8d7 for model gemma-7b received
2024-09-20 12:30:54,733 127.0.0.1 - - [20/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:54,872 Request with ID f7af5f8a for model llama3-8b received
2024-09-20 12:30:54,873 127.0.0.1 - - [20/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:54,955 Request with ID edd77547 for model llama3-8b received
2024-09-20 12:30:54,956 127.0.0.1 - - [20/Sep/2024 12:30:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:55,009 Request with ID d4b2d09b for model gemma-7b received
2024-09-20 12:30:55,010 127.0.0.1 - - [20/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:55,082 Request with ID b0b297cb for model llama3-8b received
2024-09-20 12:30:55,082 127.0.0.1 - - [20/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:55,170 Request with ID d6165c10 for model llama3-8b received
2024-09-20 12:30:55,170 127.0.0.1 - - [20/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:55,184 Request with ID b26a3c8c for model llama3-8b received
2024-09-20 12:30:55,184 127.0.0.1 - - [20/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:55,458 Request with ID 58e3fdf2 for model gemma-7b received
2024-09-20 12:30:55,458 127.0.0.1 - - [20/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:55,578 Request with ID 1e44704d for model gemma-7b received
2024-09-20 12:30:55,578 127.0.0.1 - - [20/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:55,725 Request with ID 3d127a20 for model llama3-8b received
2024-09-20 12:30:55,726 127.0.0.1 - - [20/Sep/2024 12:30:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:56,030 Request with ID 3d02e6e4 for model granite-7b received
2024-09-20 12:30:56,030 Moving batch for granite-7b from incoming to running due to dynamic batch size 16
2024-09-20 12:30:56,030 Dynamic batch size condition met for model granite-7b
2024-09-20 12:30:56,251 Request with ID 8f8a3d19 for model llama3-8b received
2024-09-20 12:30:56,252 127.0.0.1 - - [20/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:56,272 Request with ID 3a1df330 for model llama3-8b received
2024-09-20 12:30:56,273 127.0.0.1 - - [20/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:56,303 Request with ID 99bf3d4e for model llama3-8b received
2024-09-20 12:30:56,304 127.0.0.1 - - [20/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:56,425 Request with ID 2b4ee40c for model llama3-8b received
2024-09-20 12:30:56,425 127.0.0.1 - - [20/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:56,599 Request with ID ad3f3b00 for model gemma-7b received
2024-09-20 12:30:56,599 127.0.0.1 - - [20/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:56,758 Request with ID 5496eb7d for model llama3-8b received
2024-09-20 12:30:56,758 127.0.0.1 - - [20/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:56,932 Request with ID f581e14a for model llama3-8b received
2024-09-20 12:30:56,933 127.0.0.1 - - [20/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:56,935 Request with ID df31e817 for model llama3-8b received
2024-09-20 12:30:56,936 127.0.0.1 - - [20/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:56,938 Request with ID 1f6248d9 for model gemma-7b received
2024-09-20 12:30:56,939 127.0.0.1 - - [20/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:56,943 Request with ID 4428077b for model llama3-8b received
2024-09-20 12:30:56,944 127.0.0.1 - - [20/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:56,951 Request with ID 26db50f2 for model llama3-8b received
2024-09-20 12:30:56,952 127.0.0.1 - - [20/Sep/2024 12:30:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,026 Request with ID 4aa3e0c1 for model llama3-8b received
2024-09-20 12:30:57,027 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,110 Request with ID 9a9b360b for model granite-7b received
2024-09-20 12:30:57,110 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,242 Request with ID 12fdca9d for model granite-7b received
2024-09-20 12:30:57,242 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,289 Request with ID bce595e9 for model gemma-7b received
2024-09-20 12:30:57,289 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,295 Request with ID d1f3133d for model granite-7b received
2024-09-20 12:30:57,295 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,320 Request with ID 0c8c1e60 for model llama3-8b received
2024-09-20 12:30:57,321 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,368 Request with ID aaeeea5a for model llama3-8b received
2024-09-20 12:30:57,369 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,518 Request with ID dd11fd74 for model granite-7b received
2024-09-20 12:30:57,519 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,607 Request with ID 8cab1521 for model llama3-8b received
2024-09-20 12:30:57,608 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,682 Request with ID eedd9603 for model llama3-8b received
2024-09-20 12:30:57,682 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,757 Request with ID 08e43c77 for model llama3-8b received
2024-09-20 12:30:57,757 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,848 Loaded model llama3-8b
2024-09-20 12:30:57,851 Batch processing started for model llama3-8b
2024-09-20 12:30:57,894 Request with ID da4a9ffa for model llama3-8b received
2024-09-20 12:30:57,895 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:57,938 Request with ID 8e09214f for model llama3-8b received
2024-09-20 12:30:57,938 127.0.0.1 - - [20/Sep/2024 12:30:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:58,178 Request with ID bb83c031 for model llama3-8b received
2024-09-20 12:30:58,179 127.0.0.1 - - [20/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:58,287 Request with ID 3d56aee5 for model llama3-8b received
2024-09-20 12:30:58,288 127.0.0.1 - - [20/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:58,367 Request with ID f56e15c9 for model llama3-8b received
2024-09-20 12:30:58,367 127.0.0.1 - - [20/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:58,494 Request with ID ed21b50c for model gemma-7b received
2024-09-20 12:30:58,494 127.0.0.1 - - [20/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:58,522 Request with ID da74a096 for model llama3-8b received
2024-09-20 12:30:58,522 127.0.0.1 - - [20/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:58,727 Request with ID 8a022d2e for model llama3-8b received
2024-09-20 12:30:58,727 127.0.0.1 - - [20/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:58,750 Request with ID 53f26e5c for model llama3-8b received
2024-09-20 12:30:58,750 127.0.0.1 - - [20/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:58,860 Request with ID fbcbed59 for model gemma-7b received
2024-09-20 12:30:58,860 127.0.0.1 - - [20/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:58,980 Request with ID aecb61ba for model llama3-8b received
2024-09-20 12:30:58,980 127.0.0.1 - - [20/Sep/2024 12:30:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:59,119 Request with ID 1d8f24cd for model gemma-7b received
2024-09-20 12:30:59,119 Moving batch for gemma-7b from incoming to running due to dynamic batch size 64
2024-09-20 12:30:59,120 Dynamic batch size condition met for model gemma-7b
2024-09-20 12:30:59,153 Request with ID b8d2e4c6 for model llama3-8b received
2024-09-20 12:30:59,154 127.0.0.1 - - [20/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:59,187 Request with ID a7d0a242 for model llama3-8b received
2024-09-20 12:30:59,187 127.0.0.1 - - [20/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:59,219 Request with ID 69b81607 for model llama3-8b received
2024-09-20 12:30:59,219 127.0.0.1 - - [20/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:59,284 Request with ID a52070a9 for model llama3-8b received
2024-09-20 12:30:59,284 127.0.0.1 - - [20/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:59,434 Request with ID 76844a80 for model gemma-7b received
2024-09-20 12:30:59,434 127.0.0.1 - - [20/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:59,459 Request with ID 45f7cdf1 for model llama3-8b received
2024-09-20 12:30:59,460 127.0.0.1 - - [20/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:59,680 Request with ID 6676b2a4 for model llama3-8b received
2024-09-20 12:30:59,681 127.0.0.1 - - [20/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:59,685 Request with ID b6249400 for model llama3-8b received
2024-09-20 12:30:59,686 127.0.0.1 - - [20/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:59,742 Request with ID 62a55c03 for model llama3-8b received
2024-09-20 12:30:59,743 Moving batch for llama3-8b from incoming to running due to dynamic batch size 64
2024-09-20 12:30:59,743 Dynamic batch size condition met for model llama3-8b
2024-09-20 12:30:59,784 Request with ID 4e3be2db for model llama3-8b received
2024-09-20 12:30:59,784 127.0.0.1 - - [20/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:30:59,961 Request with ID fdca8cfa for model llama3-8b received
2024-09-20 12:30:59,961 127.0.0.1 - - [20/Sep/2024 12:30:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:00,305 Request with ID 16765244 for model llama3-8b received
2024-09-20 12:31:00,306 127.0.0.1 - - [20/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:00,346 Request with ID e5ce61ad for model llama3-8b received
2024-09-20 12:31:00,347 127.0.0.1 - - [20/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:00,544 Request with ID cbeaed22 for model llama3-8b received
2024-09-20 12:31:00,544 127.0.0.1 - - [20/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:00,630 Request with ID c9f4d33f for model llama3-8b received
2024-09-20 12:31:00,631 127.0.0.1 - - [20/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:00,853 Request with ID b6543892 for model llama3-8b received
2024-09-20 12:31:00,854 127.0.0.1 - - [20/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:00,855 Request with ID c3438565 for model llama3-8b received
2024-09-20 12:31:00,856 127.0.0.1 - - [20/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:00,882 Request with ID 1b84bf99 for model granite-7b received
2024-09-20 12:31:00,882 127.0.0.1 - - [20/Sep/2024 12:31:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:01,133 Request with ID f2e95469 for model gemma-7b received
2024-09-20 12:31:01,133 127.0.0.1 - - [20/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:01,147 Request with ID 613f3d23 for model granite-7b received
2024-09-20 12:31:01,148 127.0.0.1 - - [20/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:01,429 Request with ID 7d582da2 for model llama3-8b received
2024-09-20 12:31:01,429 127.0.0.1 - - [20/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:01,519 Request with ID bfeee139 for model llama3-8b received
2024-09-20 12:31:01,519 127.0.0.1 - - [20/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:01,663 Request with ID 5bb7adf1 for model gemma-7b received
2024-09-20 12:31:01,663 127.0.0.1 - - [20/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:01,751 Request with ID 8130b7ff for model gemma-7b received
2024-09-20 12:31:01,752 127.0.0.1 - - [20/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:01,799 Request with ID 8190cdd4 for model llama3-8b received
2024-09-20 12:31:01,800 127.0.0.1 - - [20/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:01,859 Request with ID 43393b47 for model llama3-8b received
2024-09-20 12:31:01,860 127.0.0.1 - - [20/Sep/2024 12:31:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:01,941 Waiting for running processes to finish
2024-09-20 12:31:03,944 Waiting for running processes to finish
2024-09-20 12:31:05,947 Waiting for running processes to finish
2024-09-20 12:31:05,986 Processed batch: ['07cde9d6', 'e953209c', '5b9c52e2', 'fa1cc622', '7c84a835', 'd3490d9b', '402525dc', 'ed616b8d', '25e53c0d', '9f893362', 'fac07de8', '693253f0', '84bddc08', '9ef68f34', '2b5b2477', '3706811c', '2d278ec9', 'f8a8a5d2', 'b86099ab', '18b613e9', '85efca65', '1fb47166', 'd577cd02', '99f94c06', 'b9150897', 'cfe3d4ba', '487f7ffa', 'a9e6e0eb', '623a1bf0', '71fc7f1c', '81acfee1', '15a58d4f', 'f94383e5', 'e24d7b25', '4b62bdb2', '7a935d4f', 'f4ba7bd3', 'd12a3109', 'ad23014a', 'f9fa90d8', '32bf2efd', '890c1061', 'eacb168e', 'c9721961', 'a6f064f6', '0bb2dde0', '08ab6e66', '32db77fd', 'c01400d0', '304cd9d3', 'a761cab4', '8a2da860', 'a500b08b', 'c842e17a', 'b2be029a', '2b936d00', '78cf85af', '611f7c85', '693f64bb', 'c980db3c', '6b9952f5', 'b2bfcc4c', '584b85e3', '6ae71cb3'] with model llama3-8b in 8.1349 seconds
2024-09-20 12:31:05,986 Saving sys info
2024-09-20 12:31:06,050 Latency for request 07cde9d6 with model llama3-8b: 45.4960 seconds
2024-09-20 12:31:06,051 Saving results with gpu monitoring
2024-09-20 12:31:06,056 Latency for request e953209c with model llama3-8b: 45.4470 seconds
2024-09-20 12:31:06,057 Saving results with gpu monitoring
2024-09-20 12:31:06,061 Latency for request 5b9c52e2 with model llama3-8b: 45.2430 seconds
2024-09-20 12:31:06,061 Saving results with gpu monitoring
2024-09-20 12:31:06,065 Latency for request fa1cc622 with model llama3-8b: 45.2300 seconds
2024-09-20 12:31:06,065 Saving results with gpu monitoring
2024-09-20 12:31:06,069 Latency for request 7c84a835 with model llama3-8b: 45.0520 seconds
2024-09-20 12:31:06,069 Saving results with gpu monitoring
2024-09-20 12:31:06,074 Latency for request d3490d9b with model llama3-8b: 45.0490 seconds
2024-09-20 12:31:06,074 Saving results with gpu monitoring
2024-09-20 12:31:06,078 Latency for request 402525dc with model llama3-8b: 44.9150 seconds
2024-09-20 12:31:06,078 Saving results with gpu monitoring
2024-09-20 12:31:06,082 Latency for request ed616b8d with model llama3-8b: 44.6710 seconds
2024-09-20 12:31:06,082 Saving results with gpu monitoring
2024-09-20 12:31:06,086 Latency for request 25e53c0d with model llama3-8b: 44.6300 seconds
2024-09-20 12:31:06,086 Saving results with gpu monitoring
2024-09-20 12:31:06,090 Latency for request 9f893362 with model llama3-8b: 44.6090 seconds
2024-09-20 12:31:06,090 Saving results with gpu monitoring
2024-09-20 12:31:06,094 Latency for request fac07de8 with model llama3-8b: 44.4240 seconds
2024-09-20 12:31:06,094 Saving results with gpu monitoring
2024-09-20 12:31:06,098 Latency for request 693253f0 with model llama3-8b: 44.3920 seconds
2024-09-20 12:31:06,098 Saving results with gpu monitoring
2024-09-20 12:31:06,102 Latency for request 84bddc08 with model llama3-8b: 44.2900 seconds
2024-09-20 12:31:06,102 Saving results with gpu monitoring
2024-09-20 12:31:06,105 Latency for request 9ef68f34 with model llama3-8b: 44.2850 seconds
2024-09-20 12:31:06,105 Saving results with gpu monitoring
2024-09-20 12:31:06,108 Latency for request 2b5b2477 with model llama3-8b: 44.0710 seconds
2024-09-20 12:31:06,108 Saving results with gpu monitoring
2024-09-20 12:31:06,111 Latency for request 3706811c with model llama3-8b: 44.0130 seconds
2024-09-20 12:31:06,111 Saving results with gpu monitoring
2024-09-20 12:31:06,114 Latency for request 2d278ec9 with model llama3-8b: 43.7880 seconds
2024-09-20 12:31:06,114 Saving results with gpu monitoring
2024-09-20 12:31:06,117 Latency for request f8a8a5d2 with model llama3-8b: 43.6860 seconds
2024-09-20 12:31:06,117 Saving results with gpu monitoring
2024-09-20 12:31:06,120 Latency for request b86099ab with model llama3-8b: 43.5830 seconds
2024-09-20 12:31:06,120 Saving results with gpu monitoring
2024-09-20 12:31:06,122 Latency for request 18b613e9 with model llama3-8b: 43.5720 seconds
2024-09-20 12:31:06,122 Saving results with gpu monitoring
2024-09-20 12:31:06,125 Latency for request 85efca65 with model llama3-8b: 43.2150 seconds
2024-09-20 12:31:06,125 Saving results with gpu monitoring
2024-09-20 12:31:06,127 Latency for request 1fb47166 with model llama3-8b: 43.1220 seconds
2024-09-20 12:31:06,127 Saving results with gpu monitoring
2024-09-20 12:31:06,130 Latency for request d577cd02 with model llama3-8b: 42.8240 seconds
2024-09-20 12:31:06,130 Saving results with gpu monitoring
2024-09-20 12:31:06,132 Latency for request 99f94c06 with model llama3-8b: 42.6890 seconds
2024-09-20 12:31:06,132 Saving results with gpu monitoring
2024-09-20 12:31:06,135 Latency for request b9150897 with model llama3-8b: 42.6710 seconds
2024-09-20 12:31:06,135 Saving results with gpu monitoring
2024-09-20 12:31:06,137 Latency for request cfe3d4ba with model llama3-8b: 42.6100 seconds
2024-09-20 12:31:06,137 Saving results with gpu monitoring
2024-09-20 12:31:06,139 Latency for request 487f7ffa with model llama3-8b: 42.5750 seconds
2024-09-20 12:31:06,139 Saving results with gpu monitoring
2024-09-20 12:31:06,141 Latency for request a9e6e0eb with model llama3-8b: 42.5400 seconds
2024-09-20 12:31:06,141 Saving results with gpu monitoring
2024-09-20 12:31:06,143 Latency for request 623a1bf0 with model llama3-8b: 42.3260 seconds
2024-09-20 12:31:06,143 Saving results with gpu monitoring
2024-09-20 12:31:06,145 Latency for request 71fc7f1c with model llama3-8b: 42.2560 seconds
2024-09-20 12:31:06,145 Saving results with gpu monitoring
2024-09-20 12:31:06,148 Latency for request 81acfee1 with model llama3-8b: 42.1090 seconds
2024-09-20 12:31:06,148 Saving results with gpu monitoring
2024-09-20 12:31:06,150 Latency for request 15a58d4f with model llama3-8b: 41.9820 seconds
2024-09-20 12:31:06,150 Saving results with gpu monitoring
2024-09-20 12:31:06,152 Latency for request f94383e5 with model llama3-8b: 41.6690 seconds
2024-09-20 12:31:06,152 Saving results with gpu monitoring
2024-09-20 12:31:06,154 Latency for request e24d7b25 with model llama3-8b: 41.3970 seconds
2024-09-20 12:31:06,154 Saving results with gpu monitoring
2024-09-20 12:31:06,156 Latency for request 4b62bdb2 with model llama3-8b: 41.3890 seconds
2024-09-20 12:31:06,156 Saving results with gpu monitoring
2024-09-20 12:31:06,158 Latency for request 7a935d4f with model llama3-8b: 41.2760 seconds
2024-09-20 12:31:06,158 Saving results with gpu monitoring
2024-09-20 12:31:06,160 Latency for request f4ba7bd3 with model llama3-8b: 40.8500 seconds
2024-09-20 12:31:06,160 Saving results with gpu monitoring
2024-09-20 12:31:06,162 Latency for request d12a3109 with model llama3-8b: 40.8440 seconds
2024-09-20 12:31:06,162 Saving results with gpu monitoring
2024-09-20 12:31:06,164 Latency for request ad23014a with model llama3-8b: 40.5230 seconds
2024-09-20 12:31:06,164 Saving results with gpu monitoring
2024-09-20 12:31:06,166 Latency for request f9fa90d8 with model llama3-8b: 40.3340 seconds
2024-09-20 12:31:06,166 Saving results with gpu monitoring
2024-09-20 12:31:06,168 Latency for request 32bf2efd with model llama3-8b: 40.2820 seconds
2024-09-20 12:31:06,168 Saving results with gpu monitoring
2024-09-20 12:31:06,170 Latency for request 890c1061 with model llama3-8b: 40.0400 seconds
2024-09-20 12:31:06,170 Saving results with gpu monitoring
2024-09-20 12:31:06,172 Latency for request eacb168e with model llama3-8b: 39.9210 seconds
2024-09-20 12:31:06,172 Saving results with gpu monitoring
2024-09-20 12:31:06,174 Latency for request c9721961 with model llama3-8b: 39.8320 seconds
2024-09-20 12:31:06,174 Saving results with gpu monitoring
2024-09-20 12:31:06,176 Latency for request a6f064f6 with model llama3-8b: 39.7890 seconds
2024-09-20 12:31:06,176 Saving results with gpu monitoring
2024-09-20 12:31:06,178 Latency for request 0bb2dde0 with model llama3-8b: 39.3610 seconds
2024-09-20 12:31:06,178 Saving results with gpu monitoring
2024-09-20 12:31:06,180 Latency for request 08ab6e66 with model llama3-8b: 39.3500 seconds
2024-09-20 12:31:06,180 Saving results with gpu monitoring
2024-09-20 12:31:06,182 Latency for request 32db77fd with model llama3-8b: 39.3030 seconds
2024-09-20 12:31:06,182 Saving results with gpu monitoring
2024-09-20 12:31:06,184 Latency for request c01400d0 with model llama3-8b: 39.1720 seconds
2024-09-20 12:31:06,184 Saving results with gpu monitoring
2024-09-20 12:31:06,186 Latency for request 304cd9d3 with model llama3-8b: 39.0900 seconds
2024-09-20 12:31:06,186 Saving results with gpu monitoring
2024-09-20 12:31:06,188 Latency for request a761cab4 with model llama3-8b: 38.7830 seconds
2024-09-20 12:31:06,188 Saving results with gpu monitoring
2024-09-20 12:31:06,190 Latency for request 8a2da860 with model llama3-8b: 38.7450 seconds
2024-09-20 12:31:06,190 Saving results with gpu monitoring
2024-09-20 12:31:06,192 Latency for request a500b08b with model llama3-8b: 37.9810 seconds
2024-09-20 12:31:06,192 Saving results with gpu monitoring
2024-09-20 12:31:06,194 Latency for request c842e17a with model llama3-8b: 37.9630 seconds
2024-09-20 12:31:06,194 Saving results with gpu monitoring
2024-09-20 12:31:06,196 Latency for request b2be029a with model llama3-8b: 37.8170 seconds
2024-09-20 12:31:06,196 Saving results with gpu monitoring
2024-09-20 12:31:06,198 Latency for request 2b936d00 with model llama3-8b: 37.7160 seconds
2024-09-20 12:31:06,198 Saving results with gpu monitoring
2024-09-20 12:31:06,200 Latency for request 78cf85af with model llama3-8b: 37.6350 seconds
2024-09-20 12:31:06,200 Saving results with gpu monitoring
2024-09-20 12:31:06,202 Latency for request 611f7c85 with model llama3-8b: 36.8170 seconds
2024-09-20 12:31:06,202 Saving results with gpu monitoring
2024-09-20 12:31:06,204 Latency for request 693f64bb with model llama3-8b: 36.5710 seconds
2024-09-20 12:31:06,204 Saving results with gpu monitoring
2024-09-20 12:31:06,206 Latency for request c980db3c with model llama3-8b: 36.5700 seconds
2024-09-20 12:31:06,206 Saving results with gpu monitoring
2024-09-20 12:31:06,208 Latency for request 6b9952f5 with model llama3-8b: 36.3330 seconds
2024-09-20 12:31:06,208 Saving results with gpu monitoring
2024-09-20 12:31:06,210 Latency for request b2bfcc4c with model llama3-8b: 35.8670 seconds
2024-09-20 12:31:06,210 Saving results with gpu monitoring
2024-09-20 12:31:06,212 Latency for request 584b85e3 with model llama3-8b: 35.7990 seconds
2024-09-20 12:31:06,212 Saving results with gpu monitoring
2024-09-20 12:31:06,214 Latency for request 6ae71cb3 with model llama3-8b: 35.6940 seconds
2024-09-20 12:31:06,214 Saving results with gpu monitoring
2024-09-20 12:31:06,216 127.0.0.1 - - [20/Sep/2024 12:31:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:06,217 Next: call load_model for llama3-8b
2024-09-20 12:31:06,217 Model llama3-8b already loaded
2024-09-20 12:31:06,222 Batch processing started for model llama3-8b
2024-09-20 12:31:07,951 Waiting for running processes to finish
2024-09-20 12:31:09,954 Waiting for running processes to finish
2024-09-20 12:31:11,956 Waiting for running processes to finish
2024-09-20 12:31:13,959 Waiting for running processes to finish
2024-09-20 12:31:14,786 Processed batch: ['6723b679', 'e4785413', '2d18a941', 'b371ebb7', 'a8d67a69', '0e1e2ada', '9b8c6b21', '3a22c700', 'a052f83e', 'c169520d', '652473cc', '192f4c9c', '3f53d64b', 'b2622677', 'e5963cef', '81d979f0', 'c15e310d', '21febf62', 'fc8e6f07', '2f25cf66', '11dd0071', 'bbd61659', 'f7807586', '7beff5b2', '408c8e2b', 'f251ec40', 'f7af5f8a', 'edd77547', 'b0b297cb', 'd6165c10', 'b26a3c8c', '3d127a20', '8f8a3d19', '3a1df330', '99bf3d4e', '2b4ee40c', '5496eb7d', 'f581e14a', 'df31e817', '4428077b', '26db50f2', '4aa3e0c1', '0c8c1e60', 'aaeeea5a', '8cab1521', 'eedd9603', '08e43c77', 'da4a9ffa', '8e09214f', 'bb83c031', '3d56aee5', 'f56e15c9', 'da74a096', '8a022d2e', '53f26e5c', 'aecb61ba', 'b8d2e4c6', 'a7d0a242', '69b81607', 'a52070a9', '45f7cdf1', '6676b2a4', 'b6249400', '62a55c03'] with model llama3-8b in 8.5640 seconds
2024-09-20 12:31:14,786 Saving sys info
2024-09-20 12:31:14,822 Latency for request 6723b679 with model llama3-8b: 23.0290 seconds
2024-09-20 12:31:14,823 Saving results with gpu monitoring
2024-09-20 12:31:14,826 Latency for request e4785413 with model llama3-8b: 22.9540 seconds
2024-09-20 12:31:14,826 Saving results with gpu monitoring
2024-09-20 12:31:14,828 Latency for request 2d18a941 with model llama3-8b: 22.8620 seconds
2024-09-20 12:31:14,828 Saving results with gpu monitoring
2024-09-20 12:31:14,831 Latency for request b371ebb7 with model llama3-8b: 22.6090 seconds
2024-09-20 12:31:14,831 Saving results with gpu monitoring
2024-09-20 12:31:14,833 Latency for request a8d67a69 with model llama3-8b: 22.5780 seconds
2024-09-20 12:31:14,833 Saving results with gpu monitoring
2024-09-20 12:31:14,835 Latency for request 0e1e2ada with model llama3-8b: 22.5700 seconds
2024-09-20 12:31:14,835 Saving results with gpu monitoring
2024-09-20 12:31:14,837 Latency for request 9b8c6b21 with model llama3-8b: 22.4960 seconds
2024-09-20 12:31:14,837 Saving results with gpu monitoring
2024-09-20 12:31:14,839 Latency for request 3a22c700 with model llama3-8b: 22.4910 seconds
2024-09-20 12:31:14,839 Saving results with gpu monitoring
2024-09-20 12:31:14,841 Latency for request a052f83e with model llama3-8b: 22.3890 seconds
2024-09-20 12:31:14,841 Saving results with gpu monitoring
2024-09-20 12:31:14,843 Latency for request c169520d with model llama3-8b: 22.3290 seconds
2024-09-20 12:31:14,843 Saving results with gpu monitoring
2024-09-20 12:31:14,845 Latency for request 652473cc with model llama3-8b: 22.1880 seconds
2024-09-20 12:31:14,845 Saving results with gpu monitoring
2024-09-20 12:31:14,847 Latency for request 192f4c9c with model llama3-8b: 21.9240 seconds
2024-09-20 12:31:14,847 Saving results with gpu monitoring
2024-09-20 12:31:14,849 Latency for request 3f53d64b with model llama3-8b: 21.9050 seconds
2024-09-20 12:31:14,849 Saving results with gpu monitoring
2024-09-20 12:31:14,851 Latency for request b2622677 with model llama3-8b: 21.7490 seconds
2024-09-20 12:31:14,851 Saving results with gpu monitoring
2024-09-20 12:31:14,853 Latency for request e5963cef with model llama3-8b: 21.6190 seconds
2024-09-20 12:31:14,853 Saving results with gpu monitoring
2024-09-20 12:31:14,855 Latency for request 81d979f0 with model llama3-8b: 21.3050 seconds
2024-09-20 12:31:14,855 Saving results with gpu monitoring
2024-09-20 12:31:14,857 Latency for request c15e310d with model llama3-8b: 21.3030 seconds
2024-09-20 12:31:14,857 Saving results with gpu monitoring
2024-09-20 12:31:14,859 Latency for request 21febf62 with model llama3-8b: 21.0530 seconds
2024-09-20 12:31:14,859 Saving results with gpu monitoring
2024-09-20 12:31:14,861 Latency for request fc8e6f07 with model llama3-8b: 21.0060 seconds
2024-09-20 12:31:14,861 Saving results with gpu monitoring
2024-09-20 12:31:14,863 Latency for request 2f25cf66 with model llama3-8b: 20.7940 seconds
2024-09-20 12:31:14,863 Saving results with gpu monitoring
2024-09-20 12:31:14,865 Latency for request 11dd0071 with model llama3-8b: 20.7860 seconds
2024-09-20 12:31:14,865 Saving results with gpu monitoring
2024-09-20 12:31:14,867 Latency for request bbd61659 with model llama3-8b: 20.7630 seconds
2024-09-20 12:31:14,867 Saving results with gpu monitoring
2024-09-20 12:31:14,869 Latency for request f7807586 with model llama3-8b: 20.5640 seconds
2024-09-20 12:31:14,869 Saving results with gpu monitoring
2024-09-20 12:31:14,871 Latency for request 7beff5b2 with model llama3-8b: 20.5090 seconds
2024-09-20 12:31:14,871 Saving results with gpu monitoring
2024-09-20 12:31:14,873 Latency for request 408c8e2b with model llama3-8b: 20.4520 seconds
2024-09-20 12:31:14,873 Saving results with gpu monitoring
2024-09-20 12:31:14,875 Latency for request f251ec40 with model llama3-8b: 20.3090 seconds
2024-09-20 12:31:14,875 Saving results with gpu monitoring
2024-09-20 12:31:14,877 Latency for request f7af5f8a with model llama3-8b: 19.9140 seconds
2024-09-20 12:31:14,877 Saving results with gpu monitoring
2024-09-20 12:31:14,879 Latency for request edd77547 with model llama3-8b: 19.8310 seconds
2024-09-20 12:31:14,879 Saving results with gpu monitoring
2024-09-20 12:31:14,881 Latency for request b0b297cb with model llama3-8b: 19.7040 seconds
2024-09-20 12:31:14,881 Saving results with gpu monitoring
2024-09-20 12:31:14,883 Latency for request d6165c10 with model llama3-8b: 19.6170 seconds
2024-09-20 12:31:14,883 Saving results with gpu monitoring
2024-09-20 12:31:14,885 Latency for request b26a3c8c with model llama3-8b: 19.6020 seconds
2024-09-20 12:31:14,885 Saving results with gpu monitoring
2024-09-20 12:31:14,887 Latency for request 3d127a20 with model llama3-8b: 19.0610 seconds
2024-09-20 12:31:14,887 Saving results with gpu monitoring
2024-09-20 12:31:14,889 Latency for request 8f8a3d19 with model llama3-8b: 18.5350 seconds
2024-09-20 12:31:14,889 Saving results with gpu monitoring
2024-09-20 12:31:14,891 Latency for request 3a1df330 with model llama3-8b: 18.5140 seconds
2024-09-20 12:31:14,891 Saving results with gpu monitoring
2024-09-20 12:31:14,893 Latency for request 99bf3d4e with model llama3-8b: 18.4830 seconds
2024-09-20 12:31:14,893 Saving results with gpu monitoring
2024-09-20 12:31:14,895 Latency for request 2b4ee40c with model llama3-8b: 18.3610 seconds
2024-09-20 12:31:14,895 Saving results with gpu monitoring
2024-09-20 12:31:14,897 Latency for request 5496eb7d with model llama3-8b: 18.0290 seconds
2024-09-20 12:31:14,897 Saving results with gpu monitoring
2024-09-20 12:31:14,899 Latency for request f581e14a with model llama3-8b: 17.8540 seconds
2024-09-20 12:31:14,899 Saving results with gpu monitoring
2024-09-20 12:31:14,901 Latency for request df31e817 with model llama3-8b: 17.8510 seconds
2024-09-20 12:31:14,901 Saving results with gpu monitoring
2024-09-20 12:31:14,903 Latency for request 4428077b with model llama3-8b: 17.8430 seconds
2024-09-20 12:31:14,903 Saving results with gpu monitoring
2024-09-20 12:31:14,905 Latency for request 26db50f2 with model llama3-8b: 17.8350 seconds
2024-09-20 12:31:14,905 Saving results with gpu monitoring
2024-09-20 12:31:14,907 Latency for request 4aa3e0c1 with model llama3-8b: 17.7600 seconds
2024-09-20 12:31:14,907 Saving results with gpu monitoring
2024-09-20 12:31:14,909 Latency for request 0c8c1e60 with model llama3-8b: 17.4660 seconds
2024-09-20 12:31:14,909 Saving results with gpu monitoring
2024-09-20 12:31:14,911 Latency for request aaeeea5a with model llama3-8b: 17.4180 seconds
2024-09-20 12:31:14,911 Saving results with gpu monitoring
2024-09-20 12:31:14,913 Latency for request 8cab1521 with model llama3-8b: 17.1790 seconds
2024-09-20 12:31:14,913 Saving results with gpu monitoring
2024-09-20 12:31:14,915 Latency for request eedd9603 with model llama3-8b: 17.1040 seconds
2024-09-20 12:31:14,915 Saving results with gpu monitoring
2024-09-20 12:31:14,917 Latency for request 08e43c77 with model llama3-8b: 17.0300 seconds
2024-09-20 12:31:14,917 Saving results with gpu monitoring
2024-09-20 12:31:14,919 Latency for request da4a9ffa with model llama3-8b: 16.8920 seconds
2024-09-20 12:31:14,919 Saving results with gpu monitoring
2024-09-20 12:31:14,921 Latency for request 8e09214f with model llama3-8b: 16.8490 seconds
2024-09-20 12:31:14,921 Saving results with gpu monitoring
2024-09-20 12:31:14,923 Latency for request bb83c031 with model llama3-8b: 16.6080 seconds
2024-09-20 12:31:14,923 Saving results with gpu monitoring
2024-09-20 12:31:14,925 Latency for request 3d56aee5 with model llama3-8b: 16.4990 seconds
2024-09-20 12:31:14,925 Saving results with gpu monitoring
2024-09-20 12:31:14,927 Latency for request f56e15c9 with model llama3-8b: 16.4190 seconds
2024-09-20 12:31:14,927 Saving results with gpu monitoring
2024-09-20 12:31:14,929 Latency for request da74a096 with model llama3-8b: 16.2640 seconds
2024-09-20 12:31:14,929 Saving results with gpu monitoring
2024-09-20 12:31:14,931 Latency for request 8a022d2e with model llama3-8b: 16.0590 seconds
2024-09-20 12:31:14,931 Saving results with gpu monitoring
2024-09-20 12:31:14,933 Latency for request 53f26e5c with model llama3-8b: 16.0360 seconds
2024-09-20 12:31:14,933 Saving results with gpu monitoring
2024-09-20 12:31:14,935 Latency for request aecb61ba with model llama3-8b: 15.8060 seconds
2024-09-20 12:31:14,935 Saving results with gpu monitoring
2024-09-20 12:31:14,937 Latency for request b8d2e4c6 with model llama3-8b: 15.6330 seconds
2024-09-20 12:31:14,937 Saving results with gpu monitoring
2024-09-20 12:31:14,939 Latency for request a7d0a242 with model llama3-8b: 15.6000 seconds
2024-09-20 12:31:14,939 Saving results with gpu monitoring
2024-09-20 12:31:14,941 Latency for request 69b81607 with model llama3-8b: 15.5670 seconds
2024-09-20 12:31:14,941 Saving results with gpu monitoring
2024-09-20 12:31:14,943 Latency for request a52070a9 with model llama3-8b: 15.5030 seconds
2024-09-20 12:31:14,943 Saving results with gpu monitoring
2024-09-20 12:31:14,945 Latency for request 45f7cdf1 with model llama3-8b: 15.3270 seconds
2024-09-20 12:31:14,945 Saving results with gpu monitoring
2024-09-20 12:31:14,947 Latency for request 6676b2a4 with model llama3-8b: 15.1060 seconds
2024-09-20 12:31:14,947 Saving results with gpu monitoring
2024-09-20 12:31:14,949 Latency for request b6249400 with model llama3-8b: 15.1010 seconds
2024-09-20 12:31:14,949 Saving results with gpu monitoring
2024-09-20 12:31:14,951 Latency for request 62a55c03 with model llama3-8b: 15.0440 seconds
2024-09-20 12:31:14,951 Saving results with gpu monitoring
2024-09-20 12:31:14,954 127.0.0.1 - - [20/Sep/2024 12:31:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:14,954 Next: call load_model for granite-7b
2024-09-20 12:31:15,063 Unloaded previous model
2024-09-20 12:31:15,967 Waiting for running processes to finish
2024-09-20 12:31:17,981 Waiting for running processes to finish
2024-09-20 12:31:19,984 Waiting for running processes to finish
2024-09-20 12:31:21,987 Waiting for running processes to finish
2024-09-20 12:31:23,989 Waiting for running processes to finish
2024-09-20 12:31:25,992 Waiting for running processes to finish
2024-09-20 12:31:27,995 Waiting for running processes to finish
2024-09-20 12:31:29,997 Waiting for running processes to finish
2024-09-20 12:31:32,000 Waiting for running processes to finish
2024-09-20 12:31:33,087 Loaded model granite-7b
2024-09-20 12:31:33,090 Batch processing started for model granite-7b
2024-09-20 12:31:34,002 Waiting for running processes to finish
2024-09-20 12:31:35,832 Processed batch: ['04f43ab0', '84b27de8', '24f82029', '890578a8', 'b297afd8', 'd32acadc', '57bcf1ea', '7a89c3db', '43306884', 'a949085d', 'e64947ce', '3c0cca34', '7ca4cf5d', '3136567c', 'dc11d249', '3d02e6e4'] with model granite-7b in 2.7422 seconds
2024-09-20 12:31:35,832 Saving sys info
2024-09-20 12:31:35,864 Latency for request 04f43ab0 with model granite-7b: 55.1690 seconds
2024-09-20 12:31:35,864 Saving results with gpu monitoring
2024-09-20 12:31:35,867 Latency for request 84b27de8 with model granite-7b: 54.4500 seconds
2024-09-20 12:31:35,867 Saving results with gpu monitoring
2024-09-20 12:31:35,869 Latency for request 24f82029 with model granite-7b: 54.1460 seconds
2024-09-20 12:31:35,869 Saving results with gpu monitoring
2024-09-20 12:31:35,871 Latency for request 890578a8 with model granite-7b: 53.6970 seconds
2024-09-20 12:31:35,871 Saving results with gpu monitoring
2024-09-20 12:31:35,873 Latency for request b297afd8 with model granite-7b: 52.9170 seconds
2024-09-20 12:31:35,873 Saving results with gpu monitoring
2024-09-20 12:31:35,875 Latency for request d32acadc with model granite-7b: 52.4640 seconds
2024-09-20 12:31:35,875 Saving results with gpu monitoring
2024-09-20 12:31:35,877 Latency for request 57bcf1ea with model granite-7b: 51.5980 seconds
2024-09-20 12:31:35,877 Saving results with gpu monitoring
2024-09-20 12:31:35,879 Latency for request 7a89c3db with model granite-7b: 50.3570 seconds
2024-09-20 12:31:35,879 Saving results with gpu monitoring
2024-09-20 12:31:35,881 Latency for request 43306884 with model granite-7b: 49.8180 seconds
2024-09-20 12:31:35,881 Saving results with gpu monitoring
2024-09-20 12:31:35,883 Latency for request a949085d with model granite-7b: 48.2990 seconds
2024-09-20 12:31:35,883 Saving results with gpu monitoring
2024-09-20 12:31:35,885 Latency for request e64947ce with model granite-7b: 47.1690 seconds
2024-09-20 12:31:35,885 Saving results with gpu monitoring
2024-09-20 12:31:35,887 Latency for request 3c0cca34 with model granite-7b: 46.2850 seconds
2024-09-20 12:31:35,887 Saving results with gpu monitoring
2024-09-20 12:31:35,889 Latency for request 7ca4cf5d with model granite-7b: 45.0660 seconds
2024-09-20 12:31:35,889 Saving results with gpu monitoring
2024-09-20 12:31:35,891 Latency for request 3136567c with model granite-7b: 44.0720 seconds
2024-09-20 12:31:35,891 Saving results with gpu monitoring
2024-09-20 12:31:35,893 Latency for request dc11d249 with model granite-7b: 44.0620 seconds
2024-09-20 12:31:35,893 Saving results with gpu monitoring
2024-09-20 12:31:35,895 Latency for request 3d02e6e4 with model granite-7b: 39.8020 seconds
2024-09-20 12:31:35,895 Saving results with gpu monitoring
2024-09-20 12:31:35,898 127.0.0.1 - - [20/Sep/2024 12:31:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:35,898 Next: call load_model for gemma-7b
2024-09-20 12:31:35,985 Unloaded previous model
2024-09-20 12:31:36,499 Waiting for running processes to finish
2024-09-20 12:31:39,505 Total time: 153.9579 seconds
2024-09-20 12:31:39,506 Total inference time: 39.4330 seconds
2024-09-20 12:31:39,506 Inference time as percentage of total time: 25.61%
2024-09-20 12:31:39,506 END
2024-09-20 12:31:39,506 127.0.0.1 - - [20/Sep/2024 12:31:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:31:58,165 Loaded model gemma-7b
2024-09-20 12:31:58,168 Batch processing started for model gemma-7b
2024-09-20 12:32:07,888 Processed batch: ['dfebf086', '34cf30ed', '95581208', 'eaca9402', 'a628c5eb', 'c4540a06', 'd384e49e', 'cfa3dd4a', 'ef4c5940', '3299fc5f', 'd5217772', '4d8e4904', '9ca5acfb', '2105500d', '18f06937', 'e6840d61', '396975b4', 'f8e57960', '8c82f52f', '813d1e8e', '4215d51d', '72a4d905', 'a7982bad', '6d4c0d6f', '6533998a', '645af5e0', '551da0db', 'c79b2f0f', '920cd38c', '8978194c', 'b21b2fad', '0d929d84', 'ab0dec3d', '5dbbd443', '9ddd6d27', 'd3f60466', 'd064f124', '60c7bc2f', '6494c9d2', '1f567e97', '92aafe2e', 'dcbf8036', '6406b5f9', '3133346b', 'bbb4513e', '549fb3fe', '83517b93', '97fed10f', '4207e47c', 'af9c115c', '2136f6a1', 'd0ca5eda', 'd36262b6', '8d657f4d', 'dbf5d8d7', 'd4b2d09b', '58e3fdf2', '1e44704d', 'ad3f3b00', '1f6248d9', 'bce595e9', 'ed21b50c', 'fbcbed59', '1d8f24cd'] with model gemma-7b in 9.7197 seconds
2024-09-20 12:32:07,888 Saving sys info
2024-09-20 12:32:07,934 Latency for request dfebf086 with model gemma-7b: 89.9580 seconds
2024-09-20 12:32:07,934 Saving results with gpu monitoring
2024-09-20 12:32:07,938 Latency for request 34cf30ed with model gemma-7b: 89.3510 seconds
2024-09-20 12:32:07,938 Saving results with gpu monitoring
2024-09-20 12:32:07,940 Latency for request 95581208 with model gemma-7b: 88.7870 seconds
2024-09-20 12:32:07,940 Saving results with gpu monitoring
2024-09-20 12:32:07,942 Latency for request eaca9402 with model gemma-7b: 88.6190 seconds
2024-09-20 12:32:07,942 Saving results with gpu monitoring
2024-09-20 12:32:07,944 Latency for request a628c5eb with model gemma-7b: 88.3820 seconds
2024-09-20 12:32:07,944 Saving results with gpu monitoring
2024-09-20 12:32:07,946 Latency for request c4540a06 with model gemma-7b: 87.5140 seconds
2024-09-20 12:32:07,946 Saving results with gpu monitoring
2024-09-20 12:32:07,948 Latency for request d384e49e with model gemma-7b: 87.2840 seconds
2024-09-20 12:32:07,948 Saving results with gpu monitoring
2024-09-20 12:32:07,950 Latency for request cfa3dd4a with model gemma-7b: 87.1260 seconds
2024-09-20 12:32:07,950 Saving results with gpu monitoring
2024-09-20 12:32:07,952 Latency for request ef4c5940 with model gemma-7b: 86.1460 seconds
2024-09-20 12:32:07,952 Saving results with gpu monitoring
2024-09-20 12:32:07,954 Latency for request 3299fc5f with model gemma-7b: 85.8260 seconds
2024-09-20 12:32:07,954 Saving results with gpu monitoring
2024-09-20 12:32:07,956 Latency for request d5217772 with model gemma-7b: 85.7500 seconds
2024-09-20 12:32:07,956 Saving results with gpu monitoring
2024-09-20 12:32:07,958 Latency for request 4d8e4904 with model gemma-7b: 85.4870 seconds
2024-09-20 12:32:07,958 Saving results with gpu monitoring
2024-09-20 12:32:07,960 Latency for request 9ca5acfb with model gemma-7b: 85.0340 seconds
2024-09-20 12:32:07,960 Saving results with gpu monitoring
2024-09-20 12:32:07,962 Latency for request 2105500d with model gemma-7b: 84.1430 seconds
2024-09-20 12:32:07,962 Saving results with gpu monitoring
2024-09-20 12:32:07,964 Latency for request 18f06937 with model gemma-7b: 84.1180 seconds
2024-09-20 12:32:07,964 Saving results with gpu monitoring
2024-09-20 12:32:07,966 Latency for request e6840d61 with model gemma-7b: 84.1180 seconds
2024-09-20 12:32:07,966 Saving results with gpu monitoring
2024-09-20 12:32:07,968 Latency for request 396975b4 with model gemma-7b: 83.8140 seconds
2024-09-20 12:32:07,968 Saving results with gpu monitoring
2024-09-20 12:32:07,970 Latency for request f8e57960 with model gemma-7b: 83.7470 seconds
2024-09-20 12:32:07,970 Saving results with gpu monitoring
2024-09-20 12:32:07,972 Latency for request 8c82f52f with model gemma-7b: 83.5740 seconds
2024-09-20 12:32:07,972 Saving results with gpu monitoring
2024-09-20 12:32:07,974 Latency for request 813d1e8e with model gemma-7b: 83.4210 seconds
2024-09-20 12:32:07,974 Saving results with gpu monitoring
2024-09-20 12:32:07,976 Latency for request 4215d51d with model gemma-7b: 83.2470 seconds
2024-09-20 12:32:07,976 Saving results with gpu monitoring
2024-09-20 12:32:07,978 Latency for request 72a4d905 with model gemma-7b: 82.9940 seconds
2024-09-20 12:32:07,978 Saving results with gpu monitoring
2024-09-20 12:32:07,980 Latency for request a7982bad with model gemma-7b: 82.8500 seconds
2024-09-20 12:32:07,980 Saving results with gpu monitoring
2024-09-20 12:32:07,982 Latency for request 6d4c0d6f with model gemma-7b: 82.8470 seconds
2024-09-20 12:32:07,982 Saving results with gpu monitoring
2024-09-20 12:32:07,984 Latency for request 6533998a with model gemma-7b: 82.6510 seconds
2024-09-20 12:32:07,984 Saving results with gpu monitoring
2024-09-20 12:32:07,986 Latency for request 645af5e0 with model gemma-7b: 81.1190 seconds
2024-09-20 12:32:07,986 Saving results with gpu monitoring
2024-09-20 12:32:07,988 Latency for request 551da0db with model gemma-7b: 80.8760 seconds
2024-09-20 12:32:07,988 Saving results with gpu monitoring
2024-09-20 12:32:07,990 Latency for request c79b2f0f with model gemma-7b: 80.3730 seconds
2024-09-20 12:32:07,990 Saving results with gpu monitoring
2024-09-20 12:32:07,992 Latency for request 920cd38c with model gemma-7b: 80.3030 seconds
2024-09-20 12:32:07,992 Saving results with gpu monitoring
2024-09-20 12:32:07,994 Latency for request 8978194c with model gemma-7b: 80.1520 seconds
2024-09-20 12:32:07,994 Saving results with gpu monitoring
2024-09-20 12:32:07,996 Latency for request b21b2fad with model gemma-7b: 79.9890 seconds
2024-09-20 12:32:07,996 Saving results with gpu monitoring
2024-09-20 12:32:07,998 Latency for request 0d929d84 with model gemma-7b: 79.8050 seconds
2024-09-20 12:32:07,999 Saving results with gpu monitoring
2024-09-20 12:32:08,000 Latency for request ab0dec3d with model gemma-7b: 79.2830 seconds
2024-09-20 12:32:08,001 Saving results with gpu monitoring
2024-09-20 12:32:08,003 Latency for request 5dbbd443 with model gemma-7b: 79.1640 seconds
2024-09-20 12:32:08,003 Saving results with gpu monitoring
2024-09-20 12:32:08,005 Latency for request 9ddd6d27 with model gemma-7b: 78.5450 seconds
2024-09-20 12:32:08,005 Saving results with gpu monitoring
2024-09-20 12:32:08,007 Latency for request d3f60466 with model gemma-7b: 78.4340 seconds
2024-09-20 12:32:08,007 Saving results with gpu monitoring
2024-09-20 12:32:08,009 Latency for request d064f124 with model gemma-7b: 77.8490 seconds
2024-09-20 12:32:08,009 Saving results with gpu monitoring
2024-09-20 12:32:08,011 Latency for request 60c7bc2f with model gemma-7b: 77.6460 seconds
2024-09-20 12:32:08,011 Saving results with gpu monitoring
2024-09-20 12:32:08,013 Latency for request 6494c9d2 with model gemma-7b: 77.5530 seconds
2024-09-20 12:32:08,013 Saving results with gpu monitoring
2024-09-20 12:32:08,015 Latency for request 1f567e97 with model gemma-7b: 77.5400 seconds
2024-09-20 12:32:08,015 Saving results with gpu monitoring
2024-09-20 12:32:08,017 Latency for request 92aafe2e with model gemma-7b: 76.9380 seconds
2024-09-20 12:32:08,017 Saving results with gpu monitoring
2024-09-20 12:32:08,019 Latency for request dcbf8036 with model gemma-7b: 76.5530 seconds
2024-09-20 12:32:08,019 Saving results with gpu monitoring
2024-09-20 12:32:08,021 Latency for request 6406b5f9 with model gemma-7b: 76.4720 seconds
2024-09-20 12:32:08,021 Saving results with gpu monitoring
2024-09-20 12:32:08,023 Latency for request 3133346b with model gemma-7b: 76.3450 seconds
2024-09-20 12:32:08,023 Saving results with gpu monitoring
2024-09-20 12:32:08,025 Latency for request bbb4513e with model gemma-7b: 75.7790 seconds
2024-09-20 12:32:08,025 Saving results with gpu monitoring
2024-09-20 12:32:08,027 Latency for request 549fb3fe with model gemma-7b: 75.6460 seconds
2024-09-20 12:32:08,027 Saving results with gpu monitoring
2024-09-20 12:32:08,029 Latency for request 83517b93 with model gemma-7b: 75.4230 seconds
2024-09-20 12:32:08,029 Saving results with gpu monitoring
2024-09-20 12:32:08,031 Latency for request 97fed10f with model gemma-7b: 75.3630 seconds
2024-09-20 12:32:08,031 Saving results with gpu monitoring
2024-09-20 12:32:08,033 Latency for request 4207e47c with model gemma-7b: 75.0240 seconds
2024-09-20 12:32:08,033 Saving results with gpu monitoring
2024-09-20 12:32:08,035 Latency for request af9c115c with model gemma-7b: 74.5550 seconds
2024-09-20 12:32:08,035 Saving results with gpu monitoring
2024-09-20 12:32:08,037 Latency for request 2136f6a1 with model gemma-7b: 74.3220 seconds
2024-09-20 12:32:08,037 Saving results with gpu monitoring
2024-09-20 12:32:08,039 Latency for request d0ca5eda with model gemma-7b: 73.4200 seconds
2024-09-20 12:32:08,039 Saving results with gpu monitoring
2024-09-20 12:32:08,041 Latency for request d36262b6 with model gemma-7b: 73.2760 seconds
2024-09-20 12:32:08,041 Saving results with gpu monitoring
2024-09-20 12:32:08,043 Latency for request 8d657f4d with model gemma-7b: 73.2320 seconds
2024-09-20 12:32:08,043 Saving results with gpu monitoring
2024-09-20 12:32:08,045 Latency for request dbf5d8d7 with model gemma-7b: 73.1550 seconds
2024-09-20 12:32:08,045 Saving results with gpu monitoring
2024-09-20 12:32:08,047 Latency for request d4b2d09b with model gemma-7b: 72.8780 seconds
2024-09-20 12:32:08,047 Saving results with gpu monitoring
2024-09-20 12:32:08,049 Latency for request 58e3fdf2 with model gemma-7b: 72.4300 seconds
2024-09-20 12:32:08,049 Saving results with gpu monitoring
2024-09-20 12:32:08,051 Latency for request 1e44704d with model gemma-7b: 72.3100 seconds
2024-09-20 12:32:08,051 Saving results with gpu monitoring
2024-09-20 12:32:08,053 Latency for request ad3f3b00 with model gemma-7b: 71.2890 seconds
2024-09-20 12:32:08,053 Saving results with gpu monitoring
2024-09-20 12:32:08,055 Latency for request 1f6248d9 with model gemma-7b: 70.9490 seconds
2024-09-20 12:32:08,055 Saving results with gpu monitoring
2024-09-20 12:32:08,057 Latency for request bce595e9 with model gemma-7b: 70.5990 seconds
2024-09-20 12:32:08,057 Saving results with gpu monitoring
2024-09-20 12:32:08,059 Latency for request ed21b50c with model gemma-7b: 69.3940 seconds
2024-09-20 12:32:08,059 Saving results with gpu monitoring
2024-09-20 12:32:08,061 Latency for request fbcbed59 with model gemma-7b: 69.0280 seconds
2024-09-20 12:32:08,061 Saving results with gpu monitoring
2024-09-20 12:32:08,063 Latency for request 1d8f24cd with model gemma-7b: 68.7680 seconds
2024-09-20 12:32:08,063 Saving results with gpu monitoring
2024-09-20 12:32:08,066 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,066 No batch to process for model llama3-8b
2024-09-20 12:32:08,067 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,067 No batch to process for model granite-7b
2024-09-20 12:32:08,068 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,068 No batch to process for model llama3-8b
2024-09-20 12:32:08,069 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,070 No batch to process for model gemma-7b
2024-09-20 12:32:08,071 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,071 No batch to process for model llama3-8b
2024-09-20 12:32:08,072 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,072 No batch to process for model granite-7b
2024-09-20 12:32:08,073 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,073 No batch to process for model llama3-8b
2024-09-20 12:32:08,074 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,075 No batch to process for model gemma-7b
2024-09-20 12:32:08,075 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,076 No batch to process for model granite-7b
2024-09-20 12:32:08,076 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,077 No batch to process for model llama3-8b
2024-09-20 12:32:08,078 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,079 No batch to process for model gemma-7b
2024-09-20 12:32:08,079 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,079 No batch to process for model granite-7b
2024-09-20 12:32:08,080 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,080 No batch to process for model llama3-8b
2024-09-20 12:32:08,081 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,081 No batch to process for model llama3-8b
2024-09-20 12:32:08,082 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,083 No batch to process for model granite-7b
2024-09-20 12:32:08,083 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,083 No batch to process for model gemma-7b
2024-09-20 12:32:08,084 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:32:08,084 No batch to process for model llama3-8b
2024-09-20 12:32:08,085 127.0.0.1 - - [20/Sep/2024 12:32:08] "POST /inference HTTP/1.1" 200 -
