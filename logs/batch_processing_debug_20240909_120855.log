2024-09-09 12:08:55,172 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.212:5000
2024-09-09 12:08:55,172 [33mPress CTRL+C to quit[0m
2024-09-09 12:08:57,773 Current time: 1725898137.7732
2024-09-09 12:08:57,773 Model gpt2-124m loading time: 0.0741 seconds, unloading time: 0.0000 seconds
2024-09-09 12:08:57,773 Adjusted time limit: 4.9259 seconds
2024-09-09 12:08:57,773 Timer for model gpt2-124m set to fire at: 1725898142.6991
2024-09-09 12:08:57,773 127.0.0.1 - - [09/Sep/2024 12:08:57] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:00,251 Current time: 1725898140.2510
2024-09-09 12:09:00,251 Model gpt2-124m loading time: 0.0741 seconds, unloading time: 0.0000 seconds
2024-09-09 12:09:00,251 Adjusted time limit: 4.9259 seconds
2024-09-09 12:09:00,251 Timer for model gpt2-124m set to fire at: 1725898142.6991
2024-09-09 12:09:00,252 127.0.0.1 - - [09/Sep/2024 12:09:00] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:01,244 Current time: 1725898141.2440
2024-09-09 12:09:01,244 Model gpt2medium-355m loading time: 0.0616 seconds, unloading time: 0.0000 seconds
2024-09-09 12:09:01,244 Adjusted time limit: 4.9384 seconds
2024-09-09 12:09:01,244 Timer for model gpt2medium-355m set to fire at: 1725898146.1824
2024-09-09 12:09:01,245 127.0.0.1 - - [09/Sep/2024 12:09:01] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:01,431 Current time: 1725898141.4313
2024-09-09 12:09:01,431 Model gpt2-124m loading time: 0.0741 seconds, unloading time: 0.0000 seconds
2024-09-09 12:09:01,431 Adjusted time limit: 4.9259 seconds
2024-09-09 12:09:01,431 Timer for model gpt2-124m set to fire at: 1725898142.6991
2024-09-09 12:09:01,432 127.0.0.1 - - [09/Sep/2024 12:09:01] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:02,538 Current time: 1725898142.5389
2024-09-09 12:09:02,538 Model gpt2-124m loading time: 0.0741 seconds, unloading time: 0.0000 seconds
2024-09-09 12:09:02,538 Adjusted time limit: 4.9259 seconds
2024-09-09 12:09:02,539 Timer for model gpt2-124m set to fire at: 1725898142.6991
2024-09-09 12:09:02,539 Batch size condition met for model gpt2-124m
2024-09-09 12:09:02,539 4
2024-09-09 12:09:02,539 Loading model gpt2-124m
2024-09-09 12:09:02,652 Batch processing started at 356921.6679 for model gpt2-124m
2024-09-09 12:09:02,749 Time limit reached for model gpt2-124m at 1725898142.7498
2024-09-09 12:09:02,855 Time limit reached for model gpt2-124m at 1725898142.8553
2024-09-09 12:09:02,960 Time limit reached for model gpt2-124m at 1725898142.9605
2024-09-09 12:09:03,065 Time limit reached for model gpt2-124m at 1725898143.0658
2024-09-09 12:09:03,171 Time limit reached for model gpt2-124m at 1725898143.1710
2024-09-09 12:09:03,276 Time limit reached for model gpt2-124m at 1725898143.2763
2024-09-09 12:09:03,376 Processed request ID c76dba64 with model gpt2-124m
2024-09-09 12:09:03,376 Processed request ID 40a48ebb with model gpt2-124m
2024-09-09 12:09:03,376 Processed request ID 4826b42f with model gpt2-124m
2024-09-09 12:09:03,377 Processed request ID 3dd7b421 with model gpt2-124m
2024-09-09 12:09:03,377 Processed batch: ['c76dba64', '40a48ebb', '4826b42f', '3dd7b421'] with model gpt2-124m in 0.7243 seconds
2024-09-09 12:09:03,377 Latency for request c76dba64 with model gpt2-124m: 5.6039 seconds
2024-09-09 12:09:03,378 Latency for request 40a48ebb with model gpt2-124m: 3.1263 seconds
2024-09-09 12:09:03,379 Latency for request 4826b42f with model gpt2-124m: 1.9461 seconds
2024-09-09 12:09:03,379 Latency for request 3dd7b421 with model gpt2-124m: 0.8383 seconds
2024-09-09 12:09:03,379 127.0.0.1 - - [09/Sep/2024 12:09:03] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:04,527 Current time: 1725898144.5271
2024-09-09 12:09:04,527 Model distilgpt2-124m loading time: 0.0349 seconds, unloading time: 0.0044 seconds
2024-09-09 12:09:04,527 Adjusted time limit: 4.9607 seconds
2024-09-09 12:09:04,527 Timer for model distilgpt2-124m set to fire at: 1725898149.4878
2024-09-09 12:09:04,527 127.0.0.1 - - [09/Sep/2024 12:09:04] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:06,184 Time limit reached for model gpt2medium-355m at 1725898146.1839
2024-09-09 12:09:06,184 Moving batch for gpt2medium-355m from incoming to running due to time limit with batch size 1
2024-09-09 12:09:06,184 Time limit condition met for model gpt2medium-355m
2024-09-09 12:09:06,185 1
2024-09-09 12:09:06,185 Padding requests generated in 0.0001 seconds
2024-09-09 12:09:06,185 Loading model gpt2medium-355m
2024-09-09 12:09:06,300 Batch processing started at 356925.3158 for model gpt2medium-355m
2024-09-09 12:09:06,350 Current time: 1725898146.3506
2024-09-09 12:09:06,350 Model distilgpt2-124m loading time: 0.0349 seconds, unloading time: 0.0062 seconds
2024-09-09 12:09:06,350 Adjusted time limit: 4.9589 seconds
2024-09-09 12:09:06,350 Timer for model distilgpt2-124m set to fire at: 1725898149.4878
2024-09-09 12:09:06,350 127.0.0.1 - - [09/Sep/2024 12:09:06] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:08,047 Current time: 1725898148.0471
2024-09-09 12:09:08,047 Model gpt2medium-355m loading time: 0.0616 seconds, unloading time: 0.0062 seconds
2024-09-09 12:09:08,047 Adjusted time limit: 4.9322 seconds
2024-09-09 12:09:08,047 Timer for model gpt2medium-355m set to fire at: 1725898146.1824
2024-09-09 12:09:08,047 127.0.0.1 - - [09/Sep/2024 12:09:08] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:09,221 Current time: 1725898149.2220
2024-09-09 12:09:09,222 Model distilgpt2-124m loading time: 0.0349 seconds, unloading time: 0.0062 seconds
2024-09-09 12:09:09,222 Adjusted time limit: 4.9589 seconds
2024-09-09 12:09:09,222 Timer for model distilgpt2-124m set to fire at: 1725898149.4878
2024-09-09 12:09:09,222 127.0.0.1 - - [09/Sep/2024 12:09:09] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:10,586 Current time: 1725898150.5864
2024-09-09 12:09:10,586 Model gpt2medium-355m loading time: 0.0616 seconds, unloading time: 0.0062 seconds
2024-09-09 12:09:10,586 Adjusted time limit: 4.9322 seconds
2024-09-09 12:09:10,586 Timer for model gpt2medium-355m set to fire at: 1725898146.1824
2024-09-09 12:09:10,586 127.0.0.1 - - [09/Sep/2024 12:09:10] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:10,889 Processed request ID 7b1d6076 with model gpt2medium-355m
2024-09-09 12:09:10,890 Processed request ID 66f6 with model gpt2medium-355m
2024-09-09 12:09:10,890 Processed request ID 2d37 with model gpt2medium-355m
2024-09-09 12:09:10,890 Processed request ID 8e74 with model gpt2medium-355m
2024-09-09 12:09:10,890 Processed batch: ['7b1d6076', '66f6', '2d37', '8e74'] with model gpt2medium-355m in 4.5900 seconds
2024-09-09 12:09:10,890 Latency for request 7b1d6076 with model gpt2medium-355m: 9.6470 seconds
2024-09-09 12:09:10,891 Latency for request 66f6 with model gpt2medium-355m: 4.7055 seconds
2024-09-09 12:09:10,891 Latency for request 2d37 with model gpt2medium-355m: 4.7055 seconds
2024-09-09 12:09:10,892 Latency for request 8e74 with model gpt2medium-355m: 4.7054 seconds
2024-09-09 12:09:10,997 Time limit reached for model distilgpt2-124m at 1725898150.9973
2024-09-09 12:09:10,997 Moving batch for distilgpt2-124m from incoming to running due to time limit with batch size 3
2024-09-09 12:09:10,997 Time limit condition met for model distilgpt2-124m
2024-09-09 12:09:10,997 3
2024-09-09 12:09:10,997 Padding requests generated in 0.0000 seconds
2024-09-09 12:09:10,997 Loading model distilgpt2-124m
2024-09-09 12:09:11,054 Batch processing started at 356930.0693 for model distilgpt2-124m
2024-09-09 12:09:12,052 Current time: 1725898152.0523
2024-09-09 12:09:12,052 Model gpt2-124m loading time: 0.0741 seconds, unloading time: 0.0037 seconds
2024-09-09 12:09:12,052 Adjusted time limit: 4.9222 seconds
2024-09-09 12:09:12,052 Timer for model gpt2-124m set to fire at: 1725898156.9745
2024-09-09 12:09:12,052 127.0.0.1 - - [09/Sep/2024 12:09:12] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:12,303 Processed request ID 525211a3 with model distilgpt2-124m
2024-09-09 12:09:12,304 Processed request ID 10c884e9 with model distilgpt2-124m
2024-09-09 12:09:12,304 Processed request ID 4268eaf5 with model distilgpt2-124m
2024-09-09 12:09:12,305 Processed request ID 1e41 with model distilgpt2-124m
2024-09-09 12:09:12,305 Processed batch: ['525211a3', '10c884e9', '4268eaf5', '1e41'] with model distilgpt2-124m in 1.2510 seconds
2024-09-09 12:09:12,305 Latency for request 525211a3 with model distilgpt2-124m: 7.7781 seconds
2024-09-09 12:09:12,305 Latency for request 10c884e9 with model distilgpt2-124m: 5.9546 seconds
2024-09-09 12:09:12,306 Latency for request 4268eaf5 with model distilgpt2-124m: 3.0833 seconds
2024-09-09 12:09:12,306 Latency for request 1e41 with model distilgpt2-124m: 1.3078 seconds
2024-09-09 12:09:13,886 Current time: 1725898153.8864
2024-09-09 12:09:13,886 Model gpt2medium-355m loading time: 0.0616 seconds, unloading time: 0.0037 seconds
2024-09-09 12:09:13,887 Adjusted time limit: 4.9347 seconds
2024-09-09 12:09:13,887 Timer for model gpt2medium-355m set to fire at: 1725898158.8211
2024-09-09 12:09:13,887 127.0.0.1 - - [09/Sep/2024 12:09:13] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:14,975 Current time: 1725898154.9751
2024-09-09 12:09:14,977 Model gpt2-124m loading time: 0.0741 seconds, unloading time: 0.0037 seconds
2024-09-09 12:09:14,977 Adjusted time limit: 4.9222 seconds
2024-09-09 12:09:14,977 Timer for model gpt2-124m set to fire at: 1725898156.9745
2024-09-09 12:09:14,977 127.0.0.1 - - [09/Sep/2024 12:09:14] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:15,982 Current time: 1725898155.9826
2024-09-09 12:09:15,982 Model distilgpt2-124m loading time: 0.0349 seconds, unloading time: 0.0037 seconds
2024-09-09 12:09:15,983 Adjusted time limit: 4.9614 seconds
2024-09-09 12:09:15,983 Timer for model distilgpt2-124m set to fire at: 1725898160.9440
2024-09-09 12:09:15,984 127.0.0.1 - - [09/Sep/2024 12:09:15] "POST /inference HTTP/1.1" 200 -
2024-09-09 12:09:16,978 Time limit reached for model gpt2-124m at 1725898156.9787
2024-09-09 12:09:16,979 Moving batch for gpt2-124m from incoming to running due to time limit with batch size 2
2024-09-09 12:09:16,979 Time limit condition met for model gpt2-124m
2024-09-09 12:09:16,979 2
2024-09-09 12:09:16,980 Padding requests generated in 0.0001 seconds
2024-09-09 12:09:16,980 Loading model gpt2-124m
2024-09-09 12:09:17,104 Batch processing started at 356936.1197 for model gpt2-124m
2024-09-09 12:09:18,011 Processed request ID 1fb6eb78 with model gpt2-124m
2024-09-09 12:09:18,011 Processed request ID 17d39a65 with model gpt2-124m
2024-09-09 12:09:18,011 Processed request ID 67cc with model gpt2-124m
2024-09-09 12:09:18,012 Processed request ID f94b with model gpt2-124m
2024-09-09 12:09:18,012 Processed batch: ['1fb6eb78', '17d39a65', '67cc', 'f94b'] with model gpt2-124m in 0.9074 seconds
2024-09-09 12:09:18,012 Latency for request 1fb6eb78 with model gpt2-124m: 5.9598 seconds
2024-09-09 12:09:18,013 Latency for request 17d39a65 with model gpt2-124m: 3.0372 seconds
2024-09-09 12:09:18,013 Latency for request 67cc with model gpt2-124m: 1.0317 seconds
2024-09-09 12:09:18,013 Latency for request f94b with model gpt2-124m: 1.0317 seconds
2024-09-09 12:09:18,844 Time limit reached for model gpt2medium-355m at 1725898158.8448
2024-09-09 12:09:18,845 Moving batch for gpt2medium-355m from incoming to running due to time limit with batch size 3
2024-09-09 12:09:18,845 Time limit condition met for model gpt2medium-355m
2024-09-09 12:09:18,845 3
2024-09-09 12:09:18,846 Padding requests generated in 0.0001 seconds
2024-09-09 12:09:18,846 Loading model gpt2medium-355m
2024-09-09 12:09:19,013 Batch processing started at 356938.0289 for model gpt2medium-355m
2024-09-09 12:09:21,650 Processed request ID 5f0a6d47 with model gpt2medium-355m
2024-09-09 12:09:21,650 Processed request ID a4972848 with model gpt2medium-355m
2024-09-09 12:09:21,650 Processed request ID 62470c1e with model gpt2medium-355m
2024-09-09 12:09:21,650 Processed request ID ba3a with model gpt2medium-355m
2024-09-09 12:09:21,651 Processed batch: ['5f0a6d47', 'a4972848', '62470c1e', 'ba3a'] with model gpt2medium-355m in 2.6371 seconds
2024-09-09 12:09:21,651 Latency for request 5f0a6d47 with model gpt2medium-355m: 13.6040 seconds
2024-09-09 12:09:21,652 Latency for request a4972848 with model gpt2medium-355m: 11.0647 seconds
2024-09-09 12:09:21,652 Latency for request 62470c1e with model gpt2medium-355m: 7.7649 seconds
2024-09-09 12:09:21,652 Latency for request ba3a with model gpt2medium-355m: 2.8050 seconds
2024-09-09 12:09:21,757 Time limit reached for model distilgpt2-124m at 1725898161.7580
2024-09-09 12:09:21,758 Moving batch for distilgpt2-124m from incoming to running due to time limit with batch size 1
2024-09-09 12:09:21,758 Time limit condition met for model distilgpt2-124m
2024-09-09 12:09:21,758 1
2024-09-09 12:09:21,758 Padding requests generated in 0.0000 seconds
2024-09-09 12:09:21,758 Loading model distilgpt2-124m
2024-09-09 12:09:21,863 Batch processing started at 356940.8790 for model distilgpt2-124m
2024-09-09 12:09:22,524 Processed request ID 2f61a7ba with model distilgpt2-124m
2024-09-09 12:09:22,525 Processed request ID 773b with model distilgpt2-124m
2024-09-09 12:09:22,525 Processed request ID b266 with model distilgpt2-124m
2024-09-09 12:09:22,525 Processed request ID a9e8 with model distilgpt2-124m
2024-09-09 12:09:22,525 Processed batch: ['2f61a7ba', '773b', 'b266', 'a9e8'] with model distilgpt2-124m in 0.6619 seconds
2024-09-09 12:09:22,525 Latency for request 2f61a7ba with model distilgpt2-124m: 6.5434 seconds
2024-09-09 12:09:22,526 Latency for request 773b with model distilgpt2-124m: 0.7678 seconds
2024-09-09 12:09:22,526 Latency for request b266 with model distilgpt2-124m: 0.7677 seconds
2024-09-09 12:09:22,527 Latency for request a9e8 with model distilgpt2-124m: 0.7677 seconds
