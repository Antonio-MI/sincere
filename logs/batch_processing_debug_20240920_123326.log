2024-09-20 12:33:26,667 Using device: cuda
2024-09-20 12:33:26,668 Scheduling mode set as batchedFCFS
2024-09-20 12:33:26,668 Monitoring status set to True
2024-09-20 12:33:41,737 [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.122.143:5000
2024-09-20 12:33:41,737 [33mPress CTRL+C to quit[0m
2024-09-20 12:34:11,851 Request with ID 199da3dc for model gemma-7b received
2024-09-20 12:34:11,851 127.0.0.1 - - [20/Sep/2024 12:34:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:12,003 Request with ID 12118cd5 for model llama3-8b received
2024-09-20 12:34:12,003 127.0.0.1 - - [20/Sep/2024 12:34:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:12,013 Request with ID 8f0cd7f3 for model llama3-8b received
2024-09-20 12:34:12,013 127.0.0.1 - - [20/Sep/2024 12:34:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:12,108 Request with ID 0e870f5c for model granite-7b received
2024-09-20 12:34:12,109 127.0.0.1 - - [20/Sep/2024 12:34:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:12,462 Request with ID dfd6fb87 for model llama3-8b received
2024-09-20 12:34:12,463 Request with ID 456b8167 for model gemma-7b received
2024-09-20 12:34:12,464 127.0.0.1 - - [20/Sep/2024 12:34:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:12,464 127.0.0.1 - - [20/Sep/2024 12:34:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:12,500 Request with ID 406bd650 for model granite-7b received
2024-09-20 12:34:12,501 127.0.0.1 - - [20/Sep/2024 12:34:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:12,504 Request with ID 5239e3d0 for model llama3-8b received
2024-09-20 12:34:12,504 127.0.0.1 - - [20/Sep/2024 12:34:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:12,521 Request with ID 15020c4c for model gemma-7b received
2024-09-20 12:34:12,521 127.0.0.1 - - [20/Sep/2024 12:34:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:12,531 Request with ID 55e1a08d for model gemma-7b received
2024-09-20 12:34:12,531 127.0.0.1 - - [20/Sep/2024 12:34:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:12,943 Request with ID 5c9875bd for model granite-7b received
2024-09-20 12:34:12,943 127.0.0.1 - - [20/Sep/2024 12:34:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:13,038 Request with ID 257750b5 for model llama3-8b received
2024-09-20 12:34:13,038 127.0.0.1 - - [20/Sep/2024 12:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:13,040 Request with ID dcdbb506 for model llama3-8b received
2024-09-20 12:34:13,040 127.0.0.1 - - [20/Sep/2024 12:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:13,207 Request with ID a645c428 for model gemma-7b received
2024-09-20 12:34:13,207 127.0.0.1 - - [20/Sep/2024 12:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:13,324 Request with ID 881d1229 for model granite-7b received
2024-09-20 12:34:13,324 127.0.0.1 - - [20/Sep/2024 12:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:13,567 Request with ID a9e0486f for model gemma-7b received
2024-09-20 12:34:13,567 127.0.0.1 - - [20/Sep/2024 12:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:13,710 Request with ID d2ae5793 for model llama3-8b received
2024-09-20 12:34:13,711 127.0.0.1 - - [20/Sep/2024 12:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:13,791 Request with ID b1de88aa for model llama3-8b received
2024-09-20 12:34:13,791 127.0.0.1 - - [20/Sep/2024 12:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:13,942 Request with ID efbe21e4 for model gemma-7b received
2024-09-20 12:34:13,942 127.0.0.1 - - [20/Sep/2024 12:34:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,205 Request with ID abe0fb0e for model gemma-7b received
2024-09-20 12:34:14,206 127.0.0.1 - - [20/Sep/2024 12:34:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,291 Request with ID c4df2272 for model granite-7b received
2024-09-20 12:34:14,292 127.0.0.1 - - [20/Sep/2024 12:34:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,332 Request with ID 1345c41b for model llama3-8b received
2024-09-20 12:34:14,333 127.0.0.1 - - [20/Sep/2024 12:34:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,423 Request with ID 01d2c24c for model llama3-8b received
2024-09-20 12:34:14,424 127.0.0.1 - - [20/Sep/2024 12:34:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,456 Request with ID 7f6192c1 for model llama3-8b received
2024-09-20 12:34:14,457 127.0.0.1 - - [20/Sep/2024 12:34:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,464 Request with ID 806fd4a5 for model gemma-7b received
2024-09-20 12:34:14,464 127.0.0.1 - - [20/Sep/2024 12:34:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,501 Request with ID cda4b91c for model gemma-7b received
2024-09-20 12:34:14,501 127.0.0.1 - - [20/Sep/2024 12:34:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,628 Request with ID c472504b for model llama3-8b received
2024-09-20 12:34:14,628 127.0.0.1 - - [20/Sep/2024 12:34:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,635 Request with ID 7ba3ce39 for model llama3-8b received
2024-09-20 12:34:14,635 127.0.0.1 - - [20/Sep/2024 12:34:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,827 Request with ID 8186fae4 for model gemma-7b received
2024-09-20 12:34:14,828 127.0.0.1 - - [20/Sep/2024 12:34:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,833 Request with ID 8fc0284c for model llama3-8b received
2024-09-20 12:34:14,834 127.0.0.1 - - [20/Sep/2024 12:34:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,926 Request with ID ebf47ba0 for model llama3-8b received
2024-09-20 12:34:14,927 127.0.0.1 - - [20/Sep/2024 12:34:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:14,940 Request with ID cbba9323 for model llama3-8b received
2024-09-20 12:34:14,940 Batch size condition met for model llama3-8b
2024-09-20 12:34:14,940 Next: call load_model for llama3-8b
2024-09-20 12:34:15,181 Request with ID 4c0c4109 for model llama3-8b received
2024-09-20 12:34:15,181 127.0.0.1 - - [20/Sep/2024 12:34:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:15,182 Request with ID b95c531e for model llama3-8b received
2024-09-20 12:34:15,182 127.0.0.1 - - [20/Sep/2024 12:34:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:15,185 Request with ID 95482ef5 for model gemma-7b received
2024-09-20 12:34:15,185 127.0.0.1 - - [20/Sep/2024 12:34:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:15,440 Request with ID 73f553de for model llama3-8b received
2024-09-20 12:34:15,444 127.0.0.1 - - [20/Sep/2024 12:34:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:15,586 Request with ID c7235c10 for model llama3-8b received
2024-09-20 12:34:15,589 127.0.0.1 - - [20/Sep/2024 12:34:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:15,593 Request with ID c8a4e924 for model llama3-8b received
2024-09-20 12:34:15,593 127.0.0.1 - - [20/Sep/2024 12:34:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:15,659 Request with ID 9e5b3e12 for model llama3-8b received
2024-09-20 12:34:15,662 127.0.0.1 - - [20/Sep/2024 12:34:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:15,828 Request with ID 3b035f88 for model llama3-8b received
2024-09-20 12:34:15,831 127.0.0.1 - - [20/Sep/2024 12:34:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:15,867 Request with ID acb1a863 for model llama3-8b received
2024-09-20 12:34:15,868 127.0.0.1 - - [20/Sep/2024 12:34:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:16,037 Request with ID 4b22f4ef for model gemma-7b received
2024-09-20 12:34:16,042 127.0.0.1 - - [20/Sep/2024 12:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:16,143 Request with ID 5e6af5cc for model llama3-8b received
2024-09-20 12:34:16,149 127.0.0.1 - - [20/Sep/2024 12:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:16,169 Request with ID ab0635a3 for model llama3-8b received
2024-09-20 12:34:16,170 127.0.0.1 - - [20/Sep/2024 12:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:16,182 Request with ID cc94fa70 for model llama3-8b received
2024-09-20 12:34:16,184 127.0.0.1 - - [20/Sep/2024 12:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:16,203 Request with ID d75c0c3c for model gemma-7b received
2024-09-20 12:34:16,207 127.0.0.1 - - [20/Sep/2024 12:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:16,395 Request with ID cb35bb39 for model llama3-8b received
2024-09-20 12:34:16,395 127.0.0.1 - - [20/Sep/2024 12:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:16,428 Request with ID 46e5acb7 for model llama3-8b received
2024-09-20 12:34:16,428 127.0.0.1 - - [20/Sep/2024 12:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:16,758 Request with ID b5c63f02 for model gemma-7b received
2024-09-20 12:34:16,758 127.0.0.1 - - [20/Sep/2024 12:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:16,761 Request with ID 0589fba6 for model llama3-8b received
2024-09-20 12:34:16,762 127.0.0.1 - - [20/Sep/2024 12:34:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:16,817 Request with ID d96823d7 for model gemma-7b received
2024-09-20 12:34:16,817 Batch size condition met for model gemma-7b
2024-09-20 12:34:17,058 Request with ID 6af692d0 for model gemma-7b received
2024-09-20 12:34:17,058 127.0.0.1 - - [20/Sep/2024 12:34:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:17,127 Request with ID 10bd27f9 for model llama3-8b received
2024-09-20 12:34:17,128 127.0.0.1 - - [20/Sep/2024 12:34:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:17,220 Request with ID a8867843 for model gemma-7b received
2024-09-20 12:34:17,220 127.0.0.1 - - [20/Sep/2024 12:34:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:17,249 Request with ID 6a22e57b for model gemma-7b received
2024-09-20 12:34:17,249 127.0.0.1 - - [20/Sep/2024 12:34:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:17,351 Request with ID 7566794d for model gemma-7b received
2024-09-20 12:34:17,352 127.0.0.1 - - [20/Sep/2024 12:34:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:17,522 Request with ID d4192722 for model gemma-7b received
2024-09-20 12:34:17,523 127.0.0.1 - - [20/Sep/2024 12:34:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:17,595 Request with ID 30e5fb31 for model llama3-8b received
2024-09-20 12:34:17,595 Batch size condition met for model llama3-8b
2024-09-20 12:34:17,711 Request with ID 3f824772 for model llama3-8b received
2024-09-20 12:34:17,711 127.0.0.1 - - [20/Sep/2024 12:34:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:17,736 Request with ID 418132d6 for model gemma-7b received
2024-09-20 12:34:17,737 127.0.0.1 - - [20/Sep/2024 12:34:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:17,857 Request with ID 75bc83a9 for model llama3-8b received
2024-09-20 12:34:17,858 127.0.0.1 - - [20/Sep/2024 12:34:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:18,041 Request with ID 2427c2a7 for model gemma-7b received
2024-09-20 12:34:18,041 127.0.0.1 - - [20/Sep/2024 12:34:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:18,052 Request with ID 3ae5e8f0 for model llama3-8b received
2024-09-20 12:34:18,053 127.0.0.1 - - [20/Sep/2024 12:34:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:18,085 Request with ID cdb072c3 for model gemma-7b received
2024-09-20 12:34:18,086 127.0.0.1 - - [20/Sep/2024 12:34:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:18,489 Request with ID d29eb82c for model gemma-7b received
2024-09-20 12:34:18,490 127.0.0.1 - - [20/Sep/2024 12:34:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:18,499 Request with ID 074e3275 for model llama3-8b received
2024-09-20 12:34:18,500 127.0.0.1 - - [20/Sep/2024 12:34:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:18,602 Request with ID da646e4e for model gemma-7b received
2024-09-20 12:34:18,602 127.0.0.1 - - [20/Sep/2024 12:34:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:18,724 Request with ID 937bf482 for model llama3-8b received
2024-09-20 12:34:18,725 127.0.0.1 - - [20/Sep/2024 12:34:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:18,777 Request with ID b798801d for model llama3-8b received
2024-09-20 12:34:18,778 127.0.0.1 - - [20/Sep/2024 12:34:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:18,785 Request with ID f3ad0b5d for model llama3-8b received
2024-09-20 12:34:18,786 127.0.0.1 - - [20/Sep/2024 12:34:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:18,883 Request with ID 39f33b41 for model llama3-8b received
2024-09-20 12:34:18,884 127.0.0.1 - - [20/Sep/2024 12:34:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:18,885 Request with ID d0d6647d for model gemma-7b received
2024-09-20 12:34:18,886 127.0.0.1 - - [20/Sep/2024 12:34:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:18,952 Request with ID 4162ed7f for model gemma-7b received
2024-09-20 12:34:18,953 127.0.0.1 - - [20/Sep/2024 12:34:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:19,077 Request with ID b49e0399 for model gemma-7b received
2024-09-20 12:34:19,078 127.0.0.1 - - [20/Sep/2024 12:34:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:19,217 Request with ID f076734c for model llama3-8b received
2024-09-20 12:34:19,218 127.0.0.1 - - [20/Sep/2024 12:34:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:19,347 Request with ID 98f83385 for model llama3-8b received
2024-09-20 12:34:19,348 127.0.0.1 - - [20/Sep/2024 12:34:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:19,359 Request with ID 975e580d for model gemma-7b received
2024-09-20 12:34:19,359 127.0.0.1 - - [20/Sep/2024 12:34:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:19,387 Request with ID 63ede937 for model llama3-8b received
2024-09-20 12:34:19,388 127.0.0.1 - - [20/Sep/2024 12:34:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:19,457 Request with ID 7b1aa20e for model llama3-8b received
2024-09-20 12:34:19,458 127.0.0.1 - - [20/Sep/2024 12:34:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:19,618 Request with ID 9f075193 for model llama3-8b received
2024-09-20 12:34:19,619 127.0.0.1 - - [20/Sep/2024 12:34:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:19,730 Request with ID 06d2a25f for model gemma-7b received
2024-09-20 12:34:19,731 127.0.0.1 - - [20/Sep/2024 12:34:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:19,859 Request with ID d59e5ae6 for model llama3-8b received
2024-09-20 12:34:19,860 127.0.0.1 - - [20/Sep/2024 12:34:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:20,008 Request with ID 037624f9 for model llama3-8b received
2024-09-20 12:34:20,009 127.0.0.1 - - [20/Sep/2024 12:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:20,073 Request with ID 685f4e28 for model llama3-8b received
2024-09-20 12:34:20,073 Batch size condition met for model llama3-8b
2024-09-20 12:34:20,121 Request with ID 2673ea71 for model llama3-8b received
2024-09-20 12:34:20,122 127.0.0.1 - - [20/Sep/2024 12:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:20,162 Request with ID 940ddd98 for model llama3-8b received
2024-09-20 12:34:20,162 127.0.0.1 - - [20/Sep/2024 12:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:20,612 Request with ID 35e6dba8 for model granite-7b received
2024-09-20 12:34:20,613 127.0.0.1 - - [20/Sep/2024 12:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:20,614 Request with ID 184cd80f for model gemma-7b received
2024-09-20 12:34:20,615 Batch size condition met for model gemma-7b
2024-09-20 12:34:20,616 Request with ID 4b1fe12a for model llama3-8b received
2024-09-20 12:34:20,617 127.0.0.1 - - [20/Sep/2024 12:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:20,878 Request with ID 62965dd9 for model llama3-8b received
2024-09-20 12:34:20,878 127.0.0.1 - - [20/Sep/2024 12:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:20,886 Request with ID 449919cd for model llama3-8b received
2024-09-20 12:34:20,886 127.0.0.1 - - [20/Sep/2024 12:34:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:21,350 Request with ID b9a9100f for model gemma-7b received
2024-09-20 12:34:21,350 127.0.0.1 - - [20/Sep/2024 12:34:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:21,391 Request with ID 7aec7736 for model gemma-7b received
2024-09-20 12:34:21,391 127.0.0.1 - - [20/Sep/2024 12:34:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:21,427 Request with ID 6b1b1d25 for model llama3-8b received
2024-09-20 12:34:21,427 127.0.0.1 - - [20/Sep/2024 12:34:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:21,632 Request with ID 4fd8abc2 for model granite-7b received
2024-09-20 12:34:21,633 127.0.0.1 - - [20/Sep/2024 12:34:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:21,634 Request with ID 7d14300c for model llama3-8b received
2024-09-20 12:34:21,635 127.0.0.1 - - [20/Sep/2024 12:34:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:21,739 Request with ID aebe4383 for model granite-7b received
2024-09-20 12:34:21,740 127.0.0.1 - - [20/Sep/2024 12:34:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:21,958 Request with ID 9fbe1d97 for model gemma-7b received
2024-09-20 12:34:21,959 127.0.0.1 - - [20/Sep/2024 12:34:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:21,968 Request with ID 63c9f252 for model granite-7b received
2024-09-20 12:34:21,968 127.0.0.1 - - [20/Sep/2024 12:34:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,033 Request with ID 76337b06 for model llama3-8b received
2024-09-20 12:34:22,033 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,218 Request with ID 732c2483 for model granite-7b received
2024-09-20 12:34:22,218 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,255 Request with ID 988a6bc4 for model gemma-7b received
2024-09-20 12:34:22,255 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,355 Request with ID 4b21ee85 for model llama3-8b received
2024-09-20 12:34:22,355 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,377 Request with ID d05e96b8 for model llama3-8b received
2024-09-20 12:34:22,378 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,395 Request with ID f58bab8b for model llama3-8b received
2024-09-20 12:34:22,396 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,522 Request with ID 2d216a3a for model llama3-8b received
2024-09-20 12:34:22,523 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,555 Request with ID b127dadd for model granite-7b received
2024-09-20 12:34:22,555 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,558 Request with ID 65e9a932 for model granite-7b received
2024-09-20 12:34:22,558 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,616 Request with ID 557a7320 for model llama3-8b received
2024-09-20 12:34:22,617 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,636 Request with ID a224828a for model llama3-8b received
2024-09-20 12:34:22,637 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,665 Request with ID 84107507 for model llama3-8b received
2024-09-20 12:34:22,665 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:22,776 Request with ID b473ecb1 for model llama3-8b received
2024-09-20 12:34:22,776 Batch size condition met for model llama3-8b
2024-09-20 12:34:22,912 Request with ID 4dd6f2a4 for model llama3-8b received
2024-09-20 12:34:22,913 127.0.0.1 - - [20/Sep/2024 12:34:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:23,044 Request with ID dd3aa23e for model gemma-7b received
2024-09-20 12:34:23,045 127.0.0.1 - - [20/Sep/2024 12:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:23,189 Request with ID 8e927bbb for model granite-7b received
2024-09-20 12:34:23,190 127.0.0.1 - - [20/Sep/2024 12:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:23,194 Request with ID 6155598d for model llama3-8b received
2024-09-20 12:34:23,195 127.0.0.1 - - [20/Sep/2024 12:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:23,213 Request with ID 91d55a44 for model gemma-7b received
2024-09-20 12:34:23,214 127.0.0.1 - - [20/Sep/2024 12:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:23,365 Request with ID 799e88db for model gemma-7b received
2024-09-20 12:34:23,365 127.0.0.1 - - [20/Sep/2024 12:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:23,374 Request with ID d4d5de71 for model llama3-8b received
2024-09-20 12:34:23,374 127.0.0.1 - - [20/Sep/2024 12:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:23,485 Request with ID 71a39985 for model llama3-8b received
2024-09-20 12:34:23,485 127.0.0.1 - - [20/Sep/2024 12:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:23,776 Request with ID 0c979fe9 for model llama3-8b received
2024-09-20 12:34:23,776 127.0.0.1 - - [20/Sep/2024 12:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:23,879 Request with ID 08e5d502 for model llama3-8b received
2024-09-20 12:34:23,880 127.0.0.1 - - [20/Sep/2024 12:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:23,929 Request with ID e0c65029 for model llama3-8b received
2024-09-20 12:34:23,930 127.0.0.1 - - [20/Sep/2024 12:34:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:24,010 Request with ID f7c11dc7 for model llama3-8b received
2024-09-20 12:34:24,011 127.0.0.1 - - [20/Sep/2024 12:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:24,182 Request with ID 1902b015 for model llama3-8b received
2024-09-20 12:34:24,183 127.0.0.1 - - [20/Sep/2024 12:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:24,205 Request with ID 5142c9fe for model gemma-7b received
2024-09-20 12:34:24,205 127.0.0.1 - - [20/Sep/2024 12:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:24,208 Request with ID 7cf84187 for model llama3-8b received
2024-09-20 12:34:24,208 127.0.0.1 - - [20/Sep/2024 12:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:24,216 Request with ID af6e9b6f for model gemma-7b received
2024-09-20 12:34:24,216 127.0.0.1 - - [20/Sep/2024 12:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:24,334 Request with ID 89b2a500 for model gemma-7b received
2024-09-20 12:34:24,334 127.0.0.1 - - [20/Sep/2024 12:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:24,403 Request with ID 418595cb for model llama3-8b received
2024-09-20 12:34:24,404 127.0.0.1 - - [20/Sep/2024 12:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:24,504 Request with ID dffb15be for model granite-7b received
2024-09-20 12:34:24,505 127.0.0.1 - - [20/Sep/2024 12:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:24,560 Request with ID 2d0ca9b7 for model gemma-7b received
2024-09-20 12:34:24,560 127.0.0.1 - - [20/Sep/2024 12:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:24,701 Request with ID a4b1209d for model llama3-8b received
2024-09-20 12:34:24,701 127.0.0.1 - - [20/Sep/2024 12:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:24,748 Request with ID 0662990d for model gemma-7b received
2024-09-20 12:34:24,749 127.0.0.1 - - [20/Sep/2024 12:34:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:25,018 Request with ID 005b9e32 for model gemma-7b received
2024-09-20 12:34:25,018 127.0.0.1 - - [20/Sep/2024 12:34:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:25,134 Request with ID 868163a9 for model gemma-7b received
2024-09-20 12:34:25,135 127.0.0.1 - - [20/Sep/2024 12:34:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:25,212 Request with ID 416543fc for model llama3-8b received
2024-09-20 12:34:25,213 127.0.0.1 - - [20/Sep/2024 12:34:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:25,251 Request with ID 69a9de6f for model granite-7b received
2024-09-20 12:34:25,252 127.0.0.1 - - [20/Sep/2024 12:34:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:25,258 Request with ID 09589a17 for model gemma-7b received
2024-09-20 12:34:25,258 127.0.0.1 - - [20/Sep/2024 12:34:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:25,574 Request with ID 5b25c202 for model llama3-8b received
2024-09-20 12:34:25,575 127.0.0.1 - - [20/Sep/2024 12:34:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:25,583 Request with ID 8fa088a2 for model gemma-7b received
2024-09-20 12:34:25,583 Batch size condition met for model gemma-7b
2024-09-20 12:34:25,697 Request with ID 561ef969 for model llama3-8b received
2024-09-20 12:34:25,697 127.0.0.1 - - [20/Sep/2024 12:34:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:25,706 Request with ID 10c95439 for model llama3-8b received
2024-09-20 12:34:25,706 Batch size condition met for model llama3-8b
2024-09-20 12:34:26,334 Request with ID 1defc8af for model llama3-8b received
2024-09-20 12:34:26,335 127.0.0.1 - - [20/Sep/2024 12:34:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:26,480 Request with ID be5b6f67 for model llama3-8b received
2024-09-20 12:34:26,480 127.0.0.1 - - [20/Sep/2024 12:34:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:26,828 Request with ID bb3ec356 for model llama3-8b received
2024-09-20 12:34:26,828 127.0.0.1 - - [20/Sep/2024 12:34:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:26,838 Request with ID d601a0e3 for model llama3-8b received
2024-09-20 12:34:26,838 127.0.0.1 - - [20/Sep/2024 12:34:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:26,864 Request with ID 993e625d for model llama3-8b received
2024-09-20 12:34:26,865 127.0.0.1 - - [20/Sep/2024 12:34:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:26,989 Request with ID 77f20ff5 for model llama3-8b received
2024-09-20 12:34:26,989 127.0.0.1 - - [20/Sep/2024 12:34:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:27,016 Request with ID 1432a424 for model llama3-8b received
2024-09-20 12:34:27,017 127.0.0.1 - - [20/Sep/2024 12:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:27,231 Request with ID 23e10d83 for model llama3-8b received
2024-09-20 12:34:27,231 127.0.0.1 - - [20/Sep/2024 12:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:27,660 Request with ID 7e42efe9 for model gemma-7b received
2024-09-20 12:34:27,661 127.0.0.1 - - [20/Sep/2024 12:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:27,785 Request with ID ba206453 for model llama3-8b received
2024-09-20 12:34:27,785 127.0.0.1 - - [20/Sep/2024 12:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:27,869 Request with ID f0ef0bac for model gemma-7b received
2024-09-20 12:34:27,869 127.0.0.1 - - [20/Sep/2024 12:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:27,910 Request with ID c7299690 for model granite-7b received
2024-09-20 12:34:27,910 Batch size condition met for model granite-7b
2024-09-20 12:34:27,976 Request with ID c70d49fd for model llama3-8b received
2024-09-20 12:34:27,976 127.0.0.1 - - [20/Sep/2024 12:34:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:28,124 Request with ID cd87837a for model llama3-8b received
2024-09-20 12:34:28,124 127.0.0.1 - - [20/Sep/2024 12:34:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:28,264 Request with ID cca9096e for model gemma-7b received
2024-09-20 12:34:28,264 127.0.0.1 - - [20/Sep/2024 12:34:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:28,316 Request with ID 98dfe150 for model gemma-7b received
2024-09-20 12:34:28,317 127.0.0.1 - - [20/Sep/2024 12:34:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:28,521 Request with ID 78b37995 for model llama3-8b received
2024-09-20 12:34:28,522 127.0.0.1 - - [20/Sep/2024 12:34:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:28,685 Request with ID 80b36a90 for model llama3-8b received
2024-09-20 12:34:28,686 127.0.0.1 - - [20/Sep/2024 12:34:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:28,690 Request with ID ea3704dd for model granite-7b received
2024-09-20 12:34:28,690 127.0.0.1 - - [20/Sep/2024 12:34:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:28,951 Request with ID 93d9176f for model gemma-7b received
2024-09-20 12:34:28,951 127.0.0.1 - - [20/Sep/2024 12:34:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:29,072 Request with ID 94219c10 for model llama3-8b received
2024-09-20 12:34:29,072 127.0.0.1 - - [20/Sep/2024 12:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:29,259 Request with ID 14c188bf for model llama3-8b received
2024-09-20 12:34:29,260 127.0.0.1 - - [20/Sep/2024 12:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:29,261 Request with ID 6e6cd3f1 for model granite-7b received
2024-09-20 12:34:29,262 127.0.0.1 - - [20/Sep/2024 12:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:29,275 Request with ID 2df94f4c for model gemma-7b received
2024-09-20 12:34:29,275 127.0.0.1 - - [20/Sep/2024 12:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:29,288 Request with ID a275c4b8 for model gemma-7b received
2024-09-20 12:34:29,288 127.0.0.1 - - [20/Sep/2024 12:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:29,310 Request with ID a6a2c7b2 for model gemma-7b received
2024-09-20 12:34:29,310 127.0.0.1 - - [20/Sep/2024 12:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:29,338 Request with ID c0848268 for model granite-7b received
2024-09-20 12:34:29,338 127.0.0.1 - - [20/Sep/2024 12:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:29,706 Request with ID 623b6153 for model llama3-8b received
2024-09-20 12:34:29,706 Batch size condition met for model llama3-8b
2024-09-20 12:34:29,785 Request with ID 669926fc for model llama3-8b received
2024-09-20 12:34:29,785 127.0.0.1 - - [20/Sep/2024 12:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:29,879 Request with ID 034e4025 for model gemma-7b received
2024-09-20 12:34:29,879 127.0.0.1 - - [20/Sep/2024 12:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:29,887 Request with ID ffabcfc5 for model llama3-8b received
2024-09-20 12:34:29,888 127.0.0.1 - - [20/Sep/2024 12:34:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,019 Request with ID 92074a8c for model llama3-8b received
2024-09-20 12:34:30,020 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,029 Request with ID 87c68460 for model llama3-8b received
2024-09-20 12:34:30,029 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,033 Request with ID a50dc9ac for model gemma-7b received
2024-09-20 12:34:30,034 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,202 Request with ID ab939dcf for model llama3-8b received
2024-09-20 12:34:30,203 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,251 Request with ID 190a6e35 for model gemma-7b received
2024-09-20 12:34:30,251 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,431 Request with ID aa3d6e78 for model llama3-8b received
2024-09-20 12:34:30,432 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,496 Request with ID c9fd7a5f for model gemma-7b received
2024-09-20 12:34:30,497 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,502 Request with ID accacc73 for model llama3-8b received
2024-09-20 12:34:30,503 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,581 Request with ID 8c3a90a7 for model llama3-8b received
2024-09-20 12:34:30,581 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,663 Request with ID 80ade681 for model llama3-8b received
2024-09-20 12:34:30,664 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,692 Request with ID 53d01df5 for model gemma-7b received
2024-09-20 12:34:30,693 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,725 Request with ID df94a881 for model llama3-8b received
2024-09-20 12:34:30,726 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,869 Request with ID 4ab7b36c for model gemma-7b received
2024-09-20 12:34:30,870 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:30,883 Request with ID 0bbfa9da for model llama3-8b received
2024-09-20 12:34:30,884 127.0.0.1 - - [20/Sep/2024 12:34:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:31,033 Request with ID 79955cc1 for model llama3-8b received
2024-09-20 12:34:31,033 127.0.0.1 - - [20/Sep/2024 12:34:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:31,380 Request with ID f678f695 for model llama3-8b received
2024-09-20 12:34:31,380 127.0.0.1 - - [20/Sep/2024 12:34:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:31,394 Request with ID 34cf05e1 for model llama3-8b received
2024-09-20 12:34:31,394 127.0.0.1 - - [20/Sep/2024 12:34:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:31,520 Request with ID 84b1cfd4 for model llama3-8b received
2024-09-20 12:34:31,521 127.0.0.1 - - [20/Sep/2024 12:34:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:31,617 Request with ID 1d69d2e1 for model llama3-8b received
2024-09-20 12:34:31,617 Batch size condition met for model llama3-8b
2024-09-20 12:34:31,669 Request with ID 5c9c5065 for model llama3-8b received
2024-09-20 12:34:31,670 127.0.0.1 - - [20/Sep/2024 12:34:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:31,750 Request with ID d2872486 for model gemma-7b received
2024-09-20 12:34:31,751 127.0.0.1 - - [20/Sep/2024 12:34:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:31,848 Request with ID 29611a18 for model llama3-8b received
2024-09-20 12:34:31,849 127.0.0.1 - - [20/Sep/2024 12:34:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:31,866 Request with ID 800128df for model llama3-8b received
2024-09-20 12:34:31,867 127.0.0.1 - - [20/Sep/2024 12:34:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:31,873 Request with ID 92f5bd1a for model llama3-8b received
2024-09-20 12:34:31,874 127.0.0.1 - - [20/Sep/2024 12:34:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:31,943 Request with ID e6c17526 for model gemma-7b received
2024-09-20 12:34:31,943 Batch size condition met for model gemma-7b
2024-09-20 12:34:32,033 Request with ID e710549d for model llama3-8b received
2024-09-20 12:34:32,033 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,094 Request with ID 0298c53f for model llama3-8b received
2024-09-20 12:34:32,095 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,218 Request with ID 1669142b for model gemma-7b received
2024-09-20 12:34:32,219 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,262 Request with ID a763a3b4 for model llama3-8b received
2024-09-20 12:34:32,262 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,372 Request with ID f0a33054 for model llama3-8b received
2024-09-20 12:34:32,373 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,399 Request with ID dffcc7c2 for model gemma-7b received
2024-09-20 12:34:32,399 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,444 Request with ID ae77d76b for model llama3-8b received
2024-09-20 12:34:32,445 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,523 Request with ID 526ad0c2 for model gemma-7b received
2024-09-20 12:34:32,524 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,569 Request with ID 28691b23 for model gemma-7b received
2024-09-20 12:34:32,569 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,610 Request with ID 5e757606 for model llama3-8b received
2024-09-20 12:34:32,610 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,619 Request with ID 5c50ecfb for model llama3-8b received
2024-09-20 12:34:32,619 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,627 Request with ID ccbf58ab for model llama3-8b received
2024-09-20 12:34:32,627 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,756 Request with ID 152869a6 for model gemma-7b received
2024-09-20 12:34:32,757 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,759 Request with ID 7e2b91c2 for model llama3-8b received
2024-09-20 12:34:32,759 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,761 Request with ID 7e5daecf for model gemma-7b received
2024-09-20 12:34:32,762 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,764 Request with ID 414cd034 for model granite-7b received
2024-09-20 12:34:32,764 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:32,771 Request with ID 505bb968 for model llama3-8b received
2024-09-20 12:34:32,771 127.0.0.1 - - [20/Sep/2024 12:34:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:33,000 Request with ID b1aac614 for model granite-7b received
2024-09-20 12:34:33,000 127.0.0.1 - - [20/Sep/2024 12:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:33,204 Request with ID 8144bbb5 for model gemma-7b received
2024-09-20 12:34:33,204 127.0.0.1 - - [20/Sep/2024 12:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:33,236 Request with ID b6bcc7da for model gemma-7b received
2024-09-20 12:34:33,236 127.0.0.1 - - [20/Sep/2024 12:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:33,322 Request with ID 06ce7ad8 for model gemma-7b received
2024-09-20 12:34:33,322 127.0.0.1 - - [20/Sep/2024 12:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:33,363 Request with ID df51ca72 for model llama3-8b received
2024-09-20 12:34:33,363 127.0.0.1 - - [20/Sep/2024 12:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:33,455 Request with ID f456f55f for model gemma-7b received
2024-09-20 12:34:33,456 127.0.0.1 - - [20/Sep/2024 12:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:33,561 Request with ID 92ca7342 for model granite-7b received
2024-09-20 12:34:33,562 127.0.0.1 - - [20/Sep/2024 12:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:33,640 Request with ID ca1c5734 for model llama3-8b received
2024-09-20 12:34:33,641 Batch size condition met for model llama3-8b
2024-09-20 12:34:33,731 Request with ID caf46003 for model llama3-8b received
2024-09-20 12:34:33,732 127.0.0.1 - - [20/Sep/2024 12:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:33,826 Request with ID 713d0ac8 for model llama3-8b received
2024-09-20 12:34:33,827 127.0.0.1 - - [20/Sep/2024 12:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:33,867 Request with ID 65f23174 for model granite-7b received
2024-09-20 12:34:33,867 127.0.0.1 - - [20/Sep/2024 12:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:33,894 Request with ID b93548d4 for model gemma-7b received
2024-09-20 12:34:33,894 127.0.0.1 - - [20/Sep/2024 12:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:33,912 Request with ID 70230025 for model granite-7b received
2024-09-20 12:34:33,913 127.0.0.1 - - [20/Sep/2024 12:34:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:34,099 Request with ID d7f81335 for model granite-7b received
2024-09-20 12:34:34,100 127.0.0.1 - - [20/Sep/2024 12:34:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:34,220 Request with ID 6d529969 for model gemma-7b received
2024-09-20 12:34:34,221 127.0.0.1 - - [20/Sep/2024 12:34:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:34,274 Request with ID a9f6338a for model gemma-7b received
2024-09-20 12:34:34,274 Request with ID 6a9084b7 for model llama3-8b received
2024-09-20 12:34:34,275 127.0.0.1 - - [20/Sep/2024 12:34:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:34,275 127.0.0.1 - - [20/Sep/2024 12:34:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:34,294 Request with ID a6ce0bf2 for model llama3-8b received
2024-09-20 12:34:34,294 127.0.0.1 - - [20/Sep/2024 12:34:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:34,422 Request with ID 2b0b51fb for model llama3-8b received
2024-09-20 12:34:34,422 127.0.0.1 - - [20/Sep/2024 12:34:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:34,606 Request with ID 3dd0a4cd for model gemma-7b received
2024-09-20 12:34:34,606 127.0.0.1 - - [20/Sep/2024 12:34:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:34,647 Request with ID ccf64479 for model gemma-7b received
2024-09-20 12:34:34,648 127.0.0.1 - - [20/Sep/2024 12:34:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:34,782 Request with ID 5d4b8b11 for model llama3-8b received
2024-09-20 12:34:34,783 127.0.0.1 - - [20/Sep/2024 12:34:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:34,931 Request with ID c449065e for model llama3-8b received
2024-09-20 12:34:34,931 127.0.0.1 - - [20/Sep/2024 12:34:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:34,949 Request with ID ed2abbdb for model llama3-8b received
2024-09-20 12:34:34,949 127.0.0.1 - - [20/Sep/2024 12:34:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:34,996 Request with ID 44ac9fc7 for model gemma-7b received
2024-09-20 12:34:34,997 Batch size condition met for model gemma-7b
2024-09-20 12:34:35,004 Request with ID 0995b486 for model llama3-8b received
2024-09-20 12:34:35,004 127.0.0.1 - - [20/Sep/2024 12:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:35,013 Request with ID 8015e48c for model llama3-8b received
2024-09-20 12:34:35,014 127.0.0.1 - - [20/Sep/2024 12:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:35,161 Request with ID 54d86efd for model llama3-8b received
2024-09-20 12:34:35,161 127.0.0.1 - - [20/Sep/2024 12:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:35,255 Request with ID 6dc171ee for model llama3-8b received
2024-09-20 12:34:35,256 127.0.0.1 - - [20/Sep/2024 12:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:35,433 Request with ID fba60b5c for model llama3-8b received
2024-09-20 12:34:35,433 127.0.0.1 - - [20/Sep/2024 12:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:35,707 Request with ID 4b70d348 for model gemma-7b received
2024-09-20 12:34:35,707 127.0.0.1 - - [20/Sep/2024 12:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:35,756 Request with ID 2b24d43c for model llama3-8b received
2024-09-20 12:34:35,757 127.0.0.1 - - [20/Sep/2024 12:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:35,760 Request with ID 12ac3e6a for model gemma-7b received
2024-09-20 12:34:35,761 127.0.0.1 - - [20/Sep/2024 12:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:35,920 Request with ID 1518d72c for model gemma-7b received
2024-09-20 12:34:35,920 127.0.0.1 - - [20/Sep/2024 12:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:35,939 Request with ID 59d2420b for model gemma-7b received
2024-09-20 12:34:35,939 127.0.0.1 - - [20/Sep/2024 12:34:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:36,042 Request with ID 701f0aed for model gemma-7b received
2024-09-20 12:34:36,042 127.0.0.1 - - [20/Sep/2024 12:34:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:36,132 Request with ID 6e802a69 for model llama3-8b received
2024-09-20 12:34:36,132 127.0.0.1 - - [20/Sep/2024 12:34:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:36,180 Request with ID 57db56cb for model llama3-8b received
2024-09-20 12:34:36,180 Batch size condition met for model llama3-8b
2024-09-20 12:34:36,252 Request with ID 1d19ec62 for model gemma-7b received
2024-09-20 12:34:36,252 127.0.0.1 - - [20/Sep/2024 12:34:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:36,330 Request with ID 21289038 for model llama3-8b received
2024-09-20 12:34:36,330 127.0.0.1 - - [20/Sep/2024 12:34:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:36,430 Request with ID f8249a1d for model llama3-8b received
2024-09-20 12:34:36,430 127.0.0.1 - - [20/Sep/2024 12:34:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:36,471 Request with ID 547384a4 for model gemma-7b received
2024-09-20 12:34:36,471 127.0.0.1 - - [20/Sep/2024 12:34:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:36,487 Request with ID d1b6bd2d for model llama3-8b received
2024-09-20 12:34:36,488 127.0.0.1 - - [20/Sep/2024 12:34:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:36,566 Request with ID 98dfa5bb for model llama3-8b received
2024-09-20 12:34:36,566 127.0.0.1 - - [20/Sep/2024 12:34:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:37,175 Request with ID c6a38e20 for model llama3-8b received
2024-09-20 12:34:37,175 127.0.0.1 - - [20/Sep/2024 12:34:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:37,327 Request with ID e1936909 for model gemma-7b received
2024-09-20 12:34:37,328 127.0.0.1 - - [20/Sep/2024 12:34:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:37,453 Request with ID abe0282b for model llama3-8b received
2024-09-20 12:34:37,454 127.0.0.1 - - [20/Sep/2024 12:34:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:37,496 Request with ID 92cc41cc for model gemma-7b received
2024-09-20 12:34:37,496 127.0.0.1 - - [20/Sep/2024 12:34:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:37,731 Loaded model llama3-8b
2024-09-20 12:34:37,734 Request with ID 58f9eda1 for model llama3-8b received
2024-09-20 12:34:37,735 127.0.0.1 - - [20/Sep/2024 12:34:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:37,737 Request with ID d6afadcf for model llama3-8b received
2024-09-20 12:34:37,737 127.0.0.1 - - [20/Sep/2024 12:34:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:37,741 Batch processing started for model llama3-8b
2024-09-20 12:34:37,852 Request with ID 94f61c58 for model llama3-8b received
2024-09-20 12:34:37,852 127.0.0.1 - - [20/Sep/2024 12:34:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:37,941 Request with ID 873109f2 for model gemma-7b received
2024-09-20 12:34:37,942 127.0.0.1 - - [20/Sep/2024 12:34:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:37,989 Request with ID 2367a6ca for model llama3-8b received
2024-09-20 12:34:37,996 127.0.0.1 - - [20/Sep/2024 12:34:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:38,024 Request with ID 6c1c0d5d for model llama3-8b received
2024-09-20 12:34:38,025 127.0.0.1 - - [20/Sep/2024 12:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:38,062 Request with ID b60f8713 for model gemma-7b received
2024-09-20 12:34:38,063 127.0.0.1 - - [20/Sep/2024 12:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:38,151 Request with ID 262a2de4 for model gemma-7b received
2024-09-20 12:34:38,151 127.0.0.1 - - [20/Sep/2024 12:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:38,280 Request with ID ade59d29 for model llama3-8b received
2024-09-20 12:34:38,280 127.0.0.1 - - [20/Sep/2024 12:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:38,438 Request with ID 7ac57011 for model llama3-8b received
2024-09-20 12:34:38,438 127.0.0.1 - - [20/Sep/2024 12:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:38,588 Request with ID 2647bf30 for model llama3-8b received
2024-09-20 12:34:38,588 127.0.0.1 - - [20/Sep/2024 12:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:38,723 Request with ID aa5440f3 for model gemma-7b received
2024-09-20 12:34:38,723 127.0.0.1 - - [20/Sep/2024 12:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:38,751 Request with ID c9b02ea1 for model gemma-7b received
2024-09-20 12:34:38,751 127.0.0.1 - - [20/Sep/2024 12:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:38,935 Request with ID 8f44ea5d for model gemma-7b received
2024-09-20 12:34:38,935 127.0.0.1 - - [20/Sep/2024 12:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:38,960 Request with ID 481da130 for model gemma-7b received
2024-09-20 12:34:38,961 Batch size condition met for model gemma-7b
2024-09-20 12:34:38,969 Request with ID d0f060fd for model gemma-7b received
2024-09-20 12:34:38,969 127.0.0.1 - - [20/Sep/2024 12:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:38,969 Request with ID 14ddbfa9 for model llama3-8b received
2024-09-20 12:34:38,970 127.0.0.1 - - [20/Sep/2024 12:34:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:39,025 Request with ID f5ef8998 for model llama3-8b received
2024-09-20 12:34:39,025 Batch size condition met for model llama3-8b
2024-09-20 12:34:39,068 Request with ID 8fa1f5d7 for model llama3-8b received
2024-09-20 12:34:39,068 127.0.0.1 - - [20/Sep/2024 12:34:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:39,129 Request with ID 626026dc for model granite-7b received
2024-09-20 12:34:39,130 127.0.0.1 - - [20/Sep/2024 12:34:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:39,376 Request with ID 4b2bd6ad for model gemma-7b received
2024-09-20 12:34:39,376 127.0.0.1 - - [20/Sep/2024 12:34:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:39,446 Request with ID 10fe70c0 for model granite-7b received
2024-09-20 12:34:39,446 127.0.0.1 - - [20/Sep/2024 12:34:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:39,485 Request with ID f3c60a7b for model llama3-8b received
2024-09-20 12:34:39,486 127.0.0.1 - - [20/Sep/2024 12:34:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:39,587 Request with ID 0c8ae58e for model llama3-8b received
2024-09-20 12:34:39,587 127.0.0.1 - - [20/Sep/2024 12:34:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:39,960 Request with ID 642e6acf for model llama3-8b received
2024-09-20 12:34:39,960 127.0.0.1 - - [20/Sep/2024 12:34:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:40,158 Request with ID ed540061 for model llama3-8b received
2024-09-20 12:34:40,159 127.0.0.1 - - [20/Sep/2024 12:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:40,231 Request with ID bfdb5028 for model gemma-7b received
2024-09-20 12:34:40,231 127.0.0.1 - - [20/Sep/2024 12:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:40,283 Request with ID 3f6681de for model llama3-8b received
2024-09-20 12:34:40,283 127.0.0.1 - - [20/Sep/2024 12:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:40,307 Request with ID c0d061c9 for model gemma-7b received
2024-09-20 12:34:40,307 127.0.0.1 - - [20/Sep/2024 12:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:40,490 Request with ID ac7c0100 for model gemma-7b received
2024-09-20 12:34:40,491 127.0.0.1 - - [20/Sep/2024 12:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:40,617 Request with ID 3d7fd49c for model llama3-8b received
2024-09-20 12:34:40,617 127.0.0.1 - - [20/Sep/2024 12:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:40,684 Request with ID 7fa3811a for model llama3-8b received
2024-09-20 12:34:40,684 127.0.0.1 - - [20/Sep/2024 12:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:40,695 Request with ID b7449462 for model llama3-8b received
2024-09-20 12:34:40,696 127.0.0.1 - - [20/Sep/2024 12:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:40,743 Request with ID f9183490 for model llama3-8b received
2024-09-20 12:34:40,743 127.0.0.1 - - [20/Sep/2024 12:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:40,821 Request with ID 0585009a for model llama3-8b received
2024-09-20 12:34:40,821 127.0.0.1 - - [20/Sep/2024 12:34:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:41,006 Request with ID 6e1f0747 for model llama3-8b received
2024-09-20 12:34:41,007 127.0.0.1 - - [20/Sep/2024 12:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:41,037 Request with ID 8e1e9e06 for model llama3-8b received
2024-09-20 12:34:41,038 127.0.0.1 - - [20/Sep/2024 12:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:41,040 Request with ID c11d086c for model granite-7b received
2024-09-20 12:34:41,041 127.0.0.1 - - [20/Sep/2024 12:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:41,069 Request with ID 70c19610 for model llama3-8b received
2024-09-20 12:34:41,070 127.0.0.1 - - [20/Sep/2024 12:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:41,250 Request with ID 43fbce84 for model llama3-8b received
2024-09-20 12:34:41,251 127.0.0.1 - - [20/Sep/2024 12:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:41,266 Request with ID 420d97c6 for model gemma-7b received
2024-09-20 12:34:41,266 127.0.0.1 - - [20/Sep/2024 12:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:41,496 Request with ID 1573d12d for model llama3-8b received
2024-09-20 12:34:41,496 Batch size condition met for model llama3-8b
2024-09-20 12:34:41,631 Request with ID 8420c74c for model gemma-7b received
2024-09-20 12:34:41,631 127.0.0.1 - - [20/Sep/2024 12:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:41,796 Processed batch: ['12118cd5', '8f0cd7f3', 'dfd6fb87', '5239e3d0', '257750b5', 'dcdbb506', 'd2ae5793', 'b1de88aa', '1345c41b', '01d2c24c', '7f6192c1', 'c472504b', '7ba3ce39', '8fc0284c', 'ebf47ba0', 'cbba9323'] with model llama3-8b in 4.0558 seconds
2024-09-20 12:34:41,797 Saving sys info
2024-09-20 12:34:41,841 Latency for request 12118cd5 with model llama3-8b: 29.7940 seconds
2024-09-20 12:34:41,842 Request with ID 62ca0afa for model llama3-8b received
2024-09-20 12:34:41,842 Saving results with gpu monitoring
2024-09-20 12:34:41,843 127.0.0.1 - - [20/Sep/2024 12:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:41,849 Latency for request 8f0cd7f3 with model llama3-8b: 29.7830 seconds
2024-09-20 12:34:41,849 Saving results with gpu monitoring
2024-09-20 12:34:41,851 Latency for request dfd6fb87 with model llama3-8b: 29.3340 seconds
2024-09-20 12:34:41,851 Saving results with gpu monitoring
2024-09-20 12:34:41,853 Latency for request 5239e3d0 with model llama3-8b: 29.2930 seconds
2024-09-20 12:34:41,853 Saving results with gpu monitoring
2024-09-20 12:34:41,855 Latency for request 257750b5 with model llama3-8b: 28.7590 seconds
2024-09-20 12:34:41,855 Saving results with gpu monitoring
2024-09-20 12:34:41,857 Latency for request dcdbb506 with model llama3-8b: 28.7570 seconds
2024-09-20 12:34:41,857 Saving results with gpu monitoring
2024-09-20 12:34:41,859 Latency for request d2ae5793 with model llama3-8b: 28.0860 seconds
2024-09-20 12:34:41,859 Saving results with gpu monitoring
2024-09-20 12:34:41,861 Latency for request b1de88aa with model llama3-8b: 28.0050 seconds
2024-09-20 12:34:41,861 Saving results with gpu monitoring
2024-09-20 12:34:41,863 Latency for request 1345c41b with model llama3-8b: 27.4640 seconds
2024-09-20 12:34:41,863 Saving results with gpu monitoring
2024-09-20 12:34:41,865 Latency for request 01d2c24c with model llama3-8b: 27.3730 seconds
2024-09-20 12:34:41,865 Saving results with gpu monitoring
2024-09-20 12:34:41,867 Latency for request 7f6192c1 with model llama3-8b: 27.3400 seconds
2024-09-20 12:34:41,867 Saving results with gpu monitoring
2024-09-20 12:34:41,869 Latency for request c472504b with model llama3-8b: 27.1690 seconds
2024-09-20 12:34:41,869 Saving results with gpu monitoring
2024-09-20 12:34:41,871 Latency for request 7ba3ce39 with model llama3-8b: 27.1620 seconds
2024-09-20 12:34:41,871 Saving results with gpu monitoring
2024-09-20 12:34:41,873 Latency for request 8fc0284c with model llama3-8b: 26.9630 seconds
2024-09-20 12:34:41,873 Saving results with gpu monitoring
2024-09-20 12:34:41,875 Latency for request ebf47ba0 with model llama3-8b: 26.8700 seconds
2024-09-20 12:34:41,875 Saving results with gpu monitoring
2024-09-20 12:34:41,877 Latency for request cbba9323 with model llama3-8b: 26.8570 seconds
2024-09-20 12:34:41,877 Saving results with gpu monitoring
2024-09-20 12:34:41,879 127.0.0.1 - - [20/Sep/2024 12:34:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:41,879 Next: call load_model for gemma-7b
2024-09-20 12:34:41,974 Unloaded previous model
2024-09-20 12:34:42,499 Request with ID d309bdef for model gemma-7b received
2024-09-20 12:34:42,500 Request with ID 052617b9 for model llama3-8b received
2024-09-20 12:34:42,500 127.0.0.1 - - [20/Sep/2024 12:34:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:42,501 127.0.0.1 - - [20/Sep/2024 12:34:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:42,502 Request with ID e92bda40 for model llama3-8b received
2024-09-20 12:34:42,507 Request with ID 66d11716 for model gemma-7b received
2024-09-20 12:34:42,508 127.0.0.1 - - [20/Sep/2024 12:34:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:42,509 127.0.0.1 - - [20/Sep/2024 12:34:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:42,697 Request with ID f948d99f for model gemma-7b received
2024-09-20 12:34:42,697 127.0.0.1 - - [20/Sep/2024 12:34:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:42,914 Request with ID 7dae1354 for model llama3-8b received
2024-09-20 12:34:42,915 127.0.0.1 - - [20/Sep/2024 12:34:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:43,063 Request with ID e2083ad1 for model llama3-8b received
2024-09-20 12:34:43,065 127.0.0.1 - - [20/Sep/2024 12:34:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:43,187 Request with ID 16453529 for model llama3-8b received
2024-09-20 12:34:43,191 Request with ID dcbe49fe for model llama3-8b received
2024-09-20 12:34:43,192 127.0.0.1 - - [20/Sep/2024 12:34:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:43,203 127.0.0.1 - - [20/Sep/2024 12:34:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:43,351 Request with ID 9c2548af for model granite-7b received
2024-09-20 12:34:43,353 127.0.0.1 - - [20/Sep/2024 12:34:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:43,549 Request with ID 578a757b for model llama3-8b received
2024-09-20 12:34:43,549 127.0.0.1 - - [20/Sep/2024 12:34:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:43,581 Request with ID 1e416643 for model llama3-8b received
2024-09-20 12:34:43,581 127.0.0.1 - - [20/Sep/2024 12:34:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:43,761 Request with ID e483fa54 for model gemma-7b received
2024-09-20 12:34:43,762 127.0.0.1 - - [20/Sep/2024 12:34:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:43,777 Request with ID e84c0b54 for model llama3-8b received
2024-09-20 12:34:43,777 127.0.0.1 - - [20/Sep/2024 12:34:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:43,988 Request with ID 51caff22 for model gemma-7b received
2024-09-20 12:34:43,988 127.0.0.1 - - [20/Sep/2024 12:34:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:44,090 Request with ID d91b2abf for model llama3-8b received
2024-09-20 12:34:44,090 127.0.0.1 - - [20/Sep/2024 12:34:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:44,274 Request with ID ed51bb4f for model llama3-8b received
2024-09-20 12:34:44,274 127.0.0.1 - - [20/Sep/2024 12:34:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:44,278 Request with ID 5aa0bdff for model llama3-8b received
2024-09-20 12:34:44,279 127.0.0.1 - - [20/Sep/2024 12:34:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:44,288 Request with ID a5e590e9 for model gemma-7b received
2024-09-20 12:34:44,288 127.0.0.1 - - [20/Sep/2024 12:34:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:44,339 Request with ID c464c5c4 for model llama3-8b received
2024-09-20 12:34:44,340 127.0.0.1 - - [20/Sep/2024 12:34:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:44,588 Request with ID a56297a4 for model gemma-7b received
2024-09-20 12:34:44,589 127.0.0.1 - - [20/Sep/2024 12:34:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:44,673 Request with ID fe3c9e9c for model gemma-7b received
2024-09-20 12:34:44,674 127.0.0.1 - - [20/Sep/2024 12:34:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:44,985 Request with ID 92830817 for model llama3-8b received
2024-09-20 12:34:44,986 127.0.0.1 - - [20/Sep/2024 12:34:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:45,009 Request with ID 12464370 for model gemma-7b received
2024-09-20 12:34:45,010 Batch size condition met for model gemma-7b
2024-09-20 12:34:45,101 Request with ID 55642676 for model gemma-7b received
2024-09-20 12:34:45,101 127.0.0.1 - - [20/Sep/2024 12:34:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:45,200 Request with ID 2d68e839 for model gemma-7b received
2024-09-20 12:34:45,200 127.0.0.1 - - [20/Sep/2024 12:34:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:45,244 Request with ID 97d12ea3 for model llama3-8b received
2024-09-20 12:34:45,244 Batch size condition met for model llama3-8b
2024-09-20 12:34:45,363 Request with ID 210d3076 for model llama3-8b received
2024-09-20 12:34:45,363 127.0.0.1 - - [20/Sep/2024 12:34:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:45,371 Request with ID df742434 for model granite-7b received
2024-09-20 12:34:45,372 127.0.0.1 - - [20/Sep/2024 12:34:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:45,720 Request with ID d35ce612 for model llama3-8b received
2024-09-20 12:34:45,721 127.0.0.1 - - [20/Sep/2024 12:34:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:45,891 Request with ID aa50501f for model llama3-8b received
2024-09-20 12:34:45,891 127.0.0.1 - - [20/Sep/2024 12:34:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:45,893 Request with ID 18a61de7 for model llama3-8b received
2024-09-20 12:34:45,894 127.0.0.1 - - [20/Sep/2024 12:34:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:46,031 Request with ID 273503b8 for model llama3-8b received
2024-09-20 12:34:46,032 127.0.0.1 - - [20/Sep/2024 12:34:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:46,175 Request with ID 0c95cbe0 for model llama3-8b received
2024-09-20 12:34:46,176 127.0.0.1 - - [20/Sep/2024 12:34:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:46,367 Request with ID 61e8adbd for model llama3-8b received
2024-09-20 12:34:46,367 127.0.0.1 - - [20/Sep/2024 12:34:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:46,487 Request with ID 181f3b08 for model llama3-8b received
2024-09-20 12:34:46,487 127.0.0.1 - - [20/Sep/2024 12:34:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:46,491 Request with ID c909ca7a for model llama3-8b received
2024-09-20 12:34:46,491 127.0.0.1 - - [20/Sep/2024 12:34:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:47,229 Request with ID e25e509d for model llama3-8b received
2024-09-20 12:34:47,230 127.0.0.1 - - [20/Sep/2024 12:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:47,478 Request with ID fba4f93a for model llama3-8b received
2024-09-20 12:34:47,479 127.0.0.1 - - [20/Sep/2024 12:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:47,514 Request with ID dd3b44e5 for model llama3-8b received
2024-09-20 12:34:47,515 127.0.0.1 - - [20/Sep/2024 12:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:47,675 Request with ID 9e0ff810 for model granite-7b received
2024-09-20 12:34:47,676 127.0.0.1 - - [20/Sep/2024 12:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:47,737 Request with ID ee3de829 for model llama3-8b received
2024-09-20 12:34:47,737 127.0.0.1 - - [20/Sep/2024 12:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:47,741 Request with ID a0caa616 for model gemma-7b received
2024-09-20 12:34:47,741 127.0.0.1 - - [20/Sep/2024 12:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:47,826 Request with ID ebc4e89d for model llama3-8b received
2024-09-20 12:34:47,826 127.0.0.1 - - [20/Sep/2024 12:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:47,903 Request with ID 1ab58c21 for model llama3-8b received
2024-09-20 12:34:47,904 127.0.0.1 - - [20/Sep/2024 12:34:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:47,990 Request with ID 55739f04 for model llama3-8b received
2024-09-20 12:34:47,990 Batch size condition met for model llama3-8b
2024-09-20 12:34:48,126 Request with ID cd46422c for model llama3-8b received
2024-09-20 12:34:48,126 127.0.0.1 - - [20/Sep/2024 12:34:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:48,337 Request with ID 84002561 for model llama3-8b received
2024-09-20 12:34:48,338 127.0.0.1 - - [20/Sep/2024 12:34:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:48,804 Request with ID 8db3ad50 for model llama3-8b received
2024-09-20 12:34:48,804 127.0.0.1 - - [20/Sep/2024 12:34:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:48,881 Request with ID e6103daa for model llama3-8b received
2024-09-20 12:34:48,882 127.0.0.1 - - [20/Sep/2024 12:34:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:49,502 Request with ID f6ae86ed for model llama3-8b received
2024-09-20 12:34:49,502 127.0.0.1 - - [20/Sep/2024 12:34:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:49,554 Request with ID a2d4cee6 for model llama3-8b received
2024-09-20 12:34:49,554 127.0.0.1 - - [20/Sep/2024 12:34:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:49,642 Request with ID 4c67a0cb for model llama3-8b received
2024-09-20 12:34:49,643 127.0.0.1 - - [20/Sep/2024 12:34:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:49,791 Request with ID 6e65fda8 for model gemma-7b received
2024-09-20 12:34:49,792 127.0.0.1 - - [20/Sep/2024 12:34:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:49,868 Request with ID 5fe35961 for model llama3-8b received
2024-09-20 12:34:49,868 127.0.0.1 - - [20/Sep/2024 12:34:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:49,904 Request with ID ec9608ef for model gemma-7b received
2024-09-20 12:34:49,904 127.0.0.1 - - [20/Sep/2024 12:34:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:49,932 Request with ID bdbec93d for model granite-7b received
2024-09-20 12:34:49,932 Batch size condition met for model granite-7b
2024-09-20 12:34:50,374 Request with ID 584212b8 for model gemma-7b received
2024-09-20 12:34:50,375 127.0.0.1 - - [20/Sep/2024 12:34:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:50,561 Request with ID b17e8f37 for model llama3-8b received
2024-09-20 12:34:50,562 Request with ID 315a622d for model llama3-8b received
2024-09-20 12:34:50,562 127.0.0.1 - - [20/Sep/2024 12:34:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:50,563 127.0.0.1 - - [20/Sep/2024 12:34:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:50,738 Request with ID f0a179c7 for model llama3-8b received
2024-09-20 12:34:50,738 127.0.0.1 - - [20/Sep/2024 12:34:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:51,193 Request with ID 363e085a for model gemma-7b received
2024-09-20 12:34:51,194 127.0.0.1 - - [20/Sep/2024 12:34:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:51,481 Request with ID 36d262a1 for model llama3-8b received
2024-09-20 12:34:51,482 127.0.0.1 - - [20/Sep/2024 12:34:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:51,555 Request with ID 19a91b28 for model gemma-7b received
2024-09-20 12:34:51,555 127.0.0.1 - - [20/Sep/2024 12:34:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:51,559 Request with ID cdc7b7dc for model gemma-7b received
2024-09-20 12:34:51,560 127.0.0.1 - - [20/Sep/2024 12:34:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:51,566 Request with ID 1ac2fb27 for model llama3-8b received
2024-09-20 12:34:51,566 127.0.0.1 - - [20/Sep/2024 12:34:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:51,831 Request with ID e92c8f17 for model llama3-8b received
2024-09-20 12:34:51,832 127.0.0.1 - - [20/Sep/2024 12:34:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:51,862 Request with ID db18c422 for model llama3-8b received
2024-09-20 12:34:51,863 127.0.0.1 - - [20/Sep/2024 12:34:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:51,879 Request with ID 71b46abc for model llama3-8b received
2024-09-20 12:34:51,880 Batch size condition met for model llama3-8b
2024-09-20 12:34:51,980 Request with ID ccb17b9b for model llama3-8b received
2024-09-20 12:34:51,980 127.0.0.1 - - [20/Sep/2024 12:34:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:52,072 Request with ID 4dfd3b32 for model llama3-8b received
2024-09-20 12:34:52,073 127.0.0.1 - - [20/Sep/2024 12:34:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:52,135 Request with ID 39c13411 for model gemma-7b received
2024-09-20 12:34:52,135 127.0.0.1 - - [20/Sep/2024 12:34:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:52,149 Request with ID 9d70a7b8 for model llama3-8b received
2024-09-20 12:34:52,149 127.0.0.1 - - [20/Sep/2024 12:34:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:52,350 Request with ID 3f061154 for model gemma-7b received
2024-09-20 12:34:52,350 127.0.0.1 - - [20/Sep/2024 12:34:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:52,620 Request with ID 88678ae9 for model granite-7b received
2024-09-20 12:34:52,620 127.0.0.1 - - [20/Sep/2024 12:34:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:52,673 Request with ID 3631f791 for model granite-7b received
2024-09-20 12:34:52,674 127.0.0.1 - - [20/Sep/2024 12:34:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:52,829 Request with ID 89672024 for model llama3-8b received
2024-09-20 12:34:52,830 127.0.0.1 - - [20/Sep/2024 12:34:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:52,831 Request with ID 07816c16 for model llama3-8b received
2024-09-20 12:34:52,832 Request with ID e34aea40 for model granite-7b received
2024-09-20 12:34:52,834 127.0.0.1 - - [20/Sep/2024 12:34:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:52,834 127.0.0.1 - - [20/Sep/2024 12:34:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:53,031 Request with ID 2cc7c424 for model llama3-8b received
2024-09-20 12:34:53,032 127.0.0.1 - - [20/Sep/2024 12:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:53,206 Request with ID 4784356d for model llama3-8b received
2024-09-20 12:34:53,207 127.0.0.1 - - [20/Sep/2024 12:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:53,286 Request with ID b2cdd7db for model gemma-7b received
2024-09-20 12:34:53,286 127.0.0.1 - - [20/Sep/2024 12:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:53,500 Request with ID 7cbe55a4 for model llama3-8b received
2024-09-20 12:34:53,500 127.0.0.1 - - [20/Sep/2024 12:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:53,703 Request with ID db9e00be for model gemma-7b received
2024-09-20 12:34:53,704 127.0.0.1 - - [20/Sep/2024 12:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:53,731 Request with ID 020dab1f for model llama3-8b received
2024-09-20 12:34:53,731 127.0.0.1 - - [20/Sep/2024 12:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:53,830 Request with ID 5c85b656 for model gemma-7b received
2024-09-20 12:34:53,830 127.0.0.1 - - [20/Sep/2024 12:34:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:54,045 Request with ID d2f93638 for model llama3-8b received
2024-09-20 12:34:54,045 127.0.0.1 - - [20/Sep/2024 12:34:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:54,259 Request with ID 92819fdc for model gemma-7b received
2024-09-20 12:34:54,259 127.0.0.1 - - [20/Sep/2024 12:34:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:54,301 Request with ID b2131bff for model gemma-7b received
2024-09-20 12:34:54,301 Batch size condition met for model gemma-7b
2024-09-20 12:34:54,474 Request with ID c4c9f617 for model llama3-8b received
2024-09-20 12:34:54,475 127.0.0.1 - - [20/Sep/2024 12:34:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:54,476 Request with ID d94a9b78 for model granite-7b received
2024-09-20 12:34:54,477 127.0.0.1 - - [20/Sep/2024 12:34:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:54,515 Request with ID cdcd694b for model llama3-8b received
2024-09-20 12:34:54,516 127.0.0.1 - - [20/Sep/2024 12:34:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:54,547 Request with ID 838b2a43 for model granite-7b received
2024-09-20 12:34:54,548 127.0.0.1 - - [20/Sep/2024 12:34:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:54,720 Request with ID 491f3d37 for model gemma-7b received
2024-09-20 12:34:54,721 127.0.0.1 - - [20/Sep/2024 12:34:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:54,865 Request with ID dee99eb4 for model llama3-8b received
2024-09-20 12:34:54,866 127.0.0.1 - - [20/Sep/2024 12:34:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:55,050 Request with ID be785ece for model llama3-8b received
2024-09-20 12:34:55,050 127.0.0.1 - - [20/Sep/2024 12:34:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:55,321 Request with ID 763f5c57 for model llama3-8b received
2024-09-20 12:34:55,321 127.0.0.1 - - [20/Sep/2024 12:34:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:55,340 Request with ID 8d8604d1 for model granite-7b received
2024-09-20 12:34:55,341 127.0.0.1 - - [20/Sep/2024 12:34:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:55,378 Request with ID 039746ab for model llama3-8b received
2024-09-20 12:34:55,378 Batch size condition met for model llama3-8b
2024-09-20 12:34:55,504 Request with ID 37a975eb for model gemma-7b received
2024-09-20 12:34:55,504 127.0.0.1 - - [20/Sep/2024 12:34:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:55,603 Request with ID 9891563d for model llama3-8b received
2024-09-20 12:34:55,603 127.0.0.1 - - [20/Sep/2024 12:34:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:55,663 Request with ID 67f0cf70 for model gemma-7b received
2024-09-20 12:34:55,664 127.0.0.1 - - [20/Sep/2024 12:34:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:55,807 Request with ID 3a6edb9b for model granite-7b received
2024-09-20 12:34:55,808 127.0.0.1 - - [20/Sep/2024 12:34:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:55,981 Request with ID 31907b5e for model llama3-8b received
2024-09-20 12:34:55,981 127.0.0.1 - - [20/Sep/2024 12:34:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,012 Request with ID 96ea68ec for model llama3-8b received
2024-09-20 12:34:56,012 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,045 Request with ID 2eb9e902 for model llama3-8b received
2024-09-20 12:34:56,046 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,107 Request with ID 4fbd8120 for model llama3-8b received
2024-09-20 12:34:56,108 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,284 Request with ID d1cfb38e for model gemma-7b received
2024-09-20 12:34:56,285 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,292 Request with ID 467e39c4 for model gemma-7b received
2024-09-20 12:34:56,293 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,307 Request with ID 65721b47 for model llama3-8b received
2024-09-20 12:34:56,308 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,364 Request with ID 36050b79 for model gemma-7b received
2024-09-20 12:34:56,365 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,397 Request with ID aab87492 for model gemma-7b received
2024-09-20 12:34:56,398 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,438 Request with ID 2dee9099 for model gemma-7b received
2024-09-20 12:34:56,438 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,463 Request with ID a5098e82 for model llama3-8b received
2024-09-20 12:34:56,464 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,591 Request with ID ad21681f for model llama3-8b received
2024-09-20 12:34:56,592 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,657 Request with ID fe2912a1 for model gemma-7b received
2024-09-20 12:34:56,657 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,680 Request with ID f912785b for model llama3-8b received
2024-09-20 12:34:56,681 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:56,869 Request with ID 24472fb2 for model granite-7b received
2024-09-20 12:34:56,869 127.0.0.1 - - [20/Sep/2024 12:34:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:57,030 Request with ID 8ebcc558 for model granite-7b received
2024-09-20 12:34:57,030 127.0.0.1 - - [20/Sep/2024 12:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:57,405 Request with ID cf903ac4 for model gemma-7b received
2024-09-20 12:34:57,407 Request with ID 006fbfca for model llama3-8b received
2024-09-20 12:34:57,408 Request with ID 1cd41adc for model gemma-7b received
2024-09-20 12:34:57,409 127.0.0.1 - - [20/Sep/2024 12:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:57,409 127.0.0.1 - - [20/Sep/2024 12:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:57,410 127.0.0.1 - - [20/Sep/2024 12:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:57,490 Request with ID 01818cef for model llama3-8b received
2024-09-20 12:34:57,490 127.0.0.1 - - [20/Sep/2024 12:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:57,548 Request with ID cdc93232 for model llama3-8b received
2024-09-20 12:34:57,549 127.0.0.1 - - [20/Sep/2024 12:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:57,550 Request with ID 7329c828 for model llama3-8b received
2024-09-20 12:34:57,551 127.0.0.1 - - [20/Sep/2024 12:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:57,602 Request with ID 1b0d87b3 for model llama3-8b received
2024-09-20 12:34:57,602 127.0.0.1 - - [20/Sep/2024 12:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:57,712 Request with ID dc9453d1 for model llama3-8b received
2024-09-20 12:34:57,712 127.0.0.1 - - [20/Sep/2024 12:34:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:57,865 Request with ID dcac0688 for model llama3-8b received
2024-09-20 12:34:57,865 Batch size condition met for model llama3-8b
2024-09-20 12:34:58,004 Request with ID eadef196 for model gemma-7b received
2024-09-20 12:34:58,005 127.0.0.1 - - [20/Sep/2024 12:34:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:58,438 Request with ID 8aca7809 for model granite-7b received
2024-09-20 12:34:58,438 127.0.0.1 - - [20/Sep/2024 12:34:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:58,505 Request with ID 0e5faccc for model llama3-8b received
2024-09-20 12:34:58,506 127.0.0.1 - - [20/Sep/2024 12:34:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:58,589 Request with ID 661bdedb for model llama3-8b received
2024-09-20 12:34:58,590 127.0.0.1 - - [20/Sep/2024 12:34:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:58,597 Request with ID 7319349b for model gemma-7b received
2024-09-20 12:34:58,597 127.0.0.1 - - [20/Sep/2024 12:34:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:58,600 Request with ID d687e667 for model gemma-7b received
2024-09-20 12:34:58,601 127.0.0.1 - - [20/Sep/2024 12:34:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:58,641 Request with ID eaf684b4 for model llama3-8b received
2024-09-20 12:34:58,641 127.0.0.1 - - [20/Sep/2024 12:34:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:58,805 Request with ID deac026b for model gemma-7b received
2024-09-20 12:34:58,805 127.0.0.1 - - [20/Sep/2024 12:34:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:58,817 Request with ID 7c25b12d for model gemma-7b received
2024-09-20 12:34:58,817 Batch size condition met for model gemma-7b
2024-09-20 12:34:59,046 Request with ID 437495d5 for model llama3-8b received
2024-09-20 12:34:59,047 127.0.0.1 - - [20/Sep/2024 12:34:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:59,051 Request with ID cdbf16b5 for model gemma-7b received
2024-09-20 12:34:59,052 127.0.0.1 - - [20/Sep/2024 12:34:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:59,328 Request with ID d160b9a3 for model llama3-8b received
2024-09-20 12:34:59,329 127.0.0.1 - - [20/Sep/2024 12:34:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:59,593 Request with ID 04fd04b1 for model llama3-8b received
2024-09-20 12:34:59,593 127.0.0.1 - - [20/Sep/2024 12:34:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:59,594 Request with ID 198292e7 for model llama3-8b received
2024-09-20 12:34:59,595 Request with ID 7cb55e11 for model llama3-8b received
2024-09-20 12:34:59,596 127.0.0.1 - - [20/Sep/2024 12:34:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:59,597 127.0.0.1 - - [20/Sep/2024 12:34:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:59,690 Request with ID 45013802 for model gemma-7b received
2024-09-20 12:34:59,691 127.0.0.1 - - [20/Sep/2024 12:34:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:59,748 Request with ID 94dfe074 for model llama3-8b received
2024-09-20 12:34:59,749 127.0.0.1 - - [20/Sep/2024 12:34:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:59,815 Request with ID ec01a286 for model gemma-7b received
2024-09-20 12:34:59,816 127.0.0.1 - - [20/Sep/2024 12:34:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:34:59,887 Loaded model gemma-7b
2024-09-20 12:34:59,889 Batch processing started for model gemma-7b
2024-09-20 12:35:00,189 Request with ID 15ad52d5 for model gemma-7b received
2024-09-20 12:35:00,190 127.0.0.1 - - [20/Sep/2024 12:35:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:00,347 Request with ID 385561ab for model granite-7b received
2024-09-20 12:35:00,348 127.0.0.1 - - [20/Sep/2024 12:35:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:00,365 Request with ID 0bd5a034 for model llama3-8b received
2024-09-20 12:35:00,365 127.0.0.1 - - [20/Sep/2024 12:35:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:00,393 Request with ID e9d2b3a3 for model llama3-8b received
2024-09-20 12:35:00,393 127.0.0.1 - - [20/Sep/2024 12:35:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:00,502 Request with ID 78e79fae for model llama3-8b received
2024-09-20 12:35:00,502 127.0.0.1 - - [20/Sep/2024 12:35:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:00,527 Request with ID c41b653b for model gemma-7b received
2024-09-20 12:35:00,527 127.0.0.1 - - [20/Sep/2024 12:35:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:00,713 Request with ID 16683494 for model llama3-8b received
2024-09-20 12:35:00,713 127.0.0.1 - - [20/Sep/2024 12:35:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:00,850 Request with ID 769bc229 for model llama3-8b received
2024-09-20 12:35:00,850 127.0.0.1 - - [20/Sep/2024 12:35:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:00,984 Request with ID 57fb708d for model granite-7b received
2024-09-20 12:35:00,984 127.0.0.1 - - [20/Sep/2024 12:35:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:01,187 Request with ID 4100e8e1 for model llama3-8b received
2024-09-20 12:35:01,188 127.0.0.1 - - [20/Sep/2024 12:35:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:01,190 Request with ID 01baaba5 for model llama3-8b received
2024-09-20 12:35:01,191 Batch size condition met for model llama3-8b
2024-09-20 12:35:01,285 Request with ID 566c0356 for model llama3-8b received
2024-09-20 12:35:01,285 127.0.0.1 - - [20/Sep/2024 12:35:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:01,771 Request with ID 0dc7e119 for model llama3-8b received
2024-09-20 12:35:01,772 127.0.0.1 - - [20/Sep/2024 12:35:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:01,795 Request with ID 3264fd2a for model llama3-8b received
2024-09-20 12:35:01,796 127.0.0.1 - - [20/Sep/2024 12:35:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:01,930 Request with ID 1ccf6492 for model llama3-8b received
2024-09-20 12:35:01,931 127.0.0.1 - - [20/Sep/2024 12:35:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:02,173 Request with ID 12db92bb for model llama3-8b received
2024-09-20 12:35:02,173 127.0.0.1 - - [20/Sep/2024 12:35:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:02,220 Request with ID fdbc36d3 for model gemma-7b received
2024-09-20 12:35:02,220 127.0.0.1 - - [20/Sep/2024 12:35:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:02,415 Request with ID 87a25cad for model gemma-7b received
2024-09-20 12:35:02,416 127.0.0.1 - - [20/Sep/2024 12:35:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:02,518 Processed batch: ['4b70d348', '12ac3e6a', '1518d72c', '59d2420b', '701f0aed', '1d19ec62', '547384a4', 'e1936909', '92cc41cc', '873109f2', 'b60f8713', '262a2de4', 'aa5440f3', 'c9b02ea1', '8f44ea5d', '481da130'] with model gemma-7b in 2.6288 seconds
2024-09-20 12:35:02,518 Saving sys info
2024-09-20 12:35:02,549 Latency for request 4b70d348 with model gemma-7b: 26.8110 seconds
2024-09-20 12:35:02,549 Saving results with gpu monitoring
2024-09-20 12:35:02,552 Latency for request 12ac3e6a with model gemma-7b: 26.7580 seconds
2024-09-20 12:35:02,552 Saving results with gpu monitoring
2024-09-20 12:35:02,554 Latency for request 1518d72c with model gemma-7b: 26.5980 seconds
2024-09-20 12:35:02,554 Saving results with gpu monitoring
2024-09-20 12:35:02,556 Latency for request 59d2420b with model gemma-7b: 26.5790 seconds
2024-09-20 12:35:02,556 Saving results with gpu monitoring
2024-09-20 12:35:02,558 Latency for request 701f0aed with model gemma-7b: 26.4760 seconds
2024-09-20 12:35:02,558 Saving results with gpu monitoring
2024-09-20 12:35:02,560 Latency for request 1d19ec62 with model gemma-7b: 26.2660 seconds
2024-09-20 12:35:02,560 Saving results with gpu monitoring
2024-09-20 12:35:02,562 Latency for request 547384a4 with model gemma-7b: 26.0470 seconds
2024-09-20 12:35:02,562 Saving results with gpu monitoring
2024-09-20 12:35:02,564 Latency for request e1936909 with model gemma-7b: 25.1910 seconds
2024-09-20 12:35:02,564 Saving results with gpu monitoring
2024-09-20 12:35:02,566 Latency for request 92cc41cc with model gemma-7b: 25.0220 seconds
2024-09-20 12:35:02,566 Saving results with gpu monitoring
2024-09-20 12:35:02,568 Latency for request 873109f2 with model gemma-7b: 24.5770 seconds
2024-09-20 12:35:02,568 Saving results with gpu monitoring
2024-09-20 12:35:02,570 Latency for request b60f8713 with model gemma-7b: 24.4560 seconds
2024-09-20 12:35:02,570 Saving results with gpu monitoring
2024-09-20 12:35:02,572 Latency for request 262a2de4 with model gemma-7b: 24.3670 seconds
2024-09-20 12:35:02,572 Saving results with gpu monitoring
2024-09-20 12:35:02,574 Latency for request aa5440f3 with model gemma-7b: 23.7950 seconds
2024-09-20 12:35:02,574 Saving results with gpu monitoring
2024-09-20 12:35:02,576 Latency for request c9b02ea1 with model gemma-7b: 23.7670 seconds
2024-09-20 12:35:02,576 Saving results with gpu monitoring
2024-09-20 12:35:02,578 Latency for request 8f44ea5d with model gemma-7b: 23.5830 seconds
2024-09-20 12:35:02,578 Saving results with gpu monitoring
2024-09-20 12:35:02,580 Latency for request 481da130 with model gemma-7b: 23.5580 seconds
2024-09-20 12:35:02,580 Saving results with gpu monitoring
2024-09-20 12:35:02,582 127.0.0.1 - - [20/Sep/2024 12:35:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:02,582 Next: call load_model for llama3-8b
2024-09-20 12:35:02,689 Unloaded previous model
2024-09-20 12:35:02,691 Request with ID ca319799 for model llama3-8b received
2024-09-20 12:35:02,909 127.0.0.1 - - [20/Sep/2024 12:35:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:02,911 Request with ID 36887a35 for model granite-7b received
2024-09-20 12:35:02,912 127.0.0.1 - - [20/Sep/2024 12:35:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:02,915 Request with ID e53b19cb for model gemma-7b received
2024-09-20 12:35:02,915 127.0.0.1 - - [20/Sep/2024 12:35:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,064 Request with ID d976d26b for model gemma-7b received
2024-09-20 12:35:03,150 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,252 Request with ID 927efbe4 for model gemma-7b received
2024-09-20 12:35:03,257 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,260 Request with ID 37987a00 for model gemma-7b received
2024-09-20 12:35:03,262 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,269 Request with ID 702b4532 for model llama3-8b received
2024-09-20 12:35:03,270 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,284 Request with ID 87fbb0db for model llama3-8b received
2024-09-20 12:35:03,284 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,416 Request with ID 934e56df for model gemma-7b received
2024-09-20 12:35:03,416 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,463 Request with ID 61722b2a for model gemma-7b received
2024-09-20 12:35:03,464 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,614 Request with ID 351495c8 for model llama3-8b received
2024-09-20 12:35:03,625 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,634 Request with ID f936a61f for model llama3-8b received
2024-09-20 12:35:03,634 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,794 Request with ID 75f353be for model gemma-7b received
2024-09-20 12:35:03,890 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,893 Request with ID b6129578 for model llama3-8b received
2024-09-20 12:35:03,894 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,895 Request with ID ada0b177 for model gemma-7b received
2024-09-20 12:35:03,896 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,898 Request with ID 55e40d12 for model gemma-7b received
2024-09-20 12:35:03,899 Request with ID d706b40a for model llama3-8b received
2024-09-20 12:35:03,899 Batch size condition met for model gemma-7b
2024-09-20 12:35:03,900 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,901 Request with ID 1707d164 for model llama3-8b received
2024-09-20 12:35:03,903 Request with ID a285fc3a for model llama3-8b received
2024-09-20 12:35:03,904 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:03,905 127.0.0.1 - - [20/Sep/2024 12:35:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:04,071 Request with ID 8f8f02a4 for model gemma-7b received
2024-09-20 12:35:04,071 127.0.0.1 - - [20/Sep/2024 12:35:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:04,146 Request with ID 901b462e for model llama3-8b received
2024-09-20 12:35:04,146 127.0.0.1 - - [20/Sep/2024 12:35:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:04,162 Request with ID a01fcd4c for model gemma-7b received
2024-09-20 12:35:04,162 127.0.0.1 - - [20/Sep/2024 12:35:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:04,287 Request with ID 45e45629 for model llama3-8b received
2024-09-20 12:35:04,287 Batch size condition met for model llama3-8b
2024-09-20 12:35:04,640 Request with ID 34e19fcb for model llama3-8b received
2024-09-20 12:35:04,640 127.0.0.1 - - [20/Sep/2024 12:35:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:04,658 Request with ID d6c97e9b for model llama3-8b received
2024-09-20 12:35:04,658 127.0.0.1 - - [20/Sep/2024 12:35:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:04,678 Request with ID 1fd29231 for model llama3-8b received
2024-09-20 12:35:04,678 127.0.0.1 - - [20/Sep/2024 12:35:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:04,796 Request with ID aee0787a for model gemma-7b received
2024-09-20 12:35:04,796 127.0.0.1 - - [20/Sep/2024 12:35:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:04,976 Request with ID f84f5f54 for model llama3-8b received
2024-09-20 12:35:04,976 127.0.0.1 - - [20/Sep/2024 12:35:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:04,979 Request with ID 8a2c9a5c for model llama3-8b received
2024-09-20 12:35:04,980 127.0.0.1 - - [20/Sep/2024 12:35:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:05,233 Request with ID da872c48 for model llama3-8b received
2024-09-20 12:35:05,233 127.0.0.1 - - [20/Sep/2024 12:35:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:05,284 Request with ID c9d9ee2d for model llama3-8b received
2024-09-20 12:35:05,284 127.0.0.1 - - [20/Sep/2024 12:35:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:05,328 Request with ID cae9e270 for model llama3-8b received
2024-09-20 12:35:05,328 127.0.0.1 - - [20/Sep/2024 12:35:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:05,369 Request with ID 049b6a7f for model llama3-8b received
2024-09-20 12:35:05,369 127.0.0.1 - - [20/Sep/2024 12:35:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:05,524 Request with ID 540c02cd for model gemma-7b received
2024-09-20 12:35:05,524 127.0.0.1 - - [20/Sep/2024 12:35:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:05,631 Request with ID 8aa960b7 for model llama3-8b received
2024-09-20 12:35:05,631 127.0.0.1 - - [20/Sep/2024 12:35:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:05,689 Request with ID e86be088 for model gemma-7b received
2024-09-20 12:35:05,690 127.0.0.1 - - [20/Sep/2024 12:35:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:05,894 Request with ID f2987c69 for model gemma-7b received
2024-09-20 12:35:05,895 127.0.0.1 - - [20/Sep/2024 12:35:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,121 Request with ID b2b0c59a for model llama3-8b received
2024-09-20 12:35:06,122 Request with ID 09e24848 for model llama3-8b received
2024-09-20 12:35:06,123 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,123 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,129 Request with ID fcc277ef for model granite-7b received
2024-09-20 12:35:06,130 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,220 Request with ID 675160d3 for model llama3-8b received
2024-09-20 12:35:06,220 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,269 Request with ID 2868b0b3 for model llama3-8b received
2024-09-20 12:35:06,270 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,272 Request with ID 27367ac9 for model gemma-7b received
2024-09-20 12:35:06,273 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,290 Request with ID 87a6a0dd for model llama3-8b received
2024-09-20 12:35:06,290 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,368 Request with ID 3d4be163 for model llama3-8b received
2024-09-20 12:35:06,369 Batch size condition met for model llama3-8b
2024-09-20 12:35:06,538 Request with ID 6a1fb158 for model llama3-8b received
2024-09-20 12:35:06,539 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,713 Request with ID 3d9baeb7 for model llama3-8b received
2024-09-20 12:35:06,714 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,720 Request with ID d7ef84cd for model llama3-8b received
2024-09-20 12:35:06,721 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,727 Request with ID c1111d60 for model llama3-8b received
2024-09-20 12:35:06,728 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,750 Request with ID e4d87c4a for model llama3-8b received
2024-09-20 12:35:06,750 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,781 Request with ID 46636278 for model llama3-8b received
2024-09-20 12:35:06,781 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,861 Request with ID 3dc9d4de for model llama3-8b received
2024-09-20 12:35:06,861 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:06,989 Request with ID f0c04ee4 for model gemma-7b received
2024-09-20 12:35:06,989 127.0.0.1 - - [20/Sep/2024 12:35:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:07,008 Request with ID 05b0bff3 for model llama3-8b received
2024-09-20 12:35:07,009 127.0.0.1 - - [20/Sep/2024 12:35:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:07,134 Request with ID 2e39f061 for model gemma-7b received
2024-09-20 12:35:07,134 127.0.0.1 - - [20/Sep/2024 12:35:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:07,465 Request with ID 8d36d139 for model granite-7b received
2024-09-20 12:35:07,466 127.0.0.1 - - [20/Sep/2024 12:35:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:07,636 Request with ID 0e3ba845 for model granite-7b received
2024-09-20 12:35:07,637 Batch size condition met for model granite-7b
2024-09-20 12:35:07,738 Request with ID 8e63ab7b for model llama3-8b received
2024-09-20 12:35:07,738 127.0.0.1 - - [20/Sep/2024 12:35:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:07,765 Request with ID 580a6974 for model llama3-8b received
2024-09-20 12:35:07,765 127.0.0.1 - - [20/Sep/2024 12:35:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:07,785 Request with ID dc7360c3 for model llama3-8b received
2024-09-20 12:35:07,786 127.0.0.1 - - [20/Sep/2024 12:35:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:08,018 Request with ID a876c835 for model llama3-8b received
2024-09-20 12:35:08,019 127.0.0.1 - - [20/Sep/2024 12:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:08,049 Request with ID af8c2e68 for model gemma-7b received
2024-09-20 12:35:08,050 127.0.0.1 - - [20/Sep/2024 12:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:08,225 Request with ID 71a8a934 for model llama3-8b received
2024-09-20 12:35:08,225 127.0.0.1 - - [20/Sep/2024 12:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:08,242 Request with ID a5934bf2 for model llama3-8b received
2024-09-20 12:35:08,243 127.0.0.1 - - [20/Sep/2024 12:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:08,262 Request with ID 1287dc43 for model llama3-8b received
2024-09-20 12:35:08,262 127.0.0.1 - - [20/Sep/2024 12:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:08,328 Request with ID 2261010f for model granite-7b received
2024-09-20 12:35:08,329 127.0.0.1 - - [20/Sep/2024 12:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:08,433 Request with ID 2068b18d for model gemma-7b received
2024-09-20 12:35:08,433 127.0.0.1 - - [20/Sep/2024 12:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:08,536 Request with ID 19d9c749 for model gemma-7b received
2024-09-20 12:35:08,536 127.0.0.1 - - [20/Sep/2024 12:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:08,629 Request with ID c3446ced for model llama3-8b received
2024-09-20 12:35:08,629 Batch size condition met for model llama3-8b
2024-09-20 12:35:08,644 Request with ID cc0bd32e for model llama3-8b received
2024-09-20 12:35:08,644 127.0.0.1 - - [20/Sep/2024 12:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:08,773 Request with ID 2177624b for model gemma-7b received
2024-09-20 12:35:08,773 127.0.0.1 - - [20/Sep/2024 12:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:08,946 Request with ID e64a8fb0 for model llama3-8b received
2024-09-20 12:35:08,946 127.0.0.1 - - [20/Sep/2024 12:35:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,033 Request with ID 06af30b6 for model llama3-8b received
2024-09-20 12:35:09,034 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,065 Request with ID 0c20cff9 for model llama3-8b received
2024-09-20 12:35:09,065 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,087 Request with ID 3320f748 for model gemma-7b received
2024-09-20 12:35:09,087 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,133 Request with ID 525a2911 for model llama3-8b received
2024-09-20 12:35:09,133 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,314 Request with ID 05cde655 for model llama3-8b received
2024-09-20 12:35:09,314 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,340 Request with ID 41fa4c61 for model llama3-8b received
2024-09-20 12:35:09,341 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,419 Request with ID 99cfd30c for model gemma-7b received
2024-09-20 12:35:09,419 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,531 Request with ID 9f70f84c for model llama3-8b received
2024-09-20 12:35:09,532 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,614 Request with ID 581760fb for model llama3-8b received
2024-09-20 12:35:09,615 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,620 Request with ID 2fd5e184 for model llama3-8b received
2024-09-20 12:35:09,621 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,643 Request with ID 17c11675 for model gemma-7b received
2024-09-20 12:35:09,643 Batch size condition met for model gemma-7b
2024-09-20 12:35:09,850 Request with ID f1e785df for model llama3-8b received
2024-09-20 12:35:09,850 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,851 Request with ID 6c285f56 for model llama3-8b received
2024-09-20 12:35:09,851 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,860 Request with ID 6723b8e2 for model gemma-7b received
2024-09-20 12:35:09,860 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:09,873 Request with ID 8ba569b4 for model llama3-8b received
2024-09-20 12:35:09,873 127.0.0.1 - - [20/Sep/2024 12:35:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,138 Request with ID b5f27bed for model gemma-7b received
2024-09-20 12:35:10,138 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,251 Request with ID 73ae6b9b for model llama3-8b received
2024-09-20 12:35:10,251 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,260 Request with ID e27c370c for model llama3-8b received
2024-09-20 12:35:10,260 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,357 Request with ID 3c3029e3 for model llama3-8b received
2024-09-20 12:35:10,357 Batch size condition met for model llama3-8b
2024-09-20 12:35:10,361 Request with ID b31917c1 for model gemma-7b received
2024-09-20 12:35:10,361 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,405 Request with ID e169066e for model gemma-7b received
2024-09-20 12:35:10,405 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,434 Request with ID 8b133f1f for model llama3-8b received
2024-09-20 12:35:10,434 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,468 Request with ID 3ab8e112 for model llama3-8b received
2024-09-20 12:35:10,468 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,542 Request with ID 665a3a0f for model llama3-8b received
2024-09-20 12:35:10,543 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,629 Request with ID be98bc18 for model llama3-8b received
2024-09-20 12:35:10,630 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,653 Request with ID bed5c545 for model gemma-7b received
2024-09-20 12:35:10,654 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,826 Request with ID 0778ca69 for model llama3-8b received
2024-09-20 12:35:10,827 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,904 Request with ID 4544f7ea for model gemma-7b received
2024-09-20 12:35:10,905 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,928 Request with ID 305eb5f3 for model gemma-7b received
2024-09-20 12:35:10,928 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:10,931 Request with ID 1290f4f2 for model gemma-7b received
2024-09-20 12:35:10,932 127.0.0.1 - - [20/Sep/2024 12:35:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:11,250 Request with ID 3eb6907b for model llama3-8b received
2024-09-20 12:35:11,250 127.0.0.1 - - [20/Sep/2024 12:35:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:11,424 Request with ID 4152aa1b for model llama3-8b received
2024-09-20 12:35:11,424 127.0.0.1 - - [20/Sep/2024 12:35:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:11,462 Request with ID 7b140027 for model llama3-8b received
2024-09-20 12:35:11,462 127.0.0.1 - - [20/Sep/2024 12:35:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:11,558 Request with ID 8464595b for model llama3-8b received
2024-09-20 12:35:11,558 127.0.0.1 - - [20/Sep/2024 12:35:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:11,597 Request with ID d318175e for model llama3-8b received
2024-09-20 12:35:11,597 127.0.0.1 - - [20/Sep/2024 12:35:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:11,709 Request with ID 2a3f8341 for model gemma-7b received
2024-09-20 12:35:11,709 127.0.0.1 - - [20/Sep/2024 12:35:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:12,041 Request with ID 70a349ac for model llama3-8b received
2024-09-20 12:35:12,042 127.0.0.1 - - [20/Sep/2024 12:35:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:12,055 Request with ID 460017c8 for model gemma-7b received
2024-09-20 12:35:12,055 127.0.0.1 - - [20/Sep/2024 12:35:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:12,128 Request with ID 0265cb85 for model gemma-7b received
2024-09-20 12:35:12,129 127.0.0.1 - - [20/Sep/2024 12:35:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:12,321 Request with ID 1dd9e84b for model granite-7b received
2024-09-20 12:35:12,321 127.0.0.1 - - [20/Sep/2024 12:35:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:12,415 Request with ID 434fb39d for model llama3-8b received
2024-09-20 12:35:12,416 127.0.0.1 - - [20/Sep/2024 12:35:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:12,478 Request with ID 1b98f5ba for model llama3-8b received
2024-09-20 12:35:12,478 127.0.0.1 - - [20/Sep/2024 12:35:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:12,620 Request with ID d33954ab for model llama3-8b received
2024-09-20 12:35:12,620 127.0.0.1 - - [20/Sep/2024 12:35:12] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:13,034 Request with ID 59076cea for model gemma-7b received
2024-09-20 12:35:13,035 127.0.0.1 - - [20/Sep/2024 12:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:13,041 Request with ID 06c70920 for model gemma-7b received
2024-09-20 12:35:13,042 127.0.0.1 - - [20/Sep/2024 12:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:13,052 Request with ID 099dc27a for model granite-7b received
2024-09-20 12:35:13,052 127.0.0.1 - - [20/Sep/2024 12:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:13,126 Request with ID af1c5e8a for model gemma-7b received
2024-09-20 12:35:13,126 127.0.0.1 - - [20/Sep/2024 12:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:13,153 Request with ID c74ecb30 for model gemma-7b received
2024-09-20 12:35:13,154 127.0.0.1 - - [20/Sep/2024 12:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:13,253 Request with ID 6c98ead4 for model llama3-8b received
2024-09-20 12:35:13,254 127.0.0.1 - - [20/Sep/2024 12:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:13,384 Request with ID da53bfba for model llama3-8b received
2024-09-20 12:35:13,385 Batch size condition met for model llama3-8b
2024-09-20 12:35:13,447 Request with ID 1644f356 for model gemma-7b received
2024-09-20 12:35:13,447 Batch size condition met for model gemma-7b
2024-09-20 12:35:13,523 Request with ID 74be3abe for model gemma-7b received
2024-09-20 12:35:13,524 127.0.0.1 - - [20/Sep/2024 12:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:13,574 Request with ID 03ea26b0 for model gemma-7b received
2024-09-20 12:35:13,575 127.0.0.1 - - [20/Sep/2024 12:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:13,588 Request with ID 68dfc58f for model gemma-7b received
2024-09-20 12:35:13,589 127.0.0.1 - - [20/Sep/2024 12:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:13,734 Request with ID 63f9893d for model llama3-8b received
2024-09-20 12:35:13,735 127.0.0.1 - - [20/Sep/2024 12:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:13,759 Request with ID 4b0f9736 for model gemma-7b received
2024-09-20 12:35:13,759 127.0.0.1 - - [20/Sep/2024 12:35:13] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:14,134 Request with ID a7ad7155 for model llama3-8b received
2024-09-20 12:35:14,134 127.0.0.1 - - [20/Sep/2024 12:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:14,202 Request with ID 5deabc52 for model llama3-8b received
2024-09-20 12:35:14,203 127.0.0.1 - - [20/Sep/2024 12:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:14,265 Request with ID e1cf5d94 for model granite-7b received
2024-09-20 12:35:14,265 127.0.0.1 - - [20/Sep/2024 12:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:14,333 Request with ID b7bc6b60 for model llama3-8b received
2024-09-20 12:35:14,334 127.0.0.1 - - [20/Sep/2024 12:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:14,362 Request with ID 4df9b6a8 for model llama3-8b received
2024-09-20 12:35:14,362 127.0.0.1 - - [20/Sep/2024 12:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:14,411 Request with ID b492ee00 for model llama3-8b received
2024-09-20 12:35:14,412 127.0.0.1 - - [20/Sep/2024 12:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:14,462 Request with ID 81db485a for model gemma-7b received
2024-09-20 12:35:14,463 127.0.0.1 - - [20/Sep/2024 12:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:14,572 Request with ID b1d9b226 for model llama3-8b received
2024-09-20 12:35:14,573 127.0.0.1 - - [20/Sep/2024 12:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:14,631 Request with ID 0e53d38a for model gemma-7b received
2024-09-20 12:35:14,631 127.0.0.1 - - [20/Sep/2024 12:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:14,899 Request with ID 7ad04aa7 for model llama3-8b received
2024-09-20 12:35:14,899 127.0.0.1 - - [20/Sep/2024 12:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:14,968 Request with ID 47c65c9b for model llama3-8b received
2024-09-20 12:35:14,969 127.0.0.1 - - [20/Sep/2024 12:35:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:15,071 Request with ID fc5397ed for model llama3-8b received
2024-09-20 12:35:15,072 127.0.0.1 - - [20/Sep/2024 12:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:15,133 Request with ID 5c0e6b81 for model llama3-8b received
2024-09-20 12:35:15,133 127.0.0.1 - - [20/Sep/2024 12:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:15,193 Request with ID d7097b10 for model granite-7b received
2024-09-20 12:35:15,194 127.0.0.1 - - [20/Sep/2024 12:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:15,202 Request with ID 9aa972fb for model llama3-8b received
2024-09-20 12:35:15,203 127.0.0.1 - - [20/Sep/2024 12:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:15,367 Request with ID c0e41844 for model llama3-8b received
2024-09-20 12:35:15,368 127.0.0.1 - - [20/Sep/2024 12:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:15,417 Request with ID ed76d1be for model gemma-7b received
2024-09-20 12:35:15,418 127.0.0.1 - - [20/Sep/2024 12:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:15,461 Request with ID 72ab16b4 for model llama3-8b received
2024-09-20 12:35:15,462 127.0.0.1 - - [20/Sep/2024 12:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:15,617 Request with ID f8b00468 for model gemma-7b received
2024-09-20 12:35:15,618 127.0.0.1 - - [20/Sep/2024 12:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:15,627 Request with ID bb223272 for model llama3-8b received
2024-09-20 12:35:15,628 127.0.0.1 - - [20/Sep/2024 12:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:15,660 Request with ID 2c286414 for model granite-7b received
2024-09-20 12:35:15,660 127.0.0.1 - - [20/Sep/2024 12:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:15,735 Request with ID c2fd8a7d for model llama3-8b received
2024-09-20 12:35:15,735 Batch size condition met for model llama3-8b
2024-09-20 12:35:15,919 Request with ID d81d6e43 for model gemma-7b received
2024-09-20 12:35:15,920 Request with ID 4d1a4528 for model granite-7b received
2024-09-20 12:35:15,920 127.0.0.1 - - [20/Sep/2024 12:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:15,921 127.0.0.1 - - [20/Sep/2024 12:35:15] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:16,182 Request with ID 903827fe for model granite-7b received
2024-09-20 12:35:16,183 127.0.0.1 - - [20/Sep/2024 12:35:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:16,529 Request with ID e7df326e for model llama3-8b received
2024-09-20 12:35:16,530 127.0.0.1 - - [20/Sep/2024 12:35:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:16,543 Request with ID 253bee45 for model llama3-8b received
2024-09-20 12:35:16,543 127.0.0.1 - - [20/Sep/2024 12:35:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:16,683 Request with ID b739363c for model llama3-8b received
2024-09-20 12:35:16,684 127.0.0.1 - - [20/Sep/2024 12:35:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:16,701 Request with ID 062ee339 for model gemma-7b received
2024-09-20 12:35:16,701 127.0.0.1 - - [20/Sep/2024 12:35:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:16,935 Loaded model llama3-8b
2024-09-20 12:35:16,939 Batch processing started for model llama3-8b
2024-09-20 12:35:16,967 Request with ID 3c453958 for model gemma-7b received
2024-09-20 12:35:16,968 127.0.0.1 - - [20/Sep/2024 12:35:16] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:17,048 Request with ID fa372f16 for model gemma-7b received
2024-09-20 12:35:17,049 127.0.0.1 - - [20/Sep/2024 12:35:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:17,071 Request with ID 87dcd18f for model granite-7b received
2024-09-20 12:35:17,072 127.0.0.1 - - [20/Sep/2024 12:35:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:17,562 Request with ID f58ac380 for model llama3-8b received
2024-09-20 12:35:17,562 127.0.0.1 - - [20/Sep/2024 12:35:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:17,761 Request with ID af801e67 for model llama3-8b received
2024-09-20 12:35:17,762 127.0.0.1 - - [20/Sep/2024 12:35:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:17,790 Request with ID 3a012c83 for model llama3-8b received
2024-09-20 12:35:17,790 127.0.0.1 - - [20/Sep/2024 12:35:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:17,874 Request with ID a0d5c5a4 for model llama3-8b received
2024-09-20 12:35:17,875 127.0.0.1 - - [20/Sep/2024 12:35:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:17,894 Request with ID 86b91c35 for model llama3-8b received
2024-09-20 12:35:17,894 127.0.0.1 - - [20/Sep/2024 12:35:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:17,927 Request with ID fe18d386 for model gemma-7b received
2024-09-20 12:35:17,928 127.0.0.1 - - [20/Sep/2024 12:35:17] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:18,058 Request with ID cf7bcf86 for model llama3-8b received
2024-09-20 12:35:18,059 127.0.0.1 - - [20/Sep/2024 12:35:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:18,127 Request with ID 22c1a3e7 for model llama3-8b received
2024-09-20 12:35:18,127 127.0.0.1 - - [20/Sep/2024 12:35:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:18,261 Request with ID 4e75caf1 for model llama3-8b received
2024-09-20 12:35:18,262 127.0.0.1 - - [20/Sep/2024 12:35:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:18,357 Request with ID 4f5847c9 for model llama3-8b received
2024-09-20 12:35:18,358 127.0.0.1 - - [20/Sep/2024 12:35:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:18,476 Request with ID 96125ffa for model llama3-8b received
2024-09-20 12:35:18,476 127.0.0.1 - - [20/Sep/2024 12:35:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:18,688 Request with ID 4c83b0ce for model gemma-7b received
2024-09-20 12:35:18,689 127.0.0.1 - - [20/Sep/2024 12:35:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:18,771 Request with ID a5317346 for model llama3-8b received
2024-09-20 12:35:18,772 127.0.0.1 - - [20/Sep/2024 12:35:18] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:19,255 Request with ID 7710b31e for model llama3-8b received
2024-09-20 12:35:19,256 127.0.0.1 - - [20/Sep/2024 12:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:19,418 Request with ID 0bc4f8a4 for model llama3-8b received
2024-09-20 12:35:19,418 Batch size condition met for model llama3-8b
2024-09-20 12:35:19,515 Request with ID a7464d7f for model llama3-8b received
2024-09-20 12:35:19,516 127.0.0.1 - - [20/Sep/2024 12:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:19,564 Request with ID cf36f54f for model llama3-8b received
2024-09-20 12:35:19,565 127.0.0.1 - - [20/Sep/2024 12:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:19,566 Request with ID 681a9e31 for model granite-7b received
2024-09-20 12:35:19,566 127.0.0.1 - - [20/Sep/2024 12:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:19,703 Request with ID a22bb948 for model llama3-8b received
2024-09-20 12:35:19,704 127.0.0.1 - - [20/Sep/2024 12:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:19,801 Processed batch: ['0e5faccc', '661bdedb', 'eaf684b4', '437495d5', 'd160b9a3', '04fd04b1', '198292e7', '7cb55e11', '94dfe074', '0bd5a034', 'e9d2b3a3', '78e79fae', '16683494', '769bc229', '4100e8e1', '01baaba5'] with model llama3-8b in 2.8621 seconds
2024-09-20 12:35:19,801 Saving sys info
2024-09-20 12:35:19,832 Latency for request 0e5faccc with model llama3-8b: 21.2960 seconds
2024-09-20 12:35:19,833 Saving results with gpu monitoring
2024-09-20 12:35:19,835 Latency for request 661bdedb with model llama3-8b: 21.2120 seconds
2024-09-20 12:35:19,836 Saving results with gpu monitoring
2024-09-20 12:35:19,838 Latency for request eaf684b4 with model llama3-8b: 21.1600 seconds
2024-09-20 12:35:19,838 Saving results with gpu monitoring
2024-09-20 12:35:19,840 Latency for request 437495d5 with model llama3-8b: 20.7550 seconds
2024-09-20 12:35:19,840 Saving results with gpu monitoring
2024-09-20 12:35:19,842 Latency for request d160b9a3 with model llama3-8b: 20.4720 seconds
2024-09-20 12:35:19,842 Saving results with gpu monitoring
2024-09-20 12:35:19,844 Latency for request 04fd04b1 with model llama3-8b: 20.2080 seconds
2024-09-20 12:35:19,844 Saving results with gpu monitoring
2024-09-20 12:35:19,846 Latency for request 198292e7 with model llama3-8b: 20.2060 seconds
2024-09-20 12:35:19,846 Saving results with gpu monitoring
2024-09-20 12:35:19,848 Latency for request 7cb55e11 with model llama3-8b: 20.2050 seconds
2024-09-20 12:35:19,848 Saving results with gpu monitoring
2024-09-20 12:35:19,850 Latency for request 94dfe074 with model llama3-8b: 20.0520 seconds
2024-09-20 12:35:19,850 Saving results with gpu monitoring
2024-09-20 12:35:19,852 Latency for request 0bd5a034 with model llama3-8b: 19.4360 seconds
2024-09-20 12:35:19,852 Saving results with gpu monitoring
2024-09-20 12:35:19,854 Latency for request e9d2b3a3 with model llama3-8b: 19.4080 seconds
2024-09-20 12:35:19,854 Saving results with gpu monitoring
2024-09-20 12:35:19,857 Latency for request 78e79fae with model llama3-8b: 19.2990 seconds
2024-09-20 12:35:19,857 Saving results with gpu monitoring
2024-09-20 12:35:19,859 Latency for request 16683494 with model llama3-8b: 19.0880 seconds
2024-09-20 12:35:19,859 Saving results with gpu monitoring
2024-09-20 12:35:19,862 Request with ID 09973f60 for model llama3-8b received
2024-09-20 12:35:19,862 Latency for request 769bc229 with model llama3-8b: 18.9510 seconds
2024-09-20 12:35:19,863 127.0.0.1 - - [20/Sep/2024 12:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:19,863 Saving results with gpu monitoring
2024-09-20 12:35:19,865 Latency for request 4100e8e1 with model llama3-8b: 18.6130 seconds
2024-09-20 12:35:19,865 Saving results with gpu monitoring
2024-09-20 12:35:19,867 Latency for request 01baaba5 with model llama3-8b: 18.6100 seconds
2024-09-20 12:35:19,867 Saving results with gpu monitoring
2024-09-20 12:35:19,870 127.0.0.1 - - [20/Sep/2024 12:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:19,870 Next: call load_model for llama3-8b
2024-09-20 12:35:19,870 Model llama3-8b already loaded
2024-09-20 12:35:19,876 Batch processing started for model llama3-8b
2024-09-20 12:35:19,912 Request with ID b072cc66 for model gemma-7b received
2024-09-20 12:35:19,913 127.0.0.1 - - [20/Sep/2024 12:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:19,963 Request with ID 7e64c2b7 for model llama3-8b received
2024-09-20 12:35:19,963 127.0.0.1 - - [20/Sep/2024 12:35:19] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:20,182 Request with ID 165f390b for model gemma-7b received
2024-09-20 12:35:20,182 Batch size condition met for model gemma-7b
2024-09-20 12:35:20,294 Request with ID 3001586e for model llama3-8b received
2024-09-20 12:35:20,295 Request with ID a7705732 for model gemma-7b received
2024-09-20 12:35:20,296 127.0.0.1 - - [20/Sep/2024 12:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:20,296 127.0.0.1 - - [20/Sep/2024 12:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:20,315 Request with ID b164534e for model granite-7b received
2024-09-20 12:35:20,315 127.0.0.1 - - [20/Sep/2024 12:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:20,406 Request with ID 7740597e for model llama3-8b received
2024-09-20 12:35:20,406 127.0.0.1 - - [20/Sep/2024 12:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:20,417 Request with ID 196f0be2 for model llama3-8b received
2024-09-20 12:35:20,417 127.0.0.1 - - [20/Sep/2024 12:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:20,424 Request with ID 9e9b130d for model llama3-8b received
2024-09-20 12:35:20,424 127.0.0.1 - - [20/Sep/2024 12:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:20,519 Request with ID edc4ee82 for model gemma-7b received
2024-09-20 12:35:20,519 127.0.0.1 - - [20/Sep/2024 12:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:20,622 Request with ID 114b0d2f for model llama3-8b received
2024-09-20 12:35:20,622 127.0.0.1 - - [20/Sep/2024 12:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:20,762 Request with ID 429a1e62 for model llama3-8b received
2024-09-20 12:35:20,763 127.0.0.1 - - [20/Sep/2024 12:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:20,919 Request with ID 81e5e86e for model llama3-8b received
2024-09-20 12:35:20,920 127.0.0.1 - - [20/Sep/2024 12:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:20,937 Request with ID 57c5a3e6 for model llama3-8b received
2024-09-20 12:35:20,938 127.0.0.1 - - [20/Sep/2024 12:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:20,965 Request with ID 767e75cd for model gemma-7b received
2024-09-20 12:35:20,965 127.0.0.1 - - [20/Sep/2024 12:35:20] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:21,059 Request with ID aaf589fe for model llama3-8b received
2024-09-20 12:35:21,059 127.0.0.1 - - [20/Sep/2024 12:35:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:21,332 Request with ID 9472f8f0 for model gemma-7b received
2024-09-20 12:35:21,332 127.0.0.1 - - [20/Sep/2024 12:35:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:21,435 Request with ID 9394e7c1 for model llama3-8b received
2024-09-20 12:35:21,435 127.0.0.1 - - [20/Sep/2024 12:35:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:21,448 Request with ID b8c75020 for model llama3-8b received
2024-09-20 12:35:21,448 Batch size condition met for model llama3-8b
2024-09-20 12:35:21,589 Request with ID 778e64ab for model llama3-8b received
2024-09-20 12:35:21,589 127.0.0.1 - - [20/Sep/2024 12:35:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:21,609 Request with ID 7a2d6a0b for model llama3-8b received
2024-09-20 12:35:21,610 127.0.0.1 - - [20/Sep/2024 12:35:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:21,629 Request with ID 5a0ea72d for model granite-7b received
2024-09-20 12:35:21,629 127.0.0.1 - - [20/Sep/2024 12:35:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:21,810 Request with ID 60916f9c for model llama3-8b received
2024-09-20 12:35:21,810 127.0.0.1 - - [20/Sep/2024 12:35:21] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:22,077 Request with ID e5fcef3c for model llama3-8b received
2024-09-20 12:35:22,078 127.0.0.1 - - [20/Sep/2024 12:35:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:22,103 Request with ID e66fe14e for model llama3-8b received
2024-09-20 12:35:22,104 127.0.0.1 - - [20/Sep/2024 12:35:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:22,125 Request with ID 9b62963e for model llama3-8b received
2024-09-20 12:35:22,126 127.0.0.1 - - [20/Sep/2024 12:35:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:22,406 Request with ID 9b9210e1 for model granite-7b received
2024-09-20 12:35:22,406 127.0.0.1 - - [20/Sep/2024 12:35:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:22,513 Processed batch: ['e7df326e', '253bee45', 'b739363c', 'f58ac380', 'af801e67', '3a012c83', 'a0d5c5a4', '86b91c35', 'cf7bcf86', '22c1a3e7', '4e75caf1', '4f5847c9', '96125ffa', 'a5317346', '7710b31e', '0bc4f8a4'] with model llama3-8b in 2.6363 seconds
2024-09-20 12:35:22,513 Saving sys info
2024-09-20 12:35:22,538 Request with ID 81f73a8a for model llama3-8b received
2024-09-20 12:35:22,538 127.0.0.1 - - [20/Sep/2024 12:35:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:22,543 Latency for request e7df326e with model llama3-8b: 5.9830 seconds
2024-09-20 12:35:22,543 Saving results with gpu monitoring
2024-09-20 12:35:22,546 Latency for request 253bee45 with model llama3-8b: 5.9700 seconds
2024-09-20 12:35:22,546 Saving results with gpu monitoring
2024-09-20 12:35:22,548 Latency for request b739363c with model llama3-8b: 5.8290 seconds
2024-09-20 12:35:22,548 Saving results with gpu monitoring
2024-09-20 12:35:22,550 Latency for request f58ac380 with model llama3-8b: 4.9510 seconds
2024-09-20 12:35:22,550 Saving results with gpu monitoring
2024-09-20 12:35:22,552 Latency for request af801e67 with model llama3-8b: 4.7520 seconds
2024-09-20 12:35:22,552 Saving results with gpu monitoring
2024-09-20 12:35:22,554 Latency for request 3a012c83 with model llama3-8b: 4.7220 seconds
2024-09-20 12:35:22,554 Saving results with gpu monitoring
2024-09-20 12:35:22,556 Latency for request a0d5c5a4 with model llama3-8b: 4.6380 seconds
2024-09-20 12:35:22,556 Saving results with gpu monitoring
2024-09-20 12:35:22,558 Latency for request 86b91c35 with model llama3-8b: 4.6190 seconds
2024-09-20 12:35:22,558 Saving results with gpu monitoring
2024-09-20 12:35:22,560 Latency for request cf7bcf86 with model llama3-8b: 4.4540 seconds
2024-09-20 12:35:22,560 Saving results with gpu monitoring
2024-09-20 12:35:22,562 Latency for request 22c1a3e7 with model llama3-8b: 4.3860 seconds
2024-09-20 12:35:22,562 Saving results with gpu monitoring
2024-09-20 12:35:22,564 Latency for request 4e75caf1 with model llama3-8b: 4.2520 seconds
2024-09-20 12:35:22,564 Saving results with gpu monitoring
2024-09-20 12:35:22,566 Latency for request 4f5847c9 with model llama3-8b: 4.1550 seconds
2024-09-20 12:35:22,566 Saving results with gpu monitoring
2024-09-20 12:35:22,568 Latency for request 96125ffa with model llama3-8b: 4.0370 seconds
2024-09-20 12:35:22,568 Saving results with gpu monitoring
2024-09-20 12:35:22,570 Latency for request a5317346 with model llama3-8b: 3.7410 seconds
2024-09-20 12:35:22,570 Saving results with gpu monitoring
2024-09-20 12:35:22,572 Latency for request 7710b31e with model llama3-8b: 3.2570 seconds
2024-09-20 12:35:22,572 Saving results with gpu monitoring
2024-09-20 12:35:22,574 Latency for request 0bc4f8a4 with model llama3-8b: 3.0950 seconds
2024-09-20 12:35:22,574 Saving results with gpu monitoring
2024-09-20 12:35:22,576 127.0.0.1 - - [20/Sep/2024 12:35:22] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:22,576 Next: call load_model for gemma-7b
2024-09-20 12:35:22,668 Unloaded previous model
2024-09-20 12:35:23,167 Request with ID 7fe96b08 for model granite-7b received
2024-09-20 12:35:23,167 127.0.0.1 - - [20/Sep/2024 12:35:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:23,168 Request with ID 612a4f9b for model gemma-7b received
2024-09-20 12:35:23,168 127.0.0.1 - - [20/Sep/2024 12:35:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:23,170 Request with ID 3a2e012b for model llama3-8b received
2024-09-20 12:35:23,171 127.0.0.1 - - [20/Sep/2024 12:35:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:23,172 Request with ID 4ce4da77 for model granite-7b received
2024-09-20 12:35:23,172 127.0.0.1 - - [20/Sep/2024 12:35:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:23,176 Request with ID da78c591 for model gemma-7b received
2024-09-20 12:35:23,177 127.0.0.1 - - [20/Sep/2024 12:35:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:23,228 Request with ID c6038ba9 for model llama3-8b received
2024-09-20 12:35:23,229 127.0.0.1 - - [20/Sep/2024 12:35:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:23,362 Request with ID d3578295 for model llama3-8b received
2024-09-20 12:35:23,368 127.0.0.1 - - [20/Sep/2024 12:35:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:23,466 Request with ID 99e6cea4 for model gemma-7b received
2024-09-20 12:35:23,467 127.0.0.1 - - [20/Sep/2024 12:35:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:23,732 Request with ID 2b11ee91 for model granite-7b received
2024-09-20 12:35:23,744 Batch size condition met for model granite-7b
2024-09-20 12:35:23,874 Request with ID 3896a13f for model gemma-7b received
2024-09-20 12:35:23,874 127.0.0.1 - - [20/Sep/2024 12:35:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:23,997 Request with ID 95456eb4 for model gemma-7b received
2024-09-20 12:35:23,998 127.0.0.1 - - [20/Sep/2024 12:35:23] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:24,199 Request with ID 4d479fbb for model llama3-8b received
2024-09-20 12:35:24,199 127.0.0.1 - - [20/Sep/2024 12:35:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:24,210 Request with ID a8ceac06 for model llama3-8b received
2024-09-20 12:35:24,211 127.0.0.1 - - [20/Sep/2024 12:35:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:24,489 Request with ID a706965a for model llama3-8b received
2024-09-20 12:35:24,490 127.0.0.1 - - [20/Sep/2024 12:35:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:24,646 Request with ID 9a480dbb for model llama3-8b received
2024-09-20 12:35:24,647 127.0.0.1 - - [20/Sep/2024 12:35:24] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:25,038 Request with ID 48f82a4f for model gemma-7b received
2024-09-20 12:35:25,038 127.0.0.1 - - [20/Sep/2024 12:35:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:25,080 Request with ID 04f5138f for model llama3-8b received
2024-09-20 12:35:25,080 127.0.0.1 - - [20/Sep/2024 12:35:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:25,176 Request with ID 30c40343 for model granite-7b received
2024-09-20 12:35:25,176 127.0.0.1 - - [20/Sep/2024 12:35:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:25,305 Request with ID fe820a9c for model gemma-7b received
2024-09-20 12:35:25,305 127.0.0.1 - - [20/Sep/2024 12:35:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:25,497 Request with ID 20aa8272 for model llama3-8b received
2024-09-20 12:35:25,497 Batch size condition met for model llama3-8b
2024-09-20 12:35:25,523 Request with ID 1378cc76 for model llama3-8b received
2024-09-20 12:35:25,524 127.0.0.1 - - [20/Sep/2024 12:35:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:25,531 Request with ID 2022791a for model llama3-8b received
2024-09-20 12:35:25,535 127.0.0.1 - - [20/Sep/2024 12:35:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:25,540 Request with ID c5a5358f for model llama3-8b received
2024-09-20 12:35:25,541 127.0.0.1 - - [20/Sep/2024 12:35:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:25,598 Request with ID 4c37b07b for model llama3-8b received
2024-09-20 12:35:25,599 127.0.0.1 - - [20/Sep/2024 12:35:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:25,624 Request with ID 1f973834 for model llama3-8b received
2024-09-20 12:35:25,624 127.0.0.1 - - [20/Sep/2024 12:35:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:25,688 Request with ID 631e83fd for model granite-7b received
2024-09-20 12:35:25,689 127.0.0.1 - - [20/Sep/2024 12:35:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:25,762 Request with ID 7f1cfa78 for model gemma-7b received
2024-09-20 12:35:25,762 127.0.0.1 - - [20/Sep/2024 12:35:25] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:26,264 Request with ID 1d45d1d1 for model llama3-8b received
2024-09-20 12:35:26,265 127.0.0.1 - - [20/Sep/2024 12:35:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:26,266 Request with ID 1e2e6e78 for model llama3-8b received
2024-09-20 12:35:26,266 127.0.0.1 - - [20/Sep/2024 12:35:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:26,333 Request with ID 10fb1296 for model llama3-8b received
2024-09-20 12:35:26,334 127.0.0.1 - - [20/Sep/2024 12:35:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:26,356 Request with ID 8fe82276 for model llama3-8b received
2024-09-20 12:35:26,356 127.0.0.1 - - [20/Sep/2024 12:35:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:26,563 Request with ID 9449370e for model llama3-8b received
2024-09-20 12:35:26,564 127.0.0.1 - - [20/Sep/2024 12:35:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:26,647 Request with ID 28c3f78f for model granite-7b received
2024-09-20 12:35:26,647 127.0.0.1 - - [20/Sep/2024 12:35:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:26,712 Request with ID c18bb542 for model gemma-7b received
2024-09-20 12:35:26,712 127.0.0.1 - - [20/Sep/2024 12:35:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:26,763 Request with ID 3303e68e for model gemma-7b received
2024-09-20 12:35:26,763 127.0.0.1 - - [20/Sep/2024 12:35:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:26,825 Request with ID c6eb8915 for model granite-7b received
2024-09-20 12:35:26,825 127.0.0.1 - - [20/Sep/2024 12:35:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:26,884 Request with ID 089fe0ec for model gemma-7b received
2024-09-20 12:35:26,885 127.0.0.1 - - [20/Sep/2024 12:35:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:26,962 Request with ID 83cd67dc for model llama3-8b received
2024-09-20 12:35:26,962 127.0.0.1 - - [20/Sep/2024 12:35:26] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:26,995 Request with ID b821cbf8 for model gemma-7b received
2024-09-20 12:35:26,996 Batch size condition met for model gemma-7b
2024-09-20 12:35:27,245 Request with ID cc184507 for model llama3-8b received
2024-09-20 12:35:27,245 127.0.0.1 - - [20/Sep/2024 12:35:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:27,305 Request with ID 358405cf for model llama3-8b received
2024-09-20 12:35:27,306 127.0.0.1 - - [20/Sep/2024 12:35:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:27,544 Request with ID acc6397e for model gemma-7b received
2024-09-20 12:35:27,545 127.0.0.1 - - [20/Sep/2024 12:35:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:27,617 Request with ID 92bbcae7 for model gemma-7b received
2024-09-20 12:35:27,617 127.0.0.1 - - [20/Sep/2024 12:35:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:27,843 Request with ID a1f5380b for model llama3-8b received
2024-09-20 12:35:27,844 127.0.0.1 - - [20/Sep/2024 12:35:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:27,882 Request with ID 4bf4e717 for model llama3-8b received
2024-09-20 12:35:27,882 127.0.0.1 - - [20/Sep/2024 12:35:27] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:27,896 Request with ID 97b57bea for model llama3-8b received
2024-09-20 12:35:27,896 Batch size condition met for model llama3-8b
2024-09-20 12:35:28,241 Request with ID 9c364af6 for model llama3-8b received
2024-09-20 12:35:28,379 127.0.0.1 - - [20/Sep/2024 12:35:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:28,381 Request with ID e370875a for model llama3-8b received
2024-09-20 12:35:28,382 127.0.0.1 - - [20/Sep/2024 12:35:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:28,382 Request with ID 180c761c for model llama3-8b received
2024-09-20 12:35:28,384 Request with ID c6437192 for model granite-7b received
2024-09-20 12:35:28,385 127.0.0.1 - - [20/Sep/2024 12:35:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:28,386 127.0.0.1 - - [20/Sep/2024 12:35:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:28,387 Request with ID 332b7d38 for model llama3-8b received
2024-09-20 12:35:28,389 127.0.0.1 - - [20/Sep/2024 12:35:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:28,395 Request with ID 929d86c0 for model gemma-7b received
2024-09-20 12:35:28,395 127.0.0.1 - - [20/Sep/2024 12:35:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:28,592 Request with ID ec9c8be7 for model llama3-8b received
2024-09-20 12:35:28,593 127.0.0.1 - - [20/Sep/2024 12:35:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:28,605 Request with ID 5a759f05 for model llama3-8b received
2024-09-20 12:35:28,606 127.0.0.1 - - [20/Sep/2024 12:35:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:28,715 Request with ID f63a76e7 for model llama3-8b received
2024-09-20 12:35:28,716 127.0.0.1 - - [20/Sep/2024 12:35:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:28,929 Request with ID 7a370472 for model gemma-7b received
2024-09-20 12:35:28,930 127.0.0.1 - - [20/Sep/2024 12:35:28] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:29,055 Request with ID dd124947 for model gemma-7b received
2024-09-20 12:35:29,056 127.0.0.1 - - [20/Sep/2024 12:35:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:29,083 Request with ID fb8e7b1b for model llama3-8b received
2024-09-20 12:35:29,084 127.0.0.1 - - [20/Sep/2024 12:35:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:29,221 Request with ID ae95a179 for model llama3-8b received
2024-09-20 12:35:29,221 127.0.0.1 - - [20/Sep/2024 12:35:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:29,328 Request with ID f8148d7a for model gemma-7b received
2024-09-20 12:35:29,328 127.0.0.1 - - [20/Sep/2024 12:35:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:29,513 Request with ID 89c9aec6 for model llama3-8b received
2024-09-20 12:35:29,514 127.0.0.1 - - [20/Sep/2024 12:35:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:29,545 Request with ID 8e9ce5e7 for model gemma-7b received
2024-09-20 12:35:29,545 127.0.0.1 - - [20/Sep/2024 12:35:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:29,661 Request with ID b15e607f for model gemma-7b received
2024-09-20 12:35:29,661 127.0.0.1 - - [20/Sep/2024 12:35:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:29,662 Request with ID 84a5c762 for model gemma-7b received
2024-09-20 12:35:29,663 127.0.0.1 - - [20/Sep/2024 12:35:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:29,856 Request with ID 12c328d8 for model llama3-8b received
2024-09-20 12:35:29,857 127.0.0.1 - - [20/Sep/2024 12:35:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:29,864 Request with ID c6286cc6 for model llama3-8b received
2024-09-20 12:35:29,864 127.0.0.1 - - [20/Sep/2024 12:35:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:29,985 Request with ID 0d600e0e for model gemma-7b received
2024-09-20 12:35:29,985 127.0.0.1 - - [20/Sep/2024 12:35:29] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,031 Request with ID 7ad34016 for model granite-7b received
2024-09-20 12:35:30,032 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,068 Request with ID d3f24542 for model llama3-8b received
2024-09-20 12:35:30,069 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,216 Request with ID 929be8f5 for model llama3-8b received
2024-09-20 12:35:30,216 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,247 Request with ID 325526c7 for model llama3-8b received
2024-09-20 12:35:30,248 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,332 Request with ID 89882531 for model llama3-8b received
2024-09-20 12:35:30,332 Batch size condition met for model llama3-8b
2024-09-20 12:35:30,395 Request with ID 12000465 for model llama3-8b received
2024-09-20 12:35:30,396 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,445 Request with ID 8222673b for model llama3-8b received
2024-09-20 12:35:30,445 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,511 Request with ID 8f4da1ab for model granite-7b received
2024-09-20 12:35:30,512 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,680 Request with ID a9e0c353 for model llama3-8b received
2024-09-20 12:35:30,681 Request with ID 87db3e5e for model llama3-8b received
2024-09-20 12:35:30,682 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,682 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,841 Request with ID 5f96bc0c for model llama3-8b received
2024-09-20 12:35:30,842 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,845 Request with ID fb98eaf4 for model llama3-8b received
2024-09-20 12:35:30,845 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,879 Request with ID f09bd120 for model gemma-7b received
2024-09-20 12:35:30,880 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,893 Request with ID 47185e94 for model granite-7b received
2024-09-20 12:35:30,893 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,979 Request with ID 4068715b for model llama3-8b received
2024-09-20 12:35:30,980 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:30,986 Request with ID f528bb09 for model granite-7b received
2024-09-20 12:35:30,987 127.0.0.1 - - [20/Sep/2024 12:35:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:31,222 Request with ID 65b91c34 for model llama3-8b received
2024-09-20 12:35:31,223 127.0.0.1 - - [20/Sep/2024 12:35:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:31,263 Request with ID 643942fd for model llama3-8b received
2024-09-20 12:35:31,264 127.0.0.1 - - [20/Sep/2024 12:35:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:31,285 Request with ID 58b597b9 for model llama3-8b received
2024-09-20 12:35:31,286 127.0.0.1 - - [20/Sep/2024 12:35:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:31,470 Request with ID 8527e980 for model llama3-8b received
2024-09-20 12:35:31,471 127.0.0.1 - - [20/Sep/2024 12:35:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:31,502 Request with ID b9ec8ee1 for model llama3-8b received
2024-09-20 12:35:31,502 127.0.0.1 - - [20/Sep/2024 12:35:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:31,578 Request with ID 7ed780bb for model gemma-7b received
2024-09-20 12:35:31,579 127.0.0.1 - - [20/Sep/2024 12:35:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:31,604 Request with ID 66f6961e for model llama3-8b received
2024-09-20 12:35:31,605 127.0.0.1 - - [20/Sep/2024 12:35:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:31,608 Request with ID ef492b39 for model llama3-8b received
2024-09-20 12:35:31,609 127.0.0.1 - - [20/Sep/2024 12:35:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:31,822 Request with ID 8876abe4 for model llama3-8b received
2024-09-20 12:35:31,822 127.0.0.1 - - [20/Sep/2024 12:35:31] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:31,879 Request with ID e1b068a1 for model llama3-8b received
2024-09-20 12:35:31,880 Batch size condition met for model llama3-8b
2024-09-20 12:35:32,104 Request with ID 63ccebb3 for model llama3-8b received
2024-09-20 12:35:32,104 127.0.0.1 - - [20/Sep/2024 12:35:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:32,205 Request with ID 405c8a4a for model llama3-8b received
2024-09-20 12:35:32,205 127.0.0.1 - - [20/Sep/2024 12:35:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:32,309 Request with ID c93f2fd3 for model llama3-8b received
2024-09-20 12:35:32,310 127.0.0.1 - - [20/Sep/2024 12:35:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:32,320 Request with ID 22b0c7d2 for model llama3-8b received
2024-09-20 12:35:32,321 127.0.0.1 - - [20/Sep/2024 12:35:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:32,677 Request with ID cfc06c1e for model llama3-8b received
2024-09-20 12:35:32,678 127.0.0.1 - - [20/Sep/2024 12:35:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:32,877 Request with ID 7b5c1cba for model llama3-8b received
2024-09-20 12:35:32,879 Request with ID 42bc296f for model granite-7b received
2024-09-20 12:35:32,879 127.0.0.1 - - [20/Sep/2024 12:35:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:32,880 127.0.0.1 - - [20/Sep/2024 12:35:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:32,968 Request with ID 3979d204 for model gemma-7b received
2024-09-20 12:35:32,968 127.0.0.1 - - [20/Sep/2024 12:35:32] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,001 Request with ID 9648065c for model gemma-7b received
2024-09-20 12:35:33,001 127.0.0.1 - - [20/Sep/2024 12:35:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,069 Request with ID 770c3bae for model llama3-8b received
2024-09-20 12:35:33,069 127.0.0.1 - - [20/Sep/2024 12:35:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,129 Request with ID 897dd8ec for model gemma-7b received
2024-09-20 12:35:33,130 127.0.0.1 - - [20/Sep/2024 12:35:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,203 Request with ID ebea62b9 for model llama3-8b received
2024-09-20 12:35:33,204 127.0.0.1 - - [20/Sep/2024 12:35:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,208 Request with ID 1cf9430c for model granite-7b received
2024-09-20 12:35:33,209 127.0.0.1 - - [20/Sep/2024 12:35:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,221 Request with ID b8cb9738 for model llama3-8b received
2024-09-20 12:35:33,222 127.0.0.1 - - [20/Sep/2024 12:35:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,282 Request with ID 87e929b3 for model llama3-8b received
2024-09-20 12:35:33,283 127.0.0.1 - - [20/Sep/2024 12:35:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,318 Request with ID 7863414d for model llama3-8b received
2024-09-20 12:35:33,318 127.0.0.1 - - [20/Sep/2024 12:35:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,352 Request with ID 5f663635 for model llama3-8b received
2024-09-20 12:35:33,352 127.0.0.1 - - [20/Sep/2024 12:35:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,566 Request with ID bf4f5088 for model llama3-8b received
2024-09-20 12:35:33,567 127.0.0.1 - - [20/Sep/2024 12:35:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,635 Request with ID 47998aac for model llama3-8b received
2024-09-20 12:35:33,636 127.0.0.1 - - [20/Sep/2024 12:35:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,651 Request with ID 13df833e for model gemma-7b received
2024-09-20 12:35:33,651 Batch size condition met for model gemma-7b
2024-09-20 12:35:33,783 Request with ID cd29734a for model llama3-8b received
2024-09-20 12:35:33,784 127.0.0.1 - - [20/Sep/2024 12:35:33] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:33,912 Request with ID 41b96db4 for model llama3-8b received
2024-09-20 12:35:33,912 Batch size condition met for model llama3-8b
2024-09-20 12:35:34,225 Request with ID c9670ece for model granite-7b received
2024-09-20 12:35:34,225 Request with ID 4c9cd313 for model llama3-8b received
2024-09-20 12:35:34,226 127.0.0.1 - - [20/Sep/2024 12:35:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:34,226 127.0.0.1 - - [20/Sep/2024 12:35:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:34,432 Request with ID c84462f6 for model gemma-7b received
2024-09-20 12:35:34,433 127.0.0.1 - - [20/Sep/2024 12:35:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:34,481 Request with ID 3ef1c5f3 for model gemma-7b received
2024-09-20 12:35:34,482 127.0.0.1 - - [20/Sep/2024 12:35:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:34,495 Request with ID a01f2aa9 for model llama3-8b received
2024-09-20 12:35:34,496 127.0.0.1 - - [20/Sep/2024 12:35:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:34,503 Request with ID b5592cbf for model llama3-8b received
2024-09-20 12:35:34,503 127.0.0.1 - - [20/Sep/2024 12:35:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:34,616 Request with ID ce2a6fb0 for model llama3-8b received
2024-09-20 12:35:34,616 127.0.0.1 - - [20/Sep/2024 12:35:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:34,836 Request with ID b8b9b1b9 for model granite-7b received
2024-09-20 12:35:34,836 127.0.0.1 - - [20/Sep/2024 12:35:34] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:35,027 Request with ID 9cdac71f for model gemma-7b received
2024-09-20 12:35:35,028 127.0.0.1 - - [20/Sep/2024 12:35:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:35,042 Request with ID 390aab39 for model llama3-8b received
2024-09-20 12:35:35,043 127.0.0.1 - - [20/Sep/2024 12:35:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:35,049 Request with ID 7fb38a2a for model llama3-8b received
2024-09-20 12:35:35,050 127.0.0.1 - - [20/Sep/2024 12:35:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:35,224 Request with ID 0d22fa64 for model gemma-7b received
2024-09-20 12:35:35,224 127.0.0.1 - - [20/Sep/2024 12:35:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:35,292 Request with ID 1656b4fa for model granite-7b received
2024-09-20 12:35:35,292 127.0.0.1 - - [20/Sep/2024 12:35:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:35,307 Request with ID 0687b9ef for model gemma-7b received
2024-09-20 12:35:35,308 127.0.0.1 - - [20/Sep/2024 12:35:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:35,372 Request with ID 99fb548d for model llama3-8b received
2024-09-20 12:35:35,373 127.0.0.1 - - [20/Sep/2024 12:35:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:35,561 Request with ID a723bd43 for model llama3-8b received
2024-09-20 12:35:35,562 127.0.0.1 - - [20/Sep/2024 12:35:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:35,614 Request with ID 8f4b813b for model llama3-8b received
2024-09-20 12:35:35,614 127.0.0.1 - - [20/Sep/2024 12:35:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:35,814 Request with ID a271714a for model llama3-8b received
2024-09-20 12:35:35,814 127.0.0.1 - - [20/Sep/2024 12:35:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:35,976 Request with ID ef580c1b for model llama3-8b received
2024-09-20 12:35:35,977 127.0.0.1 - - [20/Sep/2024 12:35:35] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,065 Request with ID 1802772f for model llama3-8b received
2024-09-20 12:35:36,065 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,104 Request with ID 9e3e90bf for model gemma-7b received
2024-09-20 12:35:36,105 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,108 Request with ID 1080dae0 for model llama3-8b received
2024-09-20 12:35:36,109 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,157 Request with ID ecd3c5c2 for model gemma-7b received
2024-09-20 12:35:36,157 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,380 Request with ID 905b2d8e for model granite-7b received
2024-09-20 12:35:36,380 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,485 Request with ID d823812d for model granite-7b received
2024-09-20 12:35:36,485 Batch size condition met for model granite-7b
2024-09-20 12:35:36,534 Request with ID 92f9cdf7 for model llama3-8b received
2024-09-20 12:35:36,535 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,546 Request with ID 458da62c for model llama3-8b received
2024-09-20 12:35:36,546 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,593 Request with ID 43f7039a for model llama3-8b received
2024-09-20 12:35:36,593 Batch size condition met for model llama3-8b
2024-09-20 12:35:36,656 Request with ID 237d0cea for model gemma-7b received
2024-09-20 12:35:36,656 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,724 Request with ID 0686b76c for model llama3-8b received
2024-09-20 12:35:36,724 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,802 Request with ID 49235c13 for model gemma-7b received
2024-09-20 12:35:36,803 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,806 Request with ID 23d4ebc7 for model llama3-8b received
2024-09-20 12:35:36,806 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,861 Request with ID a5c0dd1a for model gemma-7b received
2024-09-20 12:35:36,862 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:36,879 Request with ID 6b4be6f3 for model gemma-7b received
2024-09-20 12:35:36,879 127.0.0.1 - - [20/Sep/2024 12:35:36] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:37,112 Request with ID a7a93ca2 for model llama3-8b received
2024-09-20 12:35:37,112 127.0.0.1 - - [20/Sep/2024 12:35:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:37,150 Request with ID d901f1ff for model llama3-8b received
2024-09-20 12:35:37,151 127.0.0.1 - - [20/Sep/2024 12:35:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:37,320 Request with ID f89ca8ff for model gemma-7b received
2024-09-20 12:35:37,321 127.0.0.1 - - [20/Sep/2024 12:35:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:37,557 Request with ID 78b88b0f for model granite-7b received
2024-09-20 12:35:37,558 127.0.0.1 - - [20/Sep/2024 12:35:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:37,914 Request with ID 97b8f0a6 for model llama3-8b received
2024-09-20 12:35:37,914 127.0.0.1 - - [20/Sep/2024 12:35:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:37,931 Request with ID a0e8c863 for model llama3-8b received
2024-09-20 12:35:37,932 127.0.0.1 - - [20/Sep/2024 12:35:37] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:38,077 Request with ID fb8bc19c for model llama3-8b received
2024-09-20 12:35:38,078 127.0.0.1 - - [20/Sep/2024 12:35:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:38,122 Request with ID 37bb281a for model gemma-7b received
2024-09-20 12:35:38,123 127.0.0.1 - - [20/Sep/2024 12:35:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:38,145 Request with ID 38b855b2 for model gemma-7b received
2024-09-20 12:35:38,145 127.0.0.1 - - [20/Sep/2024 12:35:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:38,178 Request with ID c20846e5 for model llama3-8b received
2024-09-20 12:35:38,179 127.0.0.1 - - [20/Sep/2024 12:35:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:38,259 Request with ID 4c28a1cc for model llama3-8b received
2024-09-20 12:35:38,260 127.0.0.1 - - [20/Sep/2024 12:35:38] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:39,078 Request with ID 01f8b8b1 for model llama3-8b received
2024-09-20 12:35:39,078 127.0.0.1 - - [20/Sep/2024 12:35:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:39,146 Request with ID d78d7eff for model gemma-7b received
2024-09-20 12:35:39,146 127.0.0.1 - - [20/Sep/2024 12:35:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:39,305 Request with ID 4cf838d9 for model llama3-8b received
2024-09-20 12:35:39,306 127.0.0.1 - - [20/Sep/2024 12:35:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:39,321 Request with ID 1b7b9c6d for model llama3-8b received
2024-09-20 12:35:39,322 127.0.0.1 - - [20/Sep/2024 12:35:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:39,562 Request with ID 66eb42cf for model llama3-8b received
2024-09-20 12:35:39,563 127.0.0.1 - - [20/Sep/2024 12:35:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:39,805 Request with ID d04ccb22 for model gemma-7b received
2024-09-20 12:35:39,805 Batch size condition met for model gemma-7b
2024-09-20 12:35:39,868 Request with ID f47025b8 for model gemma-7b received
2024-09-20 12:35:39,868 127.0.0.1 - - [20/Sep/2024 12:35:39] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,028 Request with ID f884322f for model llama3-8b received
2024-09-20 12:35:40,029 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,031 Request with ID fb06d6ce for model gemma-7b received
2024-09-20 12:35:40,032 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,096 Request with ID 1a5fc327 for model llama3-8b received
2024-09-20 12:35:40,097 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,166 Request with ID 905b3bc8 for model gemma-7b received
2024-09-20 12:35:40,167 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,217 Loaded model gemma-7b
2024-09-20 12:35:40,219 Request with ID 19993d20 for model llama3-8b received
2024-09-20 12:35:40,220 Batch size condition met for model llama3-8b
2024-09-20 12:35:40,222 Batch processing started for model gemma-7b
2024-09-20 12:35:40,296 Request with ID 0be03145 for model llama3-8b received
2024-09-20 12:35:40,296 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,383 Request with ID e3e39b8d for model llama3-8b received
2024-09-20 12:35:40,383 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,445 Request with ID 609f4710 for model llama3-8b received
2024-09-20 12:35:40,445 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,591 Request with ID 5364968d for model llama3-8b received
2024-09-20 12:35:40,592 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,614 Request with ID 7b43ac24 for model llama3-8b received
2024-09-20 12:35:40,614 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,674 Request with ID 3b51c040 for model gemma-7b received
2024-09-20 12:35:40,674 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,702 Request with ID 54205908 for model llama3-8b received
2024-09-20 12:35:40,702 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,776 Request with ID b8afb72e for model llama3-8b received
2024-09-20 12:35:40,776 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,780 Request with ID 9dcec750 for model llama3-8b received
2024-09-20 12:35:40,780 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:40,909 Request with ID f559f74d for model llama3-8b received
2024-09-20 12:35:40,909 127.0.0.1 - - [20/Sep/2024 12:35:40] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:41,014 Request with ID 1e016f56 for model llama3-8b received
2024-09-20 12:35:41,015 127.0.0.1 - - [20/Sep/2024 12:35:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:41,048 Request with ID a86e4b7e for model llama3-8b received
2024-09-20 12:35:41,048 127.0.0.1 - - [20/Sep/2024 12:35:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:41,208 Request with ID 6d5fe38a for model gemma-7b received
2024-09-20 12:35:41,209 127.0.0.1 - - [20/Sep/2024 12:35:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:41,733 Request with ID f628a104 for model granite-7b received
2024-09-20 12:35:41,734 127.0.0.1 - - [20/Sep/2024 12:35:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:41,869 Request with ID c4d569c6 for model llama3-8b received
2024-09-20 12:35:41,869 127.0.0.1 - - [20/Sep/2024 12:35:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:41,875 Request with ID c80a1dee for model llama3-8b received
2024-09-20 12:35:41,876 127.0.0.1 - - [20/Sep/2024 12:35:41] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:42,025 Request with ID f7ec8fb6 for model llama3-8b received
2024-09-20 12:35:42,026 127.0.0.1 - - [20/Sep/2024 12:35:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:42,214 Request with ID 5b75adfa for model granite-7b received
2024-09-20 12:35:42,214 127.0.0.1 - - [20/Sep/2024 12:35:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:42,267 Request with ID 0fea07f1 for model granite-7b received
2024-09-20 12:35:42,268 127.0.0.1 - - [20/Sep/2024 12:35:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:42,305 Request with ID def38f58 for model llama3-8b received
2024-09-20 12:35:42,306 127.0.0.1 - - [20/Sep/2024 12:35:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:42,603 Request with ID a837a89b for model granite-7b received
2024-09-20 12:35:42,603 127.0.0.1 - - [20/Sep/2024 12:35:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:42,613 Request with ID 689fb0da for model gemma-7b received
2024-09-20 12:35:42,613 127.0.0.1 - - [20/Sep/2024 12:35:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:42,622 Request with ID 0a49f07f for model llama3-8b received
2024-09-20 12:35:42,623 Batch size condition met for model llama3-8b
2024-09-20 12:35:42,748 Request with ID ae28ed48 for model llama3-8b received
2024-09-20 12:35:42,748 127.0.0.1 - - [20/Sep/2024 12:35:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:42,859 Request with ID f3abba08 for model gemma-7b received
2024-09-20 12:35:42,859 127.0.0.1 - - [20/Sep/2024 12:35:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:42,892 Request with ID 03992f1a for model llama3-8b received
2024-09-20 12:35:42,893 127.0.0.1 - - [20/Sep/2024 12:35:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:42,946 Request with ID 259d42e1 for model granite-7b received
2024-09-20 12:35:42,946 127.0.0.1 - - [20/Sep/2024 12:35:42] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,035 Request with ID 26576509 for model llama3-8b received
2024-09-20 12:35:43,035 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,124 Processed batch: ['74be3abe', '03ea26b0', '68dfc58f', '4b0f9736', '81db485a', '0e53d38a', 'ed76d1be', 'f8b00468', 'd81d6e43', '062ee339', '3c453958', 'fa372f16', 'fe18d386', '4c83b0ce', 'b072cc66', '165f390b'] with model gemma-7b in 2.9018 seconds
2024-09-20 12:35:43,124 Saving sys info
2024-09-20 12:35:43,129 Request with ID be447e51 for model llama3-8b received
2024-09-20 12:35:43,129 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,160 Latency for request 74be3abe with model gemma-7b: 29.6010 seconds
2024-09-20 12:35:43,161 Saving results with gpu monitoring
2024-09-20 12:35:43,165 Latency for request 03ea26b0 with model gemma-7b: 29.5500 seconds
2024-09-20 12:35:43,165 Saving results with gpu monitoring
2024-09-20 12:35:43,167 Latency for request 68dfc58f with model gemma-7b: 29.5360 seconds
2024-09-20 12:35:43,167 Saving results with gpu monitoring
2024-09-20 12:35:43,169 Latency for request 4b0f9736 with model gemma-7b: 29.3650 seconds
2024-09-20 12:35:43,169 Saving results with gpu monitoring
2024-09-20 12:35:43,171 Latency for request 81db485a with model gemma-7b: 28.6620 seconds
2024-09-20 12:35:43,171 Saving results with gpu monitoring
2024-09-20 12:35:43,173 Latency for request 0e53d38a with model gemma-7b: 28.4930 seconds
2024-09-20 12:35:43,173 Saving results with gpu monitoring
2024-09-20 12:35:43,175 Latency for request ed76d1be with model gemma-7b: 27.7070 seconds
2024-09-20 12:35:43,175 Saving results with gpu monitoring
2024-09-20 12:35:43,177 Latency for request f8b00468 with model gemma-7b: 27.5070 seconds
2024-09-20 12:35:43,177 Saving results with gpu monitoring
2024-09-20 12:35:43,179 Latency for request d81d6e43 with model gemma-7b: 27.2050 seconds
2024-09-20 12:35:43,179 Saving results with gpu monitoring
2024-09-20 12:35:43,181 Latency for request 062ee339 with model gemma-7b: 26.4230 seconds
2024-09-20 12:35:43,181 Saving results with gpu monitoring
2024-09-20 12:35:43,183 Latency for request 3c453958 with model gemma-7b: 26.1570 seconds
2024-09-20 12:35:43,183 Saving results with gpu monitoring
2024-09-20 12:35:43,185 Latency for request fa372f16 with model gemma-7b: 26.0760 seconds
2024-09-20 12:35:43,185 Saving results with gpu monitoring
2024-09-20 12:35:43,187 Latency for request fe18d386 with model gemma-7b: 25.1970 seconds
2024-09-20 12:35:43,187 Saving results with gpu monitoring
2024-09-20 12:35:43,189 Latency for request 4c83b0ce with model gemma-7b: 24.4360 seconds
2024-09-20 12:35:43,189 Saving results with gpu monitoring
2024-09-20 12:35:43,191 Latency for request b072cc66 with model gemma-7b: 23.2120 seconds
2024-09-20 12:35:43,191 Saving results with gpu monitoring
2024-09-20 12:35:43,193 Latency for request 165f390b with model gemma-7b: 22.9420 seconds
2024-09-20 12:35:43,193 Saving results with gpu monitoring
2024-09-20 12:35:43,195 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,195 Next: call load_model for llama3-8b
2024-09-20 12:35:43,306 Unloaded previous model
2024-09-20 12:35:43,308 Request with ID e8b949be for model llama3-8b received
2024-09-20 12:35:43,308 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,557 Request with ID d20c7631 for model llama3-8b received
2024-09-20 12:35:43,558 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,563 Request with ID 63ab584a for model granite-7b received
2024-09-20 12:35:43,563 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,636 Request with ID 52b4367b for model gemma-7b received
2024-09-20 12:35:43,637 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,781 Request with ID acbab91f for model llama3-8b received
2024-09-20 12:35:43,783 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,785 Request with ID f06bcedc for model llama3-8b received
2024-09-20 12:35:43,785 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,788 Request with ID dc1b50c7 for model gemma-7b received
2024-09-20 12:35:43,789 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,790 Request with ID 0f9574db for model llama3-8b received
2024-09-20 12:35:43,791 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,793 Request with ID e80b6b3d for model granite-7b received
2024-09-20 12:35:43,793 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:43,916 Request with ID e3255b51 for model gemma-7b received
2024-09-20 12:35:43,917 127.0.0.1 - - [20/Sep/2024 12:35:43] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:44,019 Request with ID 75662fb7 for model llama3-8b received
2024-09-20 12:35:44,020 127.0.0.1 - - [20/Sep/2024 12:35:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:44,026 Request with ID ece20c5d for model granite-7b received
2024-09-20 12:35:44,027 127.0.0.1 - - [20/Sep/2024 12:35:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:44,353 Request with ID 27cf42a2 for model gemma-7b received
2024-09-20 12:35:44,361 127.0.0.1 - - [20/Sep/2024 12:35:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:44,387 Request with ID 75d4d6af for model llama3-8b received
2024-09-20 12:35:44,388 127.0.0.1 - - [20/Sep/2024 12:35:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:44,410 Request with ID 92fc5e7e for model llama3-8b received
2024-09-20 12:35:44,416 127.0.0.1 - - [20/Sep/2024 12:35:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:44,657 Request with ID 2f247bf7 for model llama3-8b received
2024-09-20 12:35:44,658 127.0.0.1 - - [20/Sep/2024 12:35:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:44,659 Request with ID fe164b46 for model llama3-8b received
2024-09-20 12:35:44,660 127.0.0.1 - - [20/Sep/2024 12:35:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:44,680 Request with ID 78f32bb9 for model llama3-8b received
2024-09-20 12:35:44,680 127.0.0.1 - - [20/Sep/2024 12:35:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:44,796 Request with ID ae18370c for model gemma-7b received
2024-09-20 12:35:44,796 127.0.0.1 - - [20/Sep/2024 12:35:44] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:45,007 Request with ID 4e008f3f for model llama3-8b received
2024-09-20 12:35:45,007 Batch size condition met for model llama3-8b
2024-09-20 12:35:45,151 Request with ID 3a26b5ab for model llama3-8b received
2024-09-20 12:35:45,152 127.0.0.1 - - [20/Sep/2024 12:35:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:45,442 Request with ID b5b246e5 for model gemma-7b received
2024-09-20 12:35:45,443 127.0.0.1 - - [20/Sep/2024 12:35:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:45,597 Request with ID 21491754 for model llama3-8b received
2024-09-20 12:35:45,597 127.0.0.1 - - [20/Sep/2024 12:35:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:45,608 Request with ID b995c1bc for model llama3-8b received
2024-09-20 12:35:45,609 127.0.0.1 - - [20/Sep/2024 12:35:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:45,681 Request with ID 6e65f600 for model llama3-8b received
2024-09-20 12:35:45,681 127.0.0.1 - - [20/Sep/2024 12:35:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:45,693 Request with ID ae61eb4a for model llama3-8b received
2024-09-20 12:35:45,694 127.0.0.1 - - [20/Sep/2024 12:35:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:45,695 Request with ID 473a6c5f for model llama3-8b received
2024-09-20 12:35:45,696 127.0.0.1 - - [20/Sep/2024 12:35:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:45,750 Request with ID 5beab633 for model llama3-8b received
2024-09-20 12:35:45,750 127.0.0.1 - - [20/Sep/2024 12:35:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:45,879 Request with ID 278f4a23 for model llama3-8b received
2024-09-20 12:35:45,879 127.0.0.1 - - [20/Sep/2024 12:35:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:45,944 Request with ID 0b6d7c19 for model llama3-8b received
2024-09-20 12:35:45,945 127.0.0.1 - - [20/Sep/2024 12:35:45] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:46,105 Request with ID 848a5e71 for model llama3-8b received
2024-09-20 12:35:46,106 127.0.0.1 - - [20/Sep/2024 12:35:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:46,141 Request with ID 28b14026 for model llama3-8b received
2024-09-20 12:35:46,141 127.0.0.1 - - [20/Sep/2024 12:35:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:46,155 Request with ID a6358ec1 for model llama3-8b received
2024-09-20 12:35:46,156 127.0.0.1 - - [20/Sep/2024 12:35:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:46,163 Request with ID 09f5147b for model llama3-8b received
2024-09-20 12:35:46,163 127.0.0.1 - - [20/Sep/2024 12:35:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:46,185 Request with ID 473dc32e for model granite-7b received
2024-09-20 12:35:46,186 127.0.0.1 - - [20/Sep/2024 12:35:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:46,190 Request with ID b6bb8e2c for model granite-7b received
2024-09-20 12:35:46,191 127.0.0.1 - - [20/Sep/2024 12:35:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:46,204 Request with ID 0726404a for model llama3-8b received
2024-09-20 12:35:46,204 127.0.0.1 - - [20/Sep/2024 12:35:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:46,215 Request with ID b8f428c9 for model gemma-7b received
2024-09-20 12:35:46,215 127.0.0.1 - - [20/Sep/2024 12:35:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:46,460 Request with ID 77cc040e for model llama3-8b received
2024-09-20 12:35:46,461 127.0.0.1 - - [20/Sep/2024 12:35:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:46,758 Request with ID 02f23807 for model llama3-8b received
2024-09-20 12:35:46,759 Batch size condition met for model llama3-8b
2024-09-20 12:35:46,812 Request with ID 9034e303 for model llama3-8b received
2024-09-20 12:35:46,813 127.0.0.1 - - [20/Sep/2024 12:35:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:46,843 Request with ID 077c181a for model llama3-8b received
2024-09-20 12:35:46,844 127.0.0.1 - - [20/Sep/2024 12:35:46] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:47,177 Request with ID a3602f1a for model llama3-8b received
2024-09-20 12:35:47,177 127.0.0.1 - - [20/Sep/2024 12:35:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:47,327 Request with ID 5624b5f1 for model gemma-7b received
2024-09-20 12:35:47,327 127.0.0.1 - - [20/Sep/2024 12:35:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:47,569 Request with ID 236a4cd0 for model llama3-8b received
2024-09-20 12:35:47,570 127.0.0.1 - - [20/Sep/2024 12:35:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:47,690 Request with ID ec5169ce for model gemma-7b received
2024-09-20 12:35:47,690 Batch size condition met for model gemma-7b
2024-09-20 12:35:47,748 Request with ID d620a508 for model gemma-7b received
2024-09-20 12:35:47,749 127.0.0.1 - - [20/Sep/2024 12:35:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:47,898 Request with ID cb9c3344 for model granite-7b received
2024-09-20 12:35:47,899 127.0.0.1 - - [20/Sep/2024 12:35:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:47,935 Request with ID c75e05c2 for model llama3-8b received
2024-09-20 12:35:47,935 127.0.0.1 - - [20/Sep/2024 12:35:47] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:48,148 Request with ID 1449a96b for model granite-7b received
2024-09-20 12:35:48,149 127.0.0.1 - - [20/Sep/2024 12:35:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:48,379 Request with ID 0d865ef6 for model llama3-8b received
2024-09-20 12:35:48,380 127.0.0.1 - - [20/Sep/2024 12:35:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:48,414 Request with ID 3ef660c3 for model gemma-7b received
2024-09-20 12:35:48,414 127.0.0.1 - - [20/Sep/2024 12:35:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:48,421 Request with ID 5f02ed7e for model llama3-8b received
2024-09-20 12:35:48,422 127.0.0.1 - - [20/Sep/2024 12:35:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:48,515 Request with ID 401af1d1 for model granite-7b received
2024-09-20 12:35:48,516 127.0.0.1 - - [20/Sep/2024 12:35:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:48,628 Request with ID be1a9cb3 for model llama3-8b received
2024-09-20 12:35:48,629 127.0.0.1 - - [20/Sep/2024 12:35:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:48,917 Request with ID e4f35abb for model llama3-8b received
2024-09-20 12:35:48,917 127.0.0.1 - - [20/Sep/2024 12:35:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:48,997 Request with ID 781c2e02 for model gemma-7b received
2024-09-20 12:35:48,997 127.0.0.1 - - [20/Sep/2024 12:35:48] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:49,022 Request with ID f650ca48 for model llama3-8b received
2024-09-20 12:35:49,023 127.0.0.1 - - [20/Sep/2024 12:35:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:49,063 Request with ID ed8236eb for model llama3-8b received
2024-09-20 12:35:49,064 127.0.0.1 - - [20/Sep/2024 12:35:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:49,166 Request with ID aef1a936 for model gemma-7b received
2024-09-20 12:35:49,167 127.0.0.1 - - [20/Sep/2024 12:35:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:49,272 Request with ID b41d15ed for model llama3-8b received
2024-09-20 12:35:49,272 127.0.0.1 - - [20/Sep/2024 12:35:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:49,314 Request with ID f2f6eb0a for model llama3-8b received
2024-09-20 12:35:49,314 127.0.0.1 - - [20/Sep/2024 12:35:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:49,321 Request with ID 63765820 for model granite-7b received
2024-09-20 12:35:49,322 127.0.0.1 - - [20/Sep/2024 12:35:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:49,339 Request with ID 7304e5bc for model llama3-8b received
2024-09-20 12:35:49,340 127.0.0.1 - - [20/Sep/2024 12:35:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:49,366 Request with ID c0204779 for model llama3-8b received
2024-09-20 12:35:49,366 127.0.0.1 - - [20/Sep/2024 12:35:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:49,403 Request with ID 9e63cde7 for model gemma-7b received
2024-09-20 12:35:49,403 127.0.0.1 - - [20/Sep/2024 12:35:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:49,703 Request with ID 1db5a257 for model granite-7b received
2024-09-20 12:35:49,704 Batch size condition met for model granite-7b
2024-09-20 12:35:49,736 Request with ID 7b562f33 for model llama3-8b received
2024-09-20 12:35:49,737 Batch size condition met for model llama3-8b
2024-09-20 12:35:49,821 Request with ID 748cce34 for model llama3-8b received
2024-09-20 12:35:49,822 127.0.0.1 - - [20/Sep/2024 12:35:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:49,844 Request with ID 9b9d72c3 for model llama3-8b received
2024-09-20 12:35:49,844 127.0.0.1 - - [20/Sep/2024 12:35:49] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:50,244 Request with ID c035df1a for model llama3-8b received
2024-09-20 12:35:50,245 127.0.0.1 - - [20/Sep/2024 12:35:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:50,272 Request with ID 395d9668 for model gemma-7b received
2024-09-20 12:35:50,273 127.0.0.1 - - [20/Sep/2024 12:35:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:50,376 Request with ID 838ed4c9 for model llama3-8b received
2024-09-20 12:35:50,377 127.0.0.1 - - [20/Sep/2024 12:35:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:50,503 Request with ID 127d1ae7 for model gemma-7b received
2024-09-20 12:35:50,503 127.0.0.1 - - [20/Sep/2024 12:35:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:50,561 Request with ID 0542ed48 for model granite-7b received
2024-09-20 12:35:50,562 127.0.0.1 - - [20/Sep/2024 12:35:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:50,660 Request with ID 5f043680 for model gemma-7b received
2024-09-20 12:35:50,661 127.0.0.1 - - [20/Sep/2024 12:35:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:50,819 Request with ID e5f5480d for model llama3-8b received
2024-09-20 12:35:50,820 127.0.0.1 - - [20/Sep/2024 12:35:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:50,894 Request with ID 7e79d296 for model llama3-8b received
2024-09-20 12:35:50,895 127.0.0.1 - - [20/Sep/2024 12:35:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:50,912 Request with ID 276d8c03 for model llama3-8b received
2024-09-20 12:35:50,913 127.0.0.1 - - [20/Sep/2024 12:35:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:50,950 Request with ID 4f9dba89 for model llama3-8b received
2024-09-20 12:35:50,951 127.0.0.1 - - [20/Sep/2024 12:35:50] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,062 Request with ID 8d2b6335 for model llama3-8b received
2024-09-20 12:35:51,063 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,208 Request with ID 88e6aafa for model llama3-8b received
2024-09-20 12:35:51,209 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,211 Request with ID 1e72739e for model llama3-8b received
2024-09-20 12:35:51,211 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,258 Request with ID f54986d3 for model llama3-8b received
2024-09-20 12:35:51,259 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,279 Request with ID aec97890 for model granite-7b received
2024-09-20 12:35:51,280 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,337 Request with ID 30a4584b for model llama3-8b received
2024-09-20 12:35:51,337 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,447 Request with ID 7aa55179 for model llama3-8b received
2024-09-20 12:35:51,447 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,465 Request with ID 21debc38 for model llama3-8b received
2024-09-20 12:35:51,465 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,535 Request with ID c1de57ea for model llama3-8b received
2024-09-20 12:35:51,536 Batch size condition met for model llama3-8b
2024-09-20 12:35:51,584 Request with ID 00e0172f for model granite-7b received
2024-09-20 12:35:51,584 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,587 Request with ID cde605bb for model llama3-8b received
2024-09-20 12:35:51,588 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,638 Request with ID 702f3805 for model gemma-7b received
2024-09-20 12:35:51,638 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,747 Request with ID 1274e24b for model llama3-8b received
2024-09-20 12:35:51,748 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:51,960 Request with ID 79e07827 for model gemma-7b received
2024-09-20 12:35:51,960 127.0.0.1 - - [20/Sep/2024 12:35:51] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:52,033 Request with ID 393c4f03 for model granite-7b received
2024-09-20 12:35:52,033 127.0.0.1 - - [20/Sep/2024 12:35:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:52,036 Request with ID 9470b996 for model gemma-7b received
2024-09-20 12:35:52,037 127.0.0.1 - - [20/Sep/2024 12:35:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:52,154 Request with ID 5734bb0a for model llama3-8b received
2024-09-20 12:35:52,154 127.0.0.1 - - [20/Sep/2024 12:35:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:52,243 Request with ID 89bd225f for model llama3-8b received
2024-09-20 12:35:52,243 127.0.0.1 - - [20/Sep/2024 12:35:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:52,301 Request with ID b05c0ae5 for model gemma-7b received
2024-09-20 12:35:52,301 127.0.0.1 - - [20/Sep/2024 12:35:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:52,527 Request with ID a050214d for model llama3-8b received
2024-09-20 12:35:52,527 127.0.0.1 - - [20/Sep/2024 12:35:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:52,673 Request with ID e3671ff6 for model llama3-8b received
2024-09-20 12:35:52,673 127.0.0.1 - - [20/Sep/2024 12:35:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:52,753 Request with ID 8d00a9aa for model gemma-7b received
2024-09-20 12:35:52,753 127.0.0.1 - - [20/Sep/2024 12:35:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:52,789 Request with ID 1ef0ff07 for model llama3-8b received
2024-09-20 12:35:52,789 127.0.0.1 - - [20/Sep/2024 12:35:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:52,814 Request with ID 4d2e66ff for model granite-7b received
2024-09-20 12:35:52,814 127.0.0.1 - - [20/Sep/2024 12:35:52] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:53,099 Request with ID 25c2254a for model llama3-8b received
2024-09-20 12:35:53,099 127.0.0.1 - - [20/Sep/2024 12:35:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:53,267 Request with ID 51094101 for model granite-7b received
2024-09-20 12:35:53,268 127.0.0.1 - - [20/Sep/2024 12:35:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:53,512 Request with ID ffec74ca for model llama3-8b received
2024-09-20 12:35:53,513 127.0.0.1 - - [20/Sep/2024 12:35:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:53,514 Request with ID a8393042 for model llama3-8b received
2024-09-20 12:35:53,515 127.0.0.1 - - [20/Sep/2024 12:35:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:53,584 Request with ID b7e2150e for model llama3-8b received
2024-09-20 12:35:53,585 127.0.0.1 - - [20/Sep/2024 12:35:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:53,636 Request with ID f85105df for model llama3-8b received
2024-09-20 12:35:53,637 Request with ID d5a68f37 for model llama3-8b received
2024-09-20 12:35:53,637 127.0.0.1 - - [20/Sep/2024 12:35:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:53,638 127.0.0.1 - - [20/Sep/2024 12:35:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:53,643 Request with ID ccf56721 for model gemma-7b received
2024-09-20 12:35:53,643 127.0.0.1 - - [20/Sep/2024 12:35:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:53,667 Request with ID 8e61e660 for model gemma-7b received
2024-09-20 12:35:53,668 Request with ID 24661897 for model gemma-7b received
2024-09-20 12:35:53,668 127.0.0.1 - - [20/Sep/2024 12:35:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:53,669 Batch size condition met for model gemma-7b
2024-09-20 12:35:53,706 Request with ID 4fe8c9e4 for model llama3-8b received
2024-09-20 12:35:53,707 127.0.0.1 - - [20/Sep/2024 12:35:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:53,762 Request with ID d24e2c54 for model llama3-8b received
2024-09-20 12:35:53,762 127.0.0.1 - - [20/Sep/2024 12:35:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:53,799 Request with ID 9438cd05 for model llama3-8b received
2024-09-20 12:35:53,799 Batch size condition met for model llama3-8b
2024-09-20 12:35:53,971 Request with ID 8f48b12a for model gemma-7b received
2024-09-20 12:35:53,971 127.0.0.1 - - [20/Sep/2024 12:35:53] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,012 Request with ID ec636f3c for model llama3-8b received
2024-09-20 12:35:54,013 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,038 Request with ID f2e07bc9 for model gemma-7b received
2024-09-20 12:35:54,039 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,131 Request with ID e2aa27f2 for model granite-7b received
2024-09-20 12:35:54,132 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,211 Request with ID 40384098 for model gemma-7b received
2024-09-20 12:35:54,212 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,364 Request with ID 2318ac30 for model gemma-7b received
2024-09-20 12:35:54,365 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,465 Request with ID ddabfc03 for model gemma-7b received
2024-09-20 12:35:54,466 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,592 Request with ID e1c4350b for model llama3-8b received
2024-09-20 12:35:54,593 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,611 Request with ID bcd160ab for model llama3-8b received
2024-09-20 12:35:54,612 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,790 Request with ID bbc7c028 for model gemma-7b received
2024-09-20 12:35:54,790 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,800 Request with ID 85e27585 for model llama3-8b received
2024-09-20 12:35:54,801 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,934 Request with ID 5da942ee for model gemma-7b received
2024-09-20 12:35:54,934 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,937 Request with ID 447a58cc for model gemma-7b received
2024-09-20 12:35:54,938 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,981 Request with ID 977eaafb for model llama3-8b received
2024-09-20 12:35:54,982 127.0.0.1 - - [20/Sep/2024 12:35:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:54,999 Request with ID a1d581e0 for model llama3-8b received
2024-09-20 12:35:55,000 127.0.0.1 - - [20/Sep/2024 12:35:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:55,085 Request with ID a78013e8 for model llama3-8b received
2024-09-20 12:35:55,085 127.0.0.1 - - [20/Sep/2024 12:35:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:55,134 Request with ID dab1cb63 for model gemma-7b received
2024-09-20 12:35:55,134 127.0.0.1 - - [20/Sep/2024 12:35:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:55,373 Request with ID a8ddc214 for model granite-7b received
2024-09-20 12:35:55,374 127.0.0.1 - - [20/Sep/2024 12:35:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:55,557 Request with ID e0a288dc for model llama3-8b received
2024-09-20 12:35:55,558 127.0.0.1 - - [20/Sep/2024 12:35:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:55,912 Request with ID b007f4c0 for model granite-7b received
2024-09-20 12:35:55,912 127.0.0.1 - - [20/Sep/2024 12:35:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:55,996 Request with ID fc764014 for model llama3-8b received
2024-09-20 12:35:55,997 127.0.0.1 - - [20/Sep/2024 12:35:55] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:56,338 Request with ID 88879e66 for model llama3-8b received
2024-09-20 12:35:56,339 127.0.0.1 - - [20/Sep/2024 12:35:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:56,539 Request with ID ca79055a for model llama3-8b received
2024-09-20 12:35:56,539 127.0.0.1 - - [20/Sep/2024 12:35:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:56,666 Request with ID 20ce5b24 for model gemma-7b received
2024-09-20 12:35:56,666 127.0.0.1 - - [20/Sep/2024 12:35:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:56,681 Request with ID 7aa8f8e5 for model llama3-8b received
2024-09-20 12:35:56,682 127.0.0.1 - - [20/Sep/2024 12:35:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:56,796 Request with ID bcd0525e for model llama3-8b received
2024-09-20 12:35:56,797 127.0.0.1 - - [20/Sep/2024 12:35:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:56,909 Request with ID c2a189d4 for model gemma-7b received
2024-09-20 12:35:56,910 127.0.0.1 - - [20/Sep/2024 12:35:56] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:57,010 Request with ID d26f8be8 for model llama3-8b received
2024-09-20 12:35:57,010 127.0.0.1 - - [20/Sep/2024 12:35:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:57,412 Request with ID 467b5aad for model gemma-7b received
2024-09-20 12:35:57,413 127.0.0.1 - - [20/Sep/2024 12:35:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:57,430 Request with ID ea4fc5f6 for model granite-7b received
2024-09-20 12:35:57,431 127.0.0.1 - - [20/Sep/2024 12:35:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:57,482 Request with ID 9e65bd23 for model gemma-7b received
2024-09-20 12:35:57,482 127.0.0.1 - - [20/Sep/2024 12:35:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:57,581 Request with ID 88a38398 for model llama3-8b received
2024-09-20 12:35:57,581 127.0.0.1 - - [20/Sep/2024 12:35:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:57,633 Request with ID 8e72ad4c for model gemma-7b received
2024-09-20 12:35:57,634 127.0.0.1 - - [20/Sep/2024 12:35:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:57,678 Request with ID 064fa296 for model llama3-8b received
2024-09-20 12:35:57,679 Batch size condition met for model llama3-8b
2024-09-20 12:35:57,797 Request with ID fdbff03e for model gemma-7b received
2024-09-20 12:35:57,797 127.0.0.1 - - [20/Sep/2024 12:35:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:57,845 Request with ID 567e4f83 for model llama3-8b received
2024-09-20 12:35:57,846 127.0.0.1 - - [20/Sep/2024 12:35:57] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:57,979 Request with ID a7324f2a for model gemma-7b received
2024-09-20 12:35:57,980 Batch size condition met for model gemma-7b
2024-09-20 12:35:58,035 Request with ID 9403b22b for model llama3-8b received
2024-09-20 12:35:58,035 127.0.0.1 - - [20/Sep/2024 12:35:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:58,501 Request with ID 9a3bc9a0 for model gemma-7b received
2024-09-20 12:35:58,502 127.0.0.1 - - [20/Sep/2024 12:35:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:58,559 Request with ID ebee8fc7 for model granite-7b received
2024-09-20 12:35:58,559 127.0.0.1 - - [20/Sep/2024 12:35:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:58,620 Request with ID 38616520 for model gemma-7b received
2024-09-20 12:35:58,621 127.0.0.1 - - [20/Sep/2024 12:35:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:58,977 Request with ID eb4fde19 for model llama3-8b received
2024-09-20 12:35:58,977 127.0.0.1 - - [20/Sep/2024 12:35:58] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:59,060 Request with ID dd09796d for model llama3-8b received
2024-09-20 12:35:59,060 127.0.0.1 - - [20/Sep/2024 12:35:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:59,103 Request with ID 39a11a23 for model llama3-8b received
2024-09-20 12:35:59,104 127.0.0.1 - - [20/Sep/2024 12:35:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:59,240 Request with ID 2ca0bb39 for model gemma-7b received
2024-09-20 12:35:59,241 127.0.0.1 - - [20/Sep/2024 12:35:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:59,350 Request with ID c9f8a0d8 for model gemma-7b received
2024-09-20 12:35:59,351 127.0.0.1 - - [20/Sep/2024 12:35:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:59,443 Request with ID 392eba94 for model granite-7b received
2024-09-20 12:35:59,444 127.0.0.1 - - [20/Sep/2024 12:35:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:59,748 Request with ID e406ba7b for model llama3-8b received
2024-09-20 12:35:59,748 127.0.0.1 - - [20/Sep/2024 12:35:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:59,810 Request with ID 11eadb34 for model llama3-8b received
2024-09-20 12:35:59,811 127.0.0.1 - - [20/Sep/2024 12:35:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:35:59,935 Request with ID 3f374740 for model gemma-7b received
2024-09-20 12:35:59,936 127.0.0.1 - - [20/Sep/2024 12:35:59] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:00,050 Request with ID f7ab6fa4 for model llama3-8b received
2024-09-20 12:36:00,050 127.0.0.1 - - [20/Sep/2024 12:36:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:00,139 Request with ID 93ae7468 for model gemma-7b received
2024-09-20 12:36:00,139 127.0.0.1 - - [20/Sep/2024 12:36:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:00,232 Request with ID 8b8da9f9 for model gemma-7b received
2024-09-20 12:36:00,232 127.0.0.1 - - [20/Sep/2024 12:36:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:00,245 Request with ID 78c69703 for model gemma-7b received
2024-09-20 12:36:00,245 127.0.0.1 - - [20/Sep/2024 12:36:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:00,539 Request with ID 571e5993 for model llama3-8b received
2024-09-20 12:36:00,541 Request with ID 4ece03ef for model llama3-8b received
2024-09-20 12:36:00,541 127.0.0.1 - - [20/Sep/2024 12:36:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:00,542 127.0.0.1 - - [20/Sep/2024 12:36:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:00,663 Request with ID f5c5ebac for model granite-7b received
2024-09-20 12:36:00,663 127.0.0.1 - - [20/Sep/2024 12:36:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:00,763 Request with ID e09c39fd for model llama3-8b received
2024-09-20 12:36:00,763 127.0.0.1 - - [20/Sep/2024 12:36:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:00,794 Request with ID c4a5f3a7 for model llama3-8b received
2024-09-20 12:36:00,795 127.0.0.1 - - [20/Sep/2024 12:36:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:00,847 Request with ID 1da2219d for model gemma-7b received
2024-09-20 12:36:00,847 127.0.0.1 - - [20/Sep/2024 12:36:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:00,961 Request with ID 35910a57 for model llama3-8b received
2024-09-20 12:36:00,961 127.0.0.1 - - [20/Sep/2024 12:36:00] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:01,031 Request with ID 14379aeb for model llama3-8b received
2024-09-20 12:36:01,032 127.0.0.1 - - [20/Sep/2024 12:36:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:01,041 Request with ID c0762b0e for model llama3-8b received
2024-09-20 12:36:01,042 127.0.0.1 - - [20/Sep/2024 12:36:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:01,101 Request with ID 797cb959 for model llama3-8b received
2024-09-20 12:36:01,101 Batch size condition met for model llama3-8b
2024-09-20 12:36:01,232 Request with ID 6e2622a4 for model gemma-7b received
2024-09-20 12:36:01,232 127.0.0.1 - - [20/Sep/2024 12:36:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:01,313 Request with ID 03fdb153 for model gemma-7b received
2024-09-20 12:36:01,314 127.0.0.1 - - [20/Sep/2024 12:36:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:01,439 Request with ID 25272f6f for model gemma-7b received
2024-09-20 12:36:01,440 127.0.0.1 - - [20/Sep/2024 12:36:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:01,653 Request with ID cf726599 for model llama3-8b received
2024-09-20 12:36:01,653 127.0.0.1 - - [20/Sep/2024 12:36:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:01,656 Request with ID bf8800a4 for model granite-7b received
2024-09-20 12:36:01,656 127.0.0.1 - - [20/Sep/2024 12:36:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:01,664 Request with ID 8ba2dc28 for model granite-7b received
2024-09-20 12:36:01,664 127.0.0.1 - - [20/Sep/2024 12:36:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:01,728 Request with ID 99db6099 for model llama3-8b received
2024-09-20 12:36:01,729 127.0.0.1 - - [20/Sep/2024 12:36:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:01,821 Request with ID 75215106 for model llama3-8b received
2024-09-20 12:36:01,822 127.0.0.1 - - [20/Sep/2024 12:36:01] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,005 Request with ID 864fca7e for model gemma-7b received
2024-09-20 12:36:02,006 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,075 Request with ID 34ceefac for model llama3-8b received
2024-09-20 12:36:02,076 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,107 Request with ID 33e00e35 for model llama3-8b received
2024-09-20 12:36:02,107 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,114 Request with ID 184b29ae for model llama3-8b received
2024-09-20 12:36:02,115 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,138 Request with ID 2c35365d for model gemma-7b received
2024-09-20 12:36:02,139 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,186 Request with ID 0b8d1d3b for model llama3-8b received
2024-09-20 12:36:02,186 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,189 Request with ID f66f9632 for model llama3-8b received
2024-09-20 12:36:02,189 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,293 Request with ID ca2bdfc8 for model llama3-8b received
2024-09-20 12:36:02,294 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,353 Request with ID 74ebedb2 for model llama3-8b received
2024-09-20 12:36:02,354 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,360 Request with ID fb9131ce for model gemma-7b received
2024-09-20 12:36:02,360 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,421 Request with ID 117ce472 for model gemma-7b received
2024-09-20 12:36:02,422 Batch size condition met for model gemma-7b
2024-09-20 12:36:02,493 Request with ID 3b147ad6 for model llama3-8b received
2024-09-20 12:36:02,493 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,756 Request with ID 4b6d025d for model llama3-8b received
2024-09-20 12:36:02,757 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,759 Request with ID 6a180e7b for model gemma-7b received
2024-09-20 12:36:02,759 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,776 Request with ID 4881f48f for model llama3-8b received
2024-09-20 12:36:02,777 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:02,933 Request with ID 567dc60a for model llama3-8b received
2024-09-20 12:36:02,934 127.0.0.1 - - [20/Sep/2024 12:36:02] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:03,081 Loaded model llama3-8b
2024-09-20 12:36:03,084 Request with ID 52d23bd2 for model llama3-8b received
2024-09-20 12:36:03,084 127.0.0.1 - - [20/Sep/2024 12:36:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:03,087 Batch processing started for model llama3-8b
2024-09-20 12:36:03,228 Request with ID 772542aa for model gemma-7b received
2024-09-20 12:36:03,228 127.0.0.1 - - [20/Sep/2024 12:36:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:03,259 Request with ID 8cc0b433 for model llama3-8b received
2024-09-20 12:36:03,259 Batch size condition met for model llama3-8b
2024-09-20 12:36:03,305 Request with ID 27e171bb for model llama3-8b received
2024-09-20 12:36:03,306 127.0.0.1 - - [20/Sep/2024 12:36:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:03,464 Request with ID 40cac42e for model gemma-7b received
2024-09-20 12:36:03,464 127.0.0.1 - - [20/Sep/2024 12:36:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:03,631 Request with ID 490deea3 for model llama3-8b received
2024-09-20 12:36:03,631 127.0.0.1 - - [20/Sep/2024 12:36:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:03,678 Request with ID 9e8e068b for model llama3-8b received
2024-09-20 12:36:03,678 127.0.0.1 - - [20/Sep/2024 12:36:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:03,890 Request with ID 07006fd6 for model llama3-8b received
2024-09-20 12:36:03,890 127.0.0.1 - - [20/Sep/2024 12:36:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:03,898 Request with ID b7df4727 for model llama3-8b received
2024-09-20 12:36:03,898 127.0.0.1 - - [20/Sep/2024 12:36:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:03,922 Request with ID 8afacf44 for model llama3-8b received
2024-09-20 12:36:03,922 127.0.0.1 - - [20/Sep/2024 12:36:03] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:04,119 Request with ID babced9e for model llama3-8b received
2024-09-20 12:36:04,120 127.0.0.1 - - [20/Sep/2024 12:36:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:04,174 Request with ID 7ba9c964 for model llama3-8b received
2024-09-20 12:36:04,174 127.0.0.1 - - [20/Sep/2024 12:36:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:04,231 Request with ID b9b326f9 for model llama3-8b received
2024-09-20 12:36:04,232 127.0.0.1 - - [20/Sep/2024 12:36:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:04,365 Request with ID efc39143 for model gemma-7b received
2024-09-20 12:36:04,366 127.0.0.1 - - [20/Sep/2024 12:36:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:04,374 Request with ID b24a4b20 for model llama3-8b received
2024-09-20 12:36:04,374 127.0.0.1 - - [20/Sep/2024 12:36:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:04,508 Request with ID 1a9ff4b5 for model gemma-7b received
2024-09-20 12:36:04,508 127.0.0.1 - - [20/Sep/2024 12:36:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:04,552 Request with ID ab240ac8 for model gemma-7b received
2024-09-20 12:36:04,553 127.0.0.1 - - [20/Sep/2024 12:36:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:04,629 Request with ID fa75cac9 for model gemma-7b received
2024-09-20 12:36:04,629 127.0.0.1 - - [20/Sep/2024 12:36:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:04,769 Request with ID b5ceb7b9 for model llama3-8b received
2024-09-20 12:36:04,769 127.0.0.1 - - [20/Sep/2024 12:36:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:04,851 Request with ID 10819d85 for model llama3-8b received
2024-09-20 12:36:04,852 127.0.0.1 - - [20/Sep/2024 12:36:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:04,906 Request with ID 05f347fb for model gemma-7b received
2024-09-20 12:36:04,906 127.0.0.1 - - [20/Sep/2024 12:36:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:04,977 Request with ID 25a6feeb for model llama3-8b received
2024-09-20 12:36:04,977 127.0.0.1 - - [20/Sep/2024 12:36:04] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:05,064 Request with ID b3610721 for model llama3-8b received
2024-09-20 12:36:05,064 127.0.0.1 - - [20/Sep/2024 12:36:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:05,078 Request with ID 33aac8be for model llama3-8b received
2024-09-20 12:36:05,078 127.0.0.1 - - [20/Sep/2024 12:36:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:05,352 Request with ID ec328d07 for model gemma-7b received
2024-09-20 12:36:05,352 127.0.0.1 - - [20/Sep/2024 12:36:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:05,471 Request with ID 81f5029b for model gemma-7b received
2024-09-20 12:36:05,471 127.0.0.1 - - [20/Sep/2024 12:36:05] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:05,617 Request with ID 2fd7c058 for model llama3-8b received
2024-09-20 12:36:05,617 Batch size condition met for model llama3-8b
2024-09-20 12:36:05,922 Request with ID a13af5f3 for model granite-7b received
2024-09-20 12:36:05,923 Batch size condition met for model granite-7b
2024-09-20 12:36:06,081 Request with ID b7955c6a for model llama3-8b received
2024-09-20 12:36:06,081 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:06,165 Request with ID 708cb3c5 for model llama3-8b received
2024-09-20 12:36:06,165 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:06,196 Request with ID ce6c9c78 for model llama3-8b received
2024-09-20 12:36:06,197 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:06,228 Processed batch: ['0be03145', 'e3e39b8d', '609f4710', '5364968d', '7b43ac24', '54205908', 'b8afb72e', '9dcec750', 'f559f74d', '1e016f56', 'a86e4b7e', 'c4d569c6', 'c80a1dee', 'f7ec8fb6', 'def38f58', '0a49f07f'] with model llama3-8b in 3.1410 seconds
2024-09-20 12:36:06,228 Saving sys info
2024-09-20 12:36:06,262 Latency for request 0be03145 with model llama3-8b: 25.9320 seconds
2024-09-20 12:36:06,262 Saving results with gpu monitoring
2024-09-20 12:36:06,265 Latency for request e3e39b8d with model llama3-8b: 25.8450 seconds
2024-09-20 12:36:06,265 Saving results with gpu monitoring
2024-09-20 12:36:06,267 Latency for request 609f4710 with model llama3-8b: 25.7830 seconds
2024-09-20 12:36:06,267 Saving results with gpu monitoring
2024-09-20 12:36:06,269 Latency for request 5364968d with model llama3-8b: 25.6370 seconds
2024-09-20 12:36:06,269 Saving results with gpu monitoring
2024-09-20 12:36:06,271 Latency for request 7b43ac24 with model llama3-8b: 25.6140 seconds
2024-09-20 12:36:06,271 Saving results with gpu monitoring
2024-09-20 12:36:06,273 Latency for request 54205908 with model llama3-8b: 25.5260 seconds
2024-09-20 12:36:06,273 Saving results with gpu monitoring
2024-09-20 12:36:06,275 Latency for request b8afb72e with model llama3-8b: 25.4520 seconds
2024-09-20 12:36:06,275 Saving results with gpu monitoring
2024-09-20 12:36:06,277 Latency for request 9dcec750 with model llama3-8b: 25.4480 seconds
2024-09-20 12:36:06,277 Saving results with gpu monitoring
2024-09-20 12:36:06,279 Latency for request f559f74d with model llama3-8b: 25.3190 seconds
2024-09-20 12:36:06,279 Saving results with gpu monitoring
2024-09-20 12:36:06,281 Latency for request 1e016f56 with model llama3-8b: 25.2140 seconds
2024-09-20 12:36:06,281 Saving results with gpu monitoring
2024-09-20 12:36:06,283 Latency for request a86e4b7e with model llama3-8b: 25.1800 seconds
2024-09-20 12:36:06,283 Saving results with gpu monitoring
2024-09-20 12:36:06,285 Latency for request c4d569c6 with model llama3-8b: 24.3590 seconds
2024-09-20 12:36:06,285 Saving results with gpu monitoring
2024-09-20 12:36:06,287 Latency for request c80a1dee with model llama3-8b: 24.3530 seconds
2024-09-20 12:36:06,287 Saving results with gpu monitoring
2024-09-20 12:36:06,289 Latency for request f7ec8fb6 with model llama3-8b: 24.2030 seconds
2024-09-20 12:36:06,289 Saving results with gpu monitoring
2024-09-20 12:36:06,291 Latency for request def38f58 with model llama3-8b: 23.9230 seconds
2024-09-20 12:36:06,291 Saving results with gpu monitoring
2024-09-20 12:36:06,293 Latency for request 0a49f07f with model llama3-8b: 23.6060 seconds
2024-09-20 12:36:06,293 Saving results with gpu monitoring
2024-09-20 12:36:06,295 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:06,296 Next: call load_model for gemma-7b
2024-09-20 12:36:06,389 Unloaded previous model
2024-09-20 12:36:06,391 Request with ID c43c6471 for model llama3-8b received
2024-09-20 12:36:06,392 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:06,923 Request with ID c55018fa for model gemma-7b received
2024-09-20 12:36:06,925 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:06,927 Request with ID a0ab673f for model llama3-8b received
2024-09-20 12:36:06,929 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:06,933 Request with ID c57e1629 for model llama3-8b received
2024-09-20 12:36:06,934 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:06,937 Request with ID e0e3c2b7 for model llama3-8b received
2024-09-20 12:36:06,938 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:06,943 Request with ID e05d38dc for model gemma-7b received
2024-09-20 12:36:06,945 Request with ID 34cd8263 for model llama3-8b received
2024-09-20 12:36:06,947 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:06,949 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:06,951 Request with ID 68bab447 for model llama3-8b received
2024-09-20 12:36:06,954 Request with ID 4fa4138c for model llama3-8b received
2024-09-20 12:36:06,957 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:06,958 127.0.0.1 - - [20/Sep/2024 12:36:06] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:07,100 Request with ID 21b883fd for model granite-7b received
2024-09-20 12:36:07,103 127.0.0.1 - - [20/Sep/2024 12:36:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:07,211 Request with ID 8e35d52f for model granite-7b received
2024-09-20 12:36:07,212 127.0.0.1 - - [20/Sep/2024 12:36:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:07,213 Request with ID 7e4c08e1 for model gemma-7b received
2024-09-20 12:36:07,214 127.0.0.1 - - [20/Sep/2024 12:36:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:07,220 Request with ID 4fec48a0 for model granite-7b received
2024-09-20 12:36:07,221 127.0.0.1 - - [20/Sep/2024 12:36:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:07,225 Request with ID 0007030c for model llama3-8b received
2024-09-20 12:36:07,226 127.0.0.1 - - [20/Sep/2024 12:36:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:07,361 Request with ID 5b31be9c for model llama3-8b received
2024-09-20 12:36:07,365 127.0.0.1 - - [20/Sep/2024 12:36:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:07,489 Request with ID edf4cf86 for model granite-7b received
2024-09-20 12:36:07,493 127.0.0.1 - - [20/Sep/2024 12:36:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:07,510 Request with ID 7a14cc10 for model llama3-8b received
2024-09-20 12:36:07,511 127.0.0.1 - - [20/Sep/2024 12:36:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:07,652 Request with ID 29832359 for model llama3-8b received
2024-09-20 12:36:07,653 127.0.0.1 - - [20/Sep/2024 12:36:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:07,668 Request with ID 972faa1e for model llama3-8b received
2024-09-20 12:36:07,670 127.0.0.1 - - [20/Sep/2024 12:36:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:07,799 Request with ID bee20640 for model llama3-8b received
2024-09-20 12:36:07,803 Batch size condition met for model llama3-8b
2024-09-20 12:36:07,916 Request with ID fd4b9cee for model llama3-8b received
2024-09-20 12:36:07,917 127.0.0.1 - - [20/Sep/2024 12:36:07] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:08,073 Request with ID ce1fea9c for model llama3-8b received
2024-09-20 12:36:08,073 127.0.0.1 - - [20/Sep/2024 12:36:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:08,182 Request with ID 2aae66eb for model llama3-8b received
2024-09-20 12:36:08,182 127.0.0.1 - - [20/Sep/2024 12:36:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:08,262 Request with ID 80e0438c for model llama3-8b received
2024-09-20 12:36:08,262 127.0.0.1 - - [20/Sep/2024 12:36:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:08,388 Request with ID f41a6f09 for model gemma-7b received
2024-09-20 12:36:08,388 127.0.0.1 - - [20/Sep/2024 12:36:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:08,416 Request with ID c915c8ec for model llama3-8b received
2024-09-20 12:36:08,416 127.0.0.1 - - [20/Sep/2024 12:36:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:08,622 Request with ID f0774445 for model llama3-8b received
2024-09-20 12:36:08,622 127.0.0.1 - - [20/Sep/2024 12:36:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:08,642 Request with ID 4c0c78f7 for model llama3-8b received
2024-09-20 12:36:08,643 127.0.0.1 - - [20/Sep/2024 12:36:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:08,753 Request with ID 28959c2e for model gemma-7b received
2024-09-20 12:36:08,754 127.0.0.1 - - [20/Sep/2024 12:36:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:08,872 Request with ID 50eefc22 for model llama3-8b received
2024-09-20 12:36:08,873 127.0.0.1 - - [20/Sep/2024 12:36:08] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:09,013 Request with ID 0faa0427 for model gemma-7b received
2024-09-20 12:36:09,013 Batch size condition met for model gemma-7b
2024-09-20 12:36:09,045 Request with ID 08af9f26 for model llama3-8b received
2024-09-20 12:36:09,045 127.0.0.1 - - [20/Sep/2024 12:36:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:09,079 Request with ID 79419fd0 for model llama3-8b received
2024-09-20 12:36:09,080 127.0.0.1 - - [20/Sep/2024 12:36:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:09,111 Request with ID 5d0413d3 for model llama3-8b received
2024-09-20 12:36:09,111 127.0.0.1 - - [20/Sep/2024 12:36:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:09,176 Request with ID 19cce887 for model llama3-8b received
2024-09-20 12:36:09,176 127.0.0.1 - - [20/Sep/2024 12:36:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:09,326 Request with ID 20d73af9 for model gemma-7b received
2024-09-20 12:36:09,326 127.0.0.1 - - [20/Sep/2024 12:36:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:09,351 Request with ID 34a52718 for model llama3-8b received
2024-09-20 12:36:09,351 127.0.0.1 - - [20/Sep/2024 12:36:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:09,573 Request with ID 5c387926 for model llama3-8b received
2024-09-20 12:36:09,573 127.0.0.1 - - [20/Sep/2024 12:36:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:09,577 Request with ID b6062fe1 for model llama3-8b received
2024-09-20 12:36:09,577 127.0.0.1 - - [20/Sep/2024 12:36:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:09,635 Request with ID 77c87067 for model llama3-8b received
2024-09-20 12:36:09,635 Batch size condition met for model llama3-8b
2024-09-20 12:36:09,676 Request with ID 44ce2f12 for model llama3-8b received
2024-09-20 12:36:09,677 127.0.0.1 - - [20/Sep/2024 12:36:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:09,853 Request with ID 37e92e27 for model llama3-8b received
2024-09-20 12:36:09,853 127.0.0.1 - - [20/Sep/2024 12:36:09] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:10,196 Request with ID 222392bf for model llama3-8b received
2024-09-20 12:36:10,196 127.0.0.1 - - [20/Sep/2024 12:36:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:10,237 Request with ID cb5f2c97 for model llama3-8b received
2024-09-20 12:36:10,238 127.0.0.1 - - [20/Sep/2024 12:36:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:10,435 Request with ID 3d3ce2bd for model llama3-8b received
2024-09-20 12:36:10,436 127.0.0.1 - - [20/Sep/2024 12:36:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:10,522 Request with ID 12f89ab4 for model llama3-8b received
2024-09-20 12:36:10,522 127.0.0.1 - - [20/Sep/2024 12:36:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:10,746 Request with ID c30b7bf0 for model llama3-8b received
2024-09-20 12:36:10,747 127.0.0.1 - - [20/Sep/2024 12:36:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:10,748 Request with ID 7da19ae2 for model llama3-8b received
2024-09-20 12:36:10,749 127.0.0.1 - - [20/Sep/2024 12:36:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:10,774 Request with ID e1222a50 for model granite-7b received
2024-09-20 12:36:10,775 127.0.0.1 - - [20/Sep/2024 12:36:10] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:11,026 Request with ID f08c13ba for model gemma-7b received
2024-09-20 12:36:11,026 127.0.0.1 - - [20/Sep/2024 12:36:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:11,040 Request with ID d709730e for model granite-7b received
2024-09-20 12:36:11,040 127.0.0.1 - - [20/Sep/2024 12:36:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:11,322 Request with ID acbee7a4 for model llama3-8b received
2024-09-20 12:36:11,322 127.0.0.1 - - [20/Sep/2024 12:36:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:11,412 Request with ID ebdf4b73 for model llama3-8b received
2024-09-20 12:36:11,412 127.0.0.1 - - [20/Sep/2024 12:36:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:11,555 Request with ID 878c306b for model gemma-7b received
2024-09-20 12:36:11,555 127.0.0.1 - - [20/Sep/2024 12:36:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:11,643 Request with ID f97d8d21 for model gemma-7b received
2024-09-20 12:36:11,644 127.0.0.1 - - [20/Sep/2024 12:36:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:11,690 Request with ID d943629c for model llama3-8b received
2024-09-20 12:36:11,691 127.0.0.1 - - [20/Sep/2024 12:36:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:11,751 Request with ID aa6d71ff for model llama3-8b received
2024-09-20 12:36:11,751 127.0.0.1 - - [20/Sep/2024 12:36:11] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:11,853 Waiting for running processes to finish
2024-09-20 12:36:13,855 Waiting for running processes to finish
2024-09-20 12:36:15,858 Waiting for running processes to finish
2024-09-20 12:36:17,861 Waiting for running processes to finish
2024-09-20 12:36:19,863 Waiting for running processes to finish
2024-09-20 12:36:21,866 Waiting for running processes to finish
2024-09-20 12:36:23,868 Waiting for running processes to finish
2024-09-20 12:36:25,871 Waiting for running processes to finish
2024-09-20 12:36:27,874 Waiting for running processes to finish
2024-09-20 12:36:28,177 Loaded model gemma-7b
2024-09-20 12:36:28,179 Batch processing started for model gemma-7b
2024-09-20 12:36:29,876 Waiting for running processes to finish
2024-09-20 12:36:30,931 Processed batch: ['9a3bc9a0', '38616520', '2ca0bb39', 'c9f8a0d8', '3f374740', '93ae7468', '8b8da9f9', '78c69703', '1da2219d', '6e2622a4', '03fdb153', '25272f6f', '864fca7e', '2c35365d', 'fb9131ce', '117ce472'] with model gemma-7b in 2.7519 seconds
2024-09-20 12:36:30,931 Saving sys info
2024-09-20 12:36:30,963 Latency for request 9a3bc9a0 with model gemma-7b: 32.4300 seconds
2024-09-20 12:36:30,963 Saving results with gpu monitoring
2024-09-20 12:36:30,967 Latency for request 38616520 with model gemma-7b: 32.3110 seconds
2024-09-20 12:36:30,967 Saving results with gpu monitoring
2024-09-20 12:36:30,969 Latency for request 2ca0bb39 with model gemma-7b: 31.6910 seconds
2024-09-20 12:36:30,969 Saving results with gpu monitoring
2024-09-20 12:36:30,971 Latency for request c9f8a0d8 with model gemma-7b: 31.5810 seconds
2024-09-20 12:36:30,971 Saving results with gpu monitoring
2024-09-20 12:36:30,973 Latency for request 3f374740 with model gemma-7b: 30.9960 seconds
2024-09-20 12:36:30,973 Saving results with gpu monitoring
2024-09-20 12:36:30,975 Latency for request 93ae7468 with model gemma-7b: 30.7930 seconds
2024-09-20 12:36:30,975 Saving results with gpu monitoring
2024-09-20 12:36:30,977 Latency for request 8b8da9f9 with model gemma-7b: 30.7000 seconds
2024-09-20 12:36:30,977 Saving results with gpu monitoring
2024-09-20 12:36:30,979 Latency for request 78c69703 with model gemma-7b: 30.6860 seconds
2024-09-20 12:36:30,979 Saving results with gpu monitoring
2024-09-20 12:36:30,981 Latency for request 1da2219d with model gemma-7b: 30.0850 seconds
2024-09-20 12:36:30,981 Saving results with gpu monitoring
2024-09-20 12:36:30,983 Latency for request 6e2622a4 with model gemma-7b: 29.7000 seconds
2024-09-20 12:36:30,983 Saving results with gpu monitoring
2024-09-20 12:36:30,985 Latency for request 03fdb153 with model gemma-7b: 29.6190 seconds
2024-09-20 12:36:30,985 Saving results with gpu monitoring
2024-09-20 12:36:30,987 Latency for request 25272f6f with model gemma-7b: 29.4920 seconds
2024-09-20 12:36:30,987 Saving results with gpu monitoring
2024-09-20 12:36:30,989 Latency for request 864fca7e with model gemma-7b: 28.9260 seconds
2024-09-20 12:36:30,989 Saving results with gpu monitoring
2024-09-20 12:36:30,991 Latency for request 2c35365d with model gemma-7b: 28.7930 seconds
2024-09-20 12:36:30,991 Saving results with gpu monitoring
2024-09-20 12:36:30,993 Latency for request fb9131ce with model gemma-7b: 28.5720 seconds
2024-09-20 12:36:30,993 Saving results with gpu monitoring
2024-09-20 12:36:30,995 Latency for request 117ce472 with model gemma-7b: 28.5100 seconds
2024-09-20 12:36:30,995 Saving results with gpu monitoring
2024-09-20 12:36:30,997 127.0.0.1 - - [20/Sep/2024 12:36:30] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:30,997 Next: call load_model for llama3-8b
2024-09-20 12:36:31,107 Unloaded previous model
2024-09-20 12:36:31,970 Waiting for running processes to finish
2024-09-20 12:36:33,973 Waiting for running processes to finish
2024-09-20 12:36:35,975 Waiting for running processes to finish
2024-09-20 12:36:37,978 Waiting for running processes to finish
2024-09-20 12:36:39,981 Waiting for running processes to finish
2024-09-20 12:36:41,983 Waiting for running processes to finish
2024-09-20 12:36:43,986 Waiting for running processes to finish
2024-09-20 12:36:45,988 Waiting for running processes to finish
2024-09-20 12:36:47,991 Waiting for running processes to finish
2024-09-20 12:36:49,994 Waiting for running processes to finish
2024-09-20 12:36:51,264 Loaded model llama3-8b
2024-09-20 12:36:51,267 Batch processing started for model llama3-8b
2024-09-20 12:36:51,996 Waiting for running processes to finish
2024-09-20 12:36:53,999 Waiting for running processes to finish
2024-09-20 12:36:54,261 Processed batch: ['fd4b9cee', 'ce1fea9c', '2aae66eb', '80e0438c', 'c915c8ec', 'f0774445', '4c0c78f7', '50eefc22', '08af9f26', '79419fd0', '5d0413d3', '19cce887', '34a52718', '5c387926', 'b6062fe1', '77c87067'] with model llama3-8b in 2.9936 seconds
2024-09-20 12:36:54,261 Saving sys info
2024-09-20 12:36:54,295 Latency for request fd4b9cee with model llama3-8b: 46.3450 seconds
2024-09-20 12:36:54,295 Saving results with gpu monitoring
2024-09-20 12:36:54,298 Latency for request ce1fea9c with model llama3-8b: 46.1880 seconds
2024-09-20 12:36:54,298 Saving results with gpu monitoring
2024-09-20 12:36:54,300 Latency for request 2aae66eb with model llama3-8b: 46.0790 seconds
2024-09-20 12:36:54,300 Saving results with gpu monitoring
2024-09-20 12:36:54,302 Latency for request 80e0438c with model llama3-8b: 45.9990 seconds
2024-09-20 12:36:54,302 Saving results with gpu monitoring
2024-09-20 12:36:54,304 Latency for request c915c8ec with model llama3-8b: 45.8450 seconds
2024-09-20 12:36:54,304 Saving results with gpu monitoring
2024-09-20 12:36:54,306 Latency for request f0774445 with model llama3-8b: 45.6390 seconds
2024-09-20 12:36:54,306 Saving results with gpu monitoring
2024-09-20 12:36:54,308 Latency for request 4c0c78f7 with model llama3-8b: 45.6190 seconds
2024-09-20 12:36:54,308 Saving results with gpu monitoring
2024-09-20 12:36:54,310 Latency for request 50eefc22 with model llama3-8b: 45.3890 seconds
2024-09-20 12:36:54,310 Saving results with gpu monitoring
2024-09-20 12:36:54,312 Latency for request 08af9f26 with model llama3-8b: 45.2170 seconds
2024-09-20 12:36:54,312 Saving results with gpu monitoring
2024-09-20 12:36:54,314 Latency for request 79419fd0 with model llama3-8b: 45.1820 seconds
2024-09-20 12:36:54,314 Saving results with gpu monitoring
2024-09-20 12:36:54,316 Latency for request 5d0413d3 with model llama3-8b: 45.1500 seconds
2024-09-20 12:36:54,316 Saving results with gpu monitoring
2024-09-20 12:36:54,318 Latency for request 19cce887 with model llama3-8b: 45.0850 seconds
2024-09-20 12:36:54,318 Saving results with gpu monitoring
2024-09-20 12:36:54,320 Latency for request 34a52718 with model llama3-8b: 44.9100 seconds
2024-09-20 12:36:54,320 Saving results with gpu monitoring
2024-09-20 12:36:54,322 Latency for request 5c387926 with model llama3-8b: 44.6880 seconds
2024-09-20 12:36:54,322 Saving results with gpu monitoring
2024-09-20 12:36:54,324 Latency for request b6062fe1 with model llama3-8b: 44.6850 seconds
2024-09-20 12:36:54,324 Saving results with gpu monitoring
2024-09-20 12:36:54,326 Latency for request 77c87067 with model llama3-8b: 44.6260 seconds
2024-09-20 12:36:54,326 Saving results with gpu monitoring
2024-09-20 12:36:54,329 127.0.0.1 - - [20/Sep/2024 12:36:54] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:36:54,329 Next: call load_model for granite-7b
2024-09-20 12:36:54,433 Unloaded previous model
2024-09-20 12:36:56,002 Waiting for running processes to finish
2024-09-20 12:36:58,004 Waiting for running processes to finish
2024-09-20 12:37:00,007 Waiting for running processes to finish
2024-09-20 12:37:02,009 Waiting for running processes to finish
2024-09-20 12:37:04,012 Waiting for running processes to finish
2024-09-20 12:37:06,014 Waiting for running processes to finish
2024-09-20 12:37:08,017 Waiting for running processes to finish
2024-09-20 12:37:10,020 Waiting for running processes to finish
2024-09-20 12:37:11,292 Loaded model granite-7b
2024-09-20 12:37:11,295 Batch processing started for model granite-7b
2024-09-20 12:37:12,022 Waiting for running processes to finish
2024-09-20 12:37:14,029 Processed batch: ['0542ed48', 'aec97890', '00e0172f', '393c4f03', '4d2e66ff', '51094101', 'e2aa27f2', 'a8ddc214', 'b007f4c0', 'ea4fc5f6', 'ebee8fc7', '392eba94', 'f5c5ebac', 'bf8800a4', '8ba2dc28', 'a13af5f3'] with model granite-7b in 2.7338 seconds
2024-09-20 12:37:14,029 Waiting for running processes to finish
2024-09-20 12:37:14,029 Saving sys info
2024-09-20 12:37:14,061 Latency for request 0542ed48 with model granite-7b: 83.4670 seconds
2024-09-20 12:37:14,061 Saving results with gpu monitoring
2024-09-20 12:37:14,064 Latency for request aec97890 with model granite-7b: 82.7490 seconds
2024-09-20 12:37:14,064 Saving results with gpu monitoring
2024-09-20 12:37:14,066 Latency for request 00e0172f with model granite-7b: 82.4450 seconds
2024-09-20 12:37:14,066 Saving results with gpu monitoring
2024-09-20 12:37:14,068 Latency for request 393c4f03 with model granite-7b: 81.9960 seconds
2024-09-20 12:37:14,068 Saving results with gpu monitoring
2024-09-20 12:37:14,070 Latency for request 4d2e66ff with model granite-7b: 81.2150 seconds
2024-09-20 12:37:14,070 Saving results with gpu monitoring
2024-09-20 12:37:14,072 Latency for request 51094101 with model granite-7b: 80.7620 seconds
2024-09-20 12:37:14,072 Saving results with gpu monitoring
2024-09-20 12:37:14,074 Latency for request e2aa27f2 with model granite-7b: 79.8970 seconds
2024-09-20 12:37:14,074 Saving results with gpu monitoring
2024-09-20 12:37:14,076 Latency for request a8ddc214 with model granite-7b: 78.6550 seconds
2024-09-20 12:37:14,076 Saving results with gpu monitoring
2024-09-20 12:37:14,078 Latency for request b007f4c0 with model granite-7b: 78.1170 seconds
2024-09-20 12:37:14,078 Saving results with gpu monitoring
2024-09-20 12:37:14,080 Latency for request ea4fc5f6 with model granite-7b: 76.5980 seconds
2024-09-20 12:37:14,080 Saving results with gpu monitoring
2024-09-20 12:37:14,082 Latency for request ebee8fc7 with model granite-7b: 75.4700 seconds
2024-09-20 12:37:14,082 Saving results with gpu monitoring
2024-09-20 12:37:14,084 Latency for request 392eba94 with model granite-7b: 74.5850 seconds
2024-09-20 12:37:14,084 Saving results with gpu monitoring
2024-09-20 12:37:14,086 Latency for request f5c5ebac with model granite-7b: 73.3660 seconds
2024-09-20 12:37:14,086 Saving results with gpu monitoring
2024-09-20 12:37:14,088 Latency for request bf8800a4 with model granite-7b: 72.3730 seconds
2024-09-20 12:37:14,088 Saving results with gpu monitoring
2024-09-20 12:37:14,090 Latency for request 8ba2dc28 with model granite-7b: 72.3650 seconds
2024-09-20 12:37:14,090 Saving results with gpu monitoring
2024-09-20 12:37:14,092 Latency for request a13af5f3 with model granite-7b: 68.1060 seconds
2024-09-20 12:37:14,092 Saving results with gpu monitoring
2024-09-20 12:37:14,094 127.0.0.1 - - [20/Sep/2024 12:37:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:37:14,095 No batch to process for model llama3-8b
2024-09-20 12:37:14,095 127.0.0.1 - - [20/Sep/2024 12:37:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:37:14,096 No batch to process for model llama3-8b
2024-09-20 12:37:14,097 127.0.0.1 - - [20/Sep/2024 12:37:14] "POST /inference HTTP/1.1" 200 -
2024-09-20 12:37:14,097 Next: call load_model for gemma-7b
2024-09-20 12:37:14,183 Unloaded previous model
